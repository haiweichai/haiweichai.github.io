<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>人工智能：多头自注意力（Multi-Head Attention）机制</title>
    <url>/AI-Multi-head/</url>
    <content><![CDATA[<p><figure><img src="https://yjucho1.github.io/assets/img/2018-10-13/transformer.png" alt="Multi-Head Attention"><figcaption aria-hidden="true">Multi-Head Attention</figcaption></figure></p>
<p>Self Attention 利用 Q、K、V均为同一个输入向量映射而来的Encoder-Decoder Attention，它可以无视词之间的距离直接计算依赖关系，能够学习一个句子的内部结构，实现也较为简单并且可以并行计算。</p>
<p>Multi-Head Attention同时计算多个Attention，并最终得到合并结果，通过计算多次来捕获不同子空间上的相关信息。</p>
<span id="more"></span>

<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://sungwookyoo.github.io/tips/study/Multihead_Attention/">https://sungwookyoo.github.io/tips/study/Multihead_Attention&#x2F;</a></li>
<li><a href="https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention/">https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention/</a></li>
</ol>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>Multi-Head Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>数据科学：短时傅里叶变换（Short-Time Fourier Transform，STFT）</title>
    <url>/AI-STFT/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUgbg1.png"></p>
<p>The short-time Fourier transform (STFT) is a Fourier-related transform used to determine the sinusoidal frequency and phase content of local sections of a signal as it changes over time. In practice, the procedure for computing STFTs is to divide a longer time signal into shorter segments of equal length and then compute the Fourier transform separately on each shorter segment. This reveals the Fourier spectrum on each shorter segment. One then usually plots the changing spectra as a function of time, known as a spectrogram or waterfall plot, such as commonly used in software defined radio (SDR) based spectrum displays. Full bandwidth displays covering the whole range of an SDR commonly use fast Fourier transforms (FFTs) with $2^24$ points on desktop computers.</p>
<span id="more"></span>]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Data Science</tag>
        <tag>Wigner-Ville Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：梯度累计 GRADIENT_ACCUMULATION_STEPS</title>
    <url>/AI-accumulation_steps/</url>
    <content><![CDATA[<p><code>GRADIENT_ACCUMULATION_STEPS</code>（梯度累积步数）是一种在<strong>不增加显存（VRAM）消耗</strong>的情况下，<strong>模拟出更大批量（Batch Size）训练效果</strong>的关键技术。</p>
<span id="more"></span>
<hr>
<h3 id="一个简单的比喻"><a href="#一个简单的比喻" class="headerlink" title="一个简单的比喻"></a>一个简单的比喻</h3><p>想象一下，你是一个村的村长（<strong>优化器 Optimizer</strong>），需要就一项重大决策（比如修路）征求全村所有家庭（<strong>数据集 Dataset</strong>）的意见。</p>
<ul>
<li><p><strong>理想情况 (大批量训练)</strong>: 你有一个巨大的会议室（<strong>GPU 显存</strong>），可以一次性把所有家庭的代表都请进来，听取所有意见后，当场做出一个非常全面、稳妥的决策（<strong>一次权重更新</strong>）。这是最理想的，因为你的决策基于了最充分的信息。</p>
</li>
<li><p><strong>现实困境 (小批量训练)</strong>: 可惜，你的会议室（<strong>GPU 显存</strong>）很小，一次只能进来 2 个家庭代表（<code>PER_DEVICE_TRAIN_BATCH_SIZE = 2</code>）。</p>
<ul>
<li><strong>常规做法</strong>: 你每听完 2 个家庭的意见，就根据这有限的信息对修路方案做一次微调（一次权重更新）。这样做效率很高，你很快就问遍了全村，但问题是，你的决策可能摇摆不定，因为每次的依据都太片面了，容易被个别家庭的极端意见所左右。</li>
</ul>
</li>
<li><p><strong>梯度累积的智慧</strong>: 你决定换一种方式。你依然一次只请 2 个家庭代表进来，但你听完他们的意见后，<strong>先不决策，只是拿个小本本把意见记下来</strong>。你让他们先回去，再请下一批 2 个家庭… 直到你问询了 32 批（<code>GRADIENT_ACCUMULATION_STEPS = 32</code>）代表，总共听取了 <code>2 * 32 = 64</code> 个家庭的意见后，你看着写满了意见的小本本，综合所有信息，做出了一次<strong>最终的、稳妥的决策（一次权重更新）</strong>。</p>
</li>
</ul>
<p>在这个比喻中：</p>
<ul>
<li><strong>家庭代表的数量</strong> 就是 <code>PER_DEVICE_TRAIN_BATCH_SIZE</code>。</li>
<li><strong>小本本</strong> 就是累积的梯度。</li>
<li><strong>你决定问询多少批代表再做决策</strong>，这个“批数”就是 <code>GRADIENT_ACCUMULATION_STEPS</code>。</li>
</ul>
<hr>
<h3 id="技术原理详解"><a href="#技术原理详解" class="headerlink" title="技术原理详解"></a>技术原理详解</h3><p>在标准的神经网络训练中，一个训练步骤（step）包含以下过程：</p>
<ol>
<li><strong>前向传播</strong>: 输入一个批次的数据，模型计算出预测结果和损失（loss）。</li>
<li><strong>后向传播</strong>: 根据损失计算出每个参数的梯度（gradient），即参数应该调整的方向。</li>
<li><strong>优化器步骤</strong>: 优化器（如 AdamW）根据梯度来更新模型的权重。</li>
<li><strong>清空梯度</strong>: 为下一次计算做准备。</li>
</ol>
<p>而当使用梯度累积时，这个过程发生了变化：</p>
<p><strong>对于第 1 到 <code>N-1</code> 步 (N &#x3D; <code>GRADIENT_ACCUMULATION_STEPS</code>)</strong>:</p>
<ol>
<li><strong>前向传播</strong>: 正常执行。</li>
<li><strong>后向传播</strong>: 正常执行，计算出当前“微批次 (micro-batch)”的梯度。</li>
<li><strong>关键区别</strong>: <strong>跳过“优化器步骤”</strong>。我们不立即更新权重，而是让梯度<strong>累积</strong>在模型的 <code>.grad</code> 属性中。同时，我们也不清空梯度。</li>
</ol>
<p><strong>对于第 <code>N</code> 步</strong>:</p>
<ol>
<li><strong>前向传播</strong>: 正常执行。</li>
<li><strong>后向传播</strong>: 正常执行，计算出第 <code>N</code> 个微批次的梯度，并将其<strong>加到</strong>之前已经累积的梯度上。</li>
<li><strong>执行“优化器步骤”</strong>: 优化器使用<strong>累积了 N 步的总梯度</strong>来对模型权重进行<strong>一次</strong>更新。</li>
<li><strong>清空梯度</strong>: 更新完成后，将梯度清零，准备开始下一个累积周期。</li>
</ol>
<p>这样一来，虽然硬件上每次只处理了一个小批量，但参数的更新却是基于多个小批量梯度的总和，从而在数学效果上<strong>模拟了一个大批量</strong>的训练。</p>
<h4 id="核心公式"><a href="#核心公式" class="headerlink" title="核心公式"></a>核心公式</h4><p><code>有效批量大小 (Effective Batch Size) = PER_DEVICE_TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS * GPU数量</code></p>
<p>例如，在单张 A100 上，即使你的 <code>PER_DEVICE_TRAIN_BATCH_SIZE</code> 因为显存限制只能设为 <code>2</code>，但只要将 <code>GRADIENT_ACCUMULATION_STEPS</code> 设为 <code>32</code>，你就能达到 <code>2 * 32 = 64</code> 的有效批量大小。</p>
<hr>
<h3 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h3><h4 id="优点-Pros"><a href="#优点-Pros" class="headerlink" title="优点 (Pros)"></a>优点 (Pros)</h4><ol>
<li><strong>突破显存限制</strong>: 这是其最核心的优点。它允许我们在有限的硬件资源上训练需要大批量才能稳定收敛的超大型模型。</li>
<li><strong>训练过程更稳定</strong>: 更大的有效批量意味着每次权重更新所依据的梯度方向更准确、噪声更小，这使得整个训练过程更加平稳，允许你使用更高的学习率。</li>
<li><strong>可能提升模型性能</strong>: 稳定的训练过程和更准确的梯度方向，有助于模型找到更好的局部最小值，从而可能提升最终的泛化能力。</li>
</ol>
<h4 id="缺点-Cons"><a href="#缺点-Cons" class="headerlink" title="缺点 (Cons)"></a>缺点 (Cons)</h4><ol>
<li><strong>训练时间变长 (Wall-clock Time)</strong>: 这是最大的代价。虽然模拟了大批量，但计算过程仍然是串行的。权重更新的频率降低了，完成一个 epoch 所需的实际时间会相应增加。例如，累积32步才更新一次，意味着权重更新的频率是原来的 1&#x2F;32，完成一个 epoch 的总时间大约会是原来的数倍（具体取决于数据加载等其他开销）。</li>
<li><strong>对特定层（如 BatchNorm）的影响</strong>: 对于包含批归一化（Batch Normalization）层的模型，梯度累积可能会带来问题。因为 <code>BatchNorm</code> 是在每个微批次上计算均值和方差的，而不是在整个“有效批量”上。这可能导致训练和推理时的统计数据不匹配。不过，现代大型语言模型（LLM）大多使用 Layer Normalization 或 RMS Normalization，它们不受批量大小的影响，因此这个问题在 LLM 训练中基本不存在。</li>
</ol>
<p><strong>总结</strong>: <code>GRADIENT_ACCUMULATION_STEPS</code> 是一种典型的 <strong>用时间换显存</strong>的策略。它是大规模模型训练中不可或缺的利器，使得个人或小型机构在有限的硬件条件下训练强大的模型成为可能。</p>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>GRADIENT_ACCUMULATION_STEPS</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：语言大模型训练与部署流程</title>
    <url>/AI-Gemma/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUAupF.png"></p>
<p>Gemini是Google开发的一款多模态大模型，能够处理文本、图像、音频、视频和代码等信息。目前推出的Gemini模型分为Nano、Pro、Ultra以及1.5Pro，这些模型都可以在谷歌网站上进行访问：<a href="https://gemini.google.com/">https://gemini.google.com</a> 。此外，谷歌还提供了<a href="https://ai.google.dev/gemini-api/docs/models/gemini?hl=zh-cn">Gemini模型的API</a>，可在代码中调用模型，输入文本和图片然后，输出文本回复，以及一款<a href="https://www.kaggle.com/models/google/gemma">开源大语言模型gemma</a>，该模型基于Gemini的研究和技术开发，能处理文本信息。模型有2b和7b两种参数规模以及经过指令调优（2b-it &amp; 7b-it）和未调优的基础模型等版本，可通过多种框架构建：Keras、Pytorch、Transformers、Gemma C++、TensorRT-LLM、TensorFlow Lite、MaxText、Pax、Flax。感谢我过去的学生 Weizheng Wang, Hui Wu 对本文的贡献。</p>
<span id="more"></span>

<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="配置-CentOS-Stream-10"><a href="#配置-CentOS-Stream-10" class="headerlink" title="配置 CentOS Stream 10"></a>配置 CentOS Stream 10</h3><p>本文选用 CentOS Stream 10 操作系统，内核版本 6.12.0，并配置网络环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -r                        <span class="comment"># 查看内核版本</span></span></span><br><span class="line">6.12.0-89.el10.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum --exclude=kernel* update    <span class="comment"># 禁用 yum update，避免 kernel 更新导致的生产环境不稳定风险</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nmcli connection show</span></span><br><span class="line">NAME       UUID                                  TYPE      DEVICE</span><br><span class="line">enp0s31f6  52eaa752-25be-451f-a8c1-4037030e4cb4  ethernet  enp0s31f6</span><br><span class="line">lo         4d717253-e93b-404c-9487-38d706cb9308  loopback  lo</span><br><span class="line">enp2s0     7ef8d2c6-cd0a-3123-9fef-4218782fcf1b  ethernet  --</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/NetworkManager/system-connections/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">su vi enp0s31f6.nmconnection    <span class="comment"># 编辑对应网卡的配置文件</span></span></span><br></pre></td></tr></table></figure>

<p>编辑 enp031f6.connection 文件，示例信息如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[connection]</span><br><span class="line">id=enp0s31f6</span><br><span class="line">uuid=52eaa752-25be-451f-a8c1-4037030e4cb4</span><br><span class="line">type=ethernet</span><br><span class="line">autoconnect-priority=-999</span><br><span class="line">interface-name=enp0s31f6</span><br><span class="line">timestamp=1748939249</span><br><span class="line"></span><br><span class="line">[ethernet]</span><br><span class="line"></span><br><span class="line">[ipv4]</span><br><span class="line">address1=192.168.0.125/24</span><br><span class="line">dns=192.168.0.1;</span><br><span class="line">gateway=192.168.0.1</span><br><span class="line">method=manual</span><br><span class="line"></span><br><span class="line">[ipv6]</span><br><span class="line">addr-gen-mode=eui64</span><br><span class="line">method=auto</span><br><span class="line"></span><br><span class="line">[proxy]</span><br></pre></td></tr></table></figure>

<p>修改完成后重新启动网络服务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ systemctl restart NetworkManager</span><br><span class="line">$ nmcli c reload                           # 重新加载配置文件</span><br><span class="line">$ nmcli c up enp031f6                      # 重启ens33网卡</span><br><span class="line"></span><br><span class="line">$ ping www.baidu.com -c4                   # 验证网络连接</span><br><span class="line">PING www.a.shifen.com (39.156.66.14) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=1 ttl=50 time=38.5 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=2 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=3 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=4 ttl=50 time=38.2 ms</span><br></pre></td></tr></table></figure>

<p>配置硬盘分区永久挂载：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsblk   <span class="comment"># 查看磁盘硬件</span></span></span><br><span class="line">NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sda           8:0    0 21.8T  0 disk /mnt/disk1</span><br><span class="line">sdb           8:16   0 14.6T  0 disk /mnt/disk0</span><br><span class="line">sdc           8:32   0 21.8T  0 disk /mnt/disk2</span><br><span class="line">nvme0n1     259:0    0  1.8T  0 disk</span><br><span class="line">├─nvme0n1p1 259:1    0  600M  0 part /boot/efi</span><br><span class="line">                    ...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">fdisk /dev/sda                <span class="comment"># 修改该磁盘中的分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mkfs.ext4 /dev/sda            <span class="comment"># 按 ext4 文件系统格式化分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /mnt/mydrive            <span class="comment"># 创建挂载路径</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount /dev/sda /mnt/mydrive   <span class="comment"># 临时挂载该分区</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">blkid /dev/sda                <span class="comment"># 查看该磁盘的UUID与文件系统格式</span></span></span><br><span class="line">/dev/sda: UUID=&quot;E600-A571&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;exfat&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/fstab                 <span class="comment"># 修改 /etc/fstab 文件永久挂载磁盘</span></span></span><br><span class="line">UUID=04c21771-726f-42d0-a7d3-34f4b5cd88ab /                 xfs     defaults        0 0</span><br><span class="line">UUID=246017ac-59da-4dd2-9493-dbcba61a2958 /boot             xfs     defaults        0 0</span><br><span class="line">UUID=AD2B-E205                            /boot/efi         vfat    umask=0077,shortname=winnt 0 2</span><br><span class="line">UUID=35b358b4-d3c7-443f-866d-8db5d364a46b /home             xfs     defaults        0 0</span><br><span class="line">UUID=521947e5-c326-4436-9e2d-26a148d8f42f none              swap    defaults        0 0</span><br><span class="line">UUID=40948978-7d0f-4e63-9feb-ffa7ab03f2a4 /mnt/disk0        ext4    defaults        0 0</span><br><span class="line">UUID=E600-A571                            /mnt/disk1        exfat   defaults        0 0</span><br><span class="line">UUID=C839-78EB                            /mnt/disk2        exfat   defaults        0 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload        <span class="comment"># 修改 fstab 文件后重启 daemon</span></span></span><br></pre></td></tr></table></figure>

<p>为用户名为 hwchai 的普通用户创建 Ed25519 密钥：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ su hwchai                                              # 切换到 hwchai</span><br><span class="line">$ ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519             # 创建 Ed25519 密钥</span><br><span class="line">$ chmod 700 ~/.ssh</span><br><span class="line">$ chmod 600 ~/.ssh/id_ed25519</span><br><span class="line">$ chmod 644 ~/.ssh/id_ed25519.pub                        # 设置正确的权限</span><br><span class="line">$ cat ~/.ssh/id_ed25519.pub &gt;&gt; ~/.ssh/authorized_keys    # 将公钥加入到自己的 authorized_keys 中</span><br><span class="line">$ chmod 600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">$ su vi /etc/ssh/sshd_config                             # 回到 root 账号并编辑 ssh 配置文件</span><br><span class="line">PubkeyAuthentication yes                                 # 启用公钥认证</span><br><span class="line">PasswordAuthentication no                                # 禁用密码登录（提高安全性）</span><br><span class="line">PermitRootLogin prohibit-password                        # root 仅允许密钥登录</span><br><span class="line"></span><br><span class="line">$ systemctl restart sshd</span><br></pre></td></tr></table></figure>

<h3 id="安装-Nvidia-Driver-CUDA-及-cuDNN-环境"><a href="#安装-Nvidia-Driver-CUDA-及-cuDNN-环境" class="headerlink" title="安装 Nvidia Driver, CUDA 及 cuDNN 环境"></a>安装 Nvidia Driver, CUDA 及 cuDNN 环境</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum update -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install pciutils                                <span class="comment"># 使用 yum install pciutils 安装 lspci 工具</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lspci | grep -i nvidia                              <span class="comment"># 检查显卡连接状态</span></span></span><br><span class="line">16:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">34:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ac:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ca:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y gcc kernel-devel kernel-headers     <span class="comment"># 安装编译环境和内核开发包，确保与当前内核版本相匹配</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install <span class="string">&quot;kernel-devel-uname-r == <span class="subst">$(uname -r)</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/selinux/config         <span class="comment"># 修改SELINUX=disabled。保存退出</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">setenforce 0                   <span class="comment"># 临时关闭selinux</span></span></span><br></pre></td></tr></table></figure>

<h4 id="安装-Nvidia-driver"><a href="#安装-Nvidia-driver" class="headerlink" title="安装 Nvidia driver"></a>安装 Nvidia driver</h4><p>禁用 Linux 默认的显示驱动 nouveau：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep nouveau          <span class="comment"># 该命令若无输出，则跳过以下步骤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /lib/modprobe.d/dist-blacklist.conf</span> </span><br></pre></td></tr></table></figure>

<p>编辑 &#x2F;lib&#x2F;modprobe.d&#x2F;dist-blacklist.conf 文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># blacklist nvidiafb                 # 注释掉 blacklist nvidiafb</span><br><span class="line">blacklist nouveau                    # 文件末尾添加：blacklist nouveau</span><br><span class="line">options nouveau modeset=0            # 文件末尾添加：options nouveau modeset=0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">$ dracut /boot/initramfs-$(uname -r).img $(uname -r)             # 重建 initramfs image 镜像</span><br><span class="line">$ systemctl set-default multi-user.target                        # 修改运行模式为文本模式 </span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line">$ lsmod | grep nouveau                                           # 该命令若无输出，表示禁用 nouveau 成功</span><br></pre></td></tr></table></figure>

<p>在<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">Nvidia driver download</a>根据GPU型号及操作系统选择相应的驱动程序下载至本地后安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nvidia-smi                <span class="comment"># 查看 Nvidia GPU 实时信息，验证 Nvidia driver</span></span></span><br><span class="line">Thu Jun  5 22:19:43 2025</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA A100 80GB PCIe          Off |   00000000:16:00.0 Off |                    0 |</span><br><span class="line">| N/A   28C    P0             62W /  300W |       0MiB /  81920MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line"></span><br><span class="line">                                        ......</span><br></pre></td></tr></table></figure>

<h4 id="安装-CUDA-Toolkit"><a href="#安装-CUDA-Toolkit" class="headerlink" title="安装 CUDA Toolkit"></a>安装 CUDA Toolkit</h4><p>在<a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">CUDA Toolkit 12.9 Downloads</a>中下载 CUDA 工具包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cuda/12.9.0/local_installers/cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ rpm -i cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cuda-toolkit-12-9</span><br><span class="line"></span><br><span class="line">$ echo &#x27;export PATH=/usr/local/cuda/bin:$PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ echo &#x27;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ source ~/.bashrc</span><br><span class="line">$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2025 NVIDIA Corporation</span><br><span class="line">Built on Wed_Apr__9_19:24:57_PDT_2025</span><br><span class="line">Cuda compilation tools, release 12.9, V12.9.41</span><br><span class="line">Build cuda_12.9.r12.9/compiler.35813241_0</span><br></pre></td></tr></table></figure>

<h4 id="安装-cuDNN"><a href="#安装-cuDNN" class="headerlink" title="安装 cuDNN"></a>安装 cuDNN</h4><p>在<a href="https://developer.nvidia.com/cudnn-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">cuDNN 9.10.1 Downloads</a>中下载 cuDNN 包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cudnn/9.10.1/local_installers/cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ rpm -i cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cudnn</span><br></pre></td></tr></table></figure>

<h4 id="安装Miniconda-3"><a href="#安装Miniconda-3" class="headerlink" title="安装Miniconda 3"></a>安装Miniconda 3</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda --version</span></span><br><span class="line">conda 24.4.0</span><br></pre></td></tr></table></figure>

<h3 id="安装-Pytorch-及-Transformers-等环境"><a href="#安装-Pytorch-及-Transformers-等环境" class="headerlink" title="安装 Pytorch 及 Transformers 等环境"></a>安装 Pytorch 及 Transformers 等环境</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda create -n hwchai python=3.13        <span class="comment"># 环境创建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda activate hwchai                     <span class="comment"># 激活环境</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install torch transformers bitsandbytes tensorboard trl datasets peft</span></span><br></pre></td></tr></table></figure>

<p>查看 Pytorch, CUDA 及 cuDNN 版本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.backends.cudnn.version())</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">2.7</span><span class="number">.1</span>+cu126</span><br><span class="line"><span class="number">12.6</span></span><br><span class="line"><span class="number">90501</span></span><br></pre></td></tr></table></figure>

<p>可能还有包未列出，可按照运行提示安装。</p>
<h3 id="部署-Gemma-训练环境及预训练模型"><a href="#部署-Gemma-训练环境及预训练模型" class="headerlink" title="部署 Gemma 训练环境及预训练模型"></a>部署 Gemma 训练环境及预训练模型</h3><p>注册Kaggle账号，在网站 <a href="https://www.kaggle.com/models/google/gemma">https://www.kaggle.com/models/google/gemma</a> 下载所需模型，配置要求：Python≥3.8，下载模型：</p>
<img src="https://s21.ax1x.com/2024/07/12/pk4n7AP.png" width = 95% div align=center />

<p>官方文档页面： <a href="https://github.com/google/gemma_pytorch">https://github.com/google/gemma_pytorch</a> ，文档中介绍了在Linux下使用docker配置环境并运行模型的方法，但未说明对模型进行调整的操作和对训练集的要求，使用常规Pytorch对NLP模型的训练方式即可。</p>
<p>下载的预训练模型分别存放在<code>/home/ai/gemma-2b</code>及<code>/home/ai/gemma-7b</code>中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-2b</span><br><span class="line">total 14712812</span><br><span class="line">drwxrwxr-x. 2 ai ai        4096 Jun  6 22:49 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--. 1 ai ai         634 Jun  6 22:49 config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai 10031780672 Jun  6 22:49 gemma-2b.gguf</span><br><span class="line">-rw-rw-r--. 1 ai ai         137 Jun  6 22:18 generation_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1620 Jun  6 22:49 .gitattributes</span><br><span class="line">-rw-rw-r--. 1 ai ai  4945242264 Jun  6 22:18 model-00001-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai    67121608 Jun  6 22:02 model-00002-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai       13489 Jun  6 22:02 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--. 1 ai ai         555 Jun  6 22:02 special_tokens_map.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1108 Jun  6 22:02 tokenizer_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai    17477553 Jun  6 22:02 tokenizer.json</span><br><span class="line">-rw-rw-r--. 1 ai ai     4241003 Jun  6 22:02 tokenizer.model</span><br><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-7b</span><br><span class="line">total 50054220</span><br><span class="line">drwxrwxr-x  3 ai ai        4096 Jun 29 06:13 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--  1 ai ai         636 Jun 29 06:13 config.json</span><br><span class="line">drwxrwxr-x  2 ai ai          88 Jun 29 06:13 examples</span><br><span class="line">-rw-rw-r--  1 ai ai 34158344288 Jun 29 06:13 gemma-7b.gguf</span><br><span class="line">-rw-rw-r--  1 ai ai         137 Jun 29 05:25 generation_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1620 Jun 29 06:13 .gitattributes</span><br><span class="line">-rw-rw-r--  1 ai ai  4995496656 Jun 29 05:25 model-00001-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953168 Jun 29 05:18 model-00002-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953200 Jun 29 05:11 model-00003-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  2113988336 Jun 29 05:04 model-00004-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai       20920 Jun 29 05:01 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--  1 ai ai         555 Jun 29 05:01 special_tokens_map.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1108 Jun 29 05:01 tokenizer_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai    17477553 Jun 29 05:01 tokenizer.json</span><br><span class="line">-rw-rw-r--  1 ai ai     4241003 Jun 29 05:01 tokenizer.model</span><br></pre></td></tr></table></figure>

<p>测试数据集保存在另一路径，数据形如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) [root@server01 ~]# less /dataset02/dataset/01.ont.seq/train/Exp001_shanzhu.aozhouhuangjin.raw.fastq.txt</span><br><span class="line">TGCTTCGTTCAGTTACGTATTGCTAAGGTTAAACAGACGACTACAAACTGAATCGACAGCACCTCTTTCTATTATGGTGGACTTTATGTATTATAGTTTTGATTTGTGTATTATGGATTATGGTTGGTTGCTTTGATTTAGCTAGATTATGGATTACTTAGCCTCGTAAAGTGGTATCGATCGAAATGAGTGTAATGGTCGTGATG</span><br><span class="line">ACATTTTGGAGGGTAACATCGATGTTTTGTTTAGATTGTAAAGAAGGGTGCCTATGGTATGTATGAGATGGGGTAAGAAGTGATTTTCTTGAATTGTCCATATTCCAATGTTTGGTTACTTAGTGAAATCGTCGGTGTTGATGCTTACTTGTTTTGTAGAATCATAATGGTGGCTAGC</span><br><span class="line">TACTTCAGTTTCGGTTACGTATTGCTAAGGTTAACAGACGACTACAAAACGGAATCGACAGCACCTTTATTTTGTGTTTGTCGTTGGAGAATTGATCTTTCTTCAATGAAATTTATCTCTAGAATTTATTTGTTGATTAATTTCTAGGTTGAAGAACATAAAGAAATTCATAGATTAAATCCTATCTGAATAACTGGGGCCGATCT</span><br><span class="line">ATGCGGCAATAAAAGGTTAATGATTTGTCTTTAATAAAGTTTATTTAAATCATGTATGATTAACCATGATCAATATAAATTTGGATAGGATTAATGTAATTTGATCGTAAGTACATTAATCAATCAAGATCACTATTTGGCTAGTAAAGGCAACAATTCAATTAGCATATCTATAGAAAATTGTCATATCATTACTTGGTTAAATT</span><br><span class="line">······</span><br></pre></td></tr></table></figure>

<h2 id="Gemma模型导入与配置"><a href="#Gemma模型导入与配置" class="headerlink" title="Gemma模型导入与配置"></a>Gemma模型导入与配置</h2><p>编写脚本，使用transformers加载本地模型和分词器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, PeftModel, prepare_model_for_kbit_training</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line"> AutoModelForCausalLM,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> BitsAndBytesConfig,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> TrainingArguments,</span><br><span class="line"> set_seed</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=<span class="literal">True</span>, use_fast=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.pad_token_id =  tokenizer.eos_token_id</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;left&#x27;</span></span><br><span class="line"></span><br><span class="line">data_files = &#123;<span class="string">&quot;train&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/train1.tsv&quot;</span>, <span class="string">&quot;test&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/dev1.tsv&quot;</span>&#125;</span><br><span class="line">ds = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line"></span><br><span class="line">compute_dtype = <span class="built_in">getattr</span>(torch, <span class="string">&quot;float16&quot;</span>)</span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">     load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">     bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">     bnb_4bit_compute_dtype=compute_dtype,</span><br><span class="line">     bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">       model_path, quantization_config=bnb_config, device_map=&#123;<span class="string">&quot;&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">)</span><br><span class="line">model = prepare_model_for_kbit_training(model)</span><br><span class="line"><span class="comment"># Configure the pad token in the model</span></span><br><span class="line">model.config.pad_token_id = tokenizer.pad_token_id</span><br><span class="line">model.config.use_cache = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 编辑微调配置</span></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">     lora_alpha=<span class="number">16</span>,</span><br><span class="line">     lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">     r=<span class="number">16</span>,</span><br><span class="line">     bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">     task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">     target_modules= [<span class="string">&#x27;k_proj&#x27;</span>, <span class="string">&#x27;q_proj&#x27;</span>, <span class="string">&#x27;v_proj&#x27;</span>, <span class="string">&#x27;o_proj&#x27;</span>, <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 设定训练参数</span></span><br><span class="line">training_arguments = TrainingArguments(</span><br><span class="line">     output_dir=<span class="string">&quot;./results_qlora&quot;</span>,</span><br><span class="line">     evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">     do_eval=<span class="literal">True</span>,</span><br><span class="line">     optim=<span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">     per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">     per_device_eval_batch_size=<span class="number">4</span>,</span><br><span class="line">     log_level=<span class="string">&quot;debug&quot;</span>,</span><br><span class="line">     save_steps=<span class="number">50</span>,</span><br><span class="line">     logging_steps=<span class="number">50</span>,</span><br><span class="line">     learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">     eval_steps=<span class="number">50</span>,</span><br><span class="line">     max_steps=<span class="number">300</span>,</span><br><span class="line">     warmup_steps=<span class="number">30</span>,</span><br><span class="line">     lr_scheduler_type=<span class="string">&quot;linear&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 载入训练配置</span></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">     model=model,</span><br><span class="line">     train_dataset=ds[<span class="string">&#x27;train&#x27;</span>],</span><br><span class="line">     eval_dataset=ds[<span class="string">&#x27;test&#x27;</span>],</span><br><span class="line">     peft_config=peft_config,</span><br><span class="line">     dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">     max_seq_length=<span class="number">128</span>,</span><br><span class="line">     tokenizer=tokenizer,</span><br><span class="line">     args=training_arguments,</span><br><span class="line">)</span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<p>将脚本保存为gemmatrain.py，命令行运行<code>python gemma.train.py</code> ，即可运行。</p>
<p>在上述脚本中导入了tsv格式的文本作为训练和测试集，实际上原始格式的文本并不能直接作为模型的输入，还需将一整行的文本内容（即单个输入输出对）记在同一标签“text”下。如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">text</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br></pre></td></tr></table></figure>

<p>以上格式仅为测试使用，后续会考虑数据集的具体内容和训练需求进行优化。</p>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>Gemini</tag>
      </tags>
  </entry>
  <entry>
    <title>数据科学：离散小波变换（Discrete Wavelet Transformation，DWT）</title>
    <url>/AI-DWT/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUgUjP.png"></p>
<p>The world of signal processing is a fascinating blend of mathematics, engineering, and computer science. From audio to images, and even to more abstract concepts like financial time series, the ability to manipulate and analyze signals is crucial. Among the many tools available to the signal processing engineer, the Wavelet Transform stands out due to its flexibility and adaptability. In this article, we’ll delve deep into the intuition behind wavelets, show practical examples, and provide insightful visualizations using Python.</p>
<span id="more"></span>

<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://www.scicoding.com/introduction-to-wavelet-transform-using-python/">https://www.scicoding.com/introduction-to-wavelet-transform-using-python/</a></li>
<li><a href="https://pywavelets.readthedocs.io/en/latest/ref/dwt-discrete-wavelet-transform.html">https://pywavelets.readthedocs.io/en/latest/ref/dwt-discrete-wavelet-transform.html</a></li>
</ol>
]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Data Science</tag>
        <tag>Discrete Wavelet Transformation</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：Pytorch DataLoader</title>
    <url>/AI-DataLoader/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUyxEQ.png"></p>
<p>PyTorch 数据加载实用程序的核心是 <a href="https://pytorch.ac.cn/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a> 类。它表示数据集上的 Python 可迭代对象，支持：映射式和可迭代式数据集；自定义数据加载顺序；自动批处理；单进程和多进程数据加载；自动内存固定。这些选项由 <code>DataLoader</code> 的构造函数参数配置，其签名为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>,</span><br><span class="line">           batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>,</span><br><span class="line">           pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>,</span><br><span class="line">           worker_init_fn=<span class="literal">None</span>, *, prefetch_factor=<span class="number">2</span>,</span><br><span class="line">           persistent_workers=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>本文将详细介绍了这些选项的效果和用法。内容参考 Pytorch 官方文档：<a href="https://pytorch.org/docs/stable/data.html#module-torch.utils.data">https://pytorch.org/docs/stable/data.html#module-torch.utils.data</a></p>
<span id="more"></span>

<h2 id="数据集类型"><a href="#数据集类型" class="headerlink" title="数据集类型"></a>数据集类型</h2><p><code>DataLoader</code> 构造函数最重要的参数是 dataset，它指示要从中加载数据的 “映射式数据集” 与 “可迭代式数据集”。</p>
<h3 id="映射式数据集"><a href="#映射式数据集" class="headerlink" title="映射式数据集"></a>映射式数据集</h3><p>映射式数据集是实现了 <code>__getitem__()</code> 和 <code>__len__()</code> 协议的数据集，它表示从（可能是非整数）索引&#x2F;键到数据样本的映射。</p>
<p>例如，当使用 <code>dataset[idx]</code> 访问此类数据集时，它可以从磁盘上的文件夹读取第 <code>idx</code> 个图像及其相应的标签文件。有关更多详细信息，请参阅 <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">Dataset</a>。</p>
<h3 id="可迭代式数据集"><a href="#可迭代式数据集" class="headerlink" title="可迭代式数据集"></a>可迭代式数据集</h3><p>可迭代式数据集是 <code>IterableDataset</code> 子类的实例，它实现了 <code>__iter__()</code> 协议，</p>
<p>例如，当调用 <code>iter(dataset)</code> 时，此类数据集可以返回从数据库、远程服务器读取的数据流，甚至是实时生成的日志。有关更多详细信息，请参阅 <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset">IterableDataset</a>。</p>
<p>当使用多进程数据加载的 IterableDataset 时。在每个工作进程上复制相同的数据集对象，因此必须对副本进行不同的配置，以避免重复数据。请参阅 IterableDataset 文档了解如何实现这一点。</p>
<h2 id="数据加载顺序和-Sampler"><a href="#数据加载顺序和-Sampler" class="headerlink" title="数据加载顺序和 Sampler"></a>数据加载顺序和 Sampler</h2><p>对于 可迭代式数据集，数据加载顺序完全由用户定义的可迭代对象控制。</p>
<p>本节的其余部分涉及 映射式数据集 的情况。</p>
<p>基于shuffle参数，DataLoader会自动构建顺序或随机采样器。 另外，用户可以使用sampler参数指定一个自定义的Sampler对象，该对象每次都会生成下一个要获取的索引&#x2F;键。</p>
<p>一个自定义的Sampler，每次生成一个批次索引列表，可以作为batch_sampler参数传递。 也可以通过batch_size和drop_last参数启用自动批处理。 有关详细信息，请参阅下一节。</p>
<p>注意</p>
<p>sampler和batch_sampler都不兼容可迭代数据集，因为此类数据集没有键或索引的概念。</p>
<h2 id="加载批处理和非批处理数据"><a href="#加载批处理和非批处理数据" class="headerlink" title="加载批处理和非批处理数据"></a>加载批处理和非批处理数据</h2><p>DataLoader支持通过参数batch_size、drop_last、batch_sampler和collate_fn（具有默认函数）自动将获取的单个数据样本整理成批次。</p>
<h3 id="自动批处理（默认）"><a href="#自动批处理（默认）" class="headerlink" title="自动批处理（默认）"></a>自动批处理（默认）</h3><p>这是最常见的情况，对应于获取一个数据小批量并将其整理成批处理样本，即包含一个维度为批次维度的张量（通常是第一个）。</p>
<p>当batch_size（默认1）不为None时，数据加载器会生成批处理样本，而不是单个样本。 batch_size和drop_last参数用于指定数据加载器如何获取数据集键的批次。 对于映射式数据集，用户可以另外指定batch_sampler，它每次生成一个键列表。</p>
<p>注意</p>
<p>batch_size和drop_last参数本质上用于从sampler构造batch_sampler。 对于映射式数据集，sampler由用户提供或根据shuffle参数构建。 对于可迭代数据集，sampler是一个虚拟的无限采样器。 有关采样器的更多详细信息，请参阅此节。</p>
<p>注意</p>
<p>当使用多进程从可迭代数据集中获取数据时，drop_last参数会删除每个工作程序的数据集副本的最后一个非满批次。</p>
<p>使用采样器中的索引获取样本列表后，作为collate_fn参数传递的函数用于将样本列表整理成批次。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([<span class="built_in">next</span>(dataset_iter) <span class="keyword">for</span> _ <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>可以使用自定义的collate_fn来自定义整理，例如，将顺序数据填充到批次的最大长度。 有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="禁用自动批处理"><a href="#禁用自动批处理" class="headerlink" title="禁用自动批处理"></a>禁用自动批处理</h3><p>在某些情况下，用户可能希望在数据集代码中手动处理批处理，或者只是加载单个样本。 例如，直接加载批处理数据可能更便宜（例如，从数据库中批量读取或读取连续的内存块），或者批次大小取决于数据，或者程序被设计为处理单个样本。 在这些情况下，最好不要使用自动批处理（其中collate_fn用于整理样本），而是让数据加载器直接返回dataset对象的每个成员。</p>
<p>当batch_size和batch_sampler都为None（batch_sampler的默认值为None）时，自动批处理将被禁用。 从dataset中获取的每个样本都会使用作为collate_fn参数传递的函数进行处理。</p>
<p><strong>禁用自动批处理时</strong>，默认的collate_fn只会将NumPy数组转换为PyTorch张量，其他一切保持不变。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(dataset[index])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> <span class="built_in">iter</span>(dataset):</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(data)</span><br></pre></td></tr></table></figure>

<p>有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="使用collate-fn"><a href="#使用collate-fn" class="headerlink" title="使用collate_fn"></a>使用collate_fn</h3><p>启用或禁用自动批处理时，collate_fn的使用略有不同。</p>
<p><strong>禁用自动批处理时</strong>，collate_fn会针对每个单独的数据样本进行调用，并从数据加载器迭代器中生成输出。 在这种情况下，默认的collate_fn只会将NumPy数组转换为PyTorch张量。</p>
<p><strong>启用自动批处理时</strong>，collate_fn会每次针对一个数据样本列表进行调用。 它应该将输入样本整理成一个批次，以便从数据加载器迭代器中生成。 本节的其余部分描述了默认collate_fn（default_collate()）的行为。</p>
<p>例如，如果每个数据样本包含一个 3 通道图像和一个整型类标签，即数据集的每个元素返回一个元组(image, class_index)，则默认的collate_fn会将此类元组列表整理成一个包含批处理图像张量和批处理类标签张量的单个元组。 特别是，默认的collate_fn具有以下属性</p>
<p>它始终将一个新的维度作为批处理维度前置。</p>
<p>它会自动将NumPy数组和Python数值转换为PyTorch张量。</p>
<p>它会保留数据结构，例如，如果每个样本都是一个字典，它会输出一个具有相同键集但批处理张量作为值的字典（如果值不能转换为张量，则为列表）。 list、tuple、namedtuple等也是如此。</p>
<p>用户可以使用自定义的collate_fn来实现自定义批处理，例如，沿除第一个维度以外的维度整理，填充不同长度的序列，或添加对自定义数据类型的支持。</p>
<p>如果您遇到DataLoader的输出具有与预期不同的维度或类型的情况，您可能需要检查您的collate_fn。</p>
<h2 id="单进程和多进程数据加载"><a href="#单进程和多进程数据加载" class="headerlink" title="单进程和多进程数据加载"></a>单进程和多进程数据加载</h2><p>DataLoader默认使用单进程数据加载。</p>
<p>在 Python 进程中，全局解释器锁 (GIL)阻止了跨线程真正地完全并行化 Python 代码。 为了避免数据加载阻塞计算代码，PyTorch 提供了一个简单的开关来执行多进程数据加载，只需将参数num_workers设置为正整数即可。</p>
<h3 id="单进程数据加载（默认）"><a href="#单进程数据加载（默认）" class="headerlink" title="单进程数据加载（默认）"></a>单进程数据加载（默认）</h3><p>在此模式下，数据获取在DataLoader初始化的同一个进程中完成。 因此，数据加载可能会阻塞计算。 但是，当用于在进程之间共享数据的资源（例如，共享内存、文件描述符）有限，或者当整个数据集很小且可以完全加载到内存中时，此模式可能更受欢迎。 此外，单进程加载通常显示更易读的错误跟踪，因此对调试很有用。</p>
<h3 id="多进程数据加载"><a href="#多进程数据加载" class="headerlink" title="多进程数据加载"></a>多进程数据加载</h3><p>将参数num_workers设置为正整数将打开使用指定数量的加载器工作程序进程的多进程数据加载。</p>
<p>警告</p>
<p>经过多次迭代后，加载器工作进程将消耗与父进程相同的 CPU 内存，用于父进程中所有从工作进程访问的 Python 对象。如果数据集包含大量数据（例如，您在数据集构建时加载了非常大的文件名列表）和&#x2F;或您使用了很多工作进程（总内存使用量为 number of workers * size of parent process），这可能会带来问题。最简单的解决方法是用非引用计数表示替换 Python 对象，例如 Pandas、Numpy 或 PyArrow 对象。查看 问题 #13246 了解更多关于为什么会出现这种情况以及如何解决这些问题的示例代码。</p>
<p>在此模式下，每次创建 DataLoader 的迭代器（例如，当您调用 enumerate(dataloader) 时），都会创建 num_workers 个工作进程。此时，dataset、collate_fn 和 worker_init_fn 会传递给每个工作进程，并在其中用于初始化和获取数据。这意味着数据集访问及其内部 IO、转换（包括 collate_fn）将在工作进程中运行。</p>
<p>torch.utils.data.get_worker_info() 在工作进程中返回各种有用的信息（包括工作进程 ID、数据集副本、初始种子等），并在主进程中返回 None。用户可以在数据集代码和&#x2F;或 worker_init_fn 中使用此函数来单独配置每个数据集副本，并确定代码是否在工作进程中运行。例如，这在对数据集进行分片时尤其有用。</p>
<p>对于映射式数据集，主进程使用 sampler 生成索引，并将其发送给工作进程。因此，任何洗牌随机化操作都在主进程中完成，该操作通过分配要加载的索引来指导加载。</p>
<p>对于可迭代式数据集，由于每个工作进程都获得了 dataset 对象的副本，因此简单的多进程加载通常会导致数据重复。使用 torch.utils.data.get_worker_info() 和&#x2F;或 worker_init_fn，用户可以独立地配置每个副本。（请参阅 IterableDataset 文档了解如何实现这一点。）出于类似原因，在多进程加载中，drop_last 参数将丢弃每个工作进程的可迭代式数据集副本的最后一个非完整批次。</p>
<p>当迭代结束时或当迭代器被垃圾回收时，工作进程将关闭。</p>
<p>警告</p>
<p>一般不建议在多进程加载中返回 CUDA 张量，因为在多进程中使用 CUDA 和共享 CUDA 张量时存在许多细微之处（请参阅 多进程中的 CUDA）。相反，我们建议使用 自动内存锁定（即，设置 pin_memory&#x3D;True），它可以实现快速将数据传输到支持 CUDA 的 GPU。</p>
<p>特定于平台的行为<br>由于工作进程依赖于 Python multiprocessing，因此工作进程启动行为在 Windows 上与 Unix 上不同。</p>
<p>在 Unix 上，fork() 是默认的 multiprocessing 启动方法。使用 fork()，子工作进程通常可以通过克隆的地址空间直接访问 dataset 和 Python 参数函数。</p>
<p>在 Windows 或 MacOS 上，spawn() 是默认的 multiprocessing 启动方法。使用 spawn()，会启动另一个解释器来运行您的主脚本，然后是接收 dataset、collate_fn 和其他参数的内部工作进程函数，这些参数通过 pickle 序列化。</p>
<p>这种单独的序列化意味着您应该采取两个步骤来确保在使用多进程数据加载时与 Windows 兼容。</p>
<p>将您的大部分主脚本代码包装在 if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘: 块中，以确保它在每个工作进程启动时不会再次运行（很可能生成错误）。您可以将您的数据集和 DataLoader 实例创建逻辑放在这里，因为它不需要在工作进程中重新执行。</p>
<p>确保任何自定义 collate_fn、worker_init_fn 或 dataset 代码都声明为顶层定义，位于 <strong>main</strong> 检查之外。这确保它们在工作进程中可用。（这是必要的，因为函数仅以引用形式被腌制，而不是 bytecode。）</p>
<p>多进程数据加载中的随机性<br>默认情况下，每个工作进程的 PyTorch 种子将设置为 base_seed + worker_id，其中 base_seed 是主进程使用其 RNG 生成的长整型数（因此，强制性地消耗 RNG 状态）或指定的 generator。但是，在初始化工作进程时，其他库的种子可能会重复，导致每个工作进程返回相同的随机数。（请参阅常见问题解答中的 此部分。）</p>
<p>在 worker_init_fn 中，您可以使用 torch.utils.data.get_worker_info().seed 或 torch.initial_seed() 访问为每个工作进程设置的 PyTorch 种子，并在数据加载之前使用它来设置其他库的种子。</p>
<h2 id="内存锁定"><a href="#内存锁定" class="headerlink" title="内存锁定"></a>内存锁定</h2><p>当主机到 GPU 的复制来自锁定页面（页面锁定）内存时，速度会快得多。请参阅 使用锁定页面内存缓冲区，了解何时以及如何一般性地使用锁定页面内存。</p>
<p>对于数据加载，将 pin_memory&#x3D;True 传递给 DataLoader 将自动将获取的数据张量放入锁定页面内存中，从而可以更快地将数据传输到支持 CUDA 的 GPU。</p>
<p>默认内存锁定逻辑仅识别张量以及包含张量的映射和可迭代对象。默认情况下，如果锁定页面逻辑看到一个自定义类型（如果您的 collate_fn 返回自定义批次类型，就会发生这种情况），或者如果批次的每个元素都是自定义类型，则锁定页面逻辑将无法识别它们，并且它将返回该批次（或这些元素）而不锁定页面内存。要为自定义批次或数据类型启用内存锁定，请在自定义类型上定义 pin_memory() 方法。</p>
<p>请参阅下面的示例。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class SimpleCustomBatch:</span><br><span class="line">    def __init__(self, data):</span><br><span class="line">        transposed_data = list(zip(*data))</span><br><span class="line">        self.inp = torch.stack(transposed_data[0], 0)</span><br><span class="line">        self.tgt = torch.stack(transposed_data[1], 0)</span><br><span class="line"></span><br><span class="line">    # custom memory pinning method on custom type</span><br><span class="line">    def pin_memory(self):</span><br><span class="line">        self.inp = self.inp.pin_memory()</span><br><span class="line">        self.tgt = self.tgt.pin_memory()</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">def collate_wrapper(batch):</span><br><span class="line">    return SimpleCustomBatch(batch)</span><br><span class="line"></span><br><span class="line">inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">dataset = TensorDataset(inps, tgts)</span><br><span class="line"></span><br><span class="line">loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,</span><br><span class="line">                    pin_memory=True)</span><br><span class="line"></span><br><span class="line">for batch_ndx, sample in enumerate(loader):</span><br><span class="line">    print(sample.inp.is_pinned())</span><br><span class="line">    print(sample.tgt.is_pinned())</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Class torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">None</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span>, multiprocessing_context=<span class="literal">None</span>, generator=<span class="literal">None</span>, *, prefetch_factor=<span class="literal">None</span>, persistent_workers=<span class="literal">False</span>, pin_memory_device=<span class="string">&#x27;&#x27;</span>)[source]</span><br></pre></td></tr></table></figure>

<p>数据加载器将数据集和采样器组合在一起，并提供一个遍历给定数据集的可迭代对象。</p>
<p>DataLoader 支持映射风格和可迭代风格的数据集，包含单进程或多进程加载、自定义加载顺序以及可选的自动批处理（整理）和内存固定。</p>
<p>更多细节请参见 torch.utils.data 文档页面。</p>
<p>参数<br>** dataset (Dataset) – 要加载数据的 dataset。<br>** batch_size (int, optional) – 每次加载多少个样本（默认：1）。<br>** shuffle (bool, optional) – 设置为 True 则在每个 epoch 时重新洗牌数据（默认：False）。<br>** sampler (Sampler or Iterable, optional) – 定义从 dataset 中抽取样本的策略。可以是任何实现了 <strong>len</strong> 的 Iterable。如果指定，则不能指定 shuffle。<br>** batch_sampler (Sampler or Iterable, optional) – 与 sampler 相似，但一次返回一批索引。与 batch_size、shuffle、sampler 和 drop_last 互斥。<br>** num_workers (int, optional) – 用于数据加载的子进程数量。0 表示数据将在主进程中加载。（默认：0）<br>** collate_fn (Callable, optional) – 将样本列表合并成一个包含张量（Tensor）的小批量。在使用映射风格数据集的批量加载时使用。<br>** pin_memory (bool, optional) – 如果为 True，数据加载器将在返回之前将张量复制到设备&#x2F;CUDA 固定内存中。如果你的数据元素是自定义类型，或者你的 collate_fn 返回一个自定义类型的批次，请参阅下面的示例。<br>** drop_last (bool, optional) – 设置为 True 以丢弃最后一个不完整的批次，如果数据集的大小不能被批次大小整除。如果为 False 且数据集大小不能被批次大小整除，则最后一个批次将更小。（默认：False）<br>** timeout (numeric, optional) – 如果为正数，则为从工作进程收集批次的超时值。应该始终为非负数。（默认：0）<br>** worker_init_fn (Callable, optional) – 如果不为 None，这将在每个工作进程子进程上调用，并将工作进程 ID（[0, num_workers - 1] 中的整数）作为输入，在播种和数据加载之前。（默认：None）<br>** multiprocessing_context (str or multiprocessing.context.BaseContext, optional) – 如果为 None，将使用操作系统的默认 多进程上下文。（默认：None）<br>** generator (torch.Generator, optional) – 如果不为 None，则随机采样器将使用此 RNG 生成随机索引，多进程将使用此 RNG 为工作进程生成 base_seed。（默认：None）<br>** prefetch_factor (int, optional, keyword-only arg) – 每个工作进程预先加载的批次数量。2 表示所有工作进程总共预取 2 * num_workers 个批次。（默认值取决于 num_workers 的设置值。如果 num_workers &#x3D; 0，则默认值为 ** None。否则，如果 num_workers &gt; 0，则默认值为 2）。<br>** persistent_workers (bool, optional) – 如果为 True，数据加载器在数据集被消费一次后不会关闭工作进程。这允许将工作进程的 Dataset 实例保持活动。（默认：False）<br>** pin_memory_device (str, optional) – 如果 pin_memory 为 True，则为要 pin_memory 的设备。</p>
<p>警告</p>
<p>如果使用 spawn 启动方法，则 worker_init_fn 不能是不可腌制的对象，例如 lambda 函数。有关 PyTorch 中多进程的更多详细信息，请参阅 多进程最佳实践。</p>
<p>警告</p>
<p>len(dataloader) 启发式基于所用采样器的长度。当 dataset 是一个 IterableDataset 时，它将返回一个基于 len(dataset) &#x2F; batch_size 的估计值，并根据 drop_last 进行适当的舍入，而与多进程加载配置无关。这代表了 PyTorch 可以做出的最佳猜测，因为 PyTorch 相信用户 dataset 代码在正确处理多进程加载以避免重复数据方面。</p>
<p>但是，如果分片导致多个工作进程具有不完整的最后一个批次，则此估计仍然可能不准确，因为 (1) 一个原本完整的批次可以被分成多个批次，(2) 当设置了 drop_last 时，可以丢弃多个批次。不幸的是，PyTorch 通常无法检测到此类情况。</p>
<p>有关这两种类型的数据集以及 IterableDataset 如何与 多进程数据加载 相互作用的更多详细信息，请参阅 数据集类型。</p>
<p>警告</p>
<p>有关随机种子相关问题的更多信息，请参阅 可重复性，以及 我的数据加载器工作进程返回相同的随机数 和 多进程数据加载中的随机性 说明。</p>
<p>classtorch.utils.data.Dataset(*args, **kwds)[source]<br>一个表示 Dataset 的抽象类。</p>
<p>所有表示从键到数据样本的映射的数据集都应该继承它。所有子类都应该覆盖 <strong>getitem</strong>()，支持获取给定键的数据样本。子类还可以选择覆盖 <strong>len</strong>()，这将返回许多 Sampler 实现和 DataLoader 的默认选项的数据集大小。子类还可以选择实现 <strong>getitems</strong>()，以加快批处理样本加载速度。此方法接受批次样本索引列表并返回样本列表。</p>
<p>注意</p>
<p>DataLoader 默认情况下会构造一个生成整数索引的索引采样器。要使其与具有非整数索引&#x2F;键的映射式数据集一起使用，必须提供自定义采样器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.IterableDataset(*args, **kwds)[source]</span><br></pre></td></tr></table></figure>

<p>一个可迭代的 Dataset。</p>
<p>所有表示数据样本可迭代的数据集都应该继承它。这种形式的数据集在数据来自流时特别有用。</p>
<p>所有子类都应该覆盖 <strong>iter</strong>()，它将返回此数据集中样本的迭代器。</p>
<p>当子类与 DataLoader 一起使用时，数据集中的每个项目都将从 DataLoader 迭代器中生成。当 num_workers &gt; 0 时，每个工作进程将拥有数据集对象的副本，因此通常需要独立配置每个副本，以避免工作进程返回重复数据。 get_worker_info()，在工作进程中调用时，返回有关工作进程的信息。它可以在数据集的 <strong>iter</strong>() 方法或 DataLoader 的 worker_init_fn 选项中使用，以修改每个副本的行为。</p>
<p>示例 1：在 <strong>iter</strong>() 中将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> worker_info <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># single-process data loading, return the full iterator</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="variable language_">self</span>.end</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">else</span>:  <span class="comment"># in a worker process</span></span><br><span class="line"><span class="meta">... </span>            <span class="comment"># split workload</span></span><br><span class="line"><span class="meta">... </span>            per_worker = <span class="built_in">int</span>(math.ceil((<span class="variable language_">self</span>.end - <span class="variable language_">self</span>.start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>            worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="built_in">min</span>(iter_start + per_worker, <span class="variable language_">self</span>.end)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(iter_start, iter_end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with two worker processes</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br></pre></td></tr></table></figure>

<p>示例 2：使用 worker_init_fn 将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.start, <span class="variable language_">self</span>.end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Directly doing multi-process loading yields duplicate data</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Define a `worker_init_fn` that configures each dataset copy differently</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">worker_init_fn</span>(<span class="params">worker_id</span>):</span><br><span class="line"><span class="meta">... </span>    worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>    dataset = worker_info.dataset  <span class="comment"># the dataset copy in this worker process</span></span><br><span class="line"><span class="meta">... </span>    overall_start = dataset.start</span><br><span class="line"><span class="meta">... </span>    overall_end = dataset.end</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># configure the dataset to only process the split workload</span></span><br><span class="line"><span class="meta">... </span>    per_worker = <span class="built_in">int</span>(math.ceil((overall_end - overall_start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>    worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>    dataset.start = overall_start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>    dataset.end = <span class="built_in">min</span>(dataset.start + per_worker, overall_end)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with the custom `worker_init_fn`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.TensorDataset(*tensors)[source]</span><br></pre></td></tr></table></figure>

<p>包装张量的 Dataset。</p>
<p>每个样本将通过沿第一维索引张量来检索。</p>
<p>参数<br>** tensors (Tensor) – 具有相同第一维大小的张量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.StackDataset(*args, **kwargs)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集堆叠在一起的 Dataset。</p>
<p>此类对于将作为数据集给出的复杂输入数据的不同部分组合在一起非常有用。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>images = ImageDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>texts = TextDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack = StackDataset(images, texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack[<span class="number">0</span>] == (images[<span class="number">0</span>], texts[<span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack = StackDataset(image=images, text=texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack[<span class="number">0</span>] == &#123;<span class="string">&#x27;image&#x27;</span>: images[<span class="number">0</span>], <span class="string">&#x27;text&#x27;</span>: texts[<span class="number">0</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>参数<br>** args (Dataset) – 堆叠的数据集，作为元组返回。<br>** kwargs (Dataset) – 堆叠的数据集，作为字典返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ConcatDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集组合在一起非常有用。</p>
<p>参数<br>** datasets (sequence) – 要连接的数据集列表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ChainDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>用于将多个 IterableDataset 连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集流组合在一起非常有用。连接操作是在运行时完成的，因此使用此类连接大型数据集将非常高效。</p>
<p>参数<br>** datasets (iterable of IterableDataset) – 要连接在一起的数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.Subset(dataset, indices)[source]</span><br></pre></td></tr></table></figure>

<p>在指定索引处的数据集的子集。</p>
<p>参数<br>** dataset (Dataset) – 整个 Dataset<br>** indices (sequence) – 为子集选择的整个集合中的索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data._utils.collate.collate(batch, *, collate_fn_map=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>处理每个批次中元素的集合类型的通用整理函数。</p>
<p>该函数还打开函数注册表以处理特定的元素类型。 default_collate_fn_map 为张量、NumPy 数组、数字和字符串提供默认的整理函数。</p>
<p>参数<br>** batch – 要整理的单个批次</p>
<p>collate_fn_map (Optional[Dict[Union[Type, Tuple[Type, …]], Callable]]) – 可选字典，将元素类型映射到相应的整理函数。如果元素类型不在此字典中，则此函数将按插入顺序遍历字典中的每个键，如果元素类型是键的子类，则调用相应的整理函数。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_tensor_fn</span>(<span class="params">batch, *, collate_fn_map</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># Extend this function to handle batch of tensors</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> torch.stack(batch, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    collate_map = &#123;torch.Tensor: collate_tensor_fn&#125;</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> collate(batch, collate_fn_map=collate_map)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Extend `default_collate` by in-place modifying `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(&#123;torch.Tensor: collate_tensor_fn&#125;)</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p>每个整理函数都需要一个批次的定位参数和一个整理函数字典的关键字参数，作为 collate_fn_map。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.default_collate(batch)[source]</span><br></pre></td></tr></table></figure>
<p>接收一批数据，并将批次中的元素放入一个具有额外的外部维度（批次大小）的张量中。</p>
<p>确切的输出类型可以是 torch.Tensor、Sequence 的 torch.Tensor、torch.Tensor 的集合，或者保持不变，具体取决于输入类型。 当在 DataLoader 中定义了 batch_size 或 batch_sampler 时，这将用作合并的默认函数。</p>
<p>以下是通用输入类型（基于批次内元素的类型）到输出类型映射</p>
<p>torch.Tensor -&gt; torch.Tensor（添加了外部维度批次大小）</p>
<p>NumPy 数组 -&gt; torch.Tensor</p>
<p>float -&gt; torch.Tensor</p>
<p>int -&gt; torch.Tensor</p>
<p>str -&gt; str（保持不变）</p>
<p>bytes -&gt; bytes（保持不变）</p>
<p>Mapping[K, V_i] -&gt; Mapping[K, default_collate([V_1, V_2, …])]</p>
<p>NamedTuple[V1_i, V2_i, …] -&gt; NamedTuple[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>Sequence[V1_i, V2_i, …] -&gt; Sequence[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>参数<br>batch – 要整理的单个批次</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `int`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `str`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Map` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([&#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">1</span>&#125;, &#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">100</span>&#125;])</span><br><span class="line">&#123;<span class="string">&#x27;A&#x27;</span>: tensor([  <span class="number">0</span>, <span class="number">100</span>]), <span class="string">&#x27;B&#x27;</span>: tensor([  <span class="number">1</span>, <span class="number">100</span>])&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `NamedTuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([Point(<span class="number">0</span>, <span class="number">0</span>), Point(<span class="number">1</span>, <span class="number">1</span>)])</span><br><span class="line">Point(x=tensor([<span class="number">0</span>, <span class="number">1</span>]), y=tensor([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Tuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">3</span>)])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `List` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Two options to extend `default_collate` to handle specific type</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 1: Write custom collate function and invoke `default_collate`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    elem = batch[<span class="number">0</span>]</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> <span class="built_in">isinstance</span>(elem, CustomType):  <span class="comment"># Some custom condition</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:  <span class="comment"># Fall back to `default_collate`</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> default_collate(batch)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 2: In-place modify `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_customtype_fn</span>(<span class="params">batch, *, collate_fn_map=<span class="literal">None</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(CustomType, collate_customtype_fn)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate(batch)  <span class="comment"># Handle `CustomType` automatically</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.default_convert(data)[source]</span><br></pre></td></tr></table></figure>
<p>将每个 NumPy 数组元素转换为 torch.Tensor。</p>
<p>如果输入是 Sequence、Collection 或 Mapping，它会尝试将内部的每个元素转换为 torch.Tensor。 如果输入不是 NumPy 数组，则保持不变。 当在 DataLoader 中未定义 batch_sampler 和 batch_size 时，这将用作合并的默认函数。</p>
<p>通用输入类型到输出类型映射类似于 default_collate()。 有关更多详细信息，请参阅那里的描述。</p>
<p>参数<br>data – 要转换的单个数据点</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `int`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(<span class="number">0</span>)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NumPy array</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(np.array([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NamedTuple</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">Point(x=<span class="number">0</span>, y=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(np.array(<span class="number">0</span>), np.array(<span class="number">0</span>)))</span><br><span class="line">Point(x=tensor(<span class="number">0</span>), y=tensor(<span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with List</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert([np.array([<span class="number">0</span>, <span class="number">1</span>]), np.array([<span class="number">2</span>, <span class="number">3</span>])])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">1</span>]), tensor([<span class="number">2</span>, <span class="number">3</span>])]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.get_worker_info()[source]</span><br></pre></td></tr></table></figure>

<p>返回有关当前 DataLoader 迭代器工作进程的信息。</p>
<p>在工作进程中调用时，这将返回一个保证具有以下属性的对象</p>
<p>id：当前工作进程 ID。</p>
<p>num_workers：工作进程的总数。</p>
<p>seed：为当前工作进程设置的随机种子。 此值由主进程 RNG 和工作进程 ID 确定。 有关更多详细信息，请参阅 DataLoader 的文档。</p>
<p>dataset：此进程中数据集对象的副本。 请注意，这将在与主进程不同的进程中成为不同的对象。</p>
<p>在主进程中调用时，这将返回 None。</p>
<p>注意</p>
<p>当在传递给 DataLoader 的 worker_init_fn 中使用时，此方法可用于以不同的方式设置每个工作进程，例如，使用 worker_id 配置 dataset 对象以仅读取分片数据集的特定部分，或使用 seed 为数据集代码中使用的其他库设置种子。</p>
<p>返回类型<br>Optional[WorkerInfo]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.random_split(dataset, lengths, generator=&lt;torch._C.Generator <span class="built_in">object</span>&gt;)[source]</span><br></pre></td></tr></table></figure>
<p>将数据集随机拆分为给定长度的非重叠新数据集。</p>
<p>如果给定一个加起来为 1 的分数列表，则长度将自动计算为每个提供的分数的 floor(frac * len(dataset))。</p>
<p>计算长度后，如果存在任何余数，将以循环方式将 1 个计数分配给长度，直到没有余数为止。</p>
<p>可以选择固定生成器以获得可重复的结果，例如：</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator1 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator2 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">10</span>), [<span class="number">3</span>, <span class="number">7</span>], generator=generator1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">30</span>), [<span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.4</span>], generator=generator2)</span><br></pre></td></tr></table></figure>

<p>参数<br>dataset (Dataset) – 要拆分的Dataset</p>
<p>lengths (sequence) – 要生成的拆分的长度或分数</p>
<p>generator (Generator) – 用于随机排列的生成器。</p>
<p>返回类型<br>List[Subset[T]]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.Sampler(data_source=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>所有 Sampler 的基类。</p>
<p>每个 Sampler 子类都必须提供一个 <strong>iter</strong>() 方法，提供一种方法来迭代数据集元素的索引或索引列表（批次），并且可以提供一个 <strong>len</strong>() 方法，该方法返回返回的迭代器的长度。</p>
<p>参数<br>data_source (Dataset) – 此参数未使用，将在 2.2.0 中删除。 您可能仍然拥有利用它的自定义实现。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthSampler</span>(Sampler[<span class="built_in">int</span>]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="built_in">int</span>]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">yield</span> <span class="keyword">from</span> torch.argsort(sizes).tolist()</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthBatchSampler</span>(Sampler[<span class="type">List</span>[<span class="built_in">int</span>]]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> (<span class="built_in">len</span>(<span class="variable language_">self</span>.data) + <span class="variable language_">self</span>.batch_size - <span class="number">1</span>) // <span class="variable language_">self</span>.batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">for</span> batch <span class="keyword">in</span> torch.chunk(torch.argsort(sizes), <span class="built_in">len</span>(<span class="variable language_">self</span>)):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>            <span class="keyword">yield</span> batch.tolist()</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p><strong>len</strong>() 方法不是 DataLoader 严格要求的，但预期在涉及 DataLoader 长度的任何计算中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.SequentialSampler(data_source)[source]</span><br></pre></td></tr></table></figure>

<p>按顺序采样元素，始终以相同的顺序。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>classtorch.utils.data.RandomSampler(data_source, replacement&#x3D;False, num_samples&#x3D;None, generator&#x3D;None)[source]<br>随机采样元素。 如果没有替换，则从洗牌后的数据集采样。</p>
<p>如果替换，则用户可以指定 num_samples 以进行抽取。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>replacement (bool) – 如果 True，则按需从替换中抽取样本，默认值为 <code>False</code></p>
<p>num_samples (int) – 要抽取的样本数量，默认值为 <code>len(dataset)</code>。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.SubsetRandomSampler(indices, generator&#x3D;None)[source]<br>从给定的索引列表中随机采样元素，不进行替换。</p>
<p>参数<br>indices (sequence) – 索引序列</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.WeightedRandomSampler(weights, num_samples, replacement&#x3D;True, generator&#x3D;None)[source]<br>从 [0,..,len(weights)-1] 中根据给定的概率（权重）采样元素。</p>
<p>参数<br>weights (sequence) – 权重序列，不必加起来为1</p>
<p>num_samples (int) – 要抽取的样本数</p>
<p>replacement (bool) – 如果为 True，则有放回地抽取样本。否则，则无放回地抽取样本，这意味着当为一行抽取一个样本索引时，就不能再为该行抽取该索引。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.1</span>, <span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.7</span>, <span class="number">3.0</span>, <span class="number">0.6</span>], <span class="number">5</span>, replacement=<span class="literal">True</span>))</span><br><span class="line">[<span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.05</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.1</span>], <span class="number">5</span>, replacement=<span class="literal">False</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.BatchSampler(sampler, batch_size, drop_last)[source]</span><br></pre></td></tr></table></figure>
<p>封装另一个采样器以生成一个索引小批量。</p>
<p>参数<br>sampler (Sampler or Iterable) – 基本采样器。可以是任何可迭代对象</p>
<p>batch_size (int) – 小批量的尺寸。</p>
<p>drop_last (bool) – 如果为 True，则采样器将丢弃最后一个小批量，如果其尺寸小于 batch_size</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">True</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.distributed.DistributedSampler(dataset, num_replicas=<span class="literal">None</span>, rank=<span class="literal">None</span>, shuffle=<span class="literal">True</span>, seed=<span class="number">0</span>, drop_last=<span class="literal">False</span>)[source]</span><br></pre></td></tr></table></figure>
<p>限制数据加载到数据集子集的采样器。</p>
<p>它在与 torch.nn.parallel.DistributedDataParallel 结合使用时特别有用。在这种情况下，每个进程都可以将 DistributedSampler 实例作为 DataLoader 采样器传递，并加载一个独属于它的原始数据集的子集。</p>
<p>注意</p>
<p>假设数据集大小恒定，并且任何实例都始终以相同的顺序返回相同的元素。</p>
<p>参数<br>dataset – 用于采样的数据集。</p>
<p>num_replicas (int, optional) – 参与分布式训练的进程数。默认情况下，world_size 从当前分布式组中获取。</p>
<p>rank (int, optional) – 当前进程在 num_replicas 中的排名。默认情况下，rank 从当前分布式组中获取。</p>
<p>shuffle (bool, optional) – 如果为 True（默认），则采样器将随机打乱索引。</p>
<p>seed (int, optional) – 如果 shuffle&#x3D;True，则用于随机打乱采样器的随机种子。此数字在分布式组中的所有进程中应该相同。默认值：0。</p>
<p>drop_last (bool, optional) – 如果为 True，则采样器将丢弃数据的尾部，使其在副本数上均匀可分。如果为 False，则采样器将添加额外的索引以使数据在副本上均匀可分。默认值：False。</p>
<p>警告</p>
<p>在分布式模式下，在每个纪元开始时调用 set_epoch() 方法，在创建 DataLoader 迭代器之前，对于在多个纪元中使随机打乱正常工作是必要的。否则，将始终使用相同的排序。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sampler = DistributedSampler(dataset) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loader = DataLoader(dataset, shuffle=(sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line"><span class="meta">... </span>                    sampler=sampler)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, n_epochs):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> is_distributed:</span><br><span class="line"><span class="meta">... </span>        sampler.set_epoch(epoch)</span><br><span class="line"><span class="meta">... </span>    train(loader)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>DataLoader</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：Pytorch训练可重复性（Reproducibility）</title>
    <url>/AI-Repeatability/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUAM6J.jpg"></p>
<p>在不同的 PyTorch 版本或不同平台上，不能保证完全可复现的结果。此外，即使使用相同的随机种子，CPU 和 GPU 执行之间的结果也可能无法复现。但是，您可以采取措施来限制平台、设备和 PyTorch 版本的非确定性行为来源。首先，您可以控制随机性的来源，这些来源会导致应用程序的多次执行表现不同。其次，您可以将 PyTorch 配置为避免对某些操作使用非确定性算法，以便在给定相同输入的情况下，对这些操作的多次调用将产生相同的结果。最后，在执行多进程数据加载时还需注意控制加载的随机性工作进程种子。本文内容参考 Pytorch 官方文档：<a href="https://pytorch.org/docs/stable/notes/randomness.html#controlling-sources-of-randomness">https://pytorch.org/docs/stable/notes/randomness.html#controlling-sources-of-randomness</a></p>
<blockquote class="blockquote-center">
<p>Deterministic operations are often slower than nondeterministic operations, so single-run performance may decrease for your model. However, determinism may save time in development by facilitating experimentation, debugging, and regression testing.</p>

</blockquote>

<span id="more"></span>

<h2 id="控制随机性的来源"><a href="#控制随机性的来源" class="headerlink" title="控制随机性的来源"></a>控制随机性的来源</h2><h3 id="PyTorch-随机数生成器"><a href="#PyTorch-随机数生成器" class="headerlink" title="PyTorch 随机数生成器"></a>PyTorch 随机数生成器</h3><p>您可以使用 <code>torch.manual_seed()</code> 为所有设备（CPU 和 CUDA）的 RNG 设置种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.manual_seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>某些 PyTorch 操作可能会在内部使用随机数。例如，<code>torch.svd_lowrank()</code> 就会这样做。因此，使用相同的输入参数连续多次调用它可能会得到不同的结果。但是，只要在应用程序开始时将 <code>torch.manual_seed()</code> 设置为常量，并且消除了所有其他非确定性来源，则每次在相同环境中运行应用程序时，都会生成相同的随机数序列。</p>
<p>还可以通过在后续调用之间将 <code>torch.manual_seed()</code> 设置为相同的值，从使用随机数的操作中获得相同的结果。</p>
<h3 id="Python-随机数生成器"><a href="#Python-随机数生成器" class="headerlink" title="Python 随机数生成器"></a>Python 随机数生成器</h3><p>对于自定义运算符，您可能还需要设置 Python 种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="其他库中的随机数生成器"><a href="#其他库中的随机数生成器" class="headerlink" title="其他库中的随机数生成器"></a>其他库中的随机数生成器</h3><p>如果您或您正在使用的任何库依赖于 NumPy，则可以使用以下代码为全局 NumPy RNG 设置种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>但是，某些应用程序和库可能使用 NumPy 随机数生成器对象，而不是全局 RNG（<a href="https://numpy.com.cn/doc/stable/reference/random/generator.html">https://numpy.com.cn/doc/stable/reference/random/generator.html</a>），这些对象也需要一致地设置种子。</p>
<p>如果您正在使用任何其他使用随机数生成器的库，请参阅这些库的文档，以了解如何为它们设置一致的种子。</p>
<h3 id="CUDA-卷积基准测试"><a href="#CUDA-卷积基准测试" class="headerlink" title="CUDA 卷积基准测试"></a>CUDA 卷积基准测试</h3><p>由 CUDA 卷积操作使用的 cuDNN 库可能是应用程序多次执行之间非确定性的来源。当使用一组新的尺寸参数调用 cuDNN 卷积时，一个可选功能可以运行多个卷积算法，对它们进行基准测试以找到最快的算法。然后，在该过程的剩余时间内，将针对相应的尺寸参数集一致地使用最快的算法。由于基准测试噪声和不同的硬件，即使在同一台机器上，基准测试也可能会在后续运行中选择不同的算法。</p>
<p>使用 <code>torch.backends.cudnn.benchmark = False</code> 禁用基准测试功能会导致 cuDNN 确定性地选择算法，但可能会降低性能。</p>
<p>但是，如果您不需要在应用程序的多次执行之间保持可复现性，则启用基准测试功能 <code>torch.backends.cudnn.benchmark = True</code> 可能会提高性能。</p>
<p>请注意，此设置与下面讨论的 <code>torch.backends.cudnn.deterministic</code> 设置不同。</p>
<h2 id="避免非确定性算法"><a href="#避免非确定性算法" class="headerlink" title="避免非确定性算法"></a>避免非确定性算法</h2><p><code>torch.use_deterministic_algorithms()</code> 允许您将 PyTorch 配置为在可用时使用确定性算法而不是非确定性算法，并在已知操作是非确定性算法（并且没有确定性替代算法）时抛出错误。</p>
<p>有关受影响操作的完整列表，请参阅 <a href="https://pytorch.ac.cn/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms"><code>torch.use_deterministic_algorithms()</code></a> 的文档。如果某个操作没有按照文档正确执行，或者您需要一个没有确定性实现的操作的确定性实现，请提交问题：<a href="https://github.com/pytorch/pytorch/issues?q=label:%22module:%20determinism%22">https://github.com/pytorch/pytorch/issues?q=label:%22module:%20determinism%22</a></p>
<p>例如，运行 <code>torch.Tensor.index_add_()</code> 的非确定性 CUDA 实现将引发错误：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">2</span>, <span class="number">2</span>).cuda().index_add_(<span class="number">0</span>, torch.tensor([<span class="number">0</span>, <span class="number">1</span>]), torch.randn(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">RuntimeError: index_add_cuda_ does <span class="keyword">not</span> have a deterministic implementation, but you <span class="built_in">set</span></span><br><span class="line"><span class="string">&#x27;torch.use_deterministic_algorithms(True)&#x27;</span>. ...</span><br></pre></td></tr></table></figure>

<p>当使用稀疏密集 CUDA 张量调用 <code>torch.bmm()</code> 时，它通常使用非确定性算法，但当打开确定性标志时，将使用其备用的确定性实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.bmm(torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>).to_sparse().cuda(), torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>).cuda())</span><br><span class="line">tensor([[[ <span class="number">1.1900</span>, -<span class="number">2.3409</span>],</span><br><span class="line">         [ <span class="number">0.4796</span>,  <span class="number">0.8003</span>]],</span><br><span class="line">        [[ <span class="number">0.1509</span>,  <span class="number">1.8027</span>],</span><br><span class="line">         [ <span class="number">0.0333</span>, -<span class="number">1.1444</span>]]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>此外，如果您正在使用 CUDA 张量，并且您的 CUDA 版本为 10.2 或更高版本，则应根据 CUDA 文档设置环境变量 CUBLAS_WORKSPACE_CONFIG：<a href="https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility">https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility</a></p>
<h3 id="CUDA-RNN-和-LSTM"><a href="#CUDA-RNN-和-LSTM" class="headerlink" title="CUDA RNN 和 LSTM"></a>CUDA RNN 和 LSTM</h3><p>在某些版本的 CUDA 中，RNN 和 LSTM 网络可能具有非确定性行为。有关详细信息和解决方法，请参阅 <code>torch.nn.RNN()</code> 和 <code>torch.nn.LSTM()</code>。</p>
<h3 id="填充未初始化的内存"><a href="#填充未初始化的内存" class="headerlink" title="填充未初始化的内存"></a>填充未初始化的内存</h3><p><code>torch.empty()</code> 和 <code>torch.Tensor.resize_()</code> 等操作可以返回包含未定义值的未初始化内存的张量。如果需要确定性，则使用此类张量作为另一个操作的输入是无效的，因为输出将是非确定性的。但实际上没有任何东西可以阻止运行此类无效代码。因此，为了安全起见，默认情况下 <code>torch.utils.deterministic.fill_uninitialized_memory</code> 设置为 <code>True</code>，如果设置了 <code>torch.use_deterministic_algorithms(True)</code>，它将使用已知值填充未初始化的内存。这将防止这种非确定性行为的可能性。</p>
<p>然而，填充未初始化的内存不利于性能。因此，如果您的程序有效并且不使用未初始化的内存作为操作的输入，则可以关闭此设置以获得更好的性能。</p>
<h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p>DataLoader 将按照 <a href="https://pytorch.ac.cn/docs/stable/data.html#data-loading-randomness">多进程数据加载中的随机性</a> 算法重新设定工作进程的种子。使用 <code>worker_init_fn()</code> 和 <code>generator</code> 来保持可重复性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seed_worker</span>(<span class="params">worker_id</span>):</span><br><span class="line">    worker_seed = torch.initial_seed() % <span class="number">2</span>**<span class="number">32</span></span><br><span class="line">    numpy.random.seed(worker_seed)</span><br><span class="line">    random.seed(worker_seed)</span><br><span class="line"></span><br><span class="line">g = torch.Generator()</span><br><span class="line">g.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_workers=num_workers,</span><br><span class="line">    worker_init_fn=seed_worker,</span><br><span class="line">    generator=g,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="实际实践中的随机种子定义函数"><a href="#实际实践中的随机种子定义函数" class="headerlink" title="实际实践中的随机种子定义函数"></a>实际实践中的随机种子定义函数</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, gzip, re, string, glob, time, random, shutil, itertools, json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> GradScaler, autocast</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> CrossEntropyLoss</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD, AdamW</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> LambdaLR,CosineAnnealingLR</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> IterableDataset, DataLoader, DistributedSampler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, TrainingArguments, AutoConfig, set_seed, Trainer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_seed</span>(<span class="params">seed</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Repeatability of model training process. Refer to the following link: </span></span><br><span class="line"><span class="string">https://pytorch.ac.cn/docs/stable/notes/randomness.html</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    </span><br><span class="line">    set_seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    </span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line">    os.environ[<span class="string">&quot;CUBLAS_WORKSPACE_CONFIG&quot;</span>] = <span class="string">&quot;:4096:8&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>Repeatability</tag>
      </tags>
  </entry>
  <entry>
    <title>近似最近邻搜索算法（Approximate Nearest Neighbors Oh Yeah, ANNOY）</title>
    <url>/ANNOY/</url>
    <content><![CDATA[<p><img src="https://zr9558.com/wp-content/uploads/2022/01/scann-tom-export.gif"></p>
<p>在搜索的业务场景下，基于一个现有的数据候选集（dataset），需要对新来的一个或者多个数据进行查询（query），返回在数据候选集中与该查询最相似的 Top K 数据。</p>
<span id="more"></span>]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>Approximate Nearest Neighbors Oh Yeah</tag>
        <tag>ANNOY</tag>
      </tags>
  </entry>
  <entry>
    <title>序</title>
    <url>/Exp001-hello-world/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUtC1H.jpg"></p>
<blockquote class="blockquote-center">
<p>“在学校开课的时节，我便专心教书，等到学校放寒暑假，我才从事写作。”  —— 老舍</p>

</blockquote>

<p>第一次接触Hexo|NexT主题博客，是在某位多晶相变专家的个人主页。当时不仅为他的学识所折服，更惊叹于如此优雅的知识分享方式。那时就曾想，以后一定要搭建自己的博客，来记录自己的经历和成长，今日终如愿。</p>
<span id="more"></span>

<h2 id="为什么记录生活"><a href="#为什么记录生活" class="headerlink" title="为什么记录生活"></a>为什么记录生活</h2><p>决定攻读博士学位那刻起，人生的很多种可能已再无法实现。身上的责任越来越重，太多事情需要去做，每天每天周而复始。于自身有益的、无益的信息，都未经过滤从各种渠道钻进大脑里占据一部分空间。记录生活，可以把自己从喧闹的现实生活中释放出来，放空自己，使内心重归平静。我越来越难以回忆起，去年的这个时候我在做些什么，在想些什么，对未来的人生有着什么样的想法，然后思考自己过去这一年，做了些什么有意义的事，完成了什么重要的任务，并进一步思考，未来的路应该怎么走，而不是被现实的压力驱赶着，一直低头赶路。所以需要通过文字，让过去不止是淹没在时间长河中再也打捞不起来的过去，而是一条清晰的锁链，我拽着锁链的这头，就能与过去的自己对话，了解自己的人生观是如何悄然变化。</p>
<h2 id="为什么记录技术笔记"><a href="#为什么记录技术笔记" class="headerlink" title="为什么记录技术笔记"></a>为什么记录技术笔记</h2><p>这就有很多原因了。一方面作为科研人员，没有整理技术笔记的习惯让人难以置信。技术笔记可以帮助自己理清解决问题的思路，归纳知识体系。在工作中遇到了技术难题，一味的摸索、尝试，直到柳暗花明突然解决问题，但没有停下手头的工作来思考并记录始末，则是错失了一大笔财富，或许一年后再遇到同样的问题，依然要花费大量时间重新探索。每过一段时间的技术积淀，都要停下脚步来重新思考，梳理一下零散的知识体系，或是记录一些关键问题的探索方案，延续已付出的智慧与努力的价值。这里有两点很重要，第一，亲自实践，第二，重新思考。即使是走在前人的老路上而没有做出创新性的贡献，自己重新归纳总结也有助于梳理流程，深化理解。</p>
<p>制作个人博客的另一层目的是为博士学位论文累积素材。因为一些特殊原因，今年我需要走一遍硕士毕业的流程，开了一星期夜车硬是折腾完了整篇硕士学位论文和答辩报告，写完后也实在是没有兴趣再去校对修改了。结果当然是存在大量行文逻辑不严谨的地方，虽然是形式主义，但毕竟也署着我的名字。评委发回的意见里甚至直接写上 “此处XX用词不当”，这让我始终很后悔。我很期望能写出系统、深刻的博士学位论文，于我而言，无论结果如何，这都将是我此生视若珍宝的东西之一，因此目前的准备工作必不可少。</p>
<h2 id="为什么使用Hexo并在网络上公开"><a href="#为什么使用Hexo并在网络上公开" class="headerlink" title="为什么使用Hexo并在网络上公开"></a>为什么使用Hexo并在网络上公开</h2><p>使用Hexo|NexT的初衷是觉得这非常优雅，我尤其钟爱这类极简的艺术，搭建并调整Hexo|NexT的过程也着实让我沉浸其中。</p>
<p>至于在网络上公开的原因，一方面，我越来越觉得，要把知识、经验、感悟分享出来，给他人带来价值，或经受批判后成长。</p>
<p>另一方面，离开母校后人际关系愈加复杂，喧嚣的社交早已不再适合谈及生活与理想，只有在此延续另一种形态的社交。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>期刊投稿的准备工作及注意事项</title>
    <url>/Exp002-ArticleReply/</url>
    <content><![CDATA[<p><img src="https://updatepublishing.com/journal/public/journals/5/homepageImage_en_US.jpg"></p>
<p>本文以近期返修的Acta Materialia为例，整理归纳SCI学术期刊投稿时需要准备的材料规范与模板及注意事项，包括 Manuscript, Cover Letter, Suggested Reviewers, Graphical Abstract, Highlights, Declaration of Interests, Reply等，以供参考。</p>
<span id="more"></span>

<h2 id="Cover-letter"><a href="#Cover-letter" class="headerlink" title="Cover letter"></a>Cover letter</h2><p>Cover letter是投稿时与Manuscript一同发送给Editor的投稿信件，用几句话简明扼要的交代给Editor本文的内容梗概或对于这次修改的反馈。一封内容简洁明了的Cover Letter会让Editor对论文的第一印象加分不少。在信中需简要列出文章的创新点，并且说明全部作者同意投稿，宣称没有利益冲突，该文章没有在其他期刊发表过等责任声明信息。注意期刊名斜体。在此列出本篇文章首次投稿与第三次返稿时的Cover Letter实例：</p>
<blockquote>
<p>Dear Editor,</p>
</blockquote>
<blockquote>
<p>We would like to submit the above manuscript for your consideration of its publication in <em>Acta Materialia</em>. The work described has not been submitted elsewhere for publication, in whole or in part, and all the authors listed have approved the manuscript that is enclosed.</p>
</blockquote>
<blockquote>
<p>We believe that this manuscript is appealing to general readers of Acta Materialia for its novelty, signicance, and the subject itself. Investigations on nuclear materials from decommissioned reactors can help understand radiation damage and thus reactor aging, but are scarce owing to the diculty in accessing such materials. Using synchrotron tomography, we present firstly in situ, three-dimensional characterizations of deformation dynamics of an LT21 Al alloy after 30 years’ nuclear service under quasi-static uniaxial tension. A new particle tracking analysis technique is proposed to quantify the displacement&#x2F;strain fields and microstructural evolution in the irradiated sample. Nucleation of new pores and growth of initial and newly-nucleated pores occur simultaneously, and contributes approximately equally to damage accumulation in the irradiated LT21 Al before necking occurs. It is interesting to note that nucleation of new pores prefers to occur at the top and bottom ends of precipitates (relative to the tensile direction). Such multiscale data are valuable for development of physics-based models, and for nuclear structural design.</p>
</blockquote>
<blockquote>
<p>We are looking forward to your positive response. Thank you!</p>
</blockquote>
<p>第三次返稿时Cover Letter：</p>
<blockquote>
<p>Dear Prof. Wang,</p>
</blockquote>
<blockquote>
<p>We appreciate the editor for giving us the opportunity to revise our manuscript and the constructive remarks by the reviewers. We have revised the manuscript accordingly following the reviewers’ comments.</p>
</blockquote>
<blockquote>
<p>We would like to submit the revised manuscript for your consideration of its publication in <em>Acta Materialia</em>. The work described has not been submitted elsewhere for publication, in whole or in part, and all the authors listed have approved the manuscript that is enclosed.</p>
</blockquote>
<blockquote>
<p>We are looking forward to your response.</p>
</blockquote>
<h2 id="Suggested-Reviewers"><a href="#Suggested-Reviewers" class="headerlink" title="Suggested Reviewers"></a>Suggested Reviewers</h2><p>推荐审稿人一般选择当前投递文章所研究核心领域内的大牛，通常可以从已发表高水平论文的通讯作者中寻找。本文基于同步辐射原位显微CT技术研究长时低剂量中子辐照对铝合金材料力学性能的影响，推荐审稿人便可从辐照偏析、铝合金、X射线成像与CT三个主题方向寻找审稿人，注意投递力学、材料科学方向期刊时，科学往往高于技术，审稿人推荐勿太过侧重表征分析手段。推荐理由需包含：被推荐者是哪个领域的专家，做了哪些突出的工作，以及和本篇文章所研究内容有着怎样的关联性。合理且充分的推荐理由才能对Editor起到建议作用。在此列出四条示例：</p>
<ul>
<li><p>Prof. Li is an expert in solid mechanics. Using micro computed tomography (CT) and CT-based numerical modelling, he and his group have done excellent work on the structure—property relations of various engineering materials, especially on foams. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Hutchinson is an expert in materials science. He and his group have done cutting-edge work on the property and deformation mechanisms of Al alloys, especially on precipitate hardening. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Wang is an expert in nuclear engineering and materials science. He and his group have done excellent work on radiation-induced microstructural evolution and damage of various metal materials. His expertise is directly related to this manuscript. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Aydogan is an expert in nuclear engineering. She has done excellent work on radiation effects on microstructures and mechanical properties of various metal materials. Her expertise is directly related to this manuscript. She is surely suitable and capable of reviewing this manuscript.</p>
</li>
</ul>
<h2 id="Graphical-Abstract"><a href="#Graphical-Abstract" class="headerlink" title="Graphical Abstract"></a>Graphical Abstract</h2><p>Graphical Abstract为文章的图形摘要，作者需在极简的图表内高度概括论文中的研究内容和主要创新点，不言自明最为重要，这才能让人快速了解文章的主要创新点。</p>
<p><figure><img src="https://s1.ax1x.com/2022/10/26/xWfINn.png" alt="Graphical Abstract"><figcaption aria-hidden="true">Graphical Abstract</figcaption></figure></p>
<h2 id="Highlights"><a href="#Highlights" class="headerlink" title="Highlights"></a>Highlights</h2><p>Highlights为文章的主要亮点，与Graphical Abstract类似，作者需在极简的文字内归纳总结论文的主要亮点。 Elsevier规范中明确指出Highlights的书写规则：三到五条重点；每条重点只包含85个字元；只包含最重要的发现。Acta Materialia 投稿时不再需要附上Hightlights，但大部分期刊仍然需要，以H. Y. Li, et al. <em>Powder Technol.</em> (2020)为例：</p>
<ul>
<li>First in situ characterization of particle breakage in carbonate sands</li>
<li>Particle shape and intra-granular porosity affects breakage strength</li>
<li>Fractal dimension of crack networks increases with particle breakage extent</li>
<li>Cleavage along initial pores leads to crack branching</li>
</ul>
<h2 id="Response-Letter"><a href="#Response-Letter" class="headerlink" title="Response Letter"></a>Response Letter</h2><p>在期刊投稿中，首次录用的比例相对较小，大部分的文章都会进行小修或大修。无论是小修或大修，都需要按照审稿人意见逐条认真修改并回复。若审稿人问题存在误解或错误，也可进行客观平和的解释澄清。文章审稿意见回复是除Manuscript外最重要的信息，回复与修改质量直接关系到文章接受与否。一般情况下，审稿人的问题会出现几种情况：</p>
<blockquote>
<ol>
<li>文章格式&#x2F;文字&#x2F;图表标记错误<br>Response: We are very sorry for our incorrect writing and it is rectified at Line …. or We are very sorry for our negligence of the explanation.</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>不太同意审稿人的观点，轻度argue（合理修改和把握Argue分寸，即使你要argue也最好罗列一些你的进一步证据，或别的大牛的经典文章）<br>Response: We agree with you that…., however, …… or As Reviewer suggested that It is important to … However.</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>需要补充实验<br>Response: 做这个实验。对审稿人的意见表示赞同（We agree that more study or more data would be useful to）。如果实验结果能说明问题，则要把结果补充到论文中。反之，要展示、分析数据，告知审稿人已做此实验，但没有得到有价值的结果，并阐明原因。<br>没有实验条件，或者不能在短时期内做此实验怎么办？可以向审稿人表示后期如果条件成熟了，可能会进行审稿人说的相关研究，这部分可以写到discussion部分下的subchapter下的future improvement部分。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>论文创新性不强（对于这类关于创新不足的意见，一定要好好回复。一旦不被认可的话就会评判为文章没创新点，一个没有创新的文章，很难被录用。）<br>Response：谢谢您的意见。我们这篇论文原稿的引言部分没有把新意、重要性写清楚；鉴于此，我们已经加强了引言部分，把创新性强调出来。本文的创新性就在于……。首先还是要肯定审稿人说的对，他提出的方法或者已经存在的方法也很好，但本文的核心创新点在于和已经存在的方法不一样。适当的情况下可以比较下优缺点，加一些这方面的总结（觉得自己归纳的不好就别加了，以防弄巧成拙）。</li>
</ol>
</blockquote>
<blockquote>
<ol start="5">
<li>这句话有歧义。审稿人是读者的代表，既然他们会产生误解，那么其他读者也会有误解。因此，可以把涉及的句子重新变换一下，写得清楚一些。<br>Response：谢谢提醒。我们原本的写作的确会引起歧义，现在我们根据审稿人的意见修改如下……</li>
</ol>
</blockquote>
<p>在此列出第一次修改时的Response Letter实例：</p>
<blockquote>
<p><strong>Response to reviewer’s comments:</strong> “Deformation dynamics of a neutron-irradiated aluminum alloy: an <em>in situ</em> synchrotron tomography study” by H. W. Chai, D. Fan, J. C. Yuan, L. Hu, H. L. Xie, G. H. Du, Q. J. Feng, W. Zhou, J. Y. Huang, Ms. Ref. A-21-2294.</p>
</blockquote>
<blockquote>
<p>We appreciate the constructive remarks by the referee and have revised the manuscript accordingly. The comments raised are all addressed as follows. The revision details are marked in red (reviewer #1) and in blue (reviewer #2) in the revised manuscript.</p>
</blockquote>
<blockquote>
<p>Responds to the reviewers’ comments:</p>
</blockquote>
<blockquote>
<h3 id="Reviewer-1"><a href="#Reviewer-1" class="headerlink" title="Reviewer #1"></a>Reviewer #1</h3></blockquote>
<blockquote>
<p>Authors studied the mechanical behavior of an LT21 aluminum alloy form a decommissioned research reactor with in situ synchrotron micro-tomography. They developed particle tracking analysis technique to quantify the geometric features of the precipitates and pores, the history of the pores’ evolution under loading, and the displacement and strain fields. The new analysis technique is very interesting and the analysis is thorough. However, the reviewer found some analysis and conclusions might be questionable. It needs further discussions before the manuscript is accepted for the publication. Below are the questions.</p>
</blockquote>
<blockquote>
<ol>
<li>Although both the pore distribution and pore nucleation probability (Fig.9) show sharper peaks in the mode I region than that in the mode II region, the integrated pore number and the probability in the mode II region are much larger than that in the mode I region. The reviewer feels the authors’ argument of “pore nucleation contributes equally or more to porosity increase in the sample during stable plastic deformation, compared to pore growth” is not convincing. This might be related to the definition of $\xi_i$ in Eq.(16).<br>\begin{equation}<br>\xi_i &#x3D; \frac{(\overline\psi_i-1)V_{b,i-1}}{V_{b,i}-V_{b,i-1}},<br>\end{equation}<br>$\xi_i$ is defined as the ratio between the volumes of co-existing pores in two consecutive deformation stages. Multiplying ($\psi_i$-1) with total pore volume (including both existing and newly nucleated pores) has unclear physical meaning. In the pore analysis, all the pores in each stage were already sorted out according to their belonging regions (mode I and mode II), and pre-existing and newly nucleated pores were also cataloged. Therefore, the volume increases in mode I and mode II regions can be calculated directly. The reviewer suggests authors consider revising Eq.(16) to improve the analysis results.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer. The statements about irradiation-induced Si has been rewritten, see lines 204–205, page 13.</p>
</blockquote>
<blockquote>
<ol start="2">
<li>It would be helpful to provide the ratio between the volumes of the pores in mode I and mode II regions, and the ratio between the volume growths associated to modes I and II, in each stage.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The ratio between the volumes of the pores in mode I and mode II regions, and the ratio between the volume growths associated to modes I and II, in each stage, are calculated and presented in Fig.8d. The total and growth volume of pores in mode I is smaller than that in mode II throughout the deformation process. However, considering that the volume of mode I pore nucleation region is much smaller than that of mode II region, the density of pores in mode I region is much larger than that in mode II region. Clarification has been made in Fig.8d, and lines 410–415, page 27.</p>
</blockquote>
<blockquote>
<ol start="3">
<li>Please describe how the three parameters were chosen in Eq.(13).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. Clarification has been made in lines 446-448, page 29; lines 450–453, page 30.</p>
</blockquote>
<blockquote>
<ol start="4">
<li>In the last paragraph on page 31, it is said the flat segment in Fig.10(b) corresponds to the nucleation mode II. As seen in Fig.9(c), the population of new pores in mode II is much larger than that in mode I. In Fig.10(b), however, the population in the two ends is larger than that in the flat segment. Associating the flat segment in Fig.10(b) to mode II is controversial.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. Fig.9b has been revised to discuss the pore formation in mode I only. The pores involved are confined to the vicinity of the particles (spherical region of a radius of 9 $\mu$m). The U-shaped curves means that the pores are more prone to form at the upper and lower ends of the particles. Clarification has been made in lines 418–423, pages 27–28; lines 426–428, page 29.</p>
</blockquote>
<blockquote>
<ol start="5">
<li>Eq.(9) needs a reference.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Eq.(4) is not cited from a reference and derived as follows according to the theory of probability.<br>Assuming that the sample is infinitely large ($V_{\rm s}\to+\infty$) and contains only one particle, the cumulative probability that a single pore is randomly formed outside a spherical region of radius $L_{\rm b}$, $G_{\rm s}$ can be described as<br>\begin{equation}<br>G_{\rm s}(L_{\rm b}) &#x3D; 1-\frac{4\pi L_{\rm b}^3}{3V_{\rm s}}.<br>\end{equation}<br>As for a multiple-particle system, considering that a single pore randomly formed outside the spherical region of radius $L_{\rm b}$ of each particle are independent events, the cumulative probability of random pore formation for all particles is calculated according to the multiplication rule, as<br>\begin{equation}<br>G_{\rm m}(L_{\rm b}) &#x3D; \lim_{V_{\rm s}\to+\infty}\left(1-\frac{4\pi L_{\rm b}^3}{3V_{\rm s}}\right)^{V_{\rm s}\rho_{\rm a}},<br>\end{equation}<br>where $V_{\rm s}\rho_{\rm a}$ refers to the number of particles, and $\rho_{\rm a}$, the volume density of particles.<br>Then, the cumulative probability of random pore formation inside the spherical region of radius $L_{\rm b}$ of all particles is<br>\begin{equation}<br>G_{\rm II}(L_{\rm b}) &#x3D; 1-G_{\rm m}(L_{\rm b}),<br>\end{equation}<br>and the probability density of pore formation via mode II is the derivation of $G_{\rm II}(L_{\rm b})$ over $L_{\rm b}$.<br>Clarification has been made in lines 391–404, pages 26–27.</p>
</blockquote>
<blockquote>
<ol start="6">
<li>Fig.7 needs color legends.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. The color in Fig.6 refers to particles (blue) and pores (red), respectively. Clarification has been made in the caption of Fig.3a and b, Fig.4c and Fig.6.</p>
</blockquote>
<blockquote>
<ol start="7">
<li>Fig.4(b) is described as volume rendering in the caption but as surface rendering in the context (last paragraph on page 18).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Corrected. See lines 270, page 17.</p>
</blockquote>
<blockquote>
<ol start="8">
<li>What is the typical thickness of $\beta$-AlFeSi? Can $\beta$-AlFeSi be resolved in micro-tomography?</li>
</ol>
<p><font color="#80b1d3">Response</font>: According to the SEM and TEM images, the typical thickness of $\beta$-AlFeSi is 0.5–8 $\mu$m. Thus $\beta$-AlFeSi can be resolved by the micro-CT here. In the CT characterization, the needle-shaped Fe-based particles (elongation index less than 0.4) are taken as $\beta$-AlFeSi. The spatial distribution and equivalent cross-sectional diameter distribution of these particles are presented in Fig.R1. Clarification has been made in lines 217–218, page 14.<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/26/xfiik9.png" width="85%" alt="Fig.R1 (a) Spatial distribution of $\beta$-AlFeSi particles observed by micro-CT technique; (b) A typical $\beta$-AlFeSi particle; (c) Equivalent cross-sectional diameter distribution of $\beta$-AlFeSi particles." align=center /></p>
</blockquote>
<blockquote>
<ol start="9">
<li>It seems that there are correlations in the diameter distributions, sphericities, elongation indices, and flatness indices between pores and particles. Can authors give some discussions on the possible reasons?</li>
</ol>
<p><font color="#80b1d3">Response</font>: Good question. The corresponding statements have been deleted. Since the particles in the sample are not fully accounted (only Fe-based particles), the shape and orientation distributions for the particles are removed.</p>
</blockquote>
<blockquote>
<ol start="10">
<li>On page 12, it is said “Both types of AlFeSi particles exist in the irradiated LT21 Al alloy.” Is this statement made based on Fig.1(a) or 1(b)?</li>
</ol>
<p><font color="#80b1d3">Response</font>: This statement is originally made based on the CT characterizations. Plate-shaped and needle-shaped particles are observed in CT images, and are taken as $\alpha$-AlFeSi and $\beta$-AlFeSi, respectively. In the revised manuscript, TEM images are supplemented to characterize the two types of AlFeSi particles (Fig.2c, g and h). Clarification has been made in lines 216–217, pages 13–14.</p>
</blockquote>
<blockquote>
<ol start="11">
<li>The descriptions of Fig.1(a) in the figure caption and context are different.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. We remade Fig.1 and updated the corresponding description.</p>
</blockquote>
<blockquote>
<ol start="12">
<li>In the total received dose, except of thermal neutrons and fast neutrons, what is the energy distribution of the rest portion of neutrons?</li>
</ol>
<p><font color="#80b1d3">Response</font>: The rest portion of neutrons is labeled intermediate neutrons. The dose of the intermediate neutrons is about $5.40\times10^{20}$ n&#x2F;cm$^{-2}$. Clarification has been made in lines 167–171, pages 11–12.</p>
</blockquote>
<blockquote>
<ol start="13">
<li>In X-ray imaging, the resolution is not defined as pixel size. Please revise the resolution statement on page 9.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The voxel size is 0.87 $\mu$m, and three-dimensional spatial resolution is quantified as about 3 $\mu$m. Clarification has been made in lines 127-128, page 9.</p>
</blockquote>
<blockquote>
<p>Based on the above concerns, the reviewer recommends major revision of the current manuscript.</p>
</blockquote>
<blockquote>
<h3 id="Reviewer-2"><a href="#Reviewer-2" class="headerlink" title="Reviewer #2"></a>Reviewer #2</h3></blockquote>
<blockquote>
<p>This manuscript is an ambitious analysis of the microstructural features underlying the tensile deformation of an irradiated aluminum alloy. The analysis technique, CT construction of the 3D image of internal precipitates and pores using a synchrotron beam is unique for metallographic applications. The paper also employs a number of analysis techniques developed for CT constructions that classify the microstructural characteristics of the defect structures based on size and morphology. This approach adds significant statistical information about the distribution and types of the defect structures and their influence on tensile deformation.</p>
</blockquote>
<blockquote>
<p>The paper covers a number of related areas, but seems extremely lengthy for the sake of presenting the results. There are also a number of gaps in the presentation and analyses that need to be addressed. These are described individually in the following paragraphs.</p>
</blockquote>
<blockquote>
<ol>
<li>The authors do not provide either the material composition or the irradiation temperature conditions. Without this baseline information, it is not possible to interpret many of the results in the study.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The material composition of the unirradiated and irradiated LT21 Al alloys is provided in Tabel.1. The irradiation temperature conditions are provided in the revised manuscript. The target is put in cooling water during irradiation, and the irradiation temperature fluctuates between 20 $^\circ$C and 40 $^\circ$C. Clarification has been made in lines 171–177, page 12, and lines 180–183, page 12.</p>
</blockquote>
<blockquote>
<ol start="2">
<li>The authors do cite a number of relevant studies, but by comparison to a paper by Farrell and King (<a href="https://www.osti.gov/servlets/purl/6886356">https://www.osti.gov/servlets/purl/6886356</a> this is only one of several similar studies by Farrell et al.), the levels of displacement damage (i.e. displacements per atom) and the conversion of Al to Si through the neutron capture reaction are very small. For the stated irradiation conditions, the level of damage should be insignificant. Since the authors provide no information on the unirradiated material or the temperature, it is not possible to determine the whether or not the microstructure is a consequence of the irradiation exposure or just a thermal aging problem. The paper cites 4.3$\times$10$^{20}$ n&#x2F;cm$^2$ ($&gt;$0.1 MeV) or 4.3$\times$10$^{24}$ n&#x2F;m$^2$ ($&gt;$0.1 MeV) might be 0.6 dpa and 0.01% (or 100 ppm) Si formation.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We supplement the EDS, EBSD, XRD and CT characterizations of the material before irradiation and the TEM characterizations on the irradiated material, as presented in Figs.1, 2 and 3. The grain size of the irradiated material is slightly larger than that of the unirradiated material (60 $\mu$m versus 50 $\mu$m). EBSD and EDS characterizations (Fig.1) show that the areal density of Si particles is higher in the irradiated material than in the unirradiated material, probably due to irradiation-induced transmutation and precipitation. In addition, the shape of AlFeSi particles are largely needle-shaped in the irradiated material, while largely plate-shaped in the unirradiated material. CT characterizations (Fig.3) show that the size of pores and particles in the irradiated material becomes larger than that in the unirradiated material. The shape of pores deviates further away from spheres and becomes more anisotropic. The orientations of pores become more aligned in the irradiated material. TEM images along with EDS characterizations show that nanoscale needle-shaped Mg$_2$Si particles appear in the irradiated material. Therefore, long-term irradiation here indeed induces considerable microstructural changes in the LT21 Al alloy. Clarification has been made in lines 184–185, page 12; lines 193–200, page 13; lines 208–231, pages 13–16.</p>
</blockquote>
<blockquote>
<ol start="3">
<li>The authors do mention the resolution of their technique at about 3 $\mu$m or 3$\times$10$^3$ nm, which is large for typical irradiation-induced pores (i.e. voids or bubbles) for low dose irradiations. Since the gas content or possible hydrogen uptake of the material is not known, it is not possible to claim that the pores are irradiation-induced. Again, a comparison with the work of Farrell, voids at the dose level reported here should be smaller than the resolution limit (~3 $\mu$m) for this technique.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We agree that irradiation is unlikely to induce formation of new pores visible to the micro CT, but irradiation induces growth of existed pores and particles in the unirradiated material as revealed by the CT characterizations (Fig.3c). Clarification has been made in lines 235–242, page 16; lines 249–263, pages 16–17.</p>
</blockquote>
<blockquote>
<ol start="4">
<li>The analysis in Figure 1 is also questionable. Since the figures are 2D surface images, there is no way to tell the depth of grains in the third dimension. So the distance from a visible grain boundary in EBSD does not necessarily indicate the real 3D distance from grain boundaries below the surface. This would only be possible with taking several polished sections to remove layer after layer of the surface to reveal grain depths. Further, there are several grains in the figure which are smaller than 100 $\mu$m, so the characterization of distance from the boundary is falsely skewed toward the lower numbers. This probability distribution analysis should be removed.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The probability distribution and the corresponding statements has been removed.</p>
</blockquote>
<blockquote>
<ol start="5">
<li>In addition, the comment about Si clusters former near the grain boundaries needs to be supported by a mechanism. The Si formed during the neutron irradiation is formed uniformly throughout the bulk material. Segregation and clustering at the grain boundaries would require a thermal process or based on radiation-enhanced diffusivity (RED) which is not analyzed here. The comments (near the bottom middle of page 13) “Al to Si particles tend to concentrate near grain boundaries and particle interfaces” is not supported by any analysis.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The comment about Si clusters forming near the grain boundaries has been removed. See lines 196–197, page 13.</p>
</blockquote>
<blockquote>
<ol start="6">
<li>The information in Fig.2 is also suspicious. First, it is unlikely that both the pores and precipitates have the same morphologies and characteristics. The authors are only able to extract precipitate information for the AlFeSi particles (page 14) and only use those for analysis. The removed any useful information about the Mg2Si phase, which is a major contributor to the tensile strengthening process (again see Farrell’s papers).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The shape and orientation distributions for the precipitates are removed and only those for the pores are presented in Fig.7.</p>
</blockquote>
<blockquote>
<ol start="7">
<li>In any case the information presented in Fig.2 is also constrained by the ~3 $\mu$m resolution limit of the technique, and unlikely to be irradiation-induced microstructure.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We supplement the EDS, EBSD, XRD and CT characterizations of the material before irradiation and the TEM characterizations on the irradiated material, as presented in Figs.1, 2 and 3. Such characterizations show that long-term irradiation here indeed induces considerable microstructural changes in the LT21 Al alloy. Clarification has been made in lines 184–185, page 12; lines 193–200, page 13; lines 208–231, pages 13–16.</p>
</blockquote>
<blockquote>
<ol start="8">
<li>The analysis in Figure 2 and at the bottom of page 14 is also problematic. The technique does not distinguish grain boundaries, so there is no way to determine if the precipitate shape is associated with planar, disk or needle-like growth at the grain boundaries.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer. All discussions about grain boundaries with the micro CT have been removed or corrected. Clarification has been made in lines 249–263, pages 16–17.</p>
</blockquote>
<blockquote>
<ol start="9">
<li>The particle tracking development for analyzing the deformation characteristics is a useful inclusion.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thank you.</p>
</blockquote>
<blockquote>
<ol start="10">
<li>The pore and particle tracking and growth in Fig.4 is useful. However, the authors should show pore void densities at various elevations. The figure seem to indicate that the pore growth initiates near the bottom of the selected volume between 0.09 and 0.14 strain and travels upward as the stain level increases. The authors need to explain the apparent movement of pore growth with increasing strain. This observation is also supported by the information in Figure 5 in the strain field images.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The pore density distribution is calculated and presented in Fig.R2, and is similar to the porosity distribution shown in Fig.7a. The movement of the pore growth region with increasing strain is attributed to the loading geometry. In the <em>in situ</em> CT experiment, the lower loading collet is fixed while the upper collet moves upwards to load the sample. The field of view for CT is fixed as well. The global deformation of sample thus results in an upward movement of the pore growth region. Nevertheless, the movement of the pore growth region is negligible when necking occurs in the sample. Clarification has been made in lines 131–134, page 9.<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/26/xfiG1P.png" width="50%" alt="Fig.R2 The pore number density distributions along the sample height at different strains." align=center /></p>
</blockquote>
<blockquote>
<ol start="11">
<li>The result of the displacement $u_z$ in Fig.5 are unclear. The authors do now sufficiently explain the meaning of these results. If they are the displacement vectors of the particles, there is no sense in showing very high particle displacement in the upper end of the specimen once necking occurs.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. Strain localizaitons or high displacement gradients occur in the necking region, instead of displacement localizations. In our loading geometry, the largest displacement always appear at the upper end of sample due to continuous movement of the upper collet. Clarification has been made in capture of Fig.5(a), and lines 280–281, page 19.</p>
</blockquote>
<blockquote>
<ol start="12">
<li>The sections on pore evolution and forward need to be removed. Since the resolution of the process does not account for existing microstructure below ~3 um in diameter, there is no basis for counting pore evolution or pore nucleation. The pores that seem to be ‘nucleated’ are most probably pores that are too small to resolve before the deformation process. Thus, they are not nucleated. The observations in Figure 7 of new pores are probably ones that were below the resolution limit.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer that pore nucleation cannot be resolved by the micro-CT here. The corresponding statements have been revised or removed. We have stated clearly that only pores larger than 3 $\mu$m (observable) are accounted in the revised manuscript. All the discussions are made on this basis. Clarification has been made in line 303–306, page 20; lines 316–317, page 21; lines 354–356, 361, 364, 365, 372, and 374, page 24.</p>
</blockquote>
<blockquote>
<ol start="13">
<li>Figure 6 a should be remove since there is no sense in the general pore faction once the UTS is reached. Figure 6b could be kept, but again, there should be some information about the shift in the necking region from lower in the sample to its final position. In addition, this figure should be done in absolute numbers not in ‘probablity.’ These are not probabilities (this should be changed in many other places).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. Fig.6a has been removed. The shift of the necking region is attributed to the loading geometry, as explained in the question 10. The ‘probability’ has been replaced with ‘fraction’ in the corresponding figures and statements.</p>
</blockquote>
<blockquote>
<ol start="14">
<li>The information in Figure 8 shows very little differences between deformed and undeformed or even as a function of strain level. There is no reason to include data for strains beyond 0.09 since 0.14 is past the UTS and the changes should be localized to the neck. The fact that there is no real change at the higher strain levels highlights this problem. The strains above 0.09 should be removed from the plot since they represent very highly localized processes and are washed out over the entire specimen length.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. After UTS occurs in the sample, the structural information of the necking region (0.6 mm to 1.8 mm height range) is used for statistical analysis. Clarification has been made in Fig.7, and lines 335-336, page 23.</p>
</blockquote>
<blockquote>
<ol start="15">
<li>The section on ‘Nucleation of pores’ should be removed since there is no evidence of real nucleation. The information in Fig 9 is not useful without more microstructural information below the ~3 um resolution limit. The peaks could well be due to irradiation-induced small voids which are entirely different from the ‘pores’ described in the graphs</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer that pore nucleation cannot be resolved by the micro-CT here. Nucleation&#x2F;nucleate has been revised to formation&#x2F;form or removed in the revised manuscript. Formation has been defined to include pores  We have stated clearly that only pores larger than 3 $\mu$m (observable) are accounted in the revised manuscript. All the discussions are made on this basis.</p>
</blockquote>
<blockquote>
<ol start="16">
<li>The very long section nucleation theory should be removed. It also has no basis from the resolution limit of the technique. Fitting data for nucleation in the necking region for strains greater than 0.09 also doesn’t make sense. The authors do not consider the triaxiality of the stress under the high necking strain conditions. Even for lower strain levels, the Poisson’s compressive stresses in the y and z directions are not accounted for. The values in Fig.10 only deviate from the original for strains higher than 0.09, where the model is inappropriate. The fact that the failure is shear oriented, means that the shear strains are dominate, not the normal strains. This is also a failing of the modeling effort. There is also a major objection to showing data down to the 0 um level which occurs in some of the analysis plots.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. The nucleation theory including corresponding formulas and statements has been removed. The data involving distances below 3 $\mu$m are also removed.</p>
</blockquote>
<blockquote>
<ol start="17">
<li>The modeling also does not account for the grain boundary influences on pore nucleation and growth. The authors also invoke dislocation mechanisms to help explain nucleation theory, but there are no measurements here.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. EBSD characterizations on the postmortem irradiated samples have been added to discuss the effects of grain boundaries. The modelling for mode I nucleation has been removed. Clarification has been made in Fig.11, and lines 490–506, pages 32–34.</p>
</blockquote>
<blockquote>
<ol start="18">
<li>The major failing of this paper is that it does not have accompanying microstructural information for the length scales below the synchrotron resolution limit. The paper could be useful if it were combined with a substantial amount of TEM work to look at scales down to the nano-meter range.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. CT characterization is superior in its 3D and quantitative features, compared to the SEM and TEM which can achieve high resolutions. TEM characterizations on the irradiated sample prior to loading and EBSD characterizations on the postmortem irradiated sample are added in the revised manuscript. See Figs.2 and 11, respectively.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>以 Acta Materialia 期刊为例，Reference 的书写规范中作者名需以逗号隔开，姓名缩写形如 H. W. Chai，文章标题以逗号结尾，期刊名采用 ISO4 标准期刊缩写，结尾需标注期刊刊号，年份，页码信息。</p>
<p><font size= 2>[1] K. Farrell, J. Bentley, D. N. Braski, Direct observation of radiationinduced coated cavities, Scr. Metall. 11 (3) (1977) 243–248.</font></p>
<h2 id="Declaration-of-Interests"><a href="#Declaration-of-Interests" class="headerlink" title="Declaration of Interests"></a>Declaration of Interests</h2><p>声明本文作者没有已知的竞争经济利益或个人关系，可能会影响本文中所涉及的科研成果。一般只需在第一条中打勾，如存在竞争关系方，可在第二项中注明。</p>
<ul>
<li><p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
</li>
<li><p>The authors declare the following financial interests&#x2F;personal relationships which may be considered as potential competing interests.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Scholarship, Writing and Mindset</category>
      </categories>
      <tags>
        <tag>Acta Materialia</tag>
        <tag>Scholarship</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔</title>
    <url>/Exp011-book01/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMXvV.png"></p>
<blockquote class="blockquote-center">
<p>大二时拜访友人，从合肥乘火车哐当哐当摇晃去上海，感叹前路迷蒙自身渺小，途中随笔。如今面临学生向老师的身份骤变，不觉时光如梭，如梦如幻。 </p>

</blockquote>

<p>这些年路大部分都是自己一个人走的，车是一个人坐的，所以常常靠拿着一本书看，好把时间打发过去。去上海的路上，我在火车上看到两个孩子，正巧我在读这本$\lfloor$平凡的世界$\rceil$。这两个孩子一开始友好的互相讲故事，然后开始吹牛，最后小男孩和小女孩竟然吵起了架。</p>
<span id="more"></span>

<p>过早的怀旧或许意味着衰老。但是有些人就喜欢怀旧，同时也喜欢向前生活。我自己还是小孩子的时候，跟别人说话时也会因为一些小事就发脾气吵起来，后来我自己找到了一种方法就是规避，所以从小到现在还跟我关系还不错的就只有几个人，很多人我连名字都忘记了。回来的时候在科大晃了好几天，和朋友老师都吃了饭，在空旷的视野里，本科生活的流逝时时令人不舍。</p>
<p>我想自己最近才把注意力放在一个叫做世界观的东西上。只是现在的我，就像从前的我一样，依然那么狭隘。我常常想着出去走走，去看一些东西，去体会一些东西 ，然后仿佛我的思路会开阔起来。只是偶尔想想这二十年的路，自己思考的其实还是太少。以至于以前茫然的东西，到现在好像还是茫然，以前清楚的东西，现在反而变得糊涂了。</p>
<p>好像Ph.D七年还是很遥远的东西，每次大家一起说这个的事情的时候都会不忘记幽默一下这个只是理论上的数字。跟家里亲戚吃饭，他们都指着我说这个人在某某大学里面。我点了点头，确实某某大学是个让我还算满意的大学，但是他们不在我的世界里，不知道我在关心着什么，又在担心着什么。转眼一想，确实四年的大学生活过得会非常快。</p>
<p>车上的小孩子一直都在吵，然后两家的大人们都笑着在旁边起哄。我有时候觉得小朋友的想法确实很有创意，只是我自己回不到我自己小时候的脑子里。现在记忆最深的，就是一滴墨水滴进清水里的画面，曾经看过一篇文章花了好长的篇幅来描写这个画面，具体的描述已经记不清，后来这种效果被渲染进了电视的广告里。往往这些过程带着一点哲学的韵味，不仅仅是墨水在水里面散开的过程，还有小孩子们在争吵这件事，大人的世界和小孩子的世界有着明显的决裂。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>另一种选择</title>
    <url>/Exp012-book02/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUDbcT.png"></p>
<blockquote class="blockquote-center">
<p>“如果必须坠落，就让我坠落。 我将会成为的那个人，一定会接住我。” —— Sheryl Sandberg </p>

</blockquote>

<p>近日梦断魂销之际，友人推荐 Facebook 前首席执行官 Sheryl Sandberg 在丈夫去世的极度悲痛之中所著的$\lfloor$另一种选择$\rceil$。Sheryl Sandberg 敞开心扉，从她发现丈夫猝然倒在健身房的地板上开始，描述了丈夫去世后感受到的极度悲伤与孤独。然而，本书并没有局限于作者的个人经历，而是与 Adam 关于培养复原力的开放性研究结合起来，深入探讨了我们该如何克服人生中的逆境，包括疾病、失业、性侵、自然灾害、战争、暴力等不幸。同时，来自不同群体的案例也揭示了每个人都可以培养及提升内在坚韧的复原力，并且拥有重获快乐的能力。</p>
<p>本文记录于 2025 年春节，一个月前我已辞去中物院成都科学技术发展中心兼职特聘研究员，并决定在学校恢复工作后从西南交通大学辞职。在即将正式与过去作别之际，特作此文记录我近十年的人生历程。无论是蹉跎往日，还是做出艰难抉择的今天，我都清醒地意识到感情丰富是强者的大忌，但仍无法避免沉沦的命运。或许只有经历过起起伏伏、深刻痛苦的人才能体会 Sheryl Sandberg 的感受，坚持走过坎坷的人才更能理解其中的勇敢、真挚、温暖和希望。</p>
<span id="more"></span>

<h2 id="相遇"><a href="#相遇" class="headerlink" title="相遇"></a>相遇</h2><p>2015年10月，我在中国科大物理学院就读大四，刚刚获得我将为之奋斗九年的研究所提供的保研资格。这份保研资格恰如命运的钥匙一般打开了故事的大门。</p>
<p>我虽然通过中学物理竞赛进入科大，但这样的来历在物理学院实在算不上稀奇。仗着中学时积累的数理基础，有恃无恐地游戏人生三年，英雄联盟打上了王者，平均绩点（Grade Point Average，GPA）也一落千丈。大三的暑假小学期后，学院统计保研资格时，保研线戏剧性地切在我和另一位同学陈森的头顶，我与陈森的GPA并列在保研线下第一。无法直接拿到学校的保研资格，我们不得不寻求能够提供保研资格的研究所作为读博的去处。我先后联系了天文学系的星系宇宙学实验室、近代物理系的磁共振实验室、北京的电子所、上海的应用物理研究所、合肥的等离子体所等。相对不错的研究所都存在约束条件，而能确保录取的去处科研环境都较差。犹豫不决之际，我求助了大三时打了一些零工的串节磁镜KMAX实验室的孙玄教授。孙玄教授告诉我，他的一位朋友罗教授，在美国深造多年，刚刚回国在成都创办研究所，可以提供保研名额，科研能力很强，建议我到这里试试。</p>
<p>于是机缘巧合的，我与陈森、力学院的张森共同来到了罗老师的电话面试会议。我后来了解到团队希望招聘一位力学院的学生承担有限元仿真的研究工作，两位物理学院的学生分别探索小角X射线散射（Small Angle X-ray Scattering，SAXS）及层析成像（Computed Tomography，CT）方向。然而罗老师团队面试时只从流体所争取到了两个保研名额。三选二的较量中，综合素质较强的陈森在电话面试的表现上远胜于我，我第一次落败。流体所的秘书向我表示罗老师希望三人都被录取，回去后将会争取额外的名额，行与不行一周内都将通知我。在等待的时间里，我马上飞往北京求见电子所的某位长江学者，在得到认可的答复后我终于得到片刻安心，回到合肥。一周后，我接到了来自成都的电话，电话那头的苟雪老师告知我罗老师团队争取到了额外的名额，我可以加入团队。在对比考虑后，我最终决定保研向罗老师团队。</p>
<p>关于研究方向的分配问题，力学院的张森当然是承担有限元仿真工作。大约是考虑我过去简单探索的$\lfloor$磁共振成像反卷积重建方法$\rceil$与CT方向的契合程度，我最终被确定在CT方向上，而陈森则被安排承担SAXS方向相关工作。</p>
<p>2015年12月，在我完成了最后一门课程$\lfloor$广义相对论$\rceil$的期末考试后，鄂俊成师兄招呼我和陈森年前来成都学习适应，于是我立即买票赶往成都。但临近春节，合肥直达成都的火车票早已售空，我只好买了一张合肥到汉口转成都的车票。夜间到达汉口站后，还需要等待天亮后发车的动车，我不得不在汉口站内硬捱到早晨上车。那一夜，汉口站内泡面的香气、无人值守但仍亮着灯的周黑鸭店铺、穿着邋遢席地而睡的赶路人、小孩的哭闹声以及站外不断呼唤着的“宾馆走不走”“宾馆走不走”的吆喝声，陪伴着即将迎接未知新生或激动、或忐忑、或慌张的我的情景，在往后的人生中无数次出现在我的梦境里。</p>
<p>“从成都的火车北站下车，出火车北站后向右走会看到人行天桥楼梯，上到天桥后买票乘坐任意一路快速公交向西两站后在西南交通大学站下车。找到西南交通大学的大门，我会到这里来接你。”鄂俊成师兄在QQ上对我如是说。在学校的大门口我第一次见到了至今仍然崇拜的鄂俊成师兄，第一眼看上去相貌不算出众，但却有远胜于外表的自信溢出身形。跟着鄂师兄进入大门，穿过一段环形公路，经印有西南交大校训的高楼和形似巴普洛夫楼的老楼间的小路，走进另一栋老楼机械馆的大门，穿过一段破败的长廊后乘电梯来到四楼，眼前仿佛电影里的现代化办公实验环境让人眼前一亮。</p>
<p>到达实验室已经是下午四点多，鄂师兄向我介绍了黄佳伟师兄，同样来自科大物理学院，是比我大一届的师兄。由于陈森所在的微电子系的最后一门期末考试比天文学系早了一周，陈森早已在研究所报道。简单拜会罗老师后，我和陈森两人在交大北门外的$\lfloor$很牛的馆子$\rceil$吃了一顿晚饭，并买好床上用品，在眷诚斋15栋办理好入住。西南交大为研究所学生预留了两间宿舍，但师兄们都在校外租了房子，只有陈森和我两个人住在宿舍。那时眷诚斋还没有安装空调和暖气，只有挂在宿舍中央的一个小风扇。第一个冬天着实把在合肥享受惯了暖气的我俩冻的够呛。</p>
<p>安顿好生活问题后，第二天来到实验室，鄂师兄向我明确了后续的研究方向并交给我一台高性能图形分析工作站。</p>
<p>我与罗书璇相识于2016年春节前夕，研究所内李博博士的婚礼宴席上。我刚来研究所不到还没有坐热板凳，李博老师便组织大家集体参加他的婚礼。在前一天夜里，陈森和我两人在宿舍里商量第二天随份子钱随多少的</p>
<h2 id="相知"><a href="#相知" class="headerlink" title="相知"></a>相知</h2><p>###################################### 代补充 ######################################</p>
<p>2020年3月，在黄俊宇老师的支持下，一份对聚甲基丙烯酰亚胺（Polymethacrylimide，PMI）航空泡沫结构性能关系研究的工作在被 <em>Acta Mater.</em> 拒稿后发表在了力学顶刊 <em>Int. J. Plast.</em> 上。</p>
<h2 id="沉沦"><a href="#沉沦" class="headerlink" title="沉沦"></a>沉沦</h2><p>2021年8月，在我和罗老师</p>
<h2 id="曲终人散"><a href="#曲终人散" class="headerlink" title="曲终人散"></a>曲终人散</h2><p>###################################### 代补充 ######################################</p>
<h2 id="最后附上-Sheryl-Sandberg-与丈夫的结婚誓言："><a href="#最后附上-Sheryl-Sandberg-与丈夫的结婚誓言：" class="headerlink" title="最后附上 Sheryl Sandberg 与丈夫的结婚誓言："></a>最后附上 Sheryl Sandberg 与丈夫的结婚誓言：</h2><blockquote>
<p><font color="#B5B5B5">I take you to be mine in love. I promise to love you deliberately each day, to feel your joy and your sorrow as my own. Together, we will build a home filled with honor and honesty, comfort and compassion, learning and love. I take you to be mine in friendship. I vow to celebrate all that you are, to help you become the person you aspire to be. From this day forward, your dreams are my dreams and I dedicate myself to helping you fulfill the promise of your life. I take you to be mine in faith. I believe that our commitment to each other will last a lifetime, that with you, my soul is complete. Knowing who I am and who I want to be, on this day of our marriage, I give you my heart to be forever united with yours.</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5">我将你视为我的挚爱。誓言每天都有意识地爱你，把你的喜怒哀乐视作自己的喜怒哀乐。我们将共同建立一个充满荣誉和诚实、舒适和同情、学习与爱的家庭。我将你视为我的朋友，誓言赞美你的一切，帮助你成为你渴望成为的人。从今天起，你的梦想就是我的梦想，我致力于帮助你实现你的人生承诺。我确信你是我的。我确信我们对彼此的承诺将持续一生，有了你，我的灵魂才是完整的。此刻我知道我是谁，也知道我想成为谁，在我们结婚的这一天，我把我的心交给你，愿我的心永远与你相结合。</font><br/></p>
</blockquote>
<p>只道是人生遗憾。莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>部分开放基因数据库</title>
    <url>/Exp013-GeneDataset/</url>
    <content><![CDATA[<p><img src="https://i0.wp.com/sangerinstitute.blog/wp-content/uploads/2023/08/what-is-a-gene-1440-540-1.jpg?fit=1440,540&ssl=1"></p>
<p>基因是编码蛋白质的DNA碱基对序列，蛋白质是细胞和身体的基石。基因编码蛋白质结构。很简单，是吗？但是，深入到分子的细节，很快就会变得复杂起来。在二十一世纪初的机器学习时代，学界已经充分挖掘了短基因序列内的片段间的关联关系及其与宏观性状表达间的映射；2017年兴起的人工智能序列大模型依赖 Transformer 架构实现的超长上下文关联分析能力让人类对更长尺度的生命密码解读提供了可能。</p>
<p>人工智能大模型效能与模型参数规模和喂养的数据量强相关。笔者曾先后向湖南农业大学、深圳大学、重庆医科大学等数位基因组学方向的学者请教学界开放的海量基因数据的获取途径，并查阅了一些书籍及互联网资料，本文对部分开放基因数据库做简单的归纳整理。</p>
<span id="more"></span>

<h2 id="NCBI-GenBank-综合性基因数据库"><a href="#NCBI-GenBank-综合性基因数据库" class="headerlink" title="NCBI GenBank 综合性基因数据库"></a>NCBI GenBank 综合性基因数据库</h2><p>GenBank <a href="https://ftp.ncbi.nlm.nih.gov/"><font color="#80b1d3">[Link]</font></a> 是由美国国家生物技术信息中心（National Center for Biotechnology Information, NCBI）维护的全球最大、最权威的公开核酸序列数据库，与欧洲分子生物学实验室（EMBL’s European Bioinformatics Institute, EMBL-EBI）和日本DNA数据库（DNA Data Bank of Japan, DDBJ）共同组成国际核酸序列数据库合作联盟（International Nucleotide Sequence Database Collaboration, INSDC），三方数据每日同步更新。</p>
<p>GenBank 存储DNA、RNA和蛋白质序列，包括基因组、转录组、EST（表达序列标签）、专利序列等。数据来自全球科研机构、测序中心、个人研究者的提交，所有数据可免费下载和分析。新提交的序列会快速纳入数据库并每日公开更新。GenBank 的数据按类别组织，主要包括以下子数据库：</p>
<p><strong>（一）核心核酸序列数据库</strong>：</p>
<blockquote>
<p>标准序列记录：包含基因、mRNA、非编码RNA等。</p>
<p>全基因组测序（WGS）：存储未完全组装的基因组数据。</p>
<p>转录组 shotgun 组装（TSA）：基于RNA测序的转录本数据。</p>
</blockquote>
<p><strong>（二）特殊子数据库</strong>：</p>
<blockquote>
<p><a href="https://www.ncbi.nlm.nih.gov/refseq/">RefSeq参考序列数据库</a>：高质量、非冗余的基因组、转录本和蛋白质参考序列，由NCBI人工或自动注释。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/snp/">dbSNP单核苷酸多态性数据库</a>：存储SNP（单核苷酸多态性）、INDEL（插入缺失）等遗传变异数据。</p>
<p>dbEST表达序列标签数据库：存储cDNA测序得到的短片段（EST），用于基因发现和表达研究。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/sra">Sequence Read Archive, SRA</a>：存储高通量测序（如Illumina、PacBio）的原始数据（FASTQ&#x2F;BAM格式）。</p>
</blockquote>
<p>每条GenBank记录包含以下关键信息：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       (序列名称、长度、类型)  </span><br><span class="line">DEFINITION  (简要描述)  </span><br><span class="line">ACCESSION   (唯一标识号，如KM123456)  </span><br><span class="line">VERSION    (版本号，如KM123456<span class="number">.1</span>)  </span><br><span class="line">KEYWORDS   (关键词)  </span><br><span class="line">SOURCE     (物种来源)  </span><br><span class="line">  ORGANISM (分类学信息)  </span><br><span class="line">REFERENCE  (参考文献)  </span><br><span class="line">FEATURES   (注释信息，如基因、CDS、启动子等)  </span><br><span class="line">ORIGIN     (实际序列)</span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       NM_001301717           <span class="number">2372</span> bp    mRNA    linear   PRI <span class="number">05</span>-JUN<span class="number">-2018</span></span><br><span class="line">DEFINITION  Homo sapiens zinc finger protein <span class="number">717</span> (ZNF717)<span class="punctuation">,</span> mRNA.</span><br><span class="line">ACCESSION   NM_001301717</span><br><span class="line">VERSION     NM_001301717<span class="number">.1</span></span><br><span class="line">KEYWORDS    RefSeq.</span><br><span class="line">SOURCE      Homo sapiens (human)</span><br><span class="line">  ORGANISM  Homo sapiens</span><br><span class="line">            Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;</span><br><span class="line">            Mammalia; Eutheria; Euarchontoglires; Primates; Haplorrhini;</span><br><span class="line">            Catarrhini; Hominidae; Homo.</span><br><span class="line">FEATURES             Location/Qualifiers</span><br><span class="line">     source          <span class="number">1.</span><span class="number">.2372</span></span><br><span class="line">                     /organism=<span class="string">&quot;Homo sapiens&quot;</span></span><br><span class="line">                     /mol_type=<span class="string">&quot;mRNA&quot;</span></span><br><span class="line">                     /db_xref=<span class="string">&quot;taxon:9606&quot;</span></span><br><span class="line">     gene            <span class="number">1.</span><span class="number">.2372</span></span><br><span class="line">                     /gene=<span class="string">&quot;ZNF717&quot;</span></span><br><span class="line">     CDS             <span class="number">123.</span><span class="number">.1505</span></span><br><span class="line">                     /gene=<span class="string">&quot;ZNF717&quot;</span></span><br><span class="line">                     /protein_id=<span class="string">&quot;NP_001288646.1&quot;</span></span><br><span class="line">                     /translation=<span class="string">&quot;MESKVILF...&quot;</span></span><br><span class="line">ORIGIN</span><br><span class="line">        <span class="number">1</span> gatcctgcag gacaggatgc attggctgta aactctggag gacaggtgtg ggaggggggt...</span><br></pre></td></tr></table></figure>

<p><strong>GenBank 数据库的访问方法</strong></p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ncbi.nlm.nih.gov/nuccore">NCBI 网站搜索</a>，支持按Accession号（如KM123456）、基因名称、物种、关键词等搜索。</p>
</li>
<li><p>使用 <a href="https://blast.ncbi.nlm.nih.gov/">BLAST 进行序列比对</a>，可上传FASTA序列，比对相似序列。</p>
</li>
<li><p>通过 <a href="https://ftp.ncbi.nlm.nih.gov/genbank/">GenBank FTP</a>批量下载，可下载完整的GenBank数据（按物种或日期分类）。</p>
</li>
<li><p>使用 API 或编程工具，如 Entrez Programming Utilities (E-Utilities)，适用于Python、R等语言的自动化数据获取。或者 Biopython，Python库，支持GenBank数据解析。</p>
</li>
</ol>
</blockquote>
<blockquote class="blockquote-center">
<p>GenBank 的局限性包括：数据冗余：同一基因可能有多个提交版本；注释质量不一：部分记录依赖自动注释，可能有误；非参考基因组：许多测序数据未完成高质量组装。建议的解决方案是使用RefSeq（精选的高质量参考序列），并结合Ensembl、UCSC Genome Browser等工具交叉验证。 </p>

</blockquote>


<h2 id="EMBL-EBI-欧洲分子生物学实验室核苷酸序列数据库"><a href="#EMBL-EBI-欧洲分子生物学实验室核苷酸序列数据库" class="headerlink" title="EMBL-EBI 欧洲分子生物学实验室核苷酸序列数据库"></a>EMBL-EBI 欧洲分子生物学实验室核苷酸序列数据库</h2><p>欧洲分子生物学实验室核苷酸序列数据库（European Molecular Biology Laboratory Nucleotide Sequence Database）<a href="https://www.ebi.ac.uk/"><font color="#80b1d3">[Link]</font></a>是由欧洲生物信息学研究所 EMBL-EBI 维护的全球三大公共核酸序列数据库之一，与美国NCBI GenBank和日本DDBJ共同组成国际核酸序列数据库联盟INSDC，三方数据每日同步更新。</p>
<p>EMBL数据库所有数据免费公开，支持科研和商业用途（部分数据需遵循特定条款）；存储DNA、RNA、基因组、转录组、宏基因组等序列数据；部分记录经过人工或自动化功能的高级注释（如基因、蛋白质编码区）。EMBL-EBI 维护多个相关数据库，EMBL 核心数据库包含以下内容：</p>
<p>（一）**EMBL-Bank（核心核酸序列数据库）**存储原始提交的DNA&#x2F;RNA序列，包括：</p>
<blockquote>
<p>基因组测序（如人类、小鼠、细菌等）</p>
<p>转录组数据（如mRNA、ncRNA）</p>
<p>克隆序列、合成生物学数据</p>
</blockquote>
<p>（二）<a href="https://www.ebi.ac.uk/ena"><strong>欧洲核苷酸档案库（European Nucleotide Archive, ENA）</strong></a>，EMBL 的扩展数据库，包含：</p>
<blockquote>
<p>原始测序数据（SRA）（如Illumina、PacBio、Nanopore的FASTQ文件）</p>
<p>组装基因组（如细菌、真核生物参考基因组）</p>
<p>注释信息（如基因、CDS、调控元件）</p>
</blockquote>
<p>（三）<strong>其他相关EMBL-EBI数据库</strong>：</p>
<blockquote>
<p><a href="https://www.ensembl.org/">Ensembl</a>，基因组注释、比较基因组学</p>
<p><a href="https://www.uniprot.org/">UniProt</a>，蛋白质序列与功能</p>
<p><a href="https://www.ebi.ac.uk/arrayexpress">ArrayExpress</a>，基因表达数据（微阵列、RNA-seq）</p>
<p><a href="https://www.ebi.ac.uk/pdbe/">Protein Data Bank Europe, PDBe</a>，蛋白质3D结构</p>
</blockquote>
<p>EMBL 采用标准平面文件格式（flatfile），每条记录包含：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">ID   (序列标识符)  </span><br><span class="line">AC   (Accession编号，如 LT960628)  </span><br><span class="line">DT   (提交/更新日期)  </span><br><span class="line">DE   (描述)  </span><br><span class="line">KW   (关键词)  </span><br><span class="line">OS   (物种来源)  </span><br><span class="line">OC   (分类学信息)  </span><br><span class="line">RN   (参考文献)  </span><br><span class="line">RP   (参考文献位置)  </span><br><span class="line">RX   (PubMed/DOI链接)  </span><br><span class="line">FT   (特征注释，如基因、启动子、突变位点)  </span><br><span class="line">SQ   (序列数据)  </span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">ID   LT960628; SV <span class="number">1</span>; linear; genomic DNA; STD; PRO; <span class="number">243</span> BP.</span><br><span class="line">AC   LT960628;</span><br><span class="line">DT   <span class="number">12</span>-JUL<span class="number">-2016</span> (Rel. <span class="number">118</span><span class="punctuation">,</span> Created)</span><br><span class="line">DT   <span class="number">12</span>-JUL<span class="number">-2016</span> (Rel. <span class="number">118</span><span class="punctuation">,</span> Last updated<span class="punctuation">,</span> Version <span class="number">1</span>)</span><br><span class="line">DE   Synthetic construct DNA<span class="punctuation">,</span> clone<span class="punctuation">:</span> pEX-A2J2-EGFP.</span><br><span class="line">KW   synthetic construct; EGFP; reporter gene.</span><br><span class="line">OS   synthetic construct</span><br><span class="line">OC   .</span><br><span class="line">RN   <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span></span><br><span class="line">RP   <span class="number">1</span><span class="number">-243</span></span><br><span class="line">RX   DOI; <span class="number">10.1016</span>/j.plasmid<span class="number">.2016</span><span class="number">.03</span><span class="number">.002</span>.</span><br><span class="line">FT   source          <span class="number">1.</span><span class="number">.243</span></span><br><span class="line">FT                  /organism=<span class="string">&quot;synthetic construct&quot;</span></span><br><span class="line">FT                  /mol_type=<span class="string">&quot;other DNA&quot;</span></span><br><span class="line">FT   gene            <span class="number">1.</span><span class="number">.243</span></span><br><span class="line">FT                  /gene=<span class="string">&quot;EGFP&quot;</span></span><br><span class="line">FT   CDS             <span class="number">30.</span><span class="number">.740</span></span><br><span class="line">FT                  /gene=<span class="string">&quot;EGFP&quot;</span></span><br><span class="line">FT                  /protein_id=<span class="string">&quot;CCD12345.1&quot;</span></span><br><span class="line">SQ   Sequence <span class="number">243</span> BP;</span><br><span class="line">     agctagctag ctagctagct agctagctag ctagctagct agctagctag ctagctagct agctagctag</span><br><span class="line">     ctaggatccg gtaccgagct cgaattcgag ctcgagatct ggtacccggg gatcctctag agtcgacctg</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure>

<p><strong>EMBL 数据库的访问方法</strong></p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ebi.ac.uk/ena">ENA 浏览器</a>搜索，可按 Accession号（如LT960628）、基因名、物种、测序项目 搜索。</p>
</li>
<li><p>使用 ENA API 批量获取，支持编程访问（Python&#x2F;R），示例：</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl <span class="string">&quot;https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB12345&amp;result=read_run&amp;fields=fastq_ftp&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>ENA FTP：<a href="https://ftp.ebi.ac.uk/pub/databases/ena/">https://ftp.ebi.ac.uk/pub/databases/ena/</a>，可下载FASTA、FASTQ、SAM&#x2F;BAM等格式数据。</p>
</li>
<li><p>工具整合：Galaxy、Bioconductor 等生物信息学平台支持直接调用EMBL数据。</p>
</li>
</ol>
</blockquote>
<p>EMBL 数据库的典型应用包括：<strong>基因组组装</strong>：获取参考序列或原始测序数据（如细菌基因组）；<strong>基因功能注释</strong>：通过FT字段查看CDS、启动子等特征；<strong>宏基因组分析</strong>：从ENA下载环境样本的16S rRNA数据；<strong>合成生物学</strong>：查询质粒、载体序列（如EGFP、Cas9）。</p>
<h2 id="DDBJ-日本DNA数据库"><a href="#DDBJ-日本DNA数据库" class="headerlink" title="DDBJ 日本DNA数据库"></a>DDBJ 日本DNA数据库</h2><p>DDBJ 是由日本国立遗传学研究所（National Institute of Genetics, NIG）维护的全球三大公共核酸序列数据库之一，与美国NCBI GenBank和欧洲EMBL-EBI共同组成国际核酸序列数据库联盟INSDC，三方数据每日同步，确保全球数据一致性。</p>
<p>DDBJ 为亚洲核心数据库，由日本主导，服务亚太地区研究机构；所有数据免费公开，支持科研与商业用途（需遵守数据使用政策）。特色数据包括日本本土物种基因组（如水稻、珊瑚、深海生物）；亚洲人群基因组变异数据（如JGAS、3.5KJPN项目）；微生物与极端环境生物测序数据。DDBJ 提供多个子数据库，涵盖不同数据类型：</p>
<p>（一）<strong>DDBJ Nucleotide Sequence Database 核心核酸数据库</strong>，存储DNA&#x2F;RNA序列，包括：</p>
<blockquote>
<p>基因组（全基因组、质粒、病毒）</p>
<p>转录组（mRNA、ncRNA）</p>
<p>人工合成序列</p>
</blockquote>
<p>（二）<a href="https://www.ddbj.nig.ac.jp/dra/index.html"><strong>DDBJ Sequence Read Archive, DRA</strong></a>：</p>
<blockquote>
<p>存储高通量测序原始数据（如Illumina、PacBio的FASTQ文件）。</p>
</blockquote>
<p>（三）<a href="https://www.ddbj.nig.ac.jp/jga/index.html"><strong>Japanese Genotype-phenotype Archive, JGA</strong></a>：</p>
<blockquote>
<p>存储日本人群基因组与表型关联数据（需申请访问权限）。</p>
</blockquote>
<p>（四）<strong>BioProject&#x2F;BioSample</strong></p>
<blockquote>
<p>管理测序项目（BioProject）和样本元数据（BioSample）。</p>
</blockquote>
<p>（五）<strong>其他相关数据库</strong></p>
<blockquote>
<p><a href="https://humandbs.biosciencedbc.jp/">NBDC Human Database</a>，日本人群体数据</p>
<p><a href="https://togotv.dbcls.jp/">TogoTV</a>，生物医学视频资源</p>
</blockquote>
<p>DDBJ 采用与GenBank、EMBL一致的INSDC标准格式，每条记录包含：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       (序列ID、长度、类型)  </span><br><span class="line">DEFINITION  (描述)  </span><br><span class="line">ACCESSION   (唯一编号，如LC000001)  </span><br><span class="line">VERSION    (版本号)  </span><br><span class="line">KEYWORDS   (关键词)  </span><br><span class="line">SOURCE     (物种来源)  </span><br><span class="line">  ORGANISM (分类学信息)  </span><br><span class="line">REFERENCE  (参考文献)  </span><br><span class="line">FEATURES   (基因、CDS、突变等注释)  </span><br><span class="line">ORIGIN     (序列数据)</span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       LC000001                <span class="number">502</span> bp    DNA     linear   PLN <span class="number">01</span>-JAN<span class="number">-2020</span></span><br><span class="line">DEFINITION  Oryza sativa Japonica Group mRNA for actin.</span><br><span class="line">ACCESSION   LC000001</span><br><span class="line">VERSION     LC000001<span class="number">.1</span></span><br><span class="line">KEYWORDS    actin; cytoskeleton.</span><br><span class="line">SOURCE      Oryza sativa (rice)</span><br><span class="line">  ORGANISM  Oryza sativa</span><br><span class="line">            Eukaryota; Viridiplantae; Streptophyta; Embryophyta; Tracheophyta;</span><br><span class="line">            Spermatophyta; Magnoliopsida; Poales; Poaceae; Oryza.</span><br><span class="line">FEATURES             Location/Qualifiers</span><br><span class="line">     source          <span class="number">1.</span><span class="number">.502</span></span><br><span class="line">                     /organism=<span class="string">&quot;Oryza sativa&quot;</span></span><br><span class="line">                     /mol_type=<span class="string">&quot;mRNA&quot;</span></span><br><span class="line">     gene            <span class="number">1.</span><span class="number">.502</span></span><br><span class="line">                     /gene=<span class="string">&quot;act1&quot;</span></span><br><span class="line">     CDS             <span class="number">50.</span><span class="number">.450</span></span><br><span class="line">                     /gene=<span class="string">&quot;act1&quot;</span></span><br><span class="line">                     /protein_id=<span class="string">&quot;BAA12345.1&quot;</span></span><br><span class="line">ORIGIN</span><br><span class="line">        <span class="number">1</span> atggtgaggc atgtcgtcca tccgcgcttc tcccgctcgt cgctcgtcgt cgtcgacggt</span><br><span class="line">       <span class="number">61</span> gacgatattc gcgctctcgt cgttcgagaa gctgctgctg ctgctgctgc tgctgctgct</span><br><span class="line">       ...</span><br></pre></td></tr></table></figure>

<p><strong>DDBJ 数据库的访问方法</strong>：</p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ddbj.nig.ac.jp/">DDBJ 网站</a>搜索，支持按 Accession号（如LC000001）、基因名、物种、关键词 搜索。</p>
</li>
<li><p>通过 getentry 快速检索，工具链接：<a href="https://getentry.ddbj.nig.ac.jp/">https://getentry.ddbj.nig.ac.jp/</a>，输入Accession号直接获取FASTA或GenBank格式数据。</p>
</li>
<li><p>FTP 批量下载，DDBJ FTP：<a href="https://ftp.ddbj.nig.ac.jp/">https://ftp.ddbj.nig.ac.jp/</a>，可下载完整数据库或按物种分类的数据。</p>
</li>
<li><p>提交数据至 DDBJ，提交系统：<a href="https://www.ddbj.nig.ac.jp/sub/index.html">https://www.ddbj.nig.ac.jp/sub/index.html</a>，支持基因组、转录组、变异数据提交。</p>
</li>
</ol>
</blockquote>
<p>DDBJ 的典型应用包括<strong>作物基因组研究</strong>：如水稻、大豆的基因变异分析；<strong>微生物多样性</strong>：日本本土极端环境微生物测序数据；<strong>人群遗传学</strong>：亚洲人群基因组项目（如3.5KJPN）；<strong>生物信息学工具开发</strong>：提供API和数据集用于算法测试。</p>
<h2 id="植物与微生物基因组数据库"><a href="#植物与微生物基因组数据库" class="headerlink" title="植物与微生物基因组数据库"></a>植物与微生物基因组数据库</h2><ul>
<li><a href="https://phytozome-next.jgi.doe.gov/"><strong>Phytozome 植物基因组数据库</strong></a>：植物基因组比较平台，包含多种作物基因组数据。Phytozome的基因组数据通常经过人工校正，质量较高，但要注意的是该网站上有些基因组数据是提前释放的，有使用限制，它的说明里会明确给出使用限制：可以自由使用个别或少量基因的信息，但不能完整使用全部基因组的信息。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETCYKH.png" alt="Phytozome 植物基因组数据库"><figcaption aria-hidden="true">Phytozome 植物基因组数据库</figcaption></figure></p>
<ul>
<li><a href="http://plants.ensembl.org/index.html"><strong>Ensembl Genomes 植物基因组数据库</strong></a>：Ensembl Genomes 植物基因组数据库的数据质量相对较高，好处是全部可以自由使用，但物种数量较少。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETCtrd.png" alt="Ensembl Genomes 数据库"><figcaption aria-hidden="true">Ensembl Genomes 数据库</figcaption></figure></p>
<ul>
<li><a href="https://ftp.ncbi.nlm.nih.gov/"><strong>NCBI 基因数据库</strong></a>：NCBI 基因数据库涵盖大量基因组数据，典型的子链接包括：<a href="https://ftp.ncbi.nlm.nih.gov/genomes/refseq/plant/">*&#x2F;genomes&#x2F;refseq&#x2F;plant&#x2F;</a>，这里的基因组质量也还行，物种数量较多。<a href="https://ftp.ncbi.nlm.nih.gov/genomes/genbank/plant/">*&#x2F;genomes&#x2F;genbank&#x2F;plant&#x2F;</a>，这里的基因组物种数量最全，囊括了至少95%以上的已发表的植物基因组数据，但质量参差不齐，有些只拼接到contig水平，甚至没有拼接。<a href="https://www.ncbi.nlm.nih.gov/refseq/">*&#x2F;refseq&#x2F;</a>，NCBI RefSeq 提供高质量参考基因组序列。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETPles.png" alt="NCBI 基因数据库"><figcaption aria-hidden="true">NCBI 基因数据库</figcaption></figure></p>
<ul>
<li><a href="https://genome.jgi.doe.gov/"><strong>JGI Genome Portal</strong></a>：由美国能源部联合基因组研究所维护，涵盖微生物、真菌和植物基因组。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETPdOJ.png" alt="JGI Genome Portal"><figcaption aria-hidden="true">JGI Genome Portal</figcaption></figure></p>
<h2 id="人类基因组数据库"><a href="#人类基因组数据库" class="headerlink" title="人类基因组数据库"></a>人类基因组数据库</h2><h3 id="UCSC-Genome-Browser"><a href="#UCSC-Genome-Browser" class="headerlink" title="UCSC Genome Browser"></a>UCSC Genome Browser</h3><p>网址: <a href="https://genome.ucsc.edu/">https://genome.ucsc.edu/</a></p>
<p>提供人类和其他物种基因组的可视化工具和原始数据下载。</p>
<h3 id="1000-Genomes-Project"><a href="#1000-Genomes-Project" class="headerlink" title="1000 Genomes Project"></a>1000 Genomes Project</h3><p>网址: <a href="https://www.internationalgenome.org/">https://www.internationalgenome.org/</a></p>
<p>包含全球多个人类群体的基因组变异数据。</p>
<h3 id="gnomAD（基因组聚合数据库）"><a href="#gnomAD（基因组聚合数据库）" class="headerlink" title="gnomAD（基因组聚合数据库）"></a>gnomAD（基因组聚合数据库）</h3><p>网址: <a href="https://gnomad.broadinstitute.org/">https://gnomad.broadinstitute.org/</a></p>
<p>提供大规模人群的基因组变异频率数据。</p>
<h2 id="癌症基因组数据库"><a href="#癌症基因组数据库" class="headerlink" title="癌症基因组数据库"></a>癌症基因组数据库</h2><h3 id="TCGA（癌症基因组图谱）"><a href="#TCGA（癌症基因组图谱）" class="headerlink" title="TCGA（癌症基因组图谱）"></a>TCGA（癌症基因组图谱）</h3><p>网址: <a href="https://www.cancer.gov/tcga">https://www.cancer.gov/tcga</a></p>
<p>包含多种癌症的基因组、转录组和表观组数据。</p>
<h3 id="ICGC（国际癌症基因组联盟）"><a href="#ICGC（国际癌症基因组联盟）" class="headerlink" title="ICGC（国际癌症基因组联盟）"></a>ICGC（国际癌症基因组联盟）</h3><p>网址: <a href="https://dcc.icgc.org/">https://dcc.icgc.org/</a></p>
<p>全球合作的癌症基因组数据平台。</p>
<h3 id="COSMIC（癌症体细胞突变数据库）"><a href="#COSMIC（癌症体细胞突变数据库）" class="headerlink" title="COSMIC（癌症体细胞突变数据库）"></a>COSMIC（癌症体细胞突变数据库）</h3><p>网址: <a href="https://cancer.sanger.ac.uk/cosmic">https://cancer.sanger.ac.uk/cosmic</a></p>
<p>收录癌症相关基因突变信息。</p>
<h2 id="表观基因组与功能基因组"><a href="#表观基因组与功能基因组" class="headerlink" title="表观基因组与功能基因组"></a>表观基因组与功能基因组</h2><h3 id="ENCODE（ENCyclopedia-Of-DNA-Elements）"><a href="#ENCODE（ENCyclopedia-Of-DNA-Elements）" class="headerlink" title="ENCODE（ENCyclopedia Of DNA Elements）"></a>ENCODE（ENCyclopedia Of DNA Elements）</h3><p>网址: <a href="https://www.encodeproject.org/">https://www.encodeproject.org/</a></p>
<p>人类和小鼠基因组功能元件数据库（如启动子、增强子等）。</p>
<h3 id="Roadmap-Epigenomics"><a href="#Roadmap-Epigenomics" class="headerlink" title="Roadmap Epigenomics"></a>Roadmap Epigenomics</h3><p>网址: <a href="https://www.roadmapepigenomics.org/">https://www.roadmapepigenomics.org/</a></p>
<p>人类不同细胞类型的表观基因组数据。</p>
<h2 id="宏基因组与环境DNA"><a href="#宏基因组与环境DNA" class="headerlink" title="宏基因组与环境DNA"></a>宏基因组与环境DNA</h2><h3 id="MG-RAST"><a href="#MG-RAST" class="headerlink" title="MG-RAST"></a>MG-RAST</h3><p>网址: <a href="https://www.mg-rast.org/">https://www.mg-rast.org/</a></p>
<p>微生物群落宏基因组数据分析平台。</p>
<h3 id="NCBI-SRA（Sequence-Read-Archive）"><a href="#NCBI-SRA（Sequence-Read-Archive）" class="headerlink" title="NCBI SRA（Sequence Read Archive）"></a>NCBI SRA（Sequence Read Archive）</h3><p>网址: <a href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</a></p>
<p>存储高通量测序原始数据。</p>
<h2 id="中国主导的数据库"><a href="#中国主导的数据库" class="headerlink" title="中国主导的数据库"></a>中国主导的数据库</h2><h3 id="CNGB（中国国家基因库）"><a href="#CNGB（中国国家基因库）" class="headerlink" title="CNGB（中国国家基因库）"></a>CNGB（中国国家基因库）</h3><p>网址: <a href="https://www.cngb.org/">https://www.cngb.org/</a></p>
<p>中国深圳建立的综合性基因数据库。</p>
<h3 id="GSA（组学原始数据归档库）"><a href="#GSA（组学原始数据归档库）" class="headerlink" title="GSA（组学原始数据归档库）"></a>GSA（组学原始数据归档库）</h3><p>网址: <a href="https://ngdc.cncb.ac.cn/gsa/">https://ngdc.cncb.ac.cn/gsa/</a></p>
<p>由中国科学院北京基因组研究所维护。</p>
]]></content>
      <categories>
        <category>Scholarship</category>
      </categories>
      <tags>
        <tag>Gene</tag>
        <tag>Dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>复杂网络中的节点相似度</title>
    <url>/NetSimu/</url>
    <content><![CDATA[<p><figure><img src="https://s21.ax1x.com/2024/10/22/pAdGFBt.png" alt="Network Science, Albert-László Barabási, Section 3.6, Page 16"><figcaption aria-hidden="true">Network Science, Albert-László Barabási, Section 3.6, Page 16</figcaption></figure></p>
<p>笔者在去年发表的论文 <a href="/download/2023_hwchai_Acta_Mater..pdf">“Deformation dynamics of a neutron-irradiated aluminum alloy: an in-situ synchrotron tomography study”, Acta Mater., 243, 118493 (2023).</a> 中公开了一种对三维结构中复数个目标的追踪方法（Appendix A. Particle tracking analysis, PTA）。该方法摒弃了基于三维矩阵卷积的图像配准方法，而依赖具体对象的结构参数信息，实现目标追踪时计算效率的质变以及目标对目标的映射追踪。然而该方法仍有两点不足：</p>
<ol>
<li>依赖目标自身结构特征及近邻目标位移矢量的相似程度，但未充分利用复数个目标组成的局部网络结构相似程度</li>
<li>目标结构信息依赖前序步骤，如三维数字图像降噪、二值化等。应融合自适应局部结构特征识别算法</li>
</ol>
<p>与上述第一点不谋而合的是，深度学习领域往往需要衡量两个对象的相似性，特别是在信息检索，模式匹配等方向上。本文将介绍深度学习领域衡量复杂网络中节点相似程度的工作，并简要构思 PTA 方法的后续改进计划。</p>
<span id="more"></span>

<h2 id="相似性与距离"><a href="#相似性与距离" class="headerlink" title="相似性与距离"></a>相似性与距离</h2><h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><p><a href="https://zr9558.com/2020/12/22/nodesimilarity/">https://zr9558.com/2020/12/22/nodesimilarity/</a></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>complex network</tag>
        <tag>similarity</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 02：函数、流程控制语句与NumPy初步</title>
    <url>/PythonLes03/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>通过前面两周课程的学习，我们了解了现代科研体系中编程语言的必要作用，而Python等解释型语言由于其便捷易开发的优势又是其中的主力军之一。以及对Python语言的基础知识包括注释、对象类型（数字、字符串、布尔型等）、运算符（位运算符、赋值运算符、逻辑运算符）等。第三周课程我们将学习Python语言编写时的缩进规则、函数的用法、流程控制语句以及NumPy模块的初步使用。</p>
<span id="more"></span>

<h2 id="Python语言缩进规则"><a href="#Python语言缩进规则" class="headerlink" title="Python语言缩进规则"></a>Python语言缩进规则</h2><p>和其它程序设计语言采用大括号 <code>&#123;&#125;</code> 分隔代码块不同，Python 采用代码缩进和冒号来区分代码块之间的层次。 要求严格的代码缩进是Python语法的一大特色，好比C语言中的花括号一样重要。</p>
<p>在 Python 中，对于 $\lfloor$类$\rceil$、$\lfloor$函数$\rceil$、$\lfloor$流程控制语句$\rceil$、$\lfloor$异常处理语句$\rceil$ 等，行尾的冒号和下一行的缩进，表示下一个代码块的开始，而缩进的结束则表示此代码块的结束。</p>
<p>在python中，强制要求缩进，一般使用<code>Tab</code>或<code>Space</code>来进行缩进，且缩进必须要保持一致，否则可能会出缩进的错误。官方规定是缩进四个空格，而<code>Tab</code>键不一定等于四个空格，所以需要设置一个<code>Tab</code>等于四个空格。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dataInfo</span>(<span class="params">filename,showInfor=<span class="literal">False</span></span>):</span><br><span class="line">    f = h5py.File(filename,<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:    </span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data&quot;</span>] </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">        dim = arr.shape</span><br><span class="line">        <span class="keyword">if</span> showInfor == <span class="literal">True</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Data dimension is [Theta:Y:X] = [&#x27;</span>, dim[<span class="number">0</span>],<span class="string">&#x27;:&#x27;</span>, dim[<span class="number">1</span>],<span class="string">&#x27;:&#x27;</span>, dim[<span class="number">2</span>],<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data_white&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> arr.shape[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;There is no white images in this file.&#x27;</span>)</span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data_dark&quot;</span>] </span><br><span class="line">        <span class="keyword">if</span> arr.shape[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;There is no dark images in this file.&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> dim    </span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Error !!!!!&#x27;</span>) </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Dataset \&#x27;exchange/data\&#x27; does not exist in the give file.&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>与其他语言不同，Python属于强制缩进的，它这种做法属于双刃剑，有好处也有坏处。</p>
<p>好处是强迫你写出格式化的代码，但没有规定缩进是几个空格还是<code>Tab</code>。按照约定俗成的管理，应该始终坚持使用四个空格的缩进；另一个好处是强迫你写出缩进较少的代码，你会倾向于将一段很长的代码拆分成若干函数，从而得到缩进较少的代码。</p>
<p>坏处就是复制、粘贴功能失效了，当你重构代码时，粘贴过去的代码必须重新检查缩进是否正确；此外，IDE很难像格式化Java代码那样格式化Python代码。</p>
<h3 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h3><blockquote class="blockquote-center">
<p>Python使用缩进来组织代码块，区分$\lfloor$类$\rceil$、$\lfloor$函数$\rceil$、$\lfloor$流程控制语句$\rceil$、$\lfloor$异常处理语句$\rceil$等的层次，请务必遵守约定俗成的习惯，坚持使用4个空格的缩进。在文本编辑器中，需要设置把<code>Tab</code>自动转换为4个空格，确保不混用<code>tab</code>和空格。 </p>

</blockquote>


<h2 id="Python-流程控制语句"><a href="#Python-流程控制语句" class="headerlink" title="Python 流程控制语句"></a>Python 流程控制语句</h2><p>我们可以使用 Python 来执行一些稍复杂的任务。例如，我们可以写一个生成菲波那契子序列的程序，如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fibonacci series:</span></span><br><span class="line"><span class="comment"># the sum of two elements defines the next</span></span><br><span class="line">a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> b &lt; <span class="number">10</span>:</span><br><span class="line">    <span class="built_in">print</span>(b)</span><br><span class="line">    a, b = b, a+b</span><br></pre></td></tr></table></figure>

<p>这个例子介绍了几个新功能。</p>
<ul>
<li><p>第一行包括了一个 多重赋值：变量 a 和 b 同时获得了新的值 0 和 1 最后一行又使用了一次。在这个演示中，变量赋值前，右边首先完成计算。右边的表达式从左到右计算。</p>
</li>
<li><p>条件（这里是 b &lt; 10 ）为 true 时， while 循环执行。在 Python 中，类似于 C，任何非零整数都是 True；0 是 False。条件也可以是字符串或列表，实际上可以是任何序列；</p>
</li>
<li><p>循环体是缩进的：缩进是 Python 组织语句的方法。</p>
</li>
</ul>
<p>除了这里介绍的 while 语句，Python 还从其它语言借鉴了一些流程控制功能，并有所改变。</p>
<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/while_loop.png" width="40%" alt="while语句逻辑结构" align=center />


<h3 id="if-语句"><a href="#if-语句" class="headerlink" title="if 语句"></a>if 语句</h3><p>也许最有名的是 if 语句。例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please enter an integer: &quot;</span>))</span><br><span class="line">Please enter an integer: <span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>     x = <span class="number">0</span></span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Negative changed to zero&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">elif</span> x == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Zero&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">elif</span> x == <span class="number">1</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Single&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;More&#x27;</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可能会有零到多个<code>elif</code>部分，<code>else</code>是可选的。关键字<code>elif</code>是else if的缩写，这个可以有效地避免过深的缩进。&#96;if … elif … elif …&#96;&#96; 序列用于替代其它语言中的 switch 或 case 语句。</p>
<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/if_elif_else.png" width="60%" alt="if ... elif ... else ... 逻辑结构，elif 与 else为可选项" align=center />

<p>我们可以将一个if语句嵌入到另一个if语句中，然后称之为嵌套if语句。事实上，所有的流程控制语句都可以多层嵌套。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="number">67</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> x &gt; <span class="number">10</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Above ten,&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">20</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;and also above 20!&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;but not above 20.&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;python3 exampleCode.py</span><br><span class="line">&gt;&gt;&gt;Above ten,</span><br><span class="line">&gt;&gt;&gt;<span class="keyword">and</span> also above <span class="number">20</span>!</span><br></pre></td></tr></table></figure>

<h3 id="for-语句"><a href="#for-语句" class="headerlink" title="for 语句"></a>for 语句</h3><p>Python 中的 for 语句和 C 或 Pascal 中的略有不同。通常的循环可能会依据一个等差数值步进过程（如 Pascal），或由用户来定义迭代步骤和中止条件（如 C ），Python 的 for 语句依据任意序列（链表或字符串）中的子项，按它们在序列中的顺序来进行迭代。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Measure some strings:</span></span><br><span class="line"><span class="meta">... </span>words = [<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;window&#x27;</span>, <span class="string">&#x27;defenestrate&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> w <span class="keyword">in</span> words:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(w, <span class="built_in">len</span>(w))</span><br><span class="line">...</span><br><span class="line">cat <span class="number">3</span></span><br><span class="line">window <span class="number">6</span></span><br><span class="line">defenestrate <span class="number">12</span></span><br></pre></td></tr></table></figure>

<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/for_loop.png" width="45%" alt="for语句逻辑结构" align=center />

<p>在迭代过程中修改迭代序列不安全（只有在使用链表这样的可变序列时才会有这样的情况）。如果你想要修改你迭代的序列（例如，复制选择项），你可以迭代它的复本。使用切割标识就可以很方便的做到这一点:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> w <span class="keyword">in</span> words[:]:  <span class="comment"># Loop over a slice copy of the entire list.</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> <span class="built_in">len</span>(w) &gt; <span class="number">6</span>:</span><br><span class="line"><span class="meta">... </span>        words.insert(<span class="number">0</span>, w)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words</span><br><span class="line">[<span class="string">&#x27;defenestrate&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;window&#x27;</span>, <span class="string">&#x27;defenestrate&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="range-函数"><a href="#range-函数" class="headerlink" title="range() 函数"></a>range() 函数</h3><p>如果你需要一个数值序列，内置函数<code>range()</code>会很方便，它生成一个等差级数链表:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i)</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<p><code>range(10)</code>生成了一个包含 10 个值的链表，它用链表的索引值填充了这个长度为 10 的列表，所生成的链表中不包括范围中的结束值。也可以让 range() 操作从另一个数值开始，或者可以指定一个不同的步进值（甚至是负数，有时这也被称为 “步长”）:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">range</span>(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">   <span class="number">5</span> through <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">   <span class="number">0</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">range</span>(-<span class="number">10</span>, -<span class="number">100</span>, -<span class="number">30</span>)</span><br><span class="line">  -<span class="number">10</span>, -<span class="number">40</span>, -<span class="number">70</span></span><br></pre></td></tr></table></figure>

<p>需要迭代链表索引的话，如下所示结合使用<code>range()</code>和<code>len()</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">&#x27;Mary&#x27;</span>, <span class="string">&#x27;had&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;little&#x27;</span>, <span class="string">&#x27;lamb&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i, a[i])</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span> Mary</span><br><span class="line"><span class="number">1</span> had</span><br><span class="line"><span class="number">2</span> a</span><br><span class="line"><span class="number">3</span> little</span><br><span class="line"><span class="number">4</span> lamb</span><br></pre></td></tr></table></figure>

<p>不过，这种场合可以方便的使用<code>enumerate()</code>。在序列中循环时，索引位置和对应值可以使用<code>enumerate()</code>函数同时得到:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&#x27;tic&#x27;</span>, <span class="string">&#x27;tac&#x27;</span>, <span class="string">&#x27;toe&#x27;</span>]):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i, v)</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span> tic</span><br><span class="line"><span class="number">1</span> tac</span><br><span class="line"><span class="number">2</span> toe</span><br></pre></td></tr></table></figure>

<p>如果你只是打印一个序列的话会发生奇怪的事情:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; print(range(10))</span><br><span class="line">range(0, 10)</span><br></pre></td></tr></table></figure>

<p>在不同方面 range() 函数返回的对象表现为它是一个列表，但事实上它并不是。当你迭代它时，它是一个能够像期望的序列返回连续项的对象；但为了节省空间，它并不真正构造列表。</p>
<p>我们称此类对象是 可迭代的，即适合作为那些期望从某些东西中获得连续项直到结束的函数或结构的一个目标（参数）。我们已经见过的 for 语句就是这样一个迭代器。list() 函数是另外一个（ 迭代器 ），它从可迭代（对象）中创建列表:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>

<p>以后的学习中我们会看到更多返回可迭代（对象）和以可迭代（对象）作为参数的函数。</p>
<h3 id="break-和-continue-语句-以及循环中的-else-子句"><a href="#break-和-continue-语句-以及循环中的-else-子句" class="headerlink" title="break 和 continue 语句, 以及循环中的 else 子句"></a>break 和 continue 语句, 以及循环中的 else 子句</h3><p>break 语句和 C 中的类似，用于跳出最近的一级 for 或 while 循环。</p>
<p>循环可以有一个 else 子句；它在循环迭代完整个列表（对于 for ）或执行条件为 false （对于 while ）时执行，但循环被 break 中止的情况下不会执行。以下搜索素数的示例程序演示了这个过程:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> n % x == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>            <span class="built_in">print</span>(n, <span class="string">&#x27;equals&#x27;</span>, x, <span class="string">&#x27;*&#x27;</span>, n//x)</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="comment"># loop fell through without finding a factor</span></span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(n, <span class="string">&#x27;is a prime number&#x27;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="number">2</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">3</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">4</span> equals <span class="number">2</span> * <span class="number">2</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">6</span> equals <span class="number">2</span> * <span class="number">3</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">8</span> equals <span class="number">2</span> * <span class="number">4</span></span><br><span class="line"><span class="number">9</span> equals <span class="number">3</span> * <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>(Yes, 这是正确的代码。看仔细：else 语句是属于 for 循环之中， 不是 if 语句。)</p>
<ul>
<li>与循环一起使用时，else 子句与 try 语句的 else 子句比与 if 语句的具有更多的共同点：try 语句的 else 子句在未出现异常时运行，循环的 else 子句在未出现 break 时运行。</li>
</ul>
<p>continue 语句是从 C 中借鉴来的，它表示循环继续执行下一次迭代:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> num % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&quot;Found an even number&quot;</span>, num)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">continue</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;Found a number&quot;</span>, num)</span><br><span class="line">Found an even number <span class="number">2</span></span><br><span class="line">Found a number <span class="number">3</span></span><br><span class="line">Found an even number <span class="number">4</span></span><br><span class="line">Found a number <span class="number">5</span></span><br><span class="line">Found an even number <span class="number">6</span></span><br><span class="line">Found a number <span class="number">7</span></span><br><span class="line">Found an even number <span class="number">8</span></span><br><span class="line">Found a number <span class="number">9</span></span><br></pre></td></tr></table></figure>

<h3 id="pass-语句"><a href="#pass-语句" class="headerlink" title="pass 语句"></a>pass 语句</h3><p>pass 语句什么也不做。它用于那些语法上必须要有什么语句，但程序什么也不做的场合，例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span>  <span class="comment"># Busy-wait for keyboard interrupt (Ctrl+C)</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这通常用于创建最小结构的类:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyEmptyClass</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>另一方面，pass 可以在创建新代码时用来做函数或控制体的占位符。可以让你在更抽象的级别上思考。pass 可以默默的被忽视:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">initlog</span>(<span class="params">*args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span>   <span class="comment"># Remember to implement this!</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="本章小结-1"><a href="#本章小结-1" class="headerlink" title="本章小结"></a>本章小结</h3><blockquote class="blockquote-center">
<p>通过本节的学习，我们了解了Python中的流程控制语句，包括if … elif … else …结构，while结构以及for循环的基本使用方法，以及与之配合的range()函数及break\continue语句的使用规则。 </p>

</blockquote>























<h2 id="Python语言中的函数"><a href="#Python语言中的函数" class="headerlink" title="Python语言中的函数"></a>Python语言中的函数</h2><p>在编程中，函数是一种模块化的手段，当它被调用时执行特定功能并提供反馈。可提高代码的利用率，避免重复代码，便于使用，便于维护。Python 中，不仅提供了许多现成可用的内建函数，用户还可以根据自己的需求，定义自己的函数。</p>
<p>函数也属于一种数据类型，可以使用<code>type()</code>查看，内建函数为<code>builtin_function_or_method</code>，自定义函数为<code>function</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">printhello</span>(): <span class="comment"># 自定义函数 test()，并没有实质功能</span></span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(<span class="string">&#x27;Hello world!!!&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(printhello)  <span class="comment"># printhello() 为自定义函数</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;function&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="built_in">print</span>)       <span class="comment"># print() 为内建函数</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;builtin_function_or_method&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>本章节将展示如何在Python中定义函数并调用它，这样你就可以把Python应用程序的代码模块化分解，重复利用，精简代码结构。</p>
<h3 id="创建函数"><a href="#创建函数" class="headerlink" title="创建函数"></a>创建函数</h3><p>创建函数也称为定义函数，可以理解为创建一个具有某种用途的工具，通过<code>def</code>关键词及函数标识符（函数对象名）实现，具体的语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">functionName</span>(<span class="params">parameterList</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;comments&#x27;&#x27;&#x27;</span></span><br><span class="line">    functionBody</span><br></pre></td></tr></table></figure>

<p>这里包括四个函数的基本元素：</p>
<ul>
<li>functionName: 函数名称，在调用函数时使用。</li>
<li>parameterlist: 可选参数，用于指定像函数中传递的参数。如果有多个参数，则各参数间使用逗号<code>,</code>分隔；如果不指定，则表示该函数没有输入参数。</li>
<li>comments: 可选参数，标识为函数指定注释。也称为Docstrings（文档字符串），通常用于说明该函数的功能、要传递的参数的作用等等。</li>
<li>functionBody: 函数体，实现函数的功能的具体代码块。如果函数有返回值，可以使用return语句返回。</li>
</ul>
<p>函数体“functionBody”与注释“comments”相对于def关键字必须保持缩进。</p>
<p>按照上面的基本语法，一个向终端输出随机生成的两个变量之和的Python函数示例如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunction</span>():</span><br><span class="line">	a = rand()</span><br><span class="line">	b = rand()</span><br><span class="line">    <span class="built_in">print</span>(a+b)</span><br></pre></td></tr></table></figure>

<p>我们举一个工程应用中具体的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_image</span>(<span class="params">self, geo, angle, iteration</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    VERBOSE:</span></span><br><span class="line"><span class="string">     for j in range(angleblocks):</span></span><br><span class="line"><span class="string">         angle = np.array([alpha[j]], dtype=np.float32)</span></span><br><span class="line"><span class="string">         proj_err = proj[angle_index[j]] - Ax(res, geo, angle, &#x27;ray-voxel&#x27;)</span></span><br><span class="line"><span class="string">         backprj = Atb(proj_err, geo, angle, &#x27;FDK&#x27;)</span></span><br><span class="line"><span class="string">         res += backprj</span></span><br><span class="line"><span class="string">         res[res&lt;0]=0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="variable language_">self</span>.res += <span class="variable language_">self</span>.__bm__ * <span class="number">2</span> * tigre.Atb((<span class="variable language_">self</span>.proj[<span class="variable language_">self</span>.angle_index[iteration]] - tigre.Ax(</span><br><span class="line">        <span class="variable language_">self</span>.res, geo, angle, <span class="string">&#x27;interpolated&#x27;</span>)), geo, angle, <span class="string">&#x27;matched&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_main_iter</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Goes through the main iteration for the given configuration.</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    t = <span class="variable language_">self</span>.__t__</span><br><span class="line">    Quameasopts = <span class="variable language_">self</span>.Quameasopts</span><br><span class="line">    x_rec = copy.deepcopy(<span class="variable language_">self</span>.res)</span><br><span class="line">    lambdaForTv = <span class="number">2</span> * <span class="variable language_">self</span>.__bm__ * <span class="variable language_">self</span>.__lambda__</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.niter):</span><br><span class="line"></span><br><span class="line">        res_prev = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> Quameasopts <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            res_prev = copy.deepcopy(<span class="variable language_">self</span>.res)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.verbose:</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">str</span>(<span class="variable language_">self</span>.name).upper() +</span><br><span class="line">                      <span class="string">&#x27; &#x27;</span> + <span class="string">&quot;algorithm in progress.&quot;</span>)</span><br><span class="line">                toc = default_timer()</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                tic = default_timer()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Esitmated time until completetion (s): &#x27;</span> +</span><br><span class="line">                      <span class="built_in">str</span>((<span class="variable language_">self</span>.niter - <span class="number">1</span>) * (tic - toc)))</span><br><span class="line">        <span class="built_in">getattr</span>(<span class="variable language_">self</span>, <span class="variable language_">self</span>.dataminimizing)()</span><br><span class="line"></span><br><span class="line">        x_rec_old = copy.deepcopy(x_rec)</span><br><span class="line">        x_rec = im3ddenoise(<span class="variable language_">self</span>.res, <span class="variable language_">self</span>.__numiter_tv__, <span class="number">1.</span> / lambdaForTv)</span><br><span class="line">        t_old = t</span><br><span class="line">        t = (<span class="number">1</span> + np.sqrt(<span class="number">1</span> + <span class="number">4</span> * t ** <span class="number">2</span>)) / <span class="number">2</span></span><br><span class="line">        <span class="variable language_">self</span>.res = x_rec + (t_old - <span class="number">1</span>) / t * (x_rec - x_rec_old)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.error_measurement(res_prev, i)</span><br></pre></td></tr></table></figure>

<p>在Python2.X的版本中，如果定义的函数暂时什么都不做，那么需要使用pass关键字作为点位符，或者添加Docstrings，但不可以直接添加一行单行注释，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">functionNull</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;空函数在Python2.x版本中pass是必须的&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">functionNull</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;在Python3.x的时候pass可以写或不写&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h3 id="调用函数"><a href="#调用函数" class="headerlink" title="调用函数"></a>调用函数</h3><p>调用函数也就是执行函数，调用函数的基本语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">functionNmae(parameterValue)</span><br></pre></td></tr></table></figure>

<p>共包括两个基本元素：</p>
<ul>
<li>functionName: 函数名称，要调用的函数名称必须是已经创建好的。</li>
<li>parameterValue: 指定函数需求输入的各个参数的值。如果有多个参数，则各参数间使用逗号<code>,</code>分隔；如函数无需参数输入，也必须写一对小括号在此。</li>
</ul>
<p>例如调用一个向终端输出两个随机变量之和的Python函数示例如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunction</span>():</span><br><span class="line">	a = rand()</span><br><span class="line">	b = rand()</span><br><span class="line">    <span class="built_in">print</span>(a+b)</span><br><span class="line"></span><br><span class="line">myfunction()</span><br></pre></td></tr></table></figure>

<p>在Python中我们可以使用<code>return</code>关键字，从函数中向外反馈一些参数。<code>return</code>语句可以包含一个要执行的表达式。下面的例子演示了<code>return</code>关键字在 Python 中的作用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multiplyNum</span>(<span class="params">num1</span>):</span><br><span class="line">    <span class="keyword">return</span> num1 * <span class="number">8</span></span><br><span class="line"></span><br><span class="line">result = multiplyNum(<span class="number">8</span>)</span><br><span class="line"><span class="built_in">print</span>(result)      <span class="comment"># 输出：64</span></span><br></pre></td></tr></table></figure>

<h3 id="函数中的参数"><a href="#函数中的参数" class="headerlink" title="函数中的参数"></a>函数中的参数</h3><p>在 Python 中，你也可以定义包含若干参数的函数。这里有三种可用的形式，也可以混合使用。第一种就是规规矩矩的按照位置准确传递参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask_ok</span>(<span class="params">prompt, retries, complaint</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        ok = <span class="built_in">input</span>(prompt)</span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;ye&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;nop&#x27;</span>, <span class="string">&#x27;nope&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        retries = retries - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> retries &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> OSError(<span class="string">&#x27;uncooperative user&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(complaint)</span><br><span class="line"></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;Come on, only yes or no!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="默认参数值"><a href="#默认参数值" class="headerlink" title="默认参数值"></a>默认参数值</h3><p>此外最常用的一种形式是为一个或多个参数指定默认值。这会创建一个可以使用比定义时允许的参数更少的参数调用的函数，例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask_ok</span>(<span class="params">prompt, retries=<span class="number">4</span>, complaint=<span class="string">&#x27;Yes or no, please!&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        ok = <span class="built_in">input</span>(prompt)</span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;ye&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;nop&#x27;</span>, <span class="string">&#x27;nope&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        retries = retries - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> retries &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> OSError(<span class="string">&#x27;uncooperative user&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(complaint)</span><br></pre></td></tr></table></figure>

<p>这个函数可以通过几种不同的方式调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 只给出必要的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;Do you really want to quit?&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给出一个可选的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者给出所有的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;Come on, only yes or no!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这个例子还介绍了<code>in</code>关键字。它测定序列中是否包含某个确定的值。</p>
<p>默认值在函数定义作用域被解析，如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">arg=i</span>):</span><br><span class="line">    <span class="built_in">print</span>(arg)</span><br><span class="line"></span><br><span class="line">i = <span class="number">6</span></span><br><span class="line">f()      <span class="comment"># 将会输出 5。</span></span><br></pre></td></tr></table></figure>

<p>重要警告: 默认值只被赋值一次。这使得当默认值是可变对象时会有所不同，比如列表、字典或者大多数类的实例。例如，下面的函数在后续调用过程中会累积（前面）传给它的参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a, L=[]</span>):</span><br><span class="line">    L.append(a)</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p>如果你不想让默认值在后续调用中累积，你可以像下面一样定义函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a, L=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> L <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        L = []</span><br><span class="line">    L.append(a)</span><br><span class="line">    <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>

<h3 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h3><p>函数可以通过 关键字参数 的形式来调用，形如 <code>keyword = value</code>。例如，以下的函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parrot</span>(<span class="params">voltage, state=<span class="string">&#x27;a stiff&#x27;</span>, action=<span class="string">&#x27;voom&#x27;</span>, <span class="built_in">type</span>=<span class="string">&#x27;Norwegian Blue&#x27;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- This parrot wouldn&#x27;t&quot;</span>, action, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;if you put&quot;</span>, voltage, <span class="string">&quot;volts through it.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- Lovely plumage, the&quot;</span>, <span class="built_in">type</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- It&#x27;s&quot;</span>, state, <span class="string">&quot;!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>接受一个必选参数 (voltage) 以及三个可选参数 (state, action, 和 type)。可以用以下的任一方法调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parrot(<span class="number">1000</span>)                                          <span class="comment"># 1 positional argument</span></span><br><span class="line">parrot(voltage=<span class="number">1000</span>)                                  <span class="comment"># 1 keyword argument</span></span><br><span class="line">parrot(voltage=<span class="number">1000000</span>, action=<span class="string">&#x27;VOOOOOM&#x27;</span>)             <span class="comment"># 2 keyword arguments</span></span><br><span class="line">parrot(action=<span class="string">&#x27;VOOOOOM&#x27;</span>, voltage=<span class="number">1000000</span>)             <span class="comment"># 2 keyword arguments</span></span><br><span class="line">parrot(<span class="string">&#x27;a million&#x27;</span>, <span class="string">&#x27;bereft of life&#x27;</span>, <span class="string">&#x27;jump&#x27;</span>)         <span class="comment"># 3 positional arguments</span></span><br><span class="line">parrot(<span class="string">&#x27;a thousand&#x27;</span>, state=<span class="string">&#x27;pushing up the daisies&#x27;</span>)  <span class="comment"># 1 positional, 1 keyword</span></span><br></pre></td></tr></table></figure>

<p>不过以下几种调用是无效的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parrot()                     <span class="comment"># required argument missing</span></span><br><span class="line">parrot(voltage=<span class="number">5.0</span>, <span class="string">&#x27;dead&#x27;</span>)  <span class="comment"># non-keyword argument after a keyword argument</span></span><br><span class="line">parrot(<span class="number">110</span>, voltage=<span class="number">220</span>)     <span class="comment"># duplicate value for the same argument</span></span><br><span class="line">parrot(actor=<span class="string">&#x27;John Cleese&#x27;</span>)  <span class="comment"># unknown keyword argument</span></span><br></pre></td></tr></table></figure>

<p>在函数调用中，关键字的参数必须跟随在位置参数的后面。传递的所有关键字参数必须与函数接受的某个参数相匹配 （例如 actor 不是 parrot 函数的有效参数），它们的顺序并不重要。这也包括非可选参数（例如 parrot(voltage&#x3D;1000) 也是有效的）。任何参数都不可以多次赋值。下面的示例由于这种限制将失败:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; def <span class="keyword">function</span>(a):</span></span><br><span class="line">...     pass</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; <span class="keyword">function</span>(0, a=0)</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in ?</span><br><span class="line">TypeError: function() got multiple values for keyword argument &#x27;a&#x27;</span><br></pre></td></tr></table></figure>

<p>以下为可选阅读：</p>
<p>引入一个形如 <code>**name</code> 的参数时，它接收一个字典（参见 下一小节 ），该字典包含了所有未出现在形式参数列表中的关键字参数。这里可能还会组合使用一个形如 <code>*name</code> （下一小节详细介绍） 的形式参数，它接收一个元组（下一节中会详细介绍），包含了所有没有出现在形式参数列表中的参数值（ <code>*name</code> 必须在 <code>**name</code> 之前出现）。 例如，我们这样定义一个函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cheeseshop</span>(<span class="params">kind, *arguments, **keywords</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- Do you have any&quot;</span>, kind, <span class="string">&quot;?&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- I&#x27;m sorry, we&#x27;re all out of&quot;</span>, kind)</span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> arguments:</span><br><span class="line">        <span class="built_in">print</span>(arg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">40</span>)</span><br><span class="line">    keys = <span class="built_in">sorted</span>(keywords.keys())</span><br><span class="line">    <span class="keyword">for</span> kw <span class="keyword">in</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(kw, <span class="string">&quot;:&quot;</span>, keywords[kw])</span><br></pre></td></tr></table></figure>

<p>它可以像这样调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cheeseshop(<span class="string">&quot;Limburger&quot;</span>, <span class="string">&quot;It&#x27;s very runny, sir.&quot;</span>,</span><br><span class="line">           <span class="string">&quot;It&#x27;s really very, VERY runny, sir.&quot;</span>,</span><br><span class="line">           shopkeeper=<span class="string">&quot;Michael Palin&quot;</span>,</span><br><span class="line">           client=<span class="string">&quot;John Cleese&quot;</span>,</span><br><span class="line">           sketch=<span class="string">&quot;Cheese Shop Sketch&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>当然它会按如下内容打印:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">-- Do you have <span class="built_in">any</span> Limburger ?</span><br><span class="line">-- I<span class="string">&#x27;m sorry, we&#x27;</span>re <span class="built_in">all</span> out of Limburger</span><br><span class="line">It<span class="string">&#x27;s very runny, sir.</span></span><br><span class="line"><span class="string">It&#x27;</span>s really very, VERY runny, sir.</span><br><span class="line">----------------------------------------</span><br><span class="line">client : John Cleese</span><br><span class="line">shopkeeper : Michael Palin</span><br><span class="line">sketch : Cheese Shop Sketch</span><br></pre></td></tr></table></figure>

<p>注意在打印关键字参数之前，通过对关键字字典<code>keys()</code>方法的结果进行排序，生成了关键字参数名的列表；如果不这样做，打印出来的参数的顺序是未定义的。</p>
<h3 id="可变参数列表"><a href="#可变参数列表" class="headerlink" title="可变参数列表"></a>可变参数列表</h3><p>最后，一个最不常用的选择是可以让函数调用可变个数的参数。这些参数被包装进一个元组。在这些可变个数的参数之前，可以有零到多个普通的参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">write_multiple_items</span>(<span class="params">file, separator, *args</span>):</span><br><span class="line">    file.write(separator.join(args))</span><br></pre></td></tr></table></figure>

<p>通常，这些 可变 参数是参数列表中的最后一个，因为它们将把所有的剩余输入参数传递给函数。任何出现在<code>*args</code>后的参数是关键字参数，这意味着，他们只能被用作关键字，而不是位置参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">concat</span>(<span class="params">*args, sep=<span class="string">&quot;/&quot;</span></span>):</span><br><span class="line"><span class="meta">... </span>   <span class="keyword">return</span> sep.join(args)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>concat(<span class="string">&quot;earth&quot;</span>, <span class="string">&quot;mars&quot;</span>, <span class="string">&quot;venus&quot;</span>)</span><br><span class="line"><span class="string">&#x27;earth/mars/venus&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>concat(<span class="string">&quot;earth&quot;</span>, <span class="string">&quot;mars&quot;</span>, <span class="string">&quot;venus&quot;</span>, sep=<span class="string">&quot;.&quot;</span>)</span><br><span class="line"><span class="string">&#x27;earth.mars.venus&#x27;</span></span><br></pre></td></tr></table></figure>

<p>另一种形式是<code>**arg</code>作为关键词，表示接受任意多个显式赋值的实际参数，并将其放在一个字典之中。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">bar</span>(<span class="params">param1, **param2</span>):</span><br><span class="line">        <span class="built_in">print</span> param1</span><br><span class="line">        <span class="built_in">print</span> param2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bar(<span class="number">1</span>,a=<span class="number">2</span>,b=<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>

<p>当然这两种用法可以同时出现在一个函数之中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, b=<span class="number">10</span>, *args, **kwargs</span>):</span><br><span class="line">        <span class="built_in">print</span> a</span><br><span class="line">        <span class="built_in">print</span> b</span><br><span class="line">        <span class="built_in">print</span> args</span><br><span class="line">        <span class="built_in">print</span> kwargs</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, e=<span class="number">5</span>, f=<span class="number">6</span>, g=<span class="number">7</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span> <span class="number">4</span></span><br><span class="line">&#123;<span class="string">&#x27;e&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;g&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;f&#x27;</span>: <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure>


<h3 id="参数列表的分拆"><a href="#参数列表的分拆" class="headerlink" title="参数列表的分拆"></a>参数列表的分拆</h3><p>当大家在阅读如《Python从入门到精通》等丛书时，通常会介绍到当我们尝试把元组或字典直接输入给函数，可以分别使用<code>*arg</code>或<code>**arg</code>直接向函数输入。但这是为什么呢？</p>
<p>当你要传递的参数已经是一个列表，但要调用的函数却接受分开一个个的参数值。这时候你要把已有的列表拆开来。例如内建函数<code>range()</code>需要要独立的 start，stop参数。你可以在调用函数时加一个 * 操作符来自动把参数列表拆开:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">6</span>))            <span class="comment"># normal call with separate arguments</span></span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>args = [<span class="number">3</span>, <span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(*args))            <span class="comment"># call with arguments unpacked from a list</span></span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<p>以同样的方式，可以使用 <code>**</code> 操作符分拆关键字参数为字典:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">parrot</span>(<span class="params">voltage, state=<span class="string">&#x27;a stiff&#x27;</span>, action=<span class="string">&#x27;voom&#x27;</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;-- This parrot wouldn&#x27;t&quot;</span>, action, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;if you put&quot;</span>, voltage, <span class="string">&quot;volts through it.&quot;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;E&#x27;s&quot;</span>, state, <span class="string">&quot;!&quot;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = &#123;<span class="string">&quot;voltage&quot;</span>: <span class="string">&quot;four million&quot;</span>, <span class="string">&quot;state&quot;</span>: <span class="string">&quot;bleedin&#x27; demised&quot;</span>, <span class="string">&quot;action&quot;</span>: <span class="string">&quot;VOOM&quot;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parrot(**d)</span><br><span class="line">-- This parrot wouldn<span class="string">&#x27;t VOOM if you put four million volts through it. E&#x27;</span>s bleedin<span class="string">&#x27; demised !</span></span><br></pre></td></tr></table></figure>

<h3 id="Lambda-形式"><a href="#Lambda-形式" class="headerlink" title="Lambda 形式"></a>Lambda 形式</h3><p>出于实际需要，有几种通常在函数式编程语言例如 Lisp 中出现的功能加入到了 Python。通过<code>lambda</code>关键字，可以创建短小的匿名函数。这里有一个函数返回它的两个参数的和： lambda a, b: a+b。 Lambda 形式可以用于任何需要的函数对象。出于语法限制，它们只能有一个单独的表达式。语义上讲，它们只是普通函数定义中的一个语法技巧。类似于嵌套函数定义，lambda 形式可以从外部作用域引用变量:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">make_incrementor</span>(<span class="params">n</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> <span class="keyword">lambda</span> x: x + n</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = make_incrementor(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f(<span class="number">0</span>)</span><br><span class="line"><span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f(<span class="number">1</span>)</span><br><span class="line"><span class="number">43</span></span><br></pre></td></tr></table></figure>


<h3 id="函数中的参数传递深入解析"><a href="#函数中的参数传递深入解析" class="headerlink" title="函数中的参数传递深入解析"></a>函数中的参数传递深入解析</h3><p>在Python中定义一个函数时，可以通过把参数放在括号内将它们传入函数。调用函数时，需要为参数指定一个值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">addNum</span>(<span class="params">num1, num2</span>):</span><br><span class="line">    <span class="built_in">print</span>(num1 + num2)</span><br><span class="line"></span><br><span class="line">addNum(<span class="number">2</span>,<span class="number">4</span>)       <span class="comment"># 输出：6</span></span><br></pre></td></tr></table></figure>

<p>在上面的例子中，我向名为<code>addNum</code>的函数传递了两个参数，该函数将两个参数的和输出至终端。</p>
<h4 id="定位参数、关键字参数"><a href="#定位参数、关键字参数" class="headerlink" title="定位参数、关键字参数"></a>定位参数、关键字参数</h4><p>在Python中，当定义一个函数时，函数接收的参数叫做形式参数（parameters），以下简称形参；当调用一个函数时，调用语句传递给该函数的值叫做实际参数（arguments），以下简称实参。</p>
<p>根据<a href="https://docs.python.org/3/library/inspect.html">$\lfloor$inspect模块$\rceil$</a> 的描述，Python的形参可以分成如下五类：</p>
<ul>
<li><code>POSITIONAL_OR_KEYWORD</code>，默认类型，可通过定位&#x2F;关键字实参传递；</li>
<li><code>VAR_POSITIONAL</code>，定位形参元祖，如<code>*args</code>，捕获剩下的定位实参；</li>
<li><code>KEYWORD_ONLY</code>，在<code>*</code>或<code>*args</code>之后的形参，只能通过关键字实参传递；</li>
<li><code>VAR_KEYWORD</code>，关键字形参字典，如<code>**kwargs</code>，捕获剩下的关键字实参；</li>
<li><code>POSITIONAL_ONLY</code>，只能通过定位实参传递，Python语法暂不支持，只有一些C函数（如divmod）使用。</li>
</ul>
<p>比如定义如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *args</span>):</span><br><span class="line">    <span class="built_in">print</span>(a, args)</span><br></pre></td></tr></table></figure>

<p>其中形参a属于<code>POSITIONAL_OR_KEYWORD</code>，可通过定位&#x2F;关键字实参传递：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span> ()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(a=<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span> ()</span><br></pre></td></tr></table></figure>

<p>满足形参<code>a</code>之后，剩余的定位实参将被<code>*args</code>以元组的形式捕获：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> (<span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>再比如定义如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *args, b, **kwargs</span>):</span><br><span class="line">    <span class="built_in">print</span>(a, args, b, kwargs)</span><br></pre></td></tr></table></figure>

<p>形参b属于KEYWORD_ONLY，因为它在<code>*args</code>之后定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>满足形参b之后，剩余的关键字实参将被<code>**kwargs</code>以字典的形式捕获：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>, c=<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;<span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果想定义<code>KEYWORD_ONLY</code>形参，但不想使用<code>VAR_POSITIONAL</code>形参（即<code>*args</code>），则可以在定义函数时单独的<code>*</code>号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *, b</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(a, b)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: foo() takes <span class="number">1</span> positional argument but <span class="number">2</span> were given</span><br></pre></td></tr></table></figure>

<h4 id="参数默认值"><a href="#参数默认值" class="headerlink" title="参数默认值"></a>参数默认值</h4><p>在定义函数时，我们可以给形参指定默认值，比如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(a, args, b, kwargs)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，形参的默认值存储在函数对象的__defaults__和__kwdefaults__属性里，而不是每次调用函数时动态生成，所以最好不要用可变对象充当形参的默认值。下面的例子就是反面教材：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">param=[]</span>):</span><br><span class="line"><span class="meta">... </span>    param.append(<span class="number">1</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="built_in">id</span>(param), param)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">id</span>(foo.__defaults__[<span class="number">0</span>]), foo.__defaults__[<span class="number">0</span>])</span><br><span class="line"><span class="number">140009169940232</span> []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">140009169940232</span> [<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">140009169940232</span> [<span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<h4 id="获取关于参数的信息"><a href="#获取关于参数的信息" class="headerlink" title="获取关于参数的信息"></a>获取关于参数的信息</h4><p>内省指程序在运行时检查对象类型的一种能力，本节介绍的内容就属于函数内省的范围。假设有如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs</span>):</span><br><span class="line">    c = a</span><br><span class="line">    <span class="built_in">print</span>(c, args, b, kwargs)</span><br></pre></td></tr></table></figure>

<p>就像上一节中提到的，<code>foo</code>函数有<code>__defaults__</code>、<code>__kwdefaults__</code>属性，用于记录定位参数和关键字参数的默认值；有<code>__code__</code>属性，存储函数编译后的字节码信息，其中就包括参数的名称。通过这些属性，我们可以获取关于函数参数的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__defaults__</span><br><span class="line">(<span class="number">1</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__kwdefaults__</span><br><span class="line">&#123;<span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_varnames  <span class="comment"># 参数&amp;局部变量名称</span></span><br><span class="line">(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;args&#x27;</span>, <span class="string">&#x27;kwargs&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_argcount  <span class="comment"># 定位参数数量</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_kwonlyargcount  <span class="comment"># 仅限关键字参数数量</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>但这样还是太原始、太不方便了。幸好，我们有更好的选择：Python内置的inspect模块。下面这个例子就提取了<code>foo</code>函数的签名，然后获取函数的参数信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> inspect <span class="keyword">import</span> signature</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sig = signature(foo)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sig</span><br><span class="line">&lt;Signature (a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs)&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name, param <span class="keyword">in</span> sig.parameters.items():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">str</span>(param.kind):&lt;<span class="number">21</span>&#125;</span> : <span class="subst">&#123;param.name:&lt;<span class="number">6</span>&#125;</span> = <span class="subst">&#123;param.default&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">POSITIONAL_OR_KEYWORD : a      = <span class="number">1</span></span><br><span class="line">VAR_POSITIONAL        : args   = &lt;<span class="keyword">class</span> <span class="string">&#x27;inspect._empty&#x27;</span>&gt;</span><br><span class="line">KEYWORD_ONLY          : b      = <span class="number">2</span></span><br><span class="line">VAR_KEYWORD           : kwargs = &lt;<span class="keyword">class</span> <span class="string">&#x27;inspect._empty&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>同时，inspect.Signature对象还有一个bind方法，该方法可以将一些对象绑定到函数的形参上，就像Python解释器在调用函数时做的那样。通过这种方法，框架可以在真正执行函数前验证参数，就像下面这个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bound = sig.bind(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, c=<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name, value <span class="keyword">in</span> bound.arguments.items():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name:&lt;<span class="number">6</span>&#125;</span> = <span class="subst">&#123;value&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">a      = <span class="number">1</span></span><br><span class="line">args   = (<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">kwargs = &#123;<span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bound = sig.bind(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, a=<span class="number">4</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File ...</span><br><span class="line">TypeError: multiple values <span class="keyword">for</span> argument <span class="string">&#x27;a&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="函数参数传递"><a href="#函数参数传递" class="headerlink" title="函数参数传递"></a>函数参数传递</h4><p>说起函数参数传递，可能就有人想起了引用传递、值传递……忘掉这两个概念，来看看下面两个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo1</span>(<span class="params">param: <span class="built_in">list</span></span>):</span><br><span class="line">    param += [<span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">arg1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">foo1(arg1)</span><br><span class="line"><span class="built_in">print</span>(arg1)  <span class="comment"># 输出[1, 2, 3, 4, 5]</span></span><br></pre></td></tr></table></figure>

<p>内存中有一个<code>list</code>对象（[1, 2, 3]），该对象有两个别名：<code>arg1</code>和<code>param</code>。由于<code>list</code>对象是可变的（mutable），所以可以通过<code>param</code>这个别名修改这个<code>list</code>对象的内容。</p>
<img src="https://www.yooo.ltd/images/2020/07/04/list.webp" width="75%" alt="参数传递示例01" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo2</span>(<span class="params">param: <span class="built_in">tuple</span></span>):</span><br><span class="line">    param += (<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">arg2 = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">foo2(arg2)</span><br><span class="line"><span class="built_in">print</span>(arg2)  <span class="comment"># 输出(1, 2, 3)</span></span><br></pre></td></tr></table></figure>

<p>内存中有一个<code>tuple</code>对象（(1, 2, 3)），该对象也有两个别名：<code>arg2</code>和<code>param</code>。但由于<code>tuple</code>对象是不可变的(immutable)，当执行param +&#x3D; (4, 5)时，解释器创建了一个新的<code>tuple</code>对象（(1, 2, 3, 4, 5)），并让<code>param</code>指向这个新的对象，而原来的对象没有被改变。</p>
<img src="https://www.yooo.ltd/images/2020/07/04/tuple.webp" width="75%" alt="参数传递示例02" align=center />

<p>在Python中，参数传递本质上是为已有的对象取了一个函数作用域级别的别名。如果该对象是可变的，那么就可以在函数内修改该对象，这种修改也可以被其它的别名所感知。弄清楚对象、别名的关系，就不会对值传递、引用传递这种说法感到困惑了。</p>
<h2 id="NumPy初步"><a href="#NumPy初步" class="headerlink" title="NumPy初步"></a>NumPy初步</h2><p>NumPy是Python中科学计算的基本软件包。它是一个Python库，提供多维数组对象，各种派生对象（例如蒙版数组和矩阵）以及各种例程，用于对数组进行快速操作，包括数学，逻辑，形状处理，排序，选择，I&#x2F;O，离散傅立叶变换，基本线性代数，基本统计运算，随机模拟等等。</p>
<h3 id="NumPy安装"><a href="#NumPy安装" class="headerlink" title="NumPy安装"></a>NumPy安装</h3><p>安装NumPy的唯一前提是Python本身。而Python官网上的发行版是不包含NumPy模块的。如果你希望以最简单的方式开始使用，建议你使用Anaconda发行版，它包括Python，NumPy和许多其他用于科学计算和数据科学常用的软件包。同时支持Linux、Windows和mac。</p>
<p>如果你没有NumPy，在windows平台的cmd窗口可以通过如下命令执行安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy</span><br></pre></td></tr></table></figure>

<p>默认情况使用国外线路，如果太慢，我们使用清华的镜像就可以:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>Mac 系统的 Homebrew 不包含 NumPy 或其他一些科学计算包，同样可以采用以下方式进行安装。打开终端，输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>完成安装后，你可以进行验证：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>

<p>NumPy的历史可以追溯到90年代中期，它的前身为Numeric（用C语言编写，主要用来调取C++中应用）和Numarray（用于处理高维数组，可灵活的索引、数据类型变换、广播等），2005年出现的NumPy作为继承者，吸取了Numeric中丰富的C API及Numarray的高维数组处理能力，成为Python科学计算生态系统的基础。追根溯源，NumPy是集成在Python编程语言中的向量化运算工具集，如果你是用的是Intel的CPU，它将直接调用MKL库执行C语言的向量计算库，这是目前速度最快的向量计算库。</p>
<p>将大规模向量、矩阵运算交给NumPy如果对数组进行向量化运算，例如全体四则运算、矩阵乘法、求和、按指标求和等，一定要利用NumPy的矩阵运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(<span class="number">1000000</span>)    <span class="comment"># 创建两个百万维的数组</span></span><br><span class="line">b = np.random.rand(<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">begin = time.time()            <span class="comment"># 分别用np.dot和for循环对两个数组进行点乘</span></span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用np.dot方法(向量化)用的时间:&#123;&#125; ms.&quot;</span>.<span class="built_in">format</span>(<span class="number">1000</span>*(end-begin)))</span><br><span class="line"></span><br><span class="line">c = <span class="number">0</span></span><br><span class="line">begin = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">1000000</span>):</span><br><span class="line">    c += a[i]*b[i]</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用for循环用的时间:&#123;&#125; ms.&quot;</span>.<span class="built_in">format</span>(<span class="number">1000</span>*(end-begin)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">249715.57341423497</span></span><br><span class="line">使用np.dot方法(向量化)用的时间:<span class="number">1.9905567169189453</span> ms.</span><br><span class="line"><span class="number">249715.57341423733</span></span><br><span class="line">使用<span class="keyword">for</span>循环用的时间:<span class="number">1073.1749534606934</span> ms.</span><br></pre></td></tr></table></figure>


<h2 id="Python-代码的性能分析"><a href="#Python-代码的性能分析" class="headerlink" title="Python 代码的性能分析"></a>Python 代码的性能分析</h2><p>我们怎样知道执行某个Python文件、某个函数、某段代码所耗费的总体时间？</p>
<p>作为样例，本文使用slow_func.py来进行性能分析，内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)  <span class="comment"># 等待一秒</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** <span class="number">24</span>):</span><br><span class="line">        random.random()  <span class="comment"># 生成1600万个随机数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    func1()</span><br><span class="line">    func2()</span><br></pre></td></tr></table></figure>

<p>函数func1和func2的区别在于：CPU在执行func1时基本处在闲置状态，在执行func2()时基本处于忙碌状态。这点会在之后的测试中有所体现。在笔者的测试平台（Ubuntu 18.04+Python 3.6）上，两个函数所耗费的时间均在1s左右。</p>
<h3 id="time命令"><a href="#time命令" class="headerlink" title="time命令"></a>time命令</h3><p>类UNIX平台提供了time命令以统计执行执行命令所花费的时间。当然，这是一个通用型的工具，而不局限于Python。</p>
<p>执行如下shell命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">time python3 slow_func.py</span><br></pre></td></tr></table></figure>

<p>获得如下结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">real	0m1.960s  # 命令执行时间</span><br><span class="line">user	0m0.946s  # 用户态CPU时间</span><br><span class="line">sys 	0m0.008s</span><br></pre></td></tr></table></figure>

<p>根据前两行结果中我们可以得知，slow_func.py从开始到结束共消耗了2秒左右的时间，但实际消耗的用户态CPU时间只有1秒左右。这是因为CPU在执行func1()时处于等待状态（sleep），这段时间里是不消耗CPU时间的。</p>
<h3 id="time库"><a href="#time库" class="headerlink" title="time库"></a>time库</h3><p>Python提供了标准库time来进行关于时间的操作，我们可以通过这个库来测量代码执行所耗费的时间。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> slow_func <span class="keyword">import</span> func1, func2</span><br><span class="line"></span><br><span class="line">start1, start2 = time.perf_counter(), time.process_time()</span><br><span class="line">func1()</span><br><span class="line">func2()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;perf_counter: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(time.perf_counter() - start1))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;process_time: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start2))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;获得如下结果：&quot;&quot;&quot;</span></span><br><span class="line">perf_counter: <span class="number">2.1201</span>s</span><br><span class="line">process_time: <span class="number">1.1119</span>s</span><br></pre></td></tr></table></figure>

<p>time.perf_counter()的时间差是代码开始与代码结束两个时间点的时间差，而time.process_time()的时间差是消耗的CPU时间长度，所以得出了不同的结果，这与先前的time命令的原因和结果相类似。</p>
<h3 id="time库-上下文管理器"><a href="#time库-上下文管理器" class="headerlink" title="time库+上下文管理器"></a>time库+上下文管理器</h3><p>上面提到的用time库来测量代码耗时用起来很方便，但如果经常要用到的话写起来也很繁琐。这时我们可以写一个自定义的上下文管理器来避免重复代码。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</span><br><span class="line"></span><br><span class="line"><span class="meta">@contextmanager</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_block</span>(<span class="params">label</span>):  <span class="comment"># 代码块计时上下文管理器</span></span><br><span class="line">    <span class="comment"># 进入上下文</span></span><br><span class="line">    start = time.perf_counter()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">yield</span>  <span class="comment"># 执行代码块</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="comment"># 执行完成后输出代码块耗时</span></span><br><span class="line">        used = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(label, used))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用法</span></span><br><span class="line"><span class="keyword">with</span> time_block(<span class="string">&#x27;sleep&#x27;</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line">sleep: <span class="number">1.0011</span>s</span><br></pre></td></tr></table></figure>

<h3 id="time库-函数装饰器"><a href="#time库-函数装饰器" class="headerlink" title="time库+函数装饰器"></a>time库+函数装饰器</h3><p>上下文管理器针对的是代码块，如果只想统计函数执行所消耗的时间，用函数装饰器更为方便和快捷。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_wrap</span>(<span class="params">func</span>):  <span class="comment"># 函数计时装饰器</span></span><br><span class="line"><span class="meta">    @wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        start = time.perf_counter()</span><br><span class="line">        r = func(*args, **kwargs)</span><br><span class="line">        used = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;f.__module__&#125;.&#123;f.__name__&#125;: &#123;t:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(f=func, t=used))</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@time_wrap  </span><span class="comment"># 函数定义时使用装饰器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">slow_func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行函数时自动调用装饰器</span></span><br><span class="line">slow_func()</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line">__main__.slow_func: <span class="number">1.0008</span>s</span><br></pre></td></tr></table></figure>

<h3 id="timeit库"><a href="#timeit库" class="headerlink" title="timeit库"></a>timeit库</h3><p>当需要多次重复测量Python代时以获取精确的耗时结果时，我们可以通过循环控制配合上文提到的方法来实现，也可以通过一个更便捷的、适合重复测试的标准库：timeit来实现。</p>
<p>执行如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line">setup = <span class="string">&#x27;from slow_func import func1&#x27;</span></span><br><span class="line"></span><br><span class="line">used = timeit.timeit(<span class="string">&#x27;func1()&#x27;</span>, setup=setup, number=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(used))</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">5.0039</span></span><br></pre></td></tr></table></figure>

<p>timeit库默认使用的计时器为time.perf_counter()，如果想换成测量CPU耗时的计时器，只需要附加上timer参数即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">timer = time.process_time</span><br><span class="line"></span><br><span class="line">used = timeit.timeit(<span class="string">&#x27;func1()&#x27;</span>, timer=timer, setup=setup, number=<span class="number">5</span>)  <span class="comment"># 附加timer参数</span></span><br></pre></td></tr></table></figure>

<h3 id="cProfile"><a href="#cProfile" class="headerlink" title="cProfile"></a>cProfile</h3><p>而在实际的性能分析场景中，目标代码的逻辑往往比较复杂，光靠总体执行耗时并不能帮助我们快速定位性能瓶颈。这个时候就需要请出Python的标准库：cProfile（官方文档）来对代码进行细致的性能分析了。</p>
<h4 id="命令行使用cProfile"><a href="#命令行使用cProfile" class="headerlink" title="命令行使用cProfile"></a>命令行使用cProfile</h4><p>对于单独的Python代码文件来说，通过命令行使用cProfile无疑是最方便的选择。</p>
<p>执行如下shell命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 -m cProfile -s tottime slow_func.py</span><br></pre></td></tr></table></figure>

<p>首先用python3的-m选项调用cProfile模块，然后用cProfile的-s选项让输出结果按tottime进行排序，最后执行slow_func.py文件。</p>
<p>完整调用格式为：<code>python -m cProfile [-o output_file] [-s sort_order] myscript.py</code></p>
<p>得到如下结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">        16778563 function calls (16778520 primitive calls) in 3.176 seconds</span><br><span class="line"></span><br><span class="line">  Ordered by: internal time</span><br><span class="line"></span><br><span class="line">  ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">       1    1.456    1.456    2.172    2.172 slow_func.py:8(func2)</span><br><span class="line">       1    1.001    1.001    1.001    1.001 &#123;built-in method time.sleep&#125;</span><br><span class="line">16777216    0.716    0.000    0.716    0.000 &#123;method &#x27;random&#x27; of &#x27;_random.Random&#x27; objects&#125;</span><br><span class="line">       1    0.001    0.001    0.001    0.001 &#123;built-in method _imp.create_dynamic&#125;</span><br><span class="line">       3    0.000    0.000    0.000    0.000 &#123;built-in method marshal.loads&#125;</span><br><span class="line">       # ...省略后续100多行</span><br></pre></td></tr></table></figure>

<ul>
<li>输出的第1行表明，脚本文件执行中存在1600多万次的函数调用，共耗费3.268秒。<br>** 而根据前一篇文章的测试结果，直接执行该脚本文件只需要2秒左右的时间，那多出来的1秒多花在了哪里？这是因为cProfile需要对每一次函数调用进行监控和记录，由于该文件存在较多的函数调用，所以总执行耗时也就增长了许多了。</li>
<li>第3行表明，下表内容按照internal time（内部执行时间，tottime）排序，这是由执行命令中的-s tottime参数决定的。</li>
<li>第5行为分析结果表的表头，依次为ncalls：调用次数、tottime：内部执行耗时、percall：内部执行耗时&#x2F;调用次数、cumtime：累计执行耗时、percall：累计执行耗时&#x2F;调用次数，以及最后的文件名+行号+函数名称。<br>** tottime和cumtime的区别在于，tottime不包括子函数执行所花费的时间，而cumtime是包括的。</li>
<li>第6行表明，slow_func.py中第8行的func2函数共执行了1次，内部耗时1.456秒，累计耗时2.172秒。</li>
<li>第7行表明，Python内置的sleep函数共执行了一次，耗时1.001秒。</li>
<li>第8行表明，Python内置的random函数共执行了1600多万次，耗时0.716秒。<br>** 由于random函数是被func2函数调用的，所以这0.716秒和func2函数的内部执行耗时1.456秒，共同组成了func2函数的累计执行耗时：2.172秒。</li>
<li>由于是用cProfile分析整个脚本文件，所以许多Python自身所需的函数调用也被展示在了结果里，所以分析结果表才会有100多行的规模。这个问题可以在下一小节中解决。</li>
</ul>
<h3 id="代码里使用cProfile"><a href="#代码里使用cProfile" class="headerlink" title="代码里使用cProfile"></a>代码里使用cProfile</h3><p>从本质上来说，通过命令行使用cProfile相当于在代码里使用cProfile的一个简化操作。而在命令行里分析代码有着明显的局限性：目标代码必须独立成文件、输出格式固定等等。所以，在代码里使用cProfile往往是一个更优的选择。<br>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cProfile</span><br><span class="line"><span class="keyword">import</span> pstats</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> slow_func <span class="keyword">import</span> func1, func2</span><br><span class="line"></span><br><span class="line">profile = cProfile.Profile()</span><br><span class="line">profile.enable()  <span class="comment"># 分析开始</span></span><br><span class="line">func1()</span><br><span class="line">func2()</span><br><span class="line">profile.disable()  <span class="comment"># 分析结束</span></span><br><span class="line">ram_file = StringIO()</span><br><span class="line">sort_by = <span class="string">&#x27;tottime&#x27;</span></span><br><span class="line">stats = pstats.Stats(profile, stream=ram_file)  <span class="comment"># 读取结果</span></span><br><span class="line">stats.strip_dirs().sort_stats(sort_by).print_stats()  <span class="comment"># 按格式输出至ram_file</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ram_file.getvalue())</span><br></pre></td></tr></table></figure>

<p>代码的核心逻辑是使用cProfile模块的Profile类对代码块进行性能分析，分析完成后使用pstats模块的Stats类将分析结果按一定格式写入至内存文件，最后输出该文件里写入的内容。</p>
<p>实际上这只是一个较为简单的样例，pstats模块还可以获得函数之间的调用关系、将结果持久化、显示文件路径等等，更完整的说明可以参考官方文档。</p>
<p>得到如下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        16777220 function calls in 3.225 seconds</span><br><span class="line"></span><br><span class="line">  Ordered by: internal time</span><br><span class="line"></span><br><span class="line">  ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">       1    1.517    1.517    2.224    2.224 slow_func.py:8(func2)</span><br><span class="line">       1    1.001    1.001    1.001    1.001 &#123;built-in method time.sleep&#125;</span><br><span class="line">16777216    0.707    0.000    0.707    0.000 &#123;method &#x27;random&#x27; of &#x27;_random.Random&#x27; objects&#125;</span><br><span class="line">       1    0.000    0.000    1.001    1.001 slow_func.py:5(func1)</span><br><span class="line">       1    0.000    0.000    0.000    0.000 &#123;method &#x27;disable&#x27; of &#x27;_lsprof.Profiler&#x27; objects&#125;</span><br></pre></td></tr></table></figure>

<h3 id="cProfile结果可视化"><a href="#cProfile结果可视化" class="headerlink" title="cProfile结果可视化"></a>cProfile结果可视化</h3><p>一般来说，通过以上两个例子就可以获得完善的性能分析报告了。但通过一些可视化工具对<code>cProfile</code>的报告进行二次处理，我们可以更清晰地观察函数之间的调用关系、更轻松地找出性能瓶颈，算是一个不错的辅助手段。在这里只介绍一种可视化工具：JetBrain PyCharm自带的Profile工具。</p>
<p>点击Pycharm中Run菜单里的Profile ‘xxx’项目，即可对当前运行执行方案使用cProfile进行性能分析，如下图：</p>
<img src="https://www.yooo.ltd/images/2019-03-08.01.png" width="45%" align=center />

<p>结果如下图所示。其中，Time对应cProfile中的cumtime，即累计执行耗时；Own Time对应cProfile中的tottime，即内部执行耗时。</p>
<img src="https://www.yooo.ltd/images/2019-03-08.02.png" width="95%" align=center />

<p>&emsp;</p>
<img src="https://www.yooo.ltd/images/2019-03-08.03.png" width="95%" align=center />]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 04：NumPy 数据分析基础</title>
    <url>/PythonLes05/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程仅作为学习NumPy的参考，并让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="导入NumPy作为np，并查看版本"><a href="#导入NumPy作为np，并查看版本" class="headerlink" title="导入NumPy作为np，并查看版本"></a>导入NumPy作为np，并查看版本</h2><p>将NumPy导入为 np 并打印版本号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.__version__)</span><br><span class="line"><span class="comment"># &gt; 1.13.3</span></span><br></pre></td></tr></table></figure>

<p>你必须将NumPy导入np作为简称，才能使本节课程中的其余代码正常工作。要安装NumPy，建议安装Anaconda，里面已经包含了NumPy。</p>
<h2 id="如何创建一维数组"><a href="#如何创建一维数组" class="headerlink" title="如何创建一维数组"></a>如何创建一维数组</h2><p>创建从0到9的一维数字数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"></span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>

<h2 id="创建一个布尔数组"><a href="#创建一个布尔数组" class="headerlink" title="创建一个布尔数组"></a>创建一个布尔数组</h2><p>创建一个NumPy数组元素值全为True的数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.full((<span class="number">3</span>, <span class="number">3</span>), <span class="literal">True</span>, dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="comment"># array([[ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True]], dtype=bool)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Alternate method:</span></span><br><span class="line">np.ones((<span class="number">3</span>,<span class="number">3</span>), dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="comment"># array([[ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从一维数组中提取满足指定条件的元素"><a href="#从一维数组中提取满足指定条件的元素" class="headerlink" title="从一维数组中提取满足指定条件的元素"></a>从一维数组中提取满足指定条件的元素</h2><p>从 arr 中提取所有的奇数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(arr % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt; array([False, True, False, True, False, True, False, True, False, True])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr[arr % <span class="number">2</span> == <span class="number">1</span>])</span><br><span class="line"><span class="comment"># &gt; array([1, 3, 5, 7, 9])</span></span><br></pre></td></tr></table></figure>

<h2 id="将数组中的另一个值替换满足条件的元素项"><a href="#将数组中的另一个值替换满足条件的元素项" class="headerlink" title="将数组中的另一个值替换满足条件的元素项"></a>将数组中的另一个值替换满足条件的元素项</h2><p>将arr中的所有奇数替换为-1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr[arr % <span class="number">2</span> == <span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># &gt; array([ 0, -1,  2, -1,  4, -1,  6, -1,  8, -1])</span></span><br></pre></td></tr></table></figure>

<h2 id="在不影响原始数组的情况下替换满足条件的元素项"><a href="#在不影响原始数组的情况下替换满足条件的元素项" class="headerlink" title="在不影响原始数组的情况下替换满足条件的元素项"></a>在不影响原始数组的情况下替换满足条件的元素项</h2><p>将arr中的所有奇数替换为-1，而不改变arr。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">out = np.where(arr % <span class="number">2</span> == <span class="number">1</span>, -<span class="number">1</span>, arr)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># &gt; array([0,  1,  2,  3,  4,  5,  6,  7,  8,  9])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment">#&gt; array([ 0, -1,  2, -1,  4, -1,  6, -1,  8, -1])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.where(condition, x, y)</span><br></pre></td></tr></table></figure>

<ul>
<li>condition: array_like, bool如果为True，则返回x，否则返回y。</li>
<li>x, y: array_like, 可选择的值。 x, y和condition适配广播规则。</li>
<li>returns: ndarray数组，当condition为True，元素值取自x, 否则元素值取自y。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">np.where(a &lt; <span class="number">5</span>, a, <span class="number">10</span>*a)</span><br><span class="line">array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># This can be used on multidimensional arrays too:</span></span><br><span class="line">np.where([[<span class="literal">True</span>, <span class="literal">False</span>], [<span class="literal">True</span>, <span class="literal">True</span>]],</span><br><span class="line">         [[<span class="number">1</span>   , <span class="number">2</span>    ], [<span class="number">3</span>   , <span class="number">4</span>   ]],</span><br><span class="line">         [[<span class="number">9</span>   , <span class="number">8</span>    ], [<span class="number">7</span>   , <span class="number">6</span>   ]])</span><br><span class="line"><span class="comment"># &gt;array([[1   , 8    ], [3   , 4   ]])</span></span><br></pre></td></tr></table></figure>


<h2 id="改变数组的形状"><a href="#改变数组的形状" class="headerlink" title="改变数组的形状"></a>改变数组的形状</h2><p>问题：如何将一维数组转换为2行的2维数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">arr.reshape(<span class="number">2</span>, -<span class="number">1</span>)  <span class="comment"># Setting to -1 automatically decides the number of cols</span></span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9]])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.reshape(a, newshape, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Gives a new shape to an array without changing its data.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 待改变形状的数组；</li>
<li>newshape: int 或 int 元组, 新形状应与原形状兼容。如果是整数，则结果将是该长度的1-D数组。一个形状维度可以是-1。在这种情况下，该值是从数组的长度和剩余维度推断出来的。</li>
<li>order: {‘C’, ‘F’, ‘A’} 可选项，使用此索引顺序读取a的元素，并使用此索引顺序将元素放入重塑的数组中。’C’ 意味着使用类似C的索引顺序读写元素，最后一个轴索引变化最快，回到第一个轴索引变化最慢。 ‘F’表示使用类似fortran的索引顺序读写元素，第一个索引变化最快，最后一个索引变化最慢。请注意，’C’和’F’选项不考虑底层数组的内存布局，而只参考索引的顺序。’A’表示如果A在内存中是Fortran连续的，则以类似Fortran的索引顺序读取&#x2F;写入元素，否则以类似C的顺序读取。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>).reshape((<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">a</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.reshape(a, (<span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># C-like index ordering</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line">np.reshape(a, (<span class="number">2</span>, <span class="number">3</span>), order=<span class="string">&#x27;F&#x27;</span>) <span class="comment"># Fortran-like index ordering</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="垂直叠加两个数组"><a href="#垂直叠加两个数组" class="headerlink" title="垂直叠加两个数组"></a>垂直叠加两个数组</h2><p>问题：垂直堆叠数组a和数组b</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.vstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.r_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>


<h2 id="水平叠加两个数组"><a href="#水平叠加两个数组" class="headerlink" title="水平叠加两个数组"></a>水平叠加两个数组</h2><p>问题：将数组a和数组b水平堆叠。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Answers</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.hstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.c_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>

<h2 id="获取两个NumPy数组之间的公共项"><a href="#获取两个NumPy数组之间的公共项" class="headerlink" title="获取两个NumPy数组之间的公共项"></a>获取两个NumPy数组之间的公共项</h2><p>问题：获取数组a和数组b之间的公共项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">b = np.array([<span class="number">7</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line">np.intersect1d(a,b)</span><br><span class="line"><span class="comment"># &gt; array([2, 4])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[intersect1d, comm1, comm2] = numpy.intersect1d(ar1, ar2, assume_unique=<span class="literal">False</span>, return_indices=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Find the intersection of two arrays.</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>ar1, ar2: array_like, 输入数组。即使不是一维，也会被一维化。</p>
</li>
<li><p>assume_unique: bool, 如果为True，则假定输入数组都是唯一的，这可以加快计算速度。如果为True，但ar1或ar2不是唯一的，则可能导致不正确的结果和越界索引。默认为False。</p>
</li>
<li><p>return_indices: bool, 如果为True，则返回两个数组的交点对应的索引。如果有多个值，则使用值的第一个实例。默认为False。</p>
</li>
<li><p>intersect1d: ndarray, 对共有元素和唯一元素的1D数组进行排序。</p>
</li>
<li><p>comm1: ar1中第一次出现的公共值的索引。仅当<code>return_indices</code>为<code>True</code>时提供。</p>
</li>
<li><p>comm2: ar2中第一次出现的公共值的索引。仅当<code>return_indices</code>为<code>True</code>时提供。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=<span class="literal">True</span>)</span><br><span class="line">x_ind, y_ind</span><br><span class="line"><span class="comment"># &gt;(array([0, 2, 4]), array([1, 0, 2]))</span></span><br><span class="line">xy, x[x_ind], y[y_ind]</span><br><span class="line"><span class="comment"># &gt;(array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))</span></span><br></pre></td></tr></table></figure>

<h2 id="从一个数组中删除存在于另一个数组中的项"><a href="#从一个数组中删除存在于另一个数组中的项" class="headerlink" title="从一个数组中删除存在于另一个数组中的项"></a>从一个数组中删除存在于另一个数组中的项</h2><p>问题：从数组a中删除数组b中的所有项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># From &#x27;a&#x27; remove all of &#x27;b&#x27;</span></span><br><span class="line">np.setdiff1d(a,b)</span><br><span class="line"><span class="comment"># &gt; array([1, 2, 3, 4])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setdiff1d = numpy.setdiff1d(ar1, ar2, assume_unique=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Find the set difference of two arrays.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>ar1: array_like, 输入数组；</li>
<li>ar2: array_like, 输入比较数组；</li>
<li>assume_unique: bool, 如果为True，则假定输入数组都是唯一的，这可以加快计算速度。默认为False。</li>
<li>setdiff1d: ar1中不属于ar2的值的一维数组。当assume_unique&#x3D;False时对结果进行排序，否则只在输入已排序时才对结果进行排序。</li>
</ul>
<h2 id="得到两个数组元素匹配的位置"><a href="#得到两个数组元素匹配的位置" class="headerlink" title="得到两个数组元素匹配的位置"></a>得到两个数组元素匹配的位置</h2><p>问题：获取a和b元素匹配的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">b = np.array([<span class="number">7</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">np.where(a == b)</span><br><span class="line"><span class="comment"># &gt; (array([1, 3, 5, 7]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组中提取给定范围内的所有数字"><a href="#从NumPy数组中提取给定范围内的所有数字" class="headerlink" title="从NumPy数组中提取给定范围内的所有数字"></a>从NumPy数组中提取给定范围内的所有数字</h2><p>问题：获取5到10之间的所有项目。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">index = np.where((a &gt;= <span class="number">5</span>) &amp; (a &lt;= <span class="number">10</span>))</span><br><span class="line">a[index]</span><br><span class="line"><span class="comment"># &gt; (array([6, 9, 10]),)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">index = np.where(np.logical_and(a&gt;=<span class="number">5</span>, a&lt;=<span class="number">10</span>))</span><br><span class="line">a[index]</span><br><span class="line"><span class="comment"># &gt; (array([6, 9, 10]),)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3: (thanks loganzk!)</span></span><br><span class="line">a[(a &gt;= <span class="number">5</span>) &amp; (a &lt;= <span class="number">10</span>)]</span><br></pre></td></tr></table></figure>

<h2 id="创建一个Python函数来处理标量运算并在NumPy数组上工作"><a href="#创建一个Python函数来处理标量运算并在NumPy数组上工作" class="headerlink" title="创建一个Python函数来处理标量运算并在NumPy数组上工作"></a>创建一个Python函数来处理标量运算并在NumPy数组上工作</h2><p>问题：转换适用于两个标量的函数maxx，以处理两个数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给定：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maxx</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the maximum of two items&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> x &gt;= y:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">maxx(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># &gt; 5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望的输出：</span></span><br><span class="line">a = np.array([<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>])</span><br><span class="line">pair_max(a, b)</span><br><span class="line"><span class="comment"># &gt; array([ 6.,  7.,  9.,  8.,  9.,  7.,  5.])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxx</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the maximum of two items&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> x &gt;= y:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">pair_max = np.vectorize(maxx, otypes=[<span class="built_in">float</span>])</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">pair_max(a, b)</span><br><span class="line"><span class="comment"># &gt; array([ 6.,  7.,  9.,  8.,  9.,  7.,  5.])</span></span><br></pre></td></tr></table></figure>


<h2 id="交换二维numpy数组中的两列"><a href="#交换二维numpy数组中的两列" class="headerlink" title="交换二维numpy数组中的两列"></a>交换二维numpy数组中的两列</h2><p>问题：在数组arr中交换列1和2。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, [<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="comment"># &gt; array([[1, 0, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [4, 3, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [7, 6, 8]])</span></span><br></pre></td></tr></table></figure>

<h2 id="交换二维numpy数组中的两行"><a href="#交换二维numpy数组中的两行" class="headerlink" title="交换二维numpy数组中的两行"></a>交换二维numpy数组中的两行</h2><p>问题：交换数组arr中的第1和第2行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[[<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>], :]</span><br><span class="line"><span class="comment"># &gt; array([[3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br></pre></td></tr></table></figure>

<h2 id="反转二维数组的行"><a href="#反转二维数组的行" class="headerlink" title="反转二维数组的行"></a>反转二维数组的行</h2><p>问题：反转二维数组arr的行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[::-<span class="number">1</span>]</span><br><span class="line">array([[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="反转二维数组的列"><a href="#反转二维数组的列" class="headerlink" title="反转二维数组的列"></a>反转二维数组的列</h2><p>问题：反转二维数组arr的列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, ::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; array([[2, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 4, 3],</span></span><br><span class="line"><span class="comment"># &gt;        [8, 7, 6]])</span></span><br></pre></td></tr></table></figure>

<h2 id="创建包含5到10之间随机浮动的二维数组"><a href="#创建包含5到10之间随机浮动的二维数组" class="headerlink" title="创建包含5到10之间随机浮动的二维数组"></a>创建包含5到10之间随机浮动的二维数组</h2><p>问题：创建一个形状为5x3的二维数组，以包含5到10之间的随机十进制数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution Method 1:</span></span><br><span class="line">rand_arr = np.random.randint(low=<span class="number">5</span>, high=<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>)) + np.random.random((<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># print(rand_arr)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution Method 2:</span></span><br><span class="line">rand_arr = np.random.uniform(<span class="number">5</span>,<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(rand_arr)</span><br><span class="line"><span class="comment"># &gt; [[ 8.50061025  9.10531502  6.85867783]</span></span><br><span class="line"><span class="comment"># &gt;  [ 9.76262069  9.87717411  7.13466701]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.48966403  8.33409158  6.16808631]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.75010551  9.94535696  5.27373226]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8.0850361   5.56165518  7.31244004]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中只打印小数点后三位"><a href="#在NumPy数组中只打印小数点后三位" class="headerlink" title="在NumPy数组中只打印小数点后三位"></a>在NumPy数组中只打印小数点后三位</h2><p>问题：只打印或显示numpy数组rand_arr的小数点后3位。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the random array</span></span><br><span class="line">rand_arr = np.random.random([<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Limit to 3 decimal places</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">3</span>)</span><br><span class="line">rand_arr[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 0.443,  0.109,  0.97 ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.388,  0.447,  0.191],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.891,  0.474,  0.212],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.609,  0.518,  0.403]])</span></span><br></pre></td></tr></table></figure>

<h2 id="通过e式科学记数法（如1e10）来打印一个NumPy数组"><a href="#通过e式科学记数法（如1e10）来打印一个NumPy数组" class="headerlink" title="通过e式科学记数法（如1e10）来打印一个NumPy数组"></a>通过e式科学记数法（如1e10）来打印一个NumPy数组</h2><p>问题：通过e式科学记数法来打印rand_arr（如1e10）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reset printoptions to default</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the random array</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">rand_arr = np.random.random([<span class="number">3</span>,<span class="number">3</span>])/<span class="number">1e3</span></span><br><span class="line">rand_arr</span><br><span class="line"><span class="comment"># &gt; array([[  5.434049e-04,   2.783694e-04,   4.245176e-04],</span></span><br><span class="line"><span class="comment"># &gt;        [  8.447761e-04,   4.718856e-06,   1.215691e-04],</span></span><br><span class="line"><span class="comment"># &gt;        [  6.707491e-04,   8.258528e-04,   1.367066e-04]])</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>, precision=<span class="number">6</span>)  <span class="comment"># precision is optional</span></span><br><span class="line">rand_arr</span><br><span class="line"><span class="comment"># &gt; array([[ 0.000543,  0.000278,  0.000425],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.000845,  0.000005,  0.000122],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.000671,  0.000826,  0.000137]])</span></span><br></pre></td></tr></table></figure>

<h2 id="限制numpy数组输出中打印的项目数"><a href="#限制numpy数组输出中打印的项目数" class="headerlink" title="限制numpy数组输出中打印的项目数"></a>限制numpy数组输出中打印的项目数</h2><p>问题：将numpy数组a中打印的项数限制为最多6个元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.set_printoptions(threshold=<span class="number">6</span>)</span><br><span class="line">a = np.arange(<span class="number">15</span>)</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2, ..., 12, 13, 14])</span></span><br></pre></td></tr></table></figure>

<h2 id="打印完整的numpy数组而不截断"><a href="#打印完整的numpy数组而不截断" class="headerlink" title="打印完整的numpy数组而不截断"></a>打印完整的numpy数组而不截断</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(threshold=<span class="number">6</span>)</span><br><span class="line">a = np.arange(<span class="number">15</span>\</span><br><span class="line">	&#125;<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.set_printoptions(threshold=np.nan)</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])</span></span><br></pre></td></tr></table></figure>


<h2 id="导入数字和文本的数据集保持文本在numpy数组中完好无损"><a href="#导入数字和文本的数据集保持文本在numpy数组中完好无损" class="headerlink" title="导入数字和文本的数据集保持文本在numpy数组中完好无损"></a>导入数字和文本的数据集保持文本在numpy数组中完好无损</h2><p>问题：导入鸢尾属植物数据集，保持文本不变。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first 3 rows</span></span><br><span class="line">iris[:<span class="number">3</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="从1维元组数组中提取特定列"><a href="#从1维元组数组中提取特定列" class="headerlink" title="从1维元组数组中提取特定列"></a>从1维元组数组中提取特定列</h2><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="将1维元组数组转换为2维NumPy数组"><a href="#将1维元组数组转换为2维NumPy数组" class="headerlink" title="将1维元组数组转换为2维NumPy数组"></a>将1维元组数组转换为2维NumPy数组</h2><p>问题：通过省略鸢尾属植物数据集种类的文本字段，将一维鸢尾属植物数据集转换为二维数组iris_2d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="comment"># Method 1: Convert each row to a list and get the first 4 items</span></span><br><span class="line">iris_2d = np.array([row.tolist()[:<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Alt Method 2: Import only the first 4 columns from source url</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算numpy数组的均值，中位数，标准差"><a href="#计算numpy数组的均值，中位数，标准差" class="headerlink" title="计算numpy数组的均值，中位数，标准差"></a>计算numpy数组的均值，中位数，标准差</h2><p>问题：求出鸢尾属植物萼片长度的平均值、中位数和标准差(第1列)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">mu, med, sd = np.mean(sepallength), np.median(sepallength), np.std(sepallength)</span><br><span class="line"><span class="built_in">print</span>(mu, med, sd)</span><br><span class="line"><span class="comment"># &gt; 5.84333333333 5.8 0.825301291785</span></span><br></pre></td></tr></table></figure>

<h2 id="规范化数组，使数组的值正好介于0和1之间"><a href="#规范化数组，使数组的值正好介于0和1之间" class="headerlink" title="规范化数组，使数组的值正好介于0和1之间"></a>规范化数组，使数组的值正好介于0和1之间</h2><p>问题：创建一种标准化形式的鸢尾属植物间隔长度，其值正好介于0和1之间，这样最小值为0，最大值为1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">Smax, Smin = sepallength.<span class="built_in">max</span>(), sepallength.<span class="built_in">min</span>()</span><br><span class="line">S = (sepallength - Smin)/(Smax - Smin)</span><br><span class="line"><span class="comment"># or </span></span><br><span class="line">S = (sepallength - Smin)/sepallength.ptp()  <span class="comment"># Thanks, David Ojeda!</span></span><br><span class="line"><span class="built_in">print</span>(S)</span><br><span class="line"><span class="comment"># &gt; [ 0.222  0.167  0.111  0.083  0.194  0.306  0.083  0.194  0.028  0.167</span></span><br><span class="line"><span class="comment"># &gt;   0.306  0.139  0.139  0.     0.417  0.389  0.306  0.222  0.389  0.222</span></span><br><span class="line"><span class="comment"># &gt;   0.306  0.222  0.083  0.222  0.139  0.194  0.194  0.25   0.25   0.111</span></span><br><span class="line"><span class="comment"># &gt;   0.139  0.306  0.25   0.333  0.167  0.194  0.333  0.167  0.028  0.222</span></span><br><span class="line"><span class="comment"># &gt;   0.194  0.056  0.028  0.194  0.222  0.139  0.222  0.083  0.278  0.194</span></span><br><span class="line"><span class="comment"># &gt;   0.75   0.583  0.722  0.333  0.611  0.389  0.556  0.167  0.639  0.25</span></span><br><span class="line"><span class="comment"># &gt;   0.194  0.444  0.472  0.5    0.361  0.667  0.361  0.417  0.528  0.361</span></span><br><span class="line"><span class="comment"># &gt;   0.444  0.5    0.556  0.5    0.583  0.639  0.694  0.667  0.472  0.389</span></span><br><span class="line"><span class="comment"># &gt;   0.333  0.333  0.417  0.472  0.306  0.472  0.667  0.556  0.361  0.333</span></span><br><span class="line"><span class="comment"># &gt;   0.333  0.5    0.417  0.194  0.361  0.389  0.389  0.528  0.222  0.389</span></span><br><span class="line"><span class="comment"># &gt;   0.556  0.417  0.778  0.556  0.611  0.917  0.167  0.833  0.667  0.806</span></span><br><span class="line"><span class="comment"># &gt;   0.611  0.583  0.694  0.389  0.417  0.583  0.611  0.944  0.944  0.472</span></span><br><span class="line"><span class="comment"># &gt;   0.722  0.361  0.944  0.556  0.667  0.806  0.528  0.5    0.583  0.806</span></span><br><span class="line"><span class="comment"># &gt;   0.861  1.     0.583  0.556  0.5    0.944  0.556  0.583  0.472  0.722</span></span><br><span class="line"><span class="comment"># &gt;   0.667  0.722  0.417  0.694  0.667  0.667  0.556  0.611  0.528  0.444]</span></span><br></pre></td></tr></table></figure>

<h2 id="找到numpy数组的百分位数"><a href="#找到numpy数组的百分位数" class="headerlink" title="找到numpy数组的百分位数"></a>找到numpy数组的百分位数</h2><p>问题：找到鸢尾属植物数据集的第5和第95百分位数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.percentile(sepallength, q=[<span class="number">5</span>, <span class="number">95</span>])</span><br><span class="line"><span class="comment"># &gt; array([ 4.6  ,  7.255])</span></span><br></pre></td></tr></table></figure>

<h2 id="在数组中的随机位置插入值"><a href="#在数组中的随机位置插入值" class="headerlink" title="在数组中的随机位置插入值"></a>在数组中的随机位置插入值</h2><p>问题：在iris_2d数据集中的20个随机位置插入np.nan值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到缺失值的位置"><a href="#在NumPy数组中找到缺失值的位置" class="headerlink" title="在NumPy数组中找到缺失值的位置"></a>在NumPy数组中找到缺失值的位置</h2><p>问题：在iris_2d的sepallength中查找缺失值的数量和位置（第1列）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of missing values: \n&quot;</span>, np.isnan(iris_2d[:, <span class="number">0</span>]).<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Position of missing values: \n&quot;</span>, np.where(np.isnan(iris_2d[:, <span class="number">0</span>])))</span><br><span class="line"><span class="comment"># &gt; Number of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  5</span></span><br><span class="line"><span class="comment"># &gt; Position of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  (array([ 39,  88,  99, 130, 147]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="根据两个或多个条件过滤numpy数组"><a href="#根据两个或多个条件过滤numpy数组" class="headerlink" title="根据两个或多个条件过滤numpy数组"></a>根据两个或多个条件过滤numpy数组</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">答案：</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">condition = (iris_2d[:, <span class="number">2</span>] &gt; <span class="number">1.5</span>) &amp; (iris_2d[:, <span class="number">0</span>] &lt; <span class="number">5.0</span>)</span><br><span class="line">iris_2d[condition]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.8,  3.4,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.4,  1.9,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.1,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.4,  3.3,  1. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.5,  4.5,  1.7]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组中删除包含缺失值的行"><a href="#从numpy数组中删除包含缺失值的行" class="headerlink" title="从numpy数组中删除包含缺失值的行"></a>从numpy数组中删除包含缺失值的行</h2><p>问题：选择没有任何nan值的iris_2d行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct numpy function for this.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">any_nan_in_row = np.array([~np.<span class="built_in">any</span>(np.isnan(row)) <span class="keyword">for</span> row <span class="keyword">in</span> iris_2d])</span><br><span class="line">iris_2d[any_nan_in_row][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: (By Rong)</span></span><br><span class="line">iris_2d[np.<span class="built_in">sum</span>(np.isnan(iris_2d), axis = <span class="number">1</span>) == <span class="number">0</span>][:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5. ,  3.6,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5.4,  3.9,  1.7,  0.4]])</span></span><br></pre></td></tr></table></figure>

<h2 id="找到numpy数组的两列之间的相关性"><a href="#找到numpy数组的两列之间的相关性" class="headerlink" title="找到numpy数组的两列之间的相关性"></a>找到numpy数组的两列之间的相关性</h2><p>问题：在iris_2d中找出SepalLength（第1列）和PetalLength（第3列）之间的相关性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.corrcoef(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr  </span><br><span class="line">corr, p_value = pearsonr(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Correlation coef indicates the degree of linear relationship between two numeric variables.</span></span><br><span class="line"><span class="comment"># It can range between -1 to +1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The p-value roughly indicates the probability of an uncorrelated system producing </span></span><br><span class="line"><span class="comment"># datasets that have a correlation at least as extreme as the one computed.</span></span><br><span class="line"><span class="comment"># The lower the p-value (&lt;0.01), stronger is the significance of the relationship.</span></span><br><span class="line"><span class="comment"># It is not an indicator of the strength.</span></span><br><span class="line"><span class="comment"># &gt; 0.871754157305</span></span><br></pre></td></tr></table></figure>

<h2 id="查找给定数组是否具有任何空值"><a href="#查找给定数组是否具有任何空值" class="headerlink" title="查找给定数组是否具有任何空值"></a>查找给定数组是否具有任何空值</h2><p>问题：找出iris_2d是否有任何缺失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">np.isnan(iris_2d).<span class="built_in">any</span>()</span><br><span class="line"><span class="comment"># &gt; False</span></span><br></pre></td></tr></table></figure>

<h2 id="在numpy数组中用0替换所有缺失值"><a href="#在numpy数组中用0替换所有缺失值" class="headerlink" title="在numpy数组中用0替换所有缺失值"></a>在numpy数组中用0替换所有缺失值</h2><p>问题：在numpy数组中将所有出现的nan替换为0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">iris_2d[np.isnan(iris_2d)] = <span class="number">0</span></span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="在numpy数组中查找唯一值的计数"><a href="#在numpy数组中查找唯一值的计数" class="headerlink" title="在numpy数组中查找唯一值的计数"></a>在numpy数组中查找唯一值的计数</h2><p>问题：找出鸢尾属植物物种中的独特值和独特值的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Extract the species column as an array</span></span><br><span class="line">species = np.array([row.tolist()[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the unique values and the counts</span></span><br><span class="line">np.unique(species, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        dtype=&#x27;|S15&#x27;), array([50, 50, 50]))</span></span><br></pre></td></tr></table></figure>

<h2 id="将数字转换为分类（文本）数组"><a href="#将数字转换为分类（文本）数组" class="headerlink" title="将数字转换为分类（文本）数组"></a>将数字转换为分类（文本）数组</h2><p>问题：将iris_2d的花瓣长度（第3列）加入以形成文本数组，这样如果花瓣长度为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;= 3 --&gt; &#x27;small&#x27;</span><br><span class="line"> 3-5 --&gt; &#x27;medium&#x27;</span><br><span class="line">&#x27;&gt;=5 --&gt; &#x27;large&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bin petallength </span></span><br><span class="line">petal_length_bin = np.digitize(iris[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>), [<span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map it to respective category</span></span><br><span class="line">label_map = &#123;<span class="number">1</span>: <span class="string">&#x27;small&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;medium&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;large&#x27;</span>, <span class="number">4</span>: np.nan&#125;</span><br><span class="line">petal_length_cat = [label_map[x] <span class="keyword">for</span> x <span class="keyword">in</span> petal_length_bin]</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">petal_length_cat[:<span class="number">4</span>]</span><br><span class="line">&lt;<span class="comment"># &gt; [&#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;]</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组的现有列创建新列"><a href="#从numpy数组的现有列创建新列" class="headerlink" title="从numpy数组的现有列创建新列"></a>从numpy数组的现有列创建新列</h2><p>问题：在iris_2d中为卷创建一个新列，其中volume是（pi x petallength x sepal_length ^ 2）&#x2F; 3</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Compute volume</span></span><br><span class="line">sepallength = iris_2d[:, <span class="number">0</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">petallength = iris_2d[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">volume = (np.pi * petallength * (sepallength**<span class="number">2</span>))/<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Introduce new dimension to match iris_2d&#x27;s</span></span><br><span class="line">volume = volume[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the new column</span></span><br><span class="line">out = np.hstack([iris_2d, volume])</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">out[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 38.13265162927291],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 35.200498485922445],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 30.0723720777127],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.6&#x27;, b&#x27;3.1&#x27;, b&#x27;1.5&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 33.238050274980004]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy中进行概率抽样"><a href="#在NumPy中进行概率抽样" class="headerlink" title="在NumPy中进行概率抽样"></a>在NumPy中进行概率抽样</h2><p>问题：随机抽鸢尾属植物的种类，使得刚毛的数量是云芝和维吉尼亚的两倍</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species column</span></span><br><span class="line">species = iris[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 1: Generate Probablistically</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.array([<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>])</span><br><span class="line">species_out = np.random.choice(a, <span class="number">150</span>, p=[<span class="number">0.5</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 2: Probablistic Sampling (preferred)</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">probs = np.r_[np.linspace(<span class="number">0</span>, <span class="number">0.500</span>, num=<span class="number">50</span>), np.linspace(<span class="number">0.501</span>, <span class="number">.750</span>, num=<span class="number">50</span>), np.linspace(<span class="number">.751</span>, <span class="number">1.0</span>, num=<span class="number">50</span>)]</span><br><span class="line">index = np.searchsorted(probs, np.random.random(<span class="number">150</span>))</span><br><span class="line">species_out = species[index]</span><br><span class="line"><span class="built_in">print</span>(np.unique(species_out, return_counts=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;], dtype=object), array([77, 37, 36]))</span></span><br></pre></td></tr></table></figure>

<p>方法2是首选方法，因为它创建了一个索引变量，该变量可用于取样2维表格数据。</p>
<h2 id="在按另一个数组分组时获取数组的第二大值"><a href="#在按另一个数组分组时获取数组的第二大值" class="headerlink" title="在按另一个数组分组时获取数组的第二大值"></a>在按另一个数组分组时获取数组的第二大值</h2><p>问题：第二长的物种setosa的价值是多少</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species and petal length columns</span></span><br><span class="line">petal_len_setosa = iris[iris[:, <span class="number">4</span>] == <span class="string">b&#x27;Iris-setosa&#x27;</span>, [<span class="number">2</span>]].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the second last value</span></span><br><span class="line">np.unique(np.sort(petal_len_setosa))[-<span class="number">2</span>]</span><br><span class="line"><span class="comment"># &gt; 1.7</span></span><br></pre></td></tr></table></figure>

<h2 id="按列对2D数组进行排序"><a href="#按列对2D数组进行排序" class="headerlink" title="按列对2D数组进行排序"></a>按列对2D数组进行排序</h2><p>问题：根据sepallength列对虹膜数据集进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sort by column position 0: SepalLength</span></span><br><span class="line"><span class="built_in">print</span>(iris[iris[:,<span class="number">0</span>].argsort()][:<span class="number">20</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;4.3&#x27; b&#x27;3.0&#x27; b&#x27;1.1&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.0&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;2.9&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.5&#x27; b&#x27;2.3&#x27; b&#x27;1.3&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.6&#x27; b&#x27;1.0&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.2&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.9&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.1&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.4&#x27; b&#x27;3.3&#x27; b&#x27;1.0&#x27; b&#x27;Iris-versicolor&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.5&#x27; b&#x27;4.5&#x27; b&#x27;1.7&#x27; b&#x27;Iris-virginica&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到最常见的值"><a href="#在NumPy数组中找到最常见的值" class="headerlink" title="在NumPy数组中找到最常见的值"></a>在NumPy数组中找到最常见的值</h2><p>问题：在鸢尾属植物数据集中找到最常见的花瓣长度值（第3列）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">vals, counts = np.unique(iris[:, <span class="number">2</span>], return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vals[np.argmax(counts)])</span><br><span class="line"><span class="comment"># &gt; b&#x27;1.5&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="找到第一次出现的值大于给定值的位置"><a href="#找到第一次出现的值大于给定值的位置" class="headerlink" title="找到第一次出现的值大于给定值的位置"></a>找到第一次出现的值大于给定值的位置</h2><p>问题：在虹膜数据集的petalwidth第4列中查找第一次出现的值大于1.0的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: (edit: changed argmax to argwhere. Thanks Rong!)</span></span><br><span class="line">np.argwhere(iris[:, <span class="number">3</span>].astype(<span class="built_in">float</span>) &gt; <span class="number">1.0</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># &gt; 50</span></span><br></pre></td></tr></table></figure>

<h2 id="将大于给定值的所有值替换为给定的截止值"><a href="#将大于给定值的所有值替换为给定的截止值" class="headerlink" title="将大于给定值的所有值替换为给定的截止值"></a>将大于给定值的所有值替换为给定的截止值</h2><p>问题：从数组a中，替换所有大于30到30和小于10到10的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1: Using np.clip</span></span><br><span class="line">np.clip(a, a_min=<span class="number">10</span>, a_max=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2: Using np.where</span></span><br><span class="line"><span class="built_in">print</span>(np.where(a &lt; <span class="number">10</span>, <span class="number">10</span>, np.where(a &gt; <span class="number">30</span>, <span class="number">30</span>, a)))</span><br><span class="line"><span class="comment"># &gt; [ 27.63  14.64  21.8   30.    10.    10.    30.    30.    10.    29.18  30.</span></span><br><span class="line"><span class="comment"># &gt;   11.25  10.08  10.    11.77  30.    30.    10.    30.    14.43]</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组中获取最大n值的位置"><a href="#从numpy数组中获取最大n值的位置" class="headerlink" title="从numpy数组中获取最大n值的位置"></a>从numpy数组中获取最大n值的位置</h2><p>问题：获取给定数组a中前5个最大值的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="built_in">print</span>(a.argsort())</span><br><span class="line"><span class="comment"># &gt; [18 7 3 10 15]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">np.argpartition(-a, <span class="number">5</span>)[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; [15 10  3  7 18]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Below methods will get you the values.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">a[a.argsort()][-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.sort(a)[-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.partition(a, kth=-<span class="number">5</span>)[-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 4:</span></span><br><span class="line">a[np.argpartition(-a, <span class="number">5</span>)][:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<p>计算数组中所有可能值的行数</p>
<p>问题：按行计算唯一值的计数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">arr = np.random.randint(<span class="number">1</span>,<span class="number">11</span>,size=(<span class="number">6</span>, <span class="number">10</span>))</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[ 9,  9,  4,  8,  8,  1,  5,  3,  6,  3],</span></span><br><span class="line"><span class="comment"># &gt;        [ 3,  3,  2,  1,  9,  5,  1, 10,  7,  3],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5,  2,  6,  4,  5,  5,  4,  8,  2,  2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 8,  8,  1,  3, 10, 10,  4,  3,  6,  9],</span></span><br><span class="line"><span class="comment"># &gt;        [ 2,  1,  8,  7,  3,  1,  9,  3,  6,  2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 9,  2,  6,  5,  3,  9,  4,  6,  1, 10]])</span></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">counts_of_all_values_rowwise</span>(<span class="params">arr2d</span>):</span><br><span class="line">    <span class="comment"># Unique values and its counts row wise</span></span><br><span class="line">    num_counts_array = [np.unique(row, return_counts=<span class="literal">True</span>) <span class="keyword">for</span> row <span class="keyword">in</span> arr2d]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Counts of all values row wise</span></span><br><span class="line">    <span class="keyword">return</span>([[<span class="built_in">int</span>(b[a==i]) <span class="keyword">if</span> i <span class="keyword">in</span> a <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> np.unique(arr2d)] <span class="keyword">for</span> a, b <span class="keyword">in</span> num_counts_array])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print</span></span><br><span class="line"><span class="built_in">print</span>(np.arange(<span class="number">1</span>,<span class="number">11</span>))</span><br><span class="line">counts_of_all_values_rowwise(arr)</span><br><span class="line"><span class="comment"># &gt; [ 1  2  3  4  5  6  7  8  9 10]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;  [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]]</span></span><br><span class="line"><span class="comment"># 输出包含10列，表示从1到10的数字。这些值是各行中数字的计数。 例如，cell(0，2)的值为2，这意味着数字3在第一行中恰好出现了2次。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example 2:</span></span><br><span class="line">arr = np.array([np.array(<span class="built_in">list</span>(<span class="string">&#x27;bill clinton&#x27;</span>)), np.array(<span class="built_in">list</span>(<span class="string">&#x27;narendramodi&#x27;</span>)), np.array(<span class="built_in">list</span>(<span class="string">&#x27;jjayalalitha&#x27;</span>))])</span><br><span class="line"><span class="built_in">print</span>(np.unique(arr))</span><br><span class="line">counts_of_all_values_rowwise(arr)</span><br><span class="line"><span class="comment"># &gt; [&#x27; &#x27; &#x27;a&#x27; &#x27;b&#x27; &#x27;c&#x27; &#x27;d&#x27; &#x27;e&#x27; &#x27;h&#x27; &#x27;i&#x27; &#x27;j&#x27; &#x27;l&#x27; &#x27;m&#x27; &#x27;n&#x27; &#x27;o&#x27; &#x27;r&#x27; &#x27;t&#x27; &#x27;y&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; [[1, 0, 1, 1, 0, 0, 0, 2, 0, 3, 0, 2, 1, 0, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 0, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 4, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 1, 1]]</span></span><br></pre></td></tr></table></figure>

<h2 id="将数组转换为平面一维数组"><a href="#将数组转换为平面一维数组" class="headerlink" title="将数组转换为平面一维数组"></a>将数组转换为平面一维数组</h2><p>问题：将array_of_arrays转换为扁平线性1d数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = np.arange(<span class="number">3</span>)</span><br><span class="line">arr2 = np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">arr3 = np.arange(<span class="number">7</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">array_of_arrays = np.array([arr1, arr2, arr3])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array_of_arrays: &#x27;</span>, array_of_arrays)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">arr_2d = np.array([a <span class="keyword">for</span> arr <span class="keyword">in</span> array_of_arrays <span class="keyword">for</span> a <span class="keyword">in</span> arr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">arr_2d = np.concatenate(array_of_arrays)</span><br><span class="line"><span class="built_in">print</span>(arr_2d)</span><br><span class="line"><span class="comment"># &gt; array_of_arrays:  [array([0, 1, 2]) array([3, 4, 5, 6]) array([7, 8, 9])]</span></span><br><span class="line"><span class="comment"># &gt; [0 1 2 3 4 5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 05：NumPy 数据分析进阶</title>
    <url>/PythonLes06/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程是第五周课程的延续，让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="导入数字和文本的数据集保持文本在numpy数组中完好无损"><a href="#导入数字和文本的数据集保持文本在numpy数组中完好无损" class="headerlink" title="导入数字和文本的数据集保持文本在numpy数组中完好无损"></a>导入数字和文本的数据集保持文本在numpy数组中完好无损</h2><p>问题：导入鸢尾属植物数据集，保持文本不变。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first 3 rows</span></span><br><span class="line">iris[:<span class="number">3</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<p>具体来说，dtype object是一种特殊的数据类型对象，它用于描述NumPy数组中元素的数据类型。通过指定dtype object，可以让NumPy数组支持更多的数据类型，例如复数、日期、字符串等。此外，dtype object还可以用于指定数据类型的大小、字节顺序等属性。</p>
<p>需要注意的是，使用dtype object会使得数组的运算速度变慢，因为每个元素都需要使用Python的解释器来执行运算，而不是使用NumPy的优化运算。因此，只有在必要的情况下才应该使用dtype object，否则应该尽量使用预定义的数据类型来提高数组的运算效率。</p>
<h2 id="从1维元组数组中提取特定列"><a href="#从1维元组数组中提取特定列" class="headerlink" title="从1维元组数组中提取特定列"></a>从1维元组数组中提取特定列</h2><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="将1维元组数组转换为2维NumPy数组"><a href="#将1维元组数组转换为2维NumPy数组" class="headerlink" title="将1维元组数组转换为2维NumPy数组"></a>将1维元组数组转换为2维NumPy数组</h2><p>问题：通过省略鸢尾属植物数据集种类的文本字段，将一维鸢尾属植物数据集转换为二维数组iris_2d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="comment"># Import only the first 4 columns from source url</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算numpy数组的均值，中位数，标准差"><a href="#计算numpy数组的均值，中位数，标准差" class="headerlink" title="计算numpy数组的均值，中位数，标准差"></a>计算numpy数组的均值，中位数，标准差</h2><p>问题：求出鸢尾属植物萼片长度的平均值、中位数和标准差(第1列)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">mu, med, sd = np.mean(sepallength), np.median(sepallength), np.std(sepallength)</span><br><span class="line"><span class="built_in">print</span>(mu, med, sd)</span><br><span class="line"><span class="comment"># &gt; 5.84333333333 5.8 0.825301291785</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.mean(a, axis=<span class="literal">None</span>, dtype=<span class="literal">None</span>, out=<span class="literal">None</span>, keepdims=&lt;no value&gt;, *, where=&lt;no value&gt;)</span><br><span class="line"><span class="comment"># Compute the arithmetic mean along the specified axis.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like数组，其中包含所需平均值的数字。如果a不是数组，则尝试转换。</li>
<li>axis: None或int或int元组，可选参数，计算平均值的轴向。默认值是计算平面化数组的平均值。</li>
<li>dtype: data-type，可选参数，用于计算平均值的类型。对于整数输入，默认值是float64；对于浮点输入，它与输入dtype相同。</li>
<li>out: narray，可选参数，用于放置结果的备用输出数组。默认为None；如果提供，它必须具有与预期输出相同的形状，但如果需要，将强制转换类型。</li>
<li>keepdims: bool，可选参数，如果设置为True，则减少的轴在结果中保留为大小为1的维度。使用此选项，结果将根据输入数组正确广播。如果传递默认值，则keepdim将不会传递给narray子类的mean方法，但任何非默认值将被传递。如果子类的方法没有实现keepdim，将引发任何异常。</li>
<li>where: array_like of bool，可选参数，判断计算平均值的元素。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">np.mean(a)</span><br><span class="line"><span class="number">2.5</span></span><br><span class="line">np.mean(a, axis=<span class="number">0</span>)</span><br><span class="line">array([<span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">np.mean(a, axis=<span class="number">1</span>)</span><br><span class="line">array([<span class="number">1.5</span>, <span class="number">3.5</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">5</span>, <span class="number">9</span>, <span class="number">13</span>], [<span class="number">14</span>, <span class="number">10</span>, <span class="number">12</span>], [<span class="number">11</span>, <span class="number">15</span>, <span class="number">19</span>]])</span><br><span class="line">np.mean(a)</span><br><span class="line"><span class="number">12.0</span></span><br><span class="line">np.mean(a, where=[[<span class="literal">True</span>], [<span class="literal">False</span>], [<span class="literal">False</span>]])</span><br><span class="line"><span class="number">9.0</span></span><br></pre></td></tr></table></figure>

<h2 id="找到NumPy数组的百分位数"><a href="#找到NumPy数组的百分位数" class="headerlink" title="找到NumPy数组的百分位数"></a>找到NumPy数组的百分位数</h2><p>问题：找到鸢尾属植物数据集的第5和第95百分位数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.percentile(sepallength, q=[<span class="number">5</span>, <span class="number">95</span>])</span><br><span class="line"><span class="comment"># &gt; array([ 4.6  ,  7.255])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.percentile(a, q, axis=<span class="literal">None</span>, out=<span class="literal">None</span>, overwrite_input=<span class="literal">False</span>, method=<span class="string">&#x27;linear&#x27;</span>, keepdims=<span class="literal">False</span>, *, interpolation=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Compute the q-th percentile of the data along the specified axis.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like of real numbers, 可转换为数组的输入数组或对象。</li>
<li>q: array_like of float, 用于计算百分位数的百分比或百分比序列。取值必须在0到100之间。</li>
<li>axis: {int, int的元组，None}，可选参数，计算百分位数的轴向。默认值是沿数组的平面化版本计算百分位数。</li>
<li>overwrite_input: bool，可选参数，如果为True，则允许通过中间计算修改输入数组a，以节省内存。</li>
<li>method: str, 可选参数，此参数指定用于估计百分位数的方法。有许多不同的方法，其中一些是NumPy独有的。请参阅注释以获得解释，包括’inverted_cdf’ ‘averaged_inverted_cdf’ ‘closest_observation’ ‘interpolated_inverted_cdf’ ‘hazen’ ‘weibull’ ‘linear’(默认) ‘median_unbiased’ ‘normal_unbiased’等等。</li>
<li>keepdims: bool，可选如果设置为True，则减少的轴在结果中保留为大小为1的维度。使用此选项，结果将针对原始数组正确广播。</li>
</ul>
<h2 id="查找给定数组是否具有任何空值"><a href="#查找给定数组是否具有任何空值" class="headerlink" title="查找给定数组是否具有任何空值"></a>查找给定数组是否具有任何空值</h2><p>问题：找出iris_2d是否有任何缺失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">np.isnan(iris_2d).<span class="built_in">any</span>()</span><br><span class="line"><span class="comment"># &gt; False</span></span><br></pre></td></tr></table></figure>


<h2 id="在数组中的随机位置插入值"><a href="#在数组中的随机位置插入值" class="headerlink" title="在数组中的随机位置插入值"></a>在数组中的随机位置插入值</h2><p>问题：在iris_2d数据集中的20个随机位置插入np.nan值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到缺失值的位置"><a href="#在NumPy数组中找到缺失值的位置" class="headerlink" title="在NumPy数组中找到缺失值的位置"></a>在NumPy数组中找到缺失值的位置</h2><p>问题：在iris_2d的sepallength中查找缺失值的数量和位置（第1列）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of missing values: \n&quot;</span>, np.isnan(iris_2d[:, <span class="number">0</span>]).<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Position of missing values: \n&quot;</span>, np.where(np.isnan(iris_2d[:, <span class="number">0</span>])))</span><br><span class="line"><span class="comment"># &gt; Number of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  5</span></span><br><span class="line"><span class="comment"># &gt; Position of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  (array([ 39,  88,  99, 130, 147]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="根据两个或多个条件过滤NumPy数组"><a href="#根据两个或多个条件过滤NumPy数组" class="headerlink" title="根据两个或多个条件过滤NumPy数组"></a>根据两个或多个条件过滤NumPy数组</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">condition = (iris_2d[:, <span class="number">2</span>] &gt; <span class="number">1.5</span>) &amp; (iris_2d[:, <span class="number">0</span>] &lt; <span class="number">5.0</span>)</span><br><span class="line">iris_2d[condition]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.8,  3.4,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.4,  1.9,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.1,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.4,  3.3,  1. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.5,  4.5,  1.7]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组中删除包含缺失值的行"><a href="#从NumPy数组中删除包含缺失值的行" class="headerlink" title="从NumPy数组中删除包含缺失值的行"></a>从NumPy数组中删除包含缺失值的行</h2><p>问题：选择没有任何nan值的iris_2d行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct numpy function for this.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">any_nan_in_row = np.array([~np.<span class="built_in">any</span>(np.isnan(row)) <span class="keyword">for</span> row <span class="keyword">in</span> iris_2d])</span><br><span class="line">iris_2d[any_nan_in_row][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: (By Rong)</span></span><br><span class="line">iris_2d[np.<span class="built_in">sum</span>(np.isnan(iris_2d), axis = <span class="number">1</span>) == <span class="number">0</span>][:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5. ,  3.6,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5.4,  3.9,  1.7,  0.4]])</span></span><br></pre></td></tr></table></figure>

<h2 id="找到NumPy数组的两列之间的相关性"><a href="#找到NumPy数组的两列之间的相关性" class="headerlink" title="找到NumPy数组的两列之间的相关性"></a>找到NumPy数组的两列之间的相关性</h2><p>问题：在iris_2d中找出SepalLength（第1列）和PetalLength（第3列）之间的相关性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.corrcoef(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr  </span><br><span class="line">corr, p_value = pearsonr(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Correlation coef indicates the degree of linear relationship between two numeric variables.</span></span><br><span class="line"><span class="comment"># It can range between -1 to +1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The p-value roughly indicates the probability of an uncorrelated system producing </span></span><br><span class="line"><span class="comment"># datasets that have a correlation at least as extreme as the one computed.</span></span><br><span class="line"><span class="comment"># The lower the p-value (&lt;0.01), stronger is the significance of the relationship.</span></span><br><span class="line"><span class="comment"># It is not an indicator of the strength.</span></span><br><span class="line"><span class="comment"># &gt; 0.871754157305</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.corrcoef(x, y=<span class="literal">None</span>, rowvar=<span class="literal">True</span>, bias=&lt;no value&gt;, ddof=&lt;no value&gt;, *, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Return Pearson product-moment correlation coefficients.</span></span><br></pre></td></tr></table></figure>

<img src="https://www.jmp.com/zh_cn/statistics-knowledge-portal/reference-content/correlation-coefficient-formula/_jcr_content/par/image_a25b.img.png/1557786509536.png" width="60%" alt="一维数据相关系数计算方法" align=center />

<p>相关系数 $r$ 是一个介于 -1 和 1 之间的无单位的值。统计显著性以 $p$ 值表示。</p>
<ul>
<li>$r$ 越接近 0，线性关系越弱。</li>
<li>正的 $r$ 值表示正相关，在这种情况下，两个变量的值往往一起增加。</li>
<li>负的 $r$ 值表示负相关，在这种情况下，当一个变量的值增加时，另一个变量的值往往会减少。</li>
<li>值 1 和 -1 都代表“完美”的相关性，分别表示正相关和负相关。两个完美相关的变量会以固定的比率一起变化。我们说，它们有线性关系；当绘制在散点图上时，所有的数据点可以用一条直线连接。</li>
</ul>
<h2 id="在NumPy数组中用0替换所有缺失值"><a href="#在NumPy数组中用0替换所有缺失值" class="headerlink" title="在NumPy数组中用0替换所有缺失值"></a>在NumPy数组中用0替换所有缺失值</h2><p>问题：在NumPy数组中将所有出现的nan替换为0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">iris_2d[np.isnan(iris_2d)] = <span class="number">0</span></span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中查找唯一值的计数"><a href="#在NumPy数组中查找唯一值的计数" class="headerlink" title="在NumPy数组中查找唯一值的计数"></a>在NumPy数组中查找唯一值的计数</h2><p>问题：找出鸢尾属植物物种中的独特值和独特值的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Extract the species column as an array</span></span><br><span class="line">species = np.array([row.tolist()[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the unique values and the counts</span></span><br><span class="line">np.unique(species, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        dtype=&#x27;|S15&#x27;), array([50, 50, 50]))</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.unique(ar, return_index=<span class="literal">False</span>, return_inverse=<span class="literal">False</span>, return_counts=<span class="literal">False</span>, axis=<span class="literal">None</span>, *, equal_nan=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Return Pearson product-moment correlation coefficients.</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.unique()</code>函数返回数组中已排序的唯一元素。除了唯一元素之外，还有三个可选输出:</p>
<ul>
<li>给出唯一值的输入数组的索引</li>
<li>用于重建输入数组的唯一数组的索引</li>
<li>每个唯一值在输入数组中出现的次数</li>
</ul>
<p>输入参数：</p>
<ul>
<li>ar: array_like, 输入数组。除非指定了轴，否则如果它不是1-D，它将被平面化。</li>
<li>return_index: bool, 可选参数，如果为True，还返回ar的索引，从而产生唯一数组。</li>
<li>return_inverse: bool, 可选参数，如果为True，还返回可用于重建ar的唯一数组的索引。</li>
<li>return_counts: bool, 可选参数，如果为True，还返回每个唯一项在ar中出现的次数。</li>
<li>axis: int或None, 可选参数，要操作的轴。如果为None，ar将被扁平化。如果是整数，则由给定轴索引的子数组将被平面化，并被视为具有给定轴的维度的1-D数组的元素。</li>
<li>equal_nan: bool, 可选参数，如果为True，将返回数组中的多个NaN值折叠为一个。</li>
</ul>
<p>返回参数:</p>
<ul>
<li>unique: ndarray，排序后的唯一值。</li>
<li>unique_indices: ndarray, 可选参数，原始数组中唯一值第一次出现的索引。仅当return_index为True时提供。</li>
<li>unique_inverse: ndarray, 可选参数，从unique数组重构原始数组的索引。仅当return_inverse为True时提供。</li>
<li>unique_counts: ndarray, 可选参数，每个唯一值在原始数组中出现的次数。仅当return_counts为True时提供。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.unique([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">np.unique(a)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Return the unique rows of a 2D array</span></span><br><span class="line">a = np.array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line">u, indices = np.unique(a, return_index=<span class="literal">True</span>)</span><br><span class="line">u</span><br><span class="line">array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line">indices</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">a[indices]</span><br><span class="line">array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reconstruct the input array from the unique values and inverse:</span></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">u, indices = np.unique(a, return_inverse=<span class="literal">True</span>)</span><br><span class="line">u</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">indices</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">u[indices]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reconstruct the input values from the unique values and counts:</span></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">values, counts = np.unique(a, return_counts=<span class="literal">True</span>)</span><br><span class="line">values</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">counts</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">np.repeat(values, counts)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])    <span class="comment"># original order not preserved</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到最常见的值"><a href="#在NumPy数组中找到最常见的值" class="headerlink" title="在NumPy数组中找到最常见的值"></a>在NumPy数组中找到最常见的值</h2><p>问题：在鸢尾属植物数据集中找到最常见的花瓣长度值（第3列）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">vals, counts = np.unique(iris[:, <span class="number">2</span>], return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vals[np.argmax(counts)])</span><br><span class="line"><span class="comment"># &gt; b&#x27;1.5&#x27;</span></span><br></pre></td></tr></table></figure>



<h2 id="将数字转换为分类（文本）数组"><a href="#将数字转换为分类（文本）数组" class="headerlink" title="将数字转换为分类（文本）数组"></a>将数字转换为分类（文本）数组</h2><p>问题：将iris_2d的花瓣长度（第3列）加入以形成文本数组，这样如果花瓣长度为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;= 3 --&gt; &#x27;small&#x27;</span><br><span class="line"> 3-5 --&gt; &#x27;medium&#x27;</span><br><span class="line">&#x27;&gt;=5 --&gt; &#x27;large&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bin petallength </span></span><br><span class="line">petal_length_bin = np.digitize(iris[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>), [<span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map it to respective category</span></span><br><span class="line">label_map = &#123;<span class="number">1</span>: <span class="string">&#x27;small&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;medium&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;large&#x27;</span>, <span class="number">4</span>: np.nan&#125;</span><br><span class="line">petal_length_cat = [label_map[x] <span class="keyword">for</span> x <span class="keyword">in</span> petal_length_bin]</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">petal_length_cat[:<span class="number">4</span>]</span><br><span class="line">&lt;<span class="comment"># &gt; [&#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;]</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组的现有列创建新列"><a href="#从NumPy数组的现有列创建新列" class="headerlink" title="从NumPy数组的现有列创建新列"></a>从NumPy数组的现有列创建新列</h2><p>问题：在iris_2d中创建一个新列，其数值通过其他列计算得到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Compute volume</span></span><br><span class="line">sepallength = iris_2d[:, <span class="number">0</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">petallength = iris_2d[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">volume = (np.pi * petallength * (sepallength**<span class="number">2</span>))/<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Introduce new dimension to match iris_2d&#x27;s</span></span><br><span class="line">volume = volume[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the new column</span></span><br><span class="line">out = np.hstack([iris_2d, volume])</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">out[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 38.13265162927291],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 35.200498485922445],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 30.0723720777127],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.6&#x27;, b&#x27;3.1&#x27;, b&#x27;1.5&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 33.238050274980004]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy中进行概率抽样"><a href="#在NumPy中进行概率抽样" class="headerlink" title="在NumPy中进行概率抽样"></a>在NumPy中进行概率抽样</h2><p>问题：随机抽样150组鸢尾属植物的数据，使得’Iris-setosa’的概率是’Iris-versicolor’和’Iris-virginica’的两倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species column</span></span><br><span class="line">species = iris[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 1: Generate Probablistically</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.array([<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>])</span><br><span class="line">species_out = np.random.choice(a, <span class="number">150</span>, p=[<span class="number">0.5</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 2: Probablistic Sampling (preferred)</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">probs = np.r_[np.linspace(<span class="number">0</span>, <span class="number">0.500</span>, num=<span class="number">50</span>), np.linspace(<span class="number">0.501</span>, <span class="number">.750</span>, num=<span class="number">50</span>), np.linspace(<span class="number">.751</span>, <span class="number">1.0</span>, num=<span class="number">50</span>)]</span><br><span class="line">index = np.searchsorted(probs, np.random.random(<span class="number">150</span>))</span><br><span class="line">species_out = species[index]</span><br><span class="line"><span class="built_in">print</span>(np.unique(species_out, return_counts=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;], dtype=object), array([77, 37, 36]))</span></span><br></pre></td></tr></table></figure>

<p>方法2是首选方法，因为它创建了一个索引变量，该变量可用于取样2维表格数据。</p>
<h2 id="在按另一个数组分组时获取数组的第二大值"><a href="#在按另一个数组分组时获取数组的第二大值" class="headerlink" title="在按另一个数组分组时获取数组的第二大值"></a>在按另一个数组分组时获取数组的第二大值</h2><p>问题：物种setosa中第二长的长度数值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species and petal length columns</span></span><br><span class="line">petal_len_setosa = iris[iris[:, <span class="number">4</span>] == <span class="string">b&#x27;Iris-setosa&#x27;</span>, [<span class="number">2</span>]].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the second last value</span></span><br><span class="line">np.unique(np.sort(petal_len_setosa))[-<span class="number">2</span>]</span><br><span class="line"><span class="comment"># &gt; 1.7</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.sort(a, axis=-<span class="number">1</span>, kind=<span class="literal">None</span>, order=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Return a sorted copy of an array.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 待排序的数组。</li>
<li>axis: int或None, 可选参数，排序所沿的轴向。如果为None，则在排序之前对数组进行扁平化。默认值是-1，它沿着最后一个轴排序。</li>
<li>kind: {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}，可选参数，排序算法。默认值是‘quicksort’。</li>
<li>Order: str或str的列表，可选参数，当a是一个定义了字段的数组时，这个参数指定首先比较哪个字段。可以将单个字段指定为字符串，而不需要指定所有字段，但仍将使用未指定的字段，按照它们在dtype中出现的顺序，以打破关系。</li>
<li>sorted_array: ndarray，返回值，类型和形状与a相同的数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">1</span>]])</span><br><span class="line">np.sort(a)                <span class="comment"># sort along the last axis</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>]])</span><br><span class="line">np.sort(a, axis=<span class="literal">None</span>)     <span class="comment"># sort the flattened array</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">np.sort(a, axis=<span class="number">0</span>)        <span class="comment"># sort along the first axis</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>


<h2 id="按列对2D数组进行排序"><a href="#按列对2D数组进行排序" class="headerlink" title="按列对2D数组进行排序"></a>按列对2D数组进行排序</h2><p>问题：根据sepallength列对数据集进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sort by column position 0: SepalLength</span></span><br><span class="line"><span class="built_in">print</span>(iris[iris[:,<span class="number">0</span>].argsort()][:<span class="number">20</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;4.3&#x27; b&#x27;3.0&#x27; b&#x27;1.1&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.0&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;2.9&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.5&#x27; b&#x27;2.3&#x27; b&#x27;1.3&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.6&#x27; b&#x27;1.0&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.2&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.9&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.1&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.4&#x27; b&#x27;3.3&#x27; b&#x27;1.0&#x27; b&#x27;Iris-versicolor&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.5&#x27; b&#x27;4.5&#x27; b&#x27;1.7&#x27; b&#x27;Iris-virginica&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.argsort(a, axis=-<span class="number">1</span>, kind=<span class="literal">None</span>, order=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Returns the indices that would sort an array.</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.argsort()</code>函数与<code>np.sort()</code>函数几乎完全一致，区别在于一个输出为排序后的数值，一个输出为排序后的索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">np.argsort(x)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two-dimensional array:</span></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">0</span>)  <span class="comment"># sorts along first axis (down)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">1</span>)  <span class="comment"># sorts along last axis (across)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>



<h2 id="找到第一次出现的值大于给定值的位置"><a href="#找到第一次出现的值大于给定值的位置" class="headerlink" title="找到第一次出现的值大于给定值的位置"></a>找到第一次出现的值大于给定值的位置</h2><p>问题：在数据集的petalwidth第4列中查找第一次出现的值大于1.0的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: (edit: changed argmax to argwhere. Thanks Rong!)</span></span><br><span class="line">np.argwhere(iris[:, <span class="number">3</span>].astype(<span class="built_in">float</span>) &gt; <span class="number">1.0</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># &gt; 50</span></span><br></pre></td></tr></table></figure>

<h2 id="将大于给定值的所有值替换为给定的截止值"><a href="#将大于给定值的所有值替换为给定的截止值" class="headerlink" title="将大于给定值的所有值替换为给定的截止值"></a>将大于给定值的所有值替换为给定的截止值</h2><p>问题：从数组a中，替换所有大于30为30，替换所有小于10为10。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: Using np.clip</span></span><br><span class="line">np.clip(a, a_min=<span class="number">10</span>, a_max=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>

<p><code>numpy.clip()</code>给定一个区间，区间外的值被裁剪到区间边缘。例如，如果指定了区间[0,1]，则小于0的值变为0，大于1的值变为1。不检查a_min &lt; a_max。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.clip(a, a_min, a_max, out=<span class="literal">None</span>, **kwargs)</span><br><span class="line"><span class="comment"># Clip (limit) the values in an array.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 包含要剪辑的元素的数组。</li>
<li>a_min、a_max: array_like, 或无最小值和最大值。如果是None，则不对相应的边进行裁剪。a_min和a_max只能有一个为None。</li>
<li>out: 可选参数，结果将放置在此数组中。Out必须有合适的形状来容纳输出。</li>
</ul>
<h2 id="从NumPy数组中获取最大n值的位置"><a href="#从NumPy数组中获取最大n值的位置" class="headerlink" title="从NumPy数组中获取最大n值的位置"></a>从NumPy数组中获取最大n值的位置</h2><p>问题：获取给定数组a中前5个最大值的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="built_in">print</span>(a.argsort()[-<span class="number">5</span>:])</span><br><span class="line"><span class="comment"># &gt; [18 7 3 10 15]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Below methods will get you the values.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">a[a.argsort()][-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.sort(a)[-<span class="number">5</span>:]</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 03：科学计算环境 NumPy</title>
    <url>/PythonLes04/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Numpy是Python中科学计算的核心库。它提供了一个多维数组对象，以及用于高并发处理这些数组的向量化计算工具集。NumPy允许用户在Python环境中进行向量和矩阵计算，并且由于许多底层函数实际上是用C编写的，因此你可以体验在原生Python中永远无法体验到的速度。NumPy绝对是Python在科学计算领域成功的关键之一，如果你想要进入Python中的数据科学或机器学习，你就要必须学习它。Have a good day!</p>
<span id="more"></span>

<h2 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h2><p>NumPy数组是一个值网格，所有类型都相同，并由非负整数元组索引。创建数组通常有5种常规机制：</p>
<ul>
<li>从其他Python结构（例如，列表，元组，array_like）转换</li>
<li>numpy原生数组的创建（例如，arange、ones、zeros等）</li>
<li>从磁盘读取数组，无论是标准格式还是自定义格式</li>
<li>通过使用字符串或缓冲区从原始字节创建数组</li>
<li>使用特殊库函数（例如，random）</li>
</ul>
<h3 id="直接创建"><a href="#直接创建" class="headerlink" title="直接创建"></a>直接创建</h3><p>通常，在Python中排列成array-like结构的数值数据可以通过使用array()函数转换为数组。最明显的例子是列表和元组。np.array() 直接创建：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<img src="https://pic1.zhimg.com/v2-90de7812f9fc3169cffb7e39d4c3cfd8_r.jpg" width="45%" alt="np.array()创建数组" align=center />

<p>对于一维数组，我们在写数组的时候是横着写的，而其实数组是列向量。</p>
<h3 id="内置函数创建"><a href="#内置函数创建" class="headerlink" title="内置函数创建"></a>内置函数创建</h3><p>Numpy内置了从头开始创建数组的函数，<code>zeros()</code>将创建一个用指定形状用0填充的数组。默认的<code>dtype</code>是<code>float64</code>。使用 np.ones()、np.zeros()、np.random.random() 等方法：</p>
<img src="https://pic4.zhimg.com/v2-6e73db4bcf9e406d110da4f2827200ab_r.jpg" width="100%" alt="np.ones(), np.zeros(), np.random.random()创建数组" align=center />

<p>NumPy同样可以创建多维数组。数组的形状（shape）是一个整数元组，给出了每个维度的数组大小。我们可以从嵌套的Python列表初始化NumPy数组，并使用方括号访问元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])   <span class="comment"># Create a rank 1 array</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a))            <span class="comment"># Prints &quot;&lt;class &#x27;numpy.ndarray&#x27;&gt;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(a.shape)            <span class="comment"># Prints &quot;(3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>], a[<span class="number">1</span>], a[<span class="number">2</span>])   <span class="comment"># Prints &quot;1 2 3&quot;</span></span><br><span class="line">a[<span class="number">0</span>] = <span class="number">5</span>                  <span class="comment"># Change an element of the array</span></span><br><span class="line"><span class="built_in">print</span>(a)                  <span class="comment"># Prints &quot;[5, 2, 3]&quot;</span></span><br><span class="line"></span><br><span class="line">b = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])    <span class="comment"># Create a rank 2 array</span></span><br><span class="line"><span class="built_in">print</span>(b.shape)                     <span class="comment"># Prints &quot;(2, 3)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>, <span class="number">0</span>], b[<span class="number">0</span>, <span class="number">1</span>], b[<span class="number">1</span>, <span class="number">0</span>])   <span class="comment"># Prints &quot;1 2 4&quot;</span></span><br></pre></td></tr></table></figure>

<p>我们再来看一些例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">b = np.array((<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">c = np.arange(<span class="number">5</span>)</span><br><span class="line">d = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(b)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(c)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(d)     <span class="comment"># &gt;&gt;&gt;[ 0.  1.57079633  3.14159265  4.71238898  6.28318531]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">3</span>])  <span class="comment"># &gt;&gt;&gt;3</span></span><br></pre></td></tr></table></figure>

<p>上面的代码显示了创建数组的4种不同方法。最基本的方法是将序列传递给NumPy的<code>array()</code>函数; 你可以传递任何序列（类数组），而不仅仅是常见的列表（list）数据类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3.0</span>)</span><br><span class="line">array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">array([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>,<span class="number">7</span>,<span class="number">2</span>)</span><br><span class="line">array([<span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p><code>np.arange()</code>函数对于整数参数，该函数大致相当于Python内置的<code>range()</code>。当使用非整数步长（例如0.1）时，通常使用<a href="https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/function_base.py#L24-L182">numpy.linspace</a>更好。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.linspace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, retstep=<span class="literal">False</span>, dtype=<span class="literal">None</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>start: array_like 序列的起始值；</li>
<li>stop: array_like 序列的结束值，除非endpoint被设置为False。在这种情况下，序列由除num+1个均匀间隔样本的最后一个之外的所有样本组成，因此stop值被排除在外。注意，当endpoint为False时，步长会发生变化。</li>
<li>num: int 可选项，要生成的样本数量，默认值是50，必须为非负整数；</li>
<li>endpoint: bool 可选项，如果为True，则最后一个元素为stop值，否则不包含。默认为True；</li>
<li>retstep: bool 可选项，如果True，返回(samples, step)，其中step是采样之间的间隔。</li>
<li>dtype: dtype 可选项，输出数组的数据类型。如果不指定dtype，则从start和stop推断数据类型。推断的dtype永远不会是整型；即使参数将产生一个整数数组，也选择float。</li>
<li>axis: int 可选项，1.9.0新版功能。Axis在结果中存储样品。只有当start或stop是数组类型时才相关。默认情况下(0)，样本将沿着在开始时插入的新轴。用-1得到最后的轴。</li>
</ul>
<p>这个创建函数的优点是可以保证元素的数量以及开始和结束点，对于任意的开始，停止和步骤值，<code>arange()</code>通常不会这样做。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>)</span><br><span class="line">array([<span class="number">2.</span>  , <span class="number">2.25</span>, <span class="number">2.5</span> , <span class="number">2.75</span>, <span class="number">3.</span>  ])</span><br><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>, endpoint=<span class="literal">False</span>)</span><br><span class="line">array([<span class="number">2.</span> ,  <span class="number">2.2</span>,  <span class="number">2.4</span>,  <span class="number">2.6</span>,  <span class="number">2.8</span>])</span><br><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>, retstep=<span class="literal">True</span>)</span><br><span class="line">(array([<span class="number">2.</span>  ,  <span class="number">2.25</span>,  <span class="number">2.5</span> ,  <span class="number">2.75</span>,  <span class="number">3.</span>  ]), <span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>

<p>同样类似的函数还有<code>geomspace()</code>以及<code>logspace()</code>，功能与<code>linspace()</code>函数类似，分别对应生成指数级数与对数级数数组，在此不做过多介绍。</p>
<h3 id="创建多维数组"><a href="#创建多维数组" class="headerlink" title="创建多维数组"></a>创建多维数组</h3><p>上面的数组示例是如何使用NumPy表示向量的，接下来我们将看看如何使用多维数组表示矩阵和更多的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">2</span>,<span class="number">4</span>]) <span class="comment"># &gt;&gt;&gt;25</span></span><br></pre></td></tr></table></figure>

<p>为了创建一个二维数组，我们传递一个列表的列表（或者是一个序列的序列）给<code>array()</code>函数。如果我们想要一个3D（三维）数组，我们就要传递一个列表的列表的列表，如果是一个4D（四维）数组，那就是列表的列表的列表的列表，以此类推。请注意2D（二维）数组是如何按行和列排列的。要索引2D（二维）数组，我们只需引用行数和列数即可。</p>
<p>我们再来看看一些二维情况下创建数组的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.zeros((<span class="number">2</span>,<span class="number">2</span>))   <span class="comment"># Create an array of all zeros</span></span><br><span class="line"><span class="built_in">print</span>(a)              <span class="comment"># Prints &quot;[[ 0.  0.]</span></span><br><span class="line">                      <span class="comment">#          [ 0.  0.]]&quot;</span></span><br><span class="line"></span><br><span class="line">b = np.ones((<span class="number">1</span>,<span class="number">2</span>))    <span class="comment"># Create an array of all ones</span></span><br><span class="line"><span class="built_in">print</span>(b)              <span class="comment"># Prints &quot;[[ 1.  1.]]&quot;</span></span><br><span class="line"></span><br><span class="line">c = np.full((<span class="number">2</span>,<span class="number">2</span>), <span class="number">7</span>)  <span class="comment"># Create a constant array</span></span><br><span class="line"><span class="built_in">print</span>(c)               <span class="comment"># Prints &quot;[[ 7.  7.]</span></span><br><span class="line">                       <span class="comment">#          [ 7.  7.]]&quot;</span></span><br><span class="line"></span><br><span class="line">d = np.eye(<span class="number">2</span>)         <span class="comment"># Create a 2x2 identity matrix</span></span><br><span class="line"><span class="built_in">print</span>(d)              <span class="comment"># Prints &quot;[[ 1.  0.]</span></span><br><span class="line">                      <span class="comment">#          [ 0.  1.]]&quot;</span></span><br><span class="line"></span><br><span class="line">e = np.random.random((<span class="number">2</span>,<span class="number">2</span>))  <span class="comment"># Create an array filled with random values</span></span><br><span class="line"><span class="built_in">print</span>(e)                     <span class="comment"># Might print &quot;[[ 0.91940167  0.08143941]</span></span><br><span class="line">                             <span class="comment">#               [ 0.68744134  0.87236687]]&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="数组属性"><a href="#数组属性" class="headerlink" title="数组属性"></a>数组属性</h3><p>在使用NumPy时，你会想知道数组的某些信息。很幸运，NumPy包里边包含了很多便捷的方法，可以给你想要的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Array properties</span></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a)) <span class="comment"># &gt;&gt;&gt;&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(a.dtype) <span class="comment"># &gt;&gt;&gt;int64</span></span><br><span class="line"><span class="built_in">print</span>(a.size) <span class="comment"># &gt;&gt;&gt;25</span></span><br><span class="line"><span class="built_in">print</span>(a.shape) <span class="comment"># &gt;&gt;&gt;(5, 5)</span></span><br><span class="line"><span class="built_in">print</span>(a.itemsize) <span class="comment"># &gt;&gt;&gt;8</span></span><br><span class="line"><span class="built_in">print</span>(a.ndim) <span class="comment"># &gt;&gt;&gt;2</span></span><br><span class="line"><span class="built_in">print</span>(a.nbytes) <span class="comment"># &gt;&gt;&gt;200</span></span><br></pre></td></tr></table></figure>

<p>正如你在上面的代码中看到的，NumPy数组实际上被称为<code>&#39;numpy.ndarray&#39;</code>。</p>
<ul>
<li><p><code>shape</code>属性是数组有多少行和列，上面的数组有5行和5列，所以它的shape是(5, 5)。</p>
</li>
<li><p><code>itemsize</code>属性是每个项占用的字节（Byte）数。这个数组的数据类型是<code>int64</code>，一个<code>int64</code>中有64 bit，1 byte &#x3D; 8 bit，即为8 byte。</p>
</li>
<li><p><code>ndim</code>属性是数组的维数，在本例中为2。</p>
</li>
<li><p><code>nbytes</code>属性是数组中的所有数据消耗掉的字节数。这并不计算数组信息定义开销，因此数组占用的实际内存空间将稍微大一点。</p>
</li>
</ul>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>每个NumPy数组都是相同类型元素的网格。NumPy提供了一组可用于构造数组的大量数值数据类型。NumPy在创建数组时尝试猜测数据类型，但构造数组的函数通常还包含一个可选参数来显式指定数据类型。这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>])   <span class="comment"># Let numpy choose the datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)         <span class="comment"># Prints &quot;int64&quot;</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>])   <span class="comment"># Let numpy choose the datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)             <span class="comment"># Prints &quot;float64&quot;</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>], dtype=np.int64)   <span class="comment"># Force a particular datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)                         <span class="comment"># Prints &quot;int64&quot;</span></span><br></pre></td></tr></table></figure>

<p>NumPy支持比Python更多种类的数字类型。本节显示了哪些可用，以及如何修改数组的数据类型。支持的原始类型与 C 中的原始类型紧密相关：</p>
<img src="https://s21.ax1x.com/2024/03/25/pF5SVln.png" width="85%" alt="NumPy数据类型1" align=center />

<p>由于其中许多都具有依赖于平台的定义，因此提供了一组固定大小的别名：</p>
<img src="https://s21.ax1x.com/2024/03/25/pF5SZyq.png" width="85%" alt="NumPy数据类型2" align=center />

<p>NumPy数值类型是<code>dtype</code>（数据类型）对象的实例，每个对象都具有独特的特征。导入NumPy后使用，在<code>dtypes</code>可作为<code>np.bool_</code>，<code>np.float32</code>等等。</p>
<p>上表中未列出的高级类型将在后续的课程中教授结构化数组时进行探讨。</p>
<p>有5种基本数字类型表示布尔值（bool），整数（int），无符号整数（uint）浮点（float）和复数（complex）。名称中带有数字的那些表示该类型的位大小（即，在内存中表示单个值需要多少位）。某些类型（例如<code>int</code>和<code>intp</code>）具有不同的位，取决于平台（例如，32位与64位计算机）。在与寻址原始内存的低层代码（例如C或Fortran）连接时，应考虑这一点。</p>
<p>数据类型可以用作将Python数转换为数组标量的函数，将Python数字序列转换为该类型的数组，或作为许多NumPy函数或方法接受的<code>dtype</code>关键字的参数。一些例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.float32(<span class="number">1.0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line"><span class="number">1.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.int_([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = np.arange(<span class="number">3</span>, dtype=np.uint8)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=uint8)</span><br></pre></td></tr></table></figure>

<p>数组类型也可以通过字符代码引用，主要是为了保持与较旧的包（如Numeric）的向后兼容性。有些文档可能仍然引用这些，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=<span class="string">&#x27;f&#x27;</span>)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>但我们仍然建议使用<code>dtype</code>对象。</p>
<p>要转换数组的类型，请使用 <code>.astype()</code> 方法（首选）或类型本身作为函数。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.astype(<span class="built_in">float</span>)                 </span><br><span class="line">array([  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.int8(z)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=int8)</span><br></pre></td></tr></table></figure>

<p>注意，在上面，我们使用 Python 的<code>float</code>对象作为<code>dtype</code>。NumPy中<code>int</code>是指<code>np.int_</code>，<code>bool</code>意味着<code>np.bool_</code>，<code>float</code>是<code>np.float_</code>，<code>complex</code>是<code>np.complex_</code>。其他数据类型没有Python等价物。</p>
<p>要确定数组的类型，请查看<code>dtype</code>属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.dtype</span><br><span class="line">dtype(<span class="string">&#x27;uint8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>dtype</code>对象还包含有关类型的信息，例如其位宽和字节顺序。数据类型也可以间接用于查询类型的属性，例如它是否为整数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = np.dtype(<span class="built_in">int</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">dtype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.issubdtype(d, np.integer)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.issubdtype(d, np.floating)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h3 id="数组标量"><a href="#数组标量" class="headerlink" title="数组标量"></a>数组标量</h3><p>NumPy通常将数组元素作为数组标量返回（带有关联<code>dtype</code>的标量）。数组标量与Python标量不同，但在大多数情况下它们可以互换使用（主要的例外是早于v2.x的Python版本，其中整数数组标量不能作为列表和元组的索引）。有一些例外，例如当代码需要标量的非常特定的属性或者它特定地检查值是否是Python标量时。通常，存在的问题很容易被显式转换数组标量到Python标量，采用相应的Python类型的功能（例如，固定的<code>int</code>，<code>float</code>，<code>complex</code>，<code>str</code>，<code>unicode</code>）。</p>
<p>使用数组标量的主要优点是它们保留了数组类型（Python可能没有匹配的标量类型，例如int16）。因此，使用数组标量可确保数组和标量之间的相同行为，无论值是否在数组内。NumPy标量也有许多与数组相同的方法。</p>
<h3 id="溢出错误"><a href="#溢出错误" class="headerlink" title="溢出错误"></a>溢出错误</h3><p>当值需要比数据类型中的可用内存更多的内存时，NumPy数值类型的固定大小可能会导致溢出错误。例如，<code>numpy.power</code>对于int64可以正确计算 100 * 10 * 8，但对于int32给出1874919424（不正确）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">8</span>, dtype=np.int64)</span><br><span class="line"><span class="number">10000000000000000</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">8</span>, dtype=np.int32)</span><br><span class="line"><span class="number">1874919424</span></span><br></pre></td></tr></table></figure>

<p>NumPy和Python整数类型的行为在整数溢出方面存在显着差异，并且可能会使用户期望NumPy整数的行为类似于Python中的<code>int</code>。与 NumPy 不同，Python本体的<code>int</code>是灵活的。这意味着Python整数可以扩展以容纳任何整数并且不会溢出。</p>
<p>NumPy分别提供<code>numpy.iinfo</code>和<code>numpy.finfo</code>验证NumPy整数和浮点值的最小值或最大值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.<span class="built_in">int</span>) <span class="comment"># Bounds of the default integer on this system.</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">9223372036854775808</span>, <span class="built_in">max</span>=<span class="number">9223372036854775807</span>, dtype=int64)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.int32) <span class="comment"># Bounds of a 32-bit integer</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">2147483648</span>, <span class="built_in">max</span>=<span class="number">2147483647</span>, dtype=int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.int64) <span class="comment"># Bounds of a 64-bit integer</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">9223372036854775808</span>, <span class="built_in">max</span>=<span class="number">9223372036854775807</span>, dtype=int64)</span><br></pre></td></tr></table></figure>

<p>如果int64仍然太小，则结果可能会转换为浮点数。浮点数提供了更大但不精确的可能值范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">100</span>, dtype=np.int64) <span class="comment"># Incorrect even with 64-bit int</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">100</span>, dtype=np.float64)</span><br><span class="line"><span class="number">1e+200</span></span><br></pre></td></tr></table></figure>

<h3 id="扩展精度"><a href="#扩展精度" class="headerlink" title="扩展精度"></a>扩展精度</h3><p>Python 的浮点数通常是64位浮点数，几乎等同于<code>np.float64</code>。在某些不寻常的情况下，使用更精确的浮点数可能会很有用。这在numpy中是否可行取决于硬件和开发环境：具体地说，x86机器提供80位精度的硬件浮点，虽然大多数C编译器提供这一点作为它们的<code>long double</code>类型，MSVC（Windows构建的标准）使<code>long double</code>等同于<code>double</code>（64位）。NumPy使编译器的<code>long double</code>作为<code>np.longdouble</code>可用（而<code>np.clongdouble</code>用于复数)。</p>
<p>NumPy不提供比C的<code>long double</code>更高精度的dtype；特别是128位IEEE四精度数据类型（FORTRAN的 <code>REAL*16</code> ）不可用。</p>
<p>为了有效地进行内存的校准，<code>np.longdouble</code>通常以零位进行填充，即96或者128位，哪个更有效率取决于硬件和开发环境；通常在32位系统上它们被填充到96位，而在64位系统上它们通常被填充到128位。<code>np.longdouble</code>被填充到系统默认值；为需要特定填充的用户提供了<code>np.float96</code>和<code>np.float128</code>。尽管它们的名称是这样叫的, 但是<code>np.float96</code>和<code>np.float128</code>只提供与<code>np.longdouble</code>一样的精度, 即大多数x86机器上的80位和标准Windows版本中的64位。</p>
<p>请注意，即使<code>np.longdouble</code>提供比Python中<code>float</code>更多的精度，也很容易失去额外的精度，因为Python通常强制值通过<code>float</code>传递值。</p>
<h2 id="数组索引"><a href="#数组索引" class="headerlink" title="数组索引"></a>数组索引</h2><p>NumPy提供了几种索引数组的方法。</p>
<h3 id="单元素索引"><a href="#单元素索引" class="headerlink" title="单元素索引"></a>单元素索引</h3><p>人们期望的是1-D数组的单元素索引。它的工作方式与其他标准Python序列完全相同。它从0开始计数，并接受从数组末尾开始索引的负索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">2</span>]</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>

<p>与列表和元组不同，NumPy数组支持多维数组的多维索引。这意味着没有必要将每个维度的索引分成它自己的一组方括号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape = (<span class="number">2</span>,<span class="number">5</span>) <span class="comment"># now x is 2-dimensional</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>,<span class="number">3</span>]</span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>,-<span class="number">1</span>]</span><br><span class="line"><span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>请注意，如果索引索引比维度少的多维数组，则会获得一个子维数组。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>

<p>也就是说，指定的每个索引选择与所选维度的其余部分对应的数组。在上面的示例中，选择0表示长度为5的剩余维度未指定，返回的是该维度和大小的数组。必须注意的是，返回的数组不是原始数据的副本，而是指向内存中与原始数组相同的值。在这种情况下，返回第一个位置（0）的1-D数组。因此，在返回的数组上使用单个索引会导致返回单个元素。那是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>请注意，尽管第二种情况效率较低，因为在第一个索引之后创建了一个新的临时数组，该索引随后被索引为2：<code>x[0,2] = x[0][2]</code></p>
<h3 id="切片索引（Slicing）"><a href="#切片索引（Slicing）" class="headerlink" title="切片索引（Slicing）"></a>切片索引（Slicing）</h3><p>与Python列表类似，可以对NumPy数组进行切片。由于数组可能是多维的，因此必须为数组的每个维指定一个切片：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],     <span class="comment"># Create the following rank 2 array with shape (3, 4)</span></span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">b = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]    <span class="comment"># Use slicing to pull out the subarray consisting of the first 2 rows and columns 1 and 2; </span></span><br><span class="line"><span class="built_in">print</span>(b)          <span class="comment"># b is the following array of shape (2, 2):</span></span><br><span class="line">                  <span class="comment"># [[2 3]</span></span><br><span class="line">                  <span class="comment">#  [6 7]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A slice of an array is a view into the same data, so modifying it</span></span><br><span class="line"><span class="comment"># will modify the original array.</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;2&quot;</span></span><br><span class="line">b[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">77</span>     <span class="comment"># b[0, 0] is the same piece of data as a[0, 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;77&quot;</span></span><br></pre></td></tr></table></figure>

<p>你还可以将整数索引与切片索引混合使用。 但是，这样做会产生比原始数组更低级别的数组。 请注意，这与MATLAB处理数组切片的方式完全不同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], </span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two ways of accessing the data in the middle row of the array.</span></span><br><span class="line"><span class="comment"># Mixing integer indexing with slices yields an array of lower rank,</span></span><br><span class="line"><span class="comment"># while using only slices yields an array of the same rank as the</span></span><br><span class="line"><span class="comment"># original array:</span></span><br><span class="line">row_r1 = a[<span class="number">1</span>, :]    <span class="comment"># Rank 1 view of the second row of a</span></span><br><span class="line">row_r2 = a[<span class="number">1</span>:<span class="number">2</span>, :]  <span class="comment"># Rank 2 view of the second row of a</span></span><br><span class="line"><span class="built_in">print</span>(row_r1, row_r1.shape)  <span class="comment"># Prints &quot;[5 6 7 8] (4,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(row_r2, row_r2.shape)  <span class="comment"># Prints &quot;[[5 6 7 8]] (1, 4)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can make the same distinction when accessing columns of an array:</span></span><br><span class="line">col_r1 = a[:, <span class="number">1</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1, col_r1.shape)  <span class="comment"># Prints &quot;[ 2  6 10] (3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(col_r2, col_r2.shape)  <span class="comment"># Prints &quot;[[ 2]</span></span><br><span class="line">                             <span class="comment">#          [ 6]</span></span><br><span class="line">                             <span class="comment">#          [10]] (3, 1)&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="整数数组索引"><a href="#整数数组索引" class="headerlink" title="整数数组索引"></a>整数数组索引</h3><p>使用切片索引到NumPy数组时，生成的数组视图将始终是原始数组的子数组。 相反，整数数组索引允许你使用另一个数组中的数据构造任意数组。 这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># An example of integer array indexing.</span></span><br><span class="line"><span class="comment"># The returned array will have shape (3,) and</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The above example of integer array indexing is equivalent to this:</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">0</span>], a[<span class="number">1</span>, <span class="number">1</span>], a[<span class="number">2</span>, <span class="number">0</span>]]))  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When using integer array indexing, you can reuse the same</span></span><br><span class="line"><span class="comment"># element from the source array:</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Equivalent to the previous integer array indexing example</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">1</span>], a[<span class="number">0</span>, <span class="number">1</span>]]))  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br></pre></td></tr></table></figure>

<p>整数数组索引的一个有用技巧是从矩阵的每一行中选择或改变一个元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new array from which we will select elements</span></span><br><span class="line">a = np.array([[ <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">              [ <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], </span><br><span class="line">              [ <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], </span><br><span class="line">              [<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an array of indices</span></span><br><span class="line">b = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select one element from each row of a using the indices in b</span></span><br><span class="line"><span class="built_in">print</span>(a[np.arange(<span class="number">4</span>), b])  <span class="comment"># Prints &quot;[ 1  6  7 11]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mutate one element from each row of a using the indices in b</span></span><br><span class="line">a[np.arange(<span class="number">4</span>), b] += <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)  <span class="comment"># prints &quot;array([[11,  2,  3],</span></span><br><span class="line">          <span class="comment">#                [ 4,  5, 16],</span></span><br><span class="line">          <span class="comment">#                [17,  8,  9],</span></span><br><span class="line">          <span class="comment">#                [10, 21, 12]])</span></span><br></pre></td></tr></table></figure>

<h3 id="布尔数组索引"><a href="#布尔数组索引" class="headerlink" title="布尔数组索引"></a>布尔数组索引</h3><p>布尔数组索引允许你选择数组的任意元素。通常，这种类型的索引用于选择满足某些条件的数组元素。下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line">bool_idx = (a &gt; <span class="number">2</span>)   <span class="comment"># Find the elements of a that are bigger than 2;</span></span><br><span class="line">                     <span class="comment"># this returns a numpy array of Booleans of the same</span></span><br><span class="line">                     <span class="comment"># shape as a, where each slot of bool_idx tells</span></span><br><span class="line">                     <span class="comment"># whether that element of a is &gt; 2.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bool_idx)      <span class="comment"># Prints &quot;[[False False]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We use boolean array indexing to construct a rank 1 array</span></span><br><span class="line"><span class="comment"># consisting of the elements of a corresponding to the True values</span></span><br><span class="line"><span class="comment"># of bool_idx</span></span><br><span class="line"><span class="built_in">print</span>(a[bool_idx])  <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can do all of the above in a single concise statement:</span></span><br><span class="line"><span class="built_in">print</span>(a[a &gt; <span class="number">2</span>])     <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="广播-Broadcasting"><a href="#广播-Broadcasting" class="headerlink" title="广播(Broadcasting)"></a>广播(Broadcasting)</h2><p>广播是一种强大的机制，它允许NumPy在执行算术运算时使用不同形状的数组。通常，我们有一个较小的数组和一个较大的数组，我们希望多次使用较小的数组来对较大的数组执行一些操作。</p>
<p>例如，假设我们要向矩阵的每一行添加一个常数向量。我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y = np.empty_like(x)   <span class="comment"># Create an empty matrix with the same shape as x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the vector v to each row of the matrix x with an explicit loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    y[i, :] = x[i, :] + v</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now y is the following</span></span><br><span class="line"><span class="comment"># [[ 2  2  4]</span></span><br><span class="line"><span class="comment">#  [ 5  5  7]</span></span><br><span class="line"><span class="comment">#  [ 8  8 10]</span></span><br><span class="line"><span class="comment">#  [11 11 13]]</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<p>这会凑效; 但是当矩阵 x 非常大时，在Python中计算显式循环可能会很慢。注意，向矩阵 x 的每一行添加向量 v 等同于通过垂直堆叠多个 v 副本来形成矩阵 vv，然后执行元素的求和x 和 vv。 我们可以像如下这样实现这种方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">vv = np.tile(v, (<span class="number">4</span>, <span class="number">1</span>))   <span class="comment"># Stack 4 copies of v on top of each other</span></span><br><span class="line"><span class="built_in">print</span>(vv)                 <span class="comment"># Prints &quot;[[1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]]&quot;</span></span><br><span class="line">y = x + vv  <span class="comment"># Add x and vv elementwise</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>NumPy广播允许我们在不实际创建v的多个副本的情况下执行此计算。考虑这个需求，使用广播如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y = x + v  <span class="comment"># Add v to each row of x using broadcasting</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4]</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>y&#x3D;x+v行即使x具有形状(4，3)和v具有形状(3,)，但由于广播的关系，该行的工作方式就好像v实际上具有形状(4，3)，其中每一行都是v的副本，并且求和是按元素执行的。</p>
<p>将两个数组一起广播遵循以下规则：</p>
<ul>
<li>如果数组不具有相同的rank，则将较低等级数组的形状添加1，直到两个形状具有相同的长度。</li>
<li>如果两个数组在维度上具有相同的大小，或者如果其中一个数组在该维度中的大小为1，则称这两个数组在维度上是兼容的。</li>
<li>如果数组在所有维度上兼容，则可以一起广播。</li>
<li>广播之后，每个数组的行为就好像它的形状等于两个输入数组的形状的元素最大值。</li>
<li>在一个数组的大小为1且另一个数组的大小大于1的任何维度中，第一个数组的行为就像沿着该维度复制一样</li>
</ul>
<p>支持广播的功能称为通用功能。</p>
<p>以下是广播的一些应用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute outer product of vectors</span></span><br><span class="line">v = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])  <span class="comment"># v has shape (3,)</span></span><br><span class="line">w = np.array([<span class="number">4</span>,<span class="number">5</span>])    <span class="comment"># w has shape (2,)</span></span><br><span class="line"><span class="comment"># To compute an outer product, we first reshape v to be a column</span></span><br><span class="line"><span class="comment"># vector of shape (3, 1); we can then broadcast it against w to yield</span></span><br><span class="line"><span class="comment"># an output of shape (3, 2), which is the outer product of v and w:</span></span><br><span class="line"><span class="comment"># [[ 4  5]</span></span><br><span class="line"><span class="comment">#  [ 8 10]</span></span><br><span class="line"><span class="comment">#  [12 15]]</span></span><br><span class="line"><span class="built_in">print</span>(np.reshape(v, (<span class="number">3</span>, <span class="number">1</span>)) * w)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a vector to each row of a matrix</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),</span></span><br><span class="line"><span class="comment"># giving the following matrix:</span></span><br><span class="line"><span class="comment"># [[2 4 6]</span></span><br><span class="line"><span class="comment">#  [5 7 9]]</span></span><br><span class="line"><span class="built_in">print</span>(x + v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a vector to each column of a matrix</span></span><br><span class="line"><span class="comment"># x has shape (2, 3) and w has shape (2,).</span></span><br><span class="line"><span class="comment"># If we transpose x then it has shape (3, 2) and can be broadcast</span></span><br><span class="line"><span class="comment"># against w to yield a result of shape (3, 2); transposing this result</span></span><br><span class="line"><span class="comment"># yields the final result of shape (2, 3) which is the matrix x with</span></span><br><span class="line"><span class="comment"># the vector w added to each column. Gives the following matrix:</span></span><br><span class="line"><span class="comment"># [[ 5  6  7]</span></span><br><span class="line"><span class="comment">#  [ 9 10 11]]</span></span><br><span class="line"><span class="built_in">print</span>((x.T + w).T)</span><br><span class="line"><span class="comment"># Another solution is to reshape w to be a column vector of shape (2, 1);</span></span><br><span class="line"><span class="comment"># we can then broadcast it directly against x to produce the same</span></span><br><span class="line"><span class="comment"># output.</span></span><br><span class="line"><span class="built_in">print</span>(x + np.reshape(w, (<span class="number">2</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiply a matrix by a constant:</span></span><br><span class="line"><span class="comment"># x has shape (2, 3). Numpy treats scalars as arrays of shape ();</span></span><br><span class="line"><span class="comment"># these can be broadcast together to shape (2, 3), producing the</span></span><br><span class="line"><span class="comment"># following array:</span></span><br><span class="line"><span class="comment"># [[ 2  4  6]</span></span><br><span class="line"><span class="comment">#  [ 8 10 12]]</span></span><br><span class="line"><span class="built_in">print</span>(x * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>广播通常会使你的代码更简洁，效率更高，因此你应该尽可能地使用它。</p>
<h2 id="数组中的基本数学"><a href="#数组中的基本数学" class="headerlink" title="数组中的基本数学"></a>数组中的基本数学</h2><p>基本数学函数在数组上以元素方式运行，既可以作为运算符重载，也可以作为NumPy模块中的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise sum; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 6.0  8.0]</span></span><br><span class="line"><span class="comment">#  [10.0 12.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"><span class="built_in">print</span>(np.add(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise difference; both produce the array</span></span><br><span class="line"><span class="comment"># [[-4.0 -4.0]</span></span><br><span class="line"><span class="comment">#  [-4.0 -4.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x - y)</span><br><span class="line"><span class="built_in">print</span>(np.subtract(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise product; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 5.0 12.0]</span></span><br><span class="line"><span class="comment">#  [21.0 32.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x * y)</span><br><span class="line"><span class="built_in">print</span>(np.multiply(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise division; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 0.2         0.33333333]</span></span><br><span class="line"><span class="comment">#  [ 0.42857143  0.5       ]]</span></span><br><span class="line"><span class="built_in">print</span>(x / y)</span><br><span class="line"><span class="built_in">print</span>(np.divide(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise square root; produces the array</span></span><br><span class="line"><span class="comment"># [[ 1.          1.41421356]</span></span><br><span class="line"><span class="comment">#  [ 1.73205081  2.        ]]</span></span><br><span class="line"><span class="built_in">print</span>(np.sqrt(x))</span><br></pre></td></tr></table></figure>

<p>请注意，与MATLAB不同，<code>*</code>是元素乘法，而不是矩阵乘法。 我们使用<code>dot</code>函数来计算向量的内积，将向量乘以矩阵。 <code>dot</code>既可以作为NumPy模块中的函数，也可以作为数组对象的实例方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">y = np.array([[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">v = np.array([<span class="number">9</span>,<span class="number">10</span>])</span><br><span class="line">w = np.array([<span class="number">11</span>, <span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inner product of vectors; both produce 219</span></span><br><span class="line"><span class="built_in">print</span>(v.dot(w))</span><br><span class="line"><span class="built_in">print</span>(np.dot(v, w))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix / vector product; both produce the rank 1 array [29 67]</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(v))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x, v))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix / matrix product; both produce the rank 2 array</span></span><br><span class="line"><span class="comment"># [[19 22]</span></span><br><span class="line"><span class="comment">#  [43 50]]</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(y))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x, y))</span><br></pre></td></tr></table></figure>

<p>NumPy为在数组上执行计算提供了许多有用的函数；其中最常用的函数之一是求和函数<code>sum</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x))  <span class="comment"># Compute sum of all elements; prints &quot;10&quot;</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">0</span>))  <span class="comment"># Compute sum of each column; prints &quot;[4 6]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">1</span>))  <span class="comment"># Compute sum of each row; prints &quot;[3 7]&quot;</span></span><br></pre></td></tr></table></figure>


<p>除了使用数组计算数学函数外，我们经常需要对数组中的数据进行整形或其他操作。这种操作的最简单的例子是转置一个矩阵；要转置一个矩阵，只需使用一个数组对象的T属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x)    <span class="comment"># Prints &quot;[[1 2]</span></span><br><span class="line">            <span class="comment">#          [3 4]]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(x.T)  <span class="comment"># Prints &quot;[[1 3]</span></span><br><span class="line">            <span class="comment">#          [2 4]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that taking the transpose of a rank 1 array does nothing:</span></span><br><span class="line">v = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(v)    <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(v.T)  <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="点积运算原理"><a href="#点积运算原理" class="headerlink" title="点积运算原理"></a>点积运算原理</h3><h4 id="数组特殊运算符"><a href="#数组特殊运算符" class="headerlink" title="数组特殊运算符"></a>数组特殊运算符</h4><p>NumPy还提供了一些别的用于处理数组的好用的运算符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dot, sum, min, max, cumsum</span></span><br><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">sum</span>()) <span class="comment"># &gt;&gt;&gt;45</span></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">min</span>()) <span class="comment"># &gt;&gt;&gt;0</span></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">max</span>()) <span class="comment"># &gt;&gt;&gt;9</span></span><br><span class="line"><span class="built_in">print</span>(a.cumsum()) <span class="comment"># &gt;&gt;&gt;[ 0  1  3  6 10 15 21 28 36 45]</span></span><br></pre></td></tr></table></figure>

<p>sum()、min()和max()函数的作用非常明显。将所有元素相加，找出最小和最大元素。</p>
<p>然而，cumsum()函数就不那么明显了。它将像sum()这样的每个元素相加，但是它首先将第一个元素和第二个元素相加，并将计算结果存储在一个列表中，然后将该结果添加到第三个元素中，然后再将该结果存储在一个列表中。这将对数组中的所有元素执行此操作，并返回作为列表的数组之和的运行总数。</p>
<h4 id="Where-函数"><a href="#Where-函数" class="headerlink" title="Where 函数"></a>Where 函数</h4><p>where() 函数是一个根据条件返回数组中的值的有效方法。只需要把条件传递给它，它就会返回一个使得条件为真的元素的列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Where</span></span><br><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">b = np.where(a &lt; <span class="number">50</span>) </span><br><span class="line">c = np.where(a &gt;= <span class="number">50</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(b) <span class="comment"># &gt;&gt;&gt;(array([0, 1, 2, 3, 4]),)</span></span><br><span class="line"><span class="built_in">print</span>(c) <span class="comment"># &gt;&gt;&gt;[5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>


<h2 id="字节交换"><a href="#字节交换" class="headerlink" title="字节交换"></a>字节交换</h2><h3 id="字节排序和ndarrays简介"><a href="#字节排序和ndarrays简介" class="headerlink" title="字节排序和ndarrays简介"></a>字节排序和ndarrays简介</h3><p>ndarray是一个为内存中的数据提供python数组接口的对象。经常发生的情况是，要用数组查看的内存与运行Python的计算机的字节顺序不同。</p>
<p>例如，我可能正在使用带有 little-endian CPU 的计算机 - 例如Intel Pentium，但是我已经从一个由 big-endian计算机 编写的文件中加载了一些数据。假设我已经从Sun（big-endian）计算机写入的文件中加载了4个字节。我知道这4个字节代表两个16位整数。在 big-endian 机器上，首先以最高有效字节（MSB）存储双字节整数，然后存储最低有效字节（LSB）。因此字节按内存顺序排列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MSB整数<span class="number">1</span></span><br><span class="line">LSB整数<span class="number">1</span></span><br><span class="line">MSB整数<span class="number">2</span></span><br><span class="line">LSB整数<span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>假设两个整数实际上是1和770.因为770 &#x3D; 256 * 3 + 2，内存中的4个字节将分别包含：0,1,3,2。我从文件加载的字节将包含这些内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_buffer = <span class="built_in">bytearray</span>([<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_buffer</span><br><span class="line"><span class="built_in">bytearray</span>(<span class="string">b&#x27;\x00\x01\x03\x02&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>我们可能需要使用 ndarray 来访问这些整数。在这种情况下，我们可以围绕这个内存创建一个数组，并告诉numpy有两个整数，并且它们是16位和Big-endian：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr = np.ndarray(shape=(<span class="number">2</span>,),dtype=<span class="string">&#x27;&gt;i2&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">1</span>]</span><br><span class="line"><span class="number">770</span></span><br></pre></td></tr></table></figure>

<p>注意上面的数组<code>dtype &gt; i2</code>。<code>&gt;</code> 表示 big-endian( <code>&lt;</code> 是 Little-endian )，i2 表示‘有符号的2字节整数’。例如，如果我们的数据表示单个无符号4字节小端整数，则dtype字符串将为 <code>&lt;u4</code>。</p>
<p>事实上，为什么我们不尝试呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>little_end_u4 = np.ndarray(shape=(<span class="number">1</span>,),dtype=<span class="string">&#x27;&lt;u4&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>little_end_u4[<span class="number">0</span>] == <span class="number">1</span> * <span class="number">256</span>**<span class="number">1</span> + <span class="number">3</span> * <span class="number">256</span>**<span class="number">2</span> + <span class="number">2</span> * <span class="number">256</span>**<span class="number">3</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<p>回到我们的 big_end_arr - 在这种情况下我们的基础数据是big-endian（数据字节序），我们设置dtype匹配（dtype也是big-endian）。但是，有时你需要翻转它们。</p>
<p>标量当前不包含字节顺序信息，因此从数组中提取标量将返回本机字节顺序的整数。因此：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">0</span>].dtype.byteorder == little_end_u4[<span class="number">0</span>].dtype.byteorder</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<h3 id="更改字节顺序"><a href="#更改字节顺序" class="headerlink" title="更改字节顺序"></a>更改字节顺序</h3><p>从介绍中可以想象，有两种方法可以影响数组的字节顺序与它所查看的底层内存之间的关系：</p>
<ul>
<li><p>更改数组dtype中的字节顺序信息，以便将基础数据解释为不同的字节顺序。这是作用 <code>arr.newbyteorder()</code></p>
</li>
<li><p>更改基础数据的字节顺序，保留<code>dtype</code>解释。这是做什么的 <code>arr.byteswap()</code>。</p>
</li>
</ul>
<p>需要更改字节顺序的常见情况是：</p>
<ul>
<li>数据和dtype字节顺序不匹配，并且希望更改dtype以使其与数据匹配。</li>
<li>数据和dtype字节顺序不匹配，并且希望交换数据以使它们与dtype匹配</li>
<li>数据和dtype字节顺序匹配，但希望交换数据和dtype来反映这一点</li>
</ul>
<h4 id="数据和dtype字节顺序不匹配，更改dtype以匹配数据"><a href="#数据和dtype字节顺序不匹配，更改dtype以匹配数据" class="headerlink" title="数据和dtype字节顺序不匹配，更改dtype以匹配数据"></a>数据和dtype字节顺序不匹配，更改dtype以匹配数据</h4><p>我们制作一些他们不匹配的东西：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>wrong_end_dtype_arr = np.ndarray(shape=(<span class="number">2</span>,),dtype=<span class="string">&#x27;&lt;i2&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>wrong_end_dtype_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">256</span></span><br></pre></td></tr></table></figure>

<p>这种情况的明显解决方法是更改dtype，以便它给出正确的字节顺序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr = wrong_end_dtype_arr.newbyteorder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>请注意，内存中的数组未更改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<h4 id="数据和类型字节顺序不匹配，更改数据以匹配dtype"><a href="#数据和类型字节顺序不匹配，更改数据以匹配dtype" class="headerlink" title="数据和类型字节顺序不匹配，更改数据以匹配dtype"></a>数据和类型字节顺序不匹配，更改数据以匹配dtype</h4><p>如果需要内存中的数据是某种顺序，可能希望这样做。例如，可能正在将内存写入需要特定字节排序的文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr = wrong_end_dtype_arr.byteswap()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>现在数组 已 在内存中更改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h4 id="数据和dtype字节序匹配，交换数据和dtype"><a href="#数据和dtype字节序匹配，交换数据和dtype" class="headerlink" title="数据和dtype字节序匹配，交换数据和dtype"></a>数据和dtype字节序匹配，交换数据和dtype</h4><p>可能有一个正确指定的数组dtype，但是需要数组在内存中具有相反的字节顺序，并且希望dtype匹配以便数组值有意义。在这种情况下，只需执行上述两个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr = big_end_arr.byteswap().newbyteorder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p>使用ndarray astype方法可以更简单地将数据转换为特定的dtype和字节顺序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr = big_end_arr.astype(<span class="string">&#x27;&lt;i2&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>


<h2 id="结构化数组"><a href="#结构化数组" class="headerlink" title="结构化数组"></a>结构化数组</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>结构化数组是ndarray，其数据类型是由一系列命名字段组织的简单数据类型组成。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">9</span>, <span class="number">81.0</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.0</span>)],</span><br><span class="line"><span class="meta">... </span>             dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">9</span>, <span class="number">81.</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>x 是一个长度为2的一维数组，其数据类型是一个包含三个字段的结构：</p>
<ul>
<li>长度为10或更少的字符串，名为“name”。</li>
<li>一个32位整数，名为“age”。</li>
<li>一个32位的名为’weight’的float类型。</li>
</ul>
<p>如果x在位置1处索引，则会得到一个结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>]</span><br><span class="line">(<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.0</span>)</span><br></pre></td></tr></table></figure>

<p>可以通过使用字段名称建立索引来访问和修改结构化数组的各个字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">array([<span class="number">9</span>, <span class="number">3</span>], dtype=int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;age&#x27;</span>] = <span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">5</span>, <span class="number">81.</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">5</span>, <span class="number">27.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>结构化数据类型旨在能够模仿C语言中的“结构”，并共享类似的内存布局。它们用于连接C代码和低级操作结构化缓冲区，例如用于解释二进制blob。出于这些目的，它们支持诸如子数组，嵌套数据类型和联合之类的专用功能，并允许控制结构的内存布局。</p>
<p>希望操纵表格数据的用户（例如存储在csv文件中）可能会发现其他更适合的pydata项目，例如xarray，pandas或DataArray。这些为表格数据分析提供了高级接口，并且针对该用途进行了更好的优化。例如，numpy中结构化数组的类似C-struct的内存布局可能导致较差的缓存行为。</p>
<h3 id="结构化数据类型创建"><a href="#结构化数据类型创建" class="headerlink" title="结构化数据类型创建"></a>结构化数据类型创建</h3><p>结构化数据类型可以被认为是一定长度的字节序列（结构的项目大小），它被解释为字段集合。每个字段在结构中都有一个名称，一个数据类型和一个字节偏移量。字段的数据类型可以是包括其他结构化数据类型的任何numpy数据类型，也可以是子行数据类型，其行为类似于指定形状的ndarray。字段的偏移是任意的，字段甚至可以重叠。这些偏移量通常由numpy自动确定，但也可以指定。</p>
<p>可以使用该函数创建结构化数据类型numpy.dtype。有4种不同的规范形式， 其灵活性和简洁性各不相同。这些在 “数据类型对象” 参考页面中进一步记录，总结如下：</p>
<h4 id="元组列表，每个字段一个元组"><a href="#元组列表，每个字段一个元组" class="headerlink" title="元组列表，每个字段一个元组"></a>元组列表，每个字段一个元组</h4><p>每个元组都具有以下形式（字段名称、数据类型、形状），其中Shape是可选的。 fieldname 是字符串（如果使用标题，则为元组，请参见下面的字段标题）， datatype 可以是任何可转换为数据类型的对象，而 shape 是指定子数组形状的整数元组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, np.float32), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>, (<span class="number">2</span>, <span class="number">2</span>))])</span><br><span class="line">dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>, (<span class="number">2</span>, <span class="number">2</span>))])</span><br></pre></td></tr></table></figure>

<p>如果 fieldname 是空字符串 ‘’ ，则将为字段指定格式为 f# 的默认名称， 其中 # 是字段的整数索引，从左侧开始从0开始计数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>)])</span><br><span class="line">dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>自动确定结构内字段的字节偏移量和总结构项大小。</p>
<h4 id="逗号分隔的数据类型规范字符串"><a href="#逗号分隔的数据类型规范字符串" class="headerlink" title="逗号分隔的数据类型规范字符串"></a>逗号分隔的数据类型规范字符串</h4><p>在这个速记符号中，任何 字符串dtype规范 都可以在字符串中使用， 并用逗号分隔。 字段的项目大小和字节偏移是自动确定的，并且字段名称被赋予默认名称 f0、f1等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(<span class="string">&#x27;i8, f4, S3&#x27;</span>)</span><br><span class="line">dtype([(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(<span class="string">&#x27;3int8, float32, (2, 3)float64&#x27;</span>)</span><br><span class="line">dtype([(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;i1&#x27;</span>, (<span class="number">3</span>,)), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>, (<span class="number">2</span>, <span class="number">3</span>))])</span><br></pre></td></tr></table></figure>

<h4 id="字段参数组字典"><a href="#字段参数组字典" class="headerlink" title="字段参数组字典"></a>字段参数组字典</h4><p>这是最灵活的规范形式，因为它允许控制字段的字节偏移和结构的项目大小。</p>
<p>字典有两个必需键 “names” 和 “format”，以及四个可选键 “offsets”、“itemsize”、“Aligned” 和 “title”。 名称和格式的值应该分别是相同长度的字段名列表和dtype规范列表。 可选的 “offsets” 值应该是整数字节偏移量的列表，结构中的每个字段都有一个偏移量。 如果未给出 “Offsets” ，则自动确定偏移量。可选的 “itemsize” 值应该是一个整数， 描述dtype的总大小（以字节为单位），它必须足够大以包含所有字段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;names&#x27;</span>: [<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>], <span class="string">&#x27;formats&#x27;</span>: [<span class="string">&#x27;i4&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>]&#125;)</span><br><span class="line">dtype([(<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;col2&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;names&#x27;</span>: [<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;formats&#x27;</span>: [<span class="string">&#x27;i4&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;offsets&#x27;</span>: [<span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;itemsize&#x27;</span>: <span class="number">12</span>&#125;)</span><br><span class="line">dtype(&#123;<span class="string">&#x27;names&#x27;</span>:[<span class="string">&#x27;col1&#x27;</span>,<span class="string">&#x27;col2&#x27;</span>], <span class="string">&#x27;formats&#x27;</span>:[<span class="string">&#x27;&lt;i4&#x27;</span>,<span class="string">&#x27;&lt;f4&#x27;</span>], <span class="string">&#x27;offsets&#x27;</span>:[<span class="number">0</span>,<span class="number">4</span>], <span class="string">&#x27;itemsize&#x27;</span>:<span class="number">12</span>&#125;)</span><br></pre></td></tr></table></figure>

<p>可以选择偏移量，使得字段重叠，尽管这将意味着分配给一个字段可能会破坏任何重叠字段的数据。 作为一个例外，numpy.object类型的字段不能与其他字段重叠，因为存在破坏内部对象指针然后取消引用它的风险。</p>
<p>可选的“Aligned”值可以设置为True，以使自动偏移计算使用对齐的偏移量（请参阅自动字节偏移量和对齐）， 就好像numpy.dtype的“Align”关键字参数已设置为True一样。</p>
<p>可选的 ‘titles’ 值应该是长度与 ‘names’ 相同的标题列表，请参阅下面的字段标题。</p>
<h4 id="字段名称字典"><a href="#字段名称字典" class="headerlink" title="字段名称字典"></a>字段名称字典</h4><p>不鼓励使用这种形式的规范。 字典的关键字是字段名称，值是指定类型和偏移量的元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;col1&#x27;</span>: (<span class="string">&#x27;i1&#x27;</span>, <span class="number">0</span>), <span class="string">&#x27;col2&#x27;</span>: (<span class="string">&#x27;f4&#x27;</span>, <span class="number">1</span>)&#125;)</span><br><span class="line">dtype([(<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;i1&#x27;</span>), (<span class="string">&#x27;col2&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>不鼓励使用这种形式，因为Python字典在Python 3.6之前的Python版本中不保留顺序， 并且结构化dtype中字段的顺序有意义。字段标题可以通过使用3元组来指定，见下文。</p>
<h3 id="操作和显示结构化数据类型"><a href="#操作和显示结构化数据类型" class="headerlink" title="操作和显示结构化数据类型"></a>操作和显示结构化数据类型</h3><p>可以names 在dtype对象的属性中找到结构化数据类型的字段名称列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d.names</span><br><span class="line">(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以通过names使用相同长度的字符串序列分配属性来修改字段名称。</p>
<p>dtype对象还具有类似字典的属性，fields其键是字段名称（和字段标题，见下文）， 其值是包含每个字段的dtype和字节偏移量的元组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d.fields</span><br><span class="line">mappingproxy(&#123;<span class="string">&#x27;x&#x27;</span>: (dtype(<span class="string">&#x27;int64&#x27;</span>), <span class="number">0</span>), <span class="string">&#x27;y&#x27;</span>: (dtype(<span class="string">&#x27;float32&#x27;</span>), <span class="number">8</span>)&#125;)</span><br></pre></td></tr></table></figure>

<p>对于非结构化数组，names和fields属性都相同None。 测试 dtype 是否结构化的推荐方法是， 如果dt.names不是None 而不是 dt.names ，则考虑具有0字段的dtypes。</p>
<p>如果可能，结构化数据类型的字符串表示形式显示在“元组列表”表单中，否则numpy将回退到使用更通用的字典表单。</p>
<h3 id="自动字节偏移和对齐"><a href="#自动字节偏移和对齐" class="headerlink" title="自动字节偏移和对齐"></a>自动字节偏移和对齐</h3><p>NumPy使用两种方法之一自动确定字段字节偏移量和结构化数据类型的总项目大小，具体取决于是否 align&#x3D;True指定为关键字参数numpy.dtype。</p>
<p>默认情况下（align&#x3D;False），numpy将字段打包在一起，使得每个字段从前一个字段结束的字节偏移开始，并且字段在内存中是连续的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">print_offsets</span>(<span class="params">d</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;offsets:&quot;</span>, [d.fields[name][<span class="number">1</span>] <span class="keyword">for</span> name <span class="keyword">in</span> d.names])</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;itemsize:&quot;</span>, d.itemsize)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print_offsets(np.dtype(<span class="string">&#x27;u1, u1, i4, u1, i8, u2&#x27;</span>))</span><br><span class="line">offsets: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">15</span>]</span><br><span class="line">itemsize: <span class="number">17</span></span><br></pre></td></tr></table></figure>

<p>如果align&#x3D;True设置了，NumPy将以与许多C编译器填充C结构相同的方式填充结构。在某些情况下，对齐结构可以提高性能，但代价是增加了数据类型的大小。在字段之间插入填充字节，使得每个字段的字节偏移量将是该字段对齐的倍数，对于简单数据类型，通常等于字段的字节大小，请参阅PyArray_Descr.alignment。该结构还将添加尾随填充，以使其itemsize是最大字段对齐的倍数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print_offsets(np.dtype(<span class="string">&#x27;u1, u1, i4, u1, i8, u2&#x27;</span>, align=<span class="literal">True</span>))</span><br><span class="line">offsets: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">24</span>]</span><br><span class="line">itemsize: <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>请注意，尽管默认情况下几乎所有现代C编译器都以这种方式填充，但C结构中的填充依赖于C实现，因此不能保证此内存布局与C程序中相应结构的内容完全匹配。为了获得确切的对应关系，可能需要在numpy侧或C侧进行一些工作。</p>
<p>如果使用offsets基于字典的dtype规范中的可选键指定了偏移量，则设置align&#x3D;True将检查每个字段的偏移量是其大小的倍数，并且itemsize是最大字段大小的倍数，如果不是，则引发异常。</p>
<p>如果结构化数组的字段和项目大小的偏移满足对齐条件，则数组将具有该ALIGNED flag集合。</p>
<p>便捷函数<code>numpy.lib.recfunctions.repack_fields</code>将对齐的dtype或数组转换为打包的dtype或数组，反之亦然。它需要一个dtype或结构化的ndarray作为参数，并返回一个带有字段重新打包的副本，带或不带填充字节。</p>
<h3 id="字段标题"><a href="#字段标题" class="headerlink" title="字段标题"></a>字段标题</h3><p>除了字段名称之外，字段还可以具有关联的标题，备用名称，有时用作字段的附加说明或别名。标题可用于索引数组，就像字段名一样。</p>
<p>要在使用dtype规范的list-of-tuples形式时添加标题，可以将字段名称指定为两个字符串的元组而不是单个字符串，它们分别是字段的标题和字段名称。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line">dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>当使用第一种形式的基于字典的规范时，标题可以’titles’作为如上所述的额外密钥提供。当使用第二个（不鼓励的）基于字典的规范时，可以通过提供3元素元组而不是通常的2元素元组来提供标题：(datatype, offset, title)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;name&#x27;</span>: (<span class="string">&#x27;i4&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;my title&#x27;</span>)&#125;)</span><br><span class="line">dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;&lt;i4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>该dtype.fields字典将包含标题作为键，如果使用任何头衔。这有效地表示具有标题的字段将在字典字典中表示两次。这些字段的元组值还将具有第三个元素，即字段标题。因此，并且因为names属性保留了字段顺序而fields 属性可能没有，所以建议使用dtype的names属性迭代dtype的字段，该属性不会列出标题，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name <span class="keyword">in</span> d.names:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(d.fields[name][:<span class="number">2</span>])</span><br><span class="line">(dtype(<span class="string">&#x27;int64&#x27;</span>), <span class="number">0</span>)</span><br><span class="line">(dtype(<span class="string">&#x27;float32&#x27;</span>), <span class="number">8</span>)</span><br></pre></td></tr></table></figure>

<h3 id="联合类型"><a href="#联合类型" class="headerlink" title="联合类型"></a>联合类型</h3><p>默认情况下，结构化数据类型在numpy中实现为基本类型 numpy.void， 但是可以使用 数据类型对象中 中描述的dtype规范的 (base_dtype, dtype) 形式将其他 numpy 类型解释为结构化类型。 这里，base_dtype 是所需的底层 dtype，字段和标志将从dtype复制。此 dtype 类似于 C 中的“Union”。</p>
<h3 id="将数据分配给结构化数组"><a href="#将数据分配给结构化数组" class="headerlink" title="将数据分配给结构化数组"></a>将数据分配给结构化数组</h3><p>有许多方法可以为结构化数组赋值：使用python元组，使用标量值或使用其他结构化数组。</p>
<h4 id="从Python本机类型（元组）分配"><a href="#从Python本机类型（元组）分配" class="headerlink" title="从Python本机类型（元组）分配"></a>从Python本机类型（元组）分配</h4><p>为结构化数组赋值的最简单方法是使用python元组。每个赋值应该是一个长度等于数组中字段数的元组，而不是列表或数组，因为它们将触发numpy的广播规则。元组的元素从左到右分配给数组的连续字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)], dtype=<span class="string">&#x27;i8, f4, f8&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>] = (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">1</span>, <span class="number">2.</span>, <span class="number">3.</span>), (<span class="number">7</span>, <span class="number">8.</span>, <span class="number">9.</span>)],</span><br><span class="line">     dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<h4 id="Scalars的赋值"><a href="#Scalars的赋值" class="headerlink" title="Scalars的赋值"></a>Scalars的赋值</h4><p>分配给结构化元素的标量将分配给所有字段。将标量分配给结构化数组时，或者将非结构化数组分配给结构化数组时，会发生这种情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.zeros(<span class="number">2</span>, dtype=<span class="string">&#x27;i8, f4, ?, S1&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:] = <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">3</span>, <span class="number">3.</span>, <span class="literal">True</span>, <span class="string">b&#x27;3&#x27;</span>), (<span class="number">3</span>, <span class="number">3.</span>, <span class="literal">True</span>, <span class="string">b&#x27;3&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;?&#x27;</span>), (<span class="string">&#x27;f3&#x27;</span>, <span class="string">&#x27;S1&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:] = np.arange(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">0</span>, <span class="number">0.</span>, <span class="literal">False</span>, <span class="string">b&#x27;0&#x27;</span>), (<span class="number">1</span>, <span class="number">1.</span>, <span class="literal">True</span>, <span class="string">b&#x27;1&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;?&#x27;</span>), (<span class="string">&#x27;f3&#x27;</span>, <span class="string">&#x27;S1&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>结构化数组也可以分配给非结构化数组，但前提是结构化数据类型只有一个字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>twofield = np.zeros(<span class="number">2</span>, dtype=[(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>onefield = np.zeros(<span class="number">2</span>, dtype=[(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nostruct = np.zeros(<span class="number">2</span>, dtype=<span class="string">&#x27;i4&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nostruct[:] = twofield</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">...</span><br><span class="line">TypeError: Cannot cast scalar <span class="keyword">from</span> dtype([(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>)]) to dtype(<span class="string">&#x27;int32&#x27;</span>) according to the rule <span class="string">&#x27;unsafe&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="来自其他结构化数组的赋值"><a href="#来自其他结构化数组的赋值" class="headerlink" title="来自其他结构化数组的赋值"></a>来自其他结构化数组的赋值</h4><p>两个结构化数组之间的分配就像源元素已转换为元组然后分配给目标元素一样。也就是说，源数组的第一个字段分配给目标数组的第一个字段，第二个字段同样分配，依此类推，而不管字段名称如何。具有不同数量的字段的结构化数组不能彼此分配。未包含在任何字段中的目标结构的字节不受影响。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.zeros(<span class="number">3</span>, dtype=[(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.ones(<span class="number">3</span>, dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;O&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[:] = a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([(<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>), (<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>), (<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;O&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<h4 id="涉及子数组的分配"><a href="#涉及子数组的分配" class="headerlink" title="涉及子数组的分配"></a>涉及子数组的分配</h4><p>分配给子数组的字段时，首先将指定的值广播到子数组的形状。</p>
<h3 id="索引结构化数组"><a href="#索引结构化数组" class="headerlink" title="索引结构化数组"></a>索引结构化数组</h3><h4 id="访问单个字段"><a href="#访问单个字段" class="headerlink" title="访问单个字段"></a>访问单个字段</h4><p>可以通过使用字段名称索引数组来访问和修改结构化数组的各个字段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">4</span>)], dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;foo&#x27;</span>] = <span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">10</span>, <span class="number">2.</span>), (<span class="number">10</span>, <span class="number">4.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>生成的数组是原始数组的视图。它共享相同的内存位置，写入视图将修改原始数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x[<span class="string">&#x27;bar&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[:] = <span class="number">11</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">10</span>, <span class="number">11.</span>), (<span class="number">10</span>, <span class="number">11.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>此视图与索引字段具有相同的dtype和itemsize，因此它通常是非结构化数组，但嵌套结构除外。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.dtype, y.shape, y.strides</span><br><span class="line">(dtype(<span class="string">&#x27;float32&#x27;</span>), (<span class="number">2</span>,), (<span class="number">12</span>,))</span><br></pre></td></tr></table></figure>

<p>如果访问的字段是子数组，则子数组的维度将附加到结果的形状：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.zeros((<span class="number">2</span>, <span class="number">2</span>), dtype=[(<span class="string">&#x27;a&#x27;</span>, np.int32), (<span class="string">&#x27;b&#x27;</span>, np.float64, (<span class="number">3</span>, <span class="number">3</span>))])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;a&#x27;</span>].shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;b&#x27;</span>].shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 07：Python 环境下的数字图像分析方法</title>
    <url>/PythonLes08/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Python的图像分析方法是一种强大的数据处理技术，它利用多种算法和工具来提取、处理和分析图像数据。通过Python，我们可以方便地调用各种图像处理库，如OpenCV、PIL(Pillow)、SciPy等，进行图像的预处理、特征提取、图像分割、边缘检测等操作。此外，利用Python的机器学习库，如scikit-learn、TensorFlow等，我们还可以对图像进行更高级的分析，如目标检测、图像识别、图像分类等。SciPy是构建在Python的NumPy扩展上的数学算法和便利函数的集合。它通过向用户提供用于操作和可视化数据的高级命令和类，为交互式Python会话添加了强大的功能。有了SciPy，交互式Python会话将成为可与MATLAB、IDL、Octave、R-Lab和SciLab等系统相媲美的数据处理和系统原型环境。</p>
<p>Python的数字图像分析方法章节将持续3-4周的课程，包括数字图像的基础操作，图像降噪，图像分割，边缘检测，目标检测等等。本节课程我们将学习Python在数字图像分析领域的一些基础方法。</p>
<span id="more"></span>

<h2 id="Pillow-与-PIL-库"><a href="#Pillow-与-PIL-库" class="headerlink" title="Pillow 与 PIL 库"></a>Pillow 与 PIL 库</h2><p>PIL (Python Imaging Library) 是Python平台上图像处理的标准库，功能丰富，API简单易用，不过只支持到Python 2.7。</p>
<p>PIL官方网站：<a href="http://www.pythonware.com/products/pil/">http://www.pythonware.com/products/pil/</a></p>
<p>Pillow是PIL的一个派生分支，但如今已经发展成为比PIL本身更具活力的图像处理库。</p>
<p>Pillow的Github主页：<a href="https://github.com/python-pillow/Pillow">https://github.com/python-pillow/Pillow</a><br>Pillow的文档(对应版本v3.0.0)：<a href="https://pillow.readthedocs.org/en/latest/handbook/index.html">https://pillow.readthedocs.org/en/latest/handbook/index.html</a></p>
<p>给Python安装Pillow非常简单，使用pip或easy_install只要一行代码即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在命令行使用PIP安装：</span></span><br><span class="line">pip install Pillow</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或在命令行使用easy_install安装：</span></span><br><span class="line">easy_install Pillow</span><br></pre></td></tr></table></figure>

<p>安装完成后，使用from PIL import Image就引用使用库了。如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>)</span><br><span class="line">im.rotate(<span class="number">45</span>).show()</span><br></pre></td></tr></table></figure>

<h2 id="使用-Image-类"><a href="#使用-Image-类" class="headerlink" title="使用 Image 类"></a>使用 Image 类</h2><p>PIL最重要的类是 <code>Image</code> class, 你可以通过多种方法创建这个类的实例；你可以从文件加载图像，或者处理其他图像, 或者从 scratch 创建。</p>
<p>要从文件加载图像，使用 <code>open()</code> 函数， 在 <code>Image</code> 模块:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>加载成功将返回一个 <code>Image</code> 对象。 你现在可以使用示例属性检查文件内容:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="built_in">print</span>(im.<span class="built_in">format</span>, im.size, im.mode)</span><br><span class="line"><span class="comment"># PNG (512, 512) RGB</span></span><br></pre></td></tr></table></figure>

<p><code>format</code> 这个属性标识了图像来源。如果图像不是从文件读取它的值就是None。<code>size</code>属性是一个二元tuple，包含width和height（宽度和高度，单位都是px）。 <code>mode</code> 属性定义了图像通道的数量和名称，以及像素类型和深度。常见的modes 有 “L” (luminance) 表示灰度图像, “RGB” 表示真彩色图像, 以及 “CMYK” 表示出版图像。</p>
<p>如果文件打开错误，返回 <code>IOError</code> 错误。</p>
<p>只要你有了 <code>Image</code> 类的实例，你就可以通过类的方法处理图像。比如，下列方法可以显示图像:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im.show()</span><br></pre></td></tr></table></figure>

<p>标准的 <code>im.show()</code> 效率并不高，它需要保存图像到临时文件然后通过 xv 显示图像。你需要先安装 xv ，显示图像有助于调试和测试。</p>
<h2 id="读写图像"><a href="#读写图像" class="headerlink" title="读写图像"></a>读写图像</h2><p>PIL 模块支持大量图片格式。使用在 <code>Image</code> 模块的 <code>open()</code> 函数从磁盘读取文件。你不需要知道文件格式就能打开它，这个库能够根据文件内容自动确定文件格式。</p>
<h3 id="从文件读取"><a href="#从文件读取" class="headerlink" title="从文件读取"></a>从文件读取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fp = <span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">im = Image.<span class="built_in">open</span>(fp)</span><br></pre></td></tr></table></figure>

<h3 id="从指定路径读取"><a href="#从指定路径读取" class="headerlink" title="从指定路径读取"></a>从指定路径读取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(os.path.join(os.getcwd(),<span class="string">&quot;im.png&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>要保存文件，使用 <code>Image</code> 类的 <code>save()</code> 方法。保存文件的时候文件名变得重要了。除非你指定格式，否则这个库将会以文件名的扩展名作为格式保存。</p>
<h3 id="转换文件格式到JPEG"><a href="#转换文件格式到JPEG" class="headerlink" title="转换文件格式到JPEG"></a>转换文件格式到JPEG</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    f, e = os.path.splitext(infile)</span><br><span class="line">    outfile = f + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            Image.<span class="built_in">open</span>(infile).convert(<span class="string">&#x27;RGB&#x27;</span>).save(outfile)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cannot convert&quot;</span>, infile)</span><br></pre></td></tr></table></figure>

<p><code>argv</code>是sys模块的一个全局变量，也称sys模块的一个属性！<code>argv</code>本身为一个list类型的对象，该对象持有的第1个元素是命令行中传入的模块名、从第2个元素开始（含），均为命令行中传入的参数！</p>
<p>注意：argv持有的每个元素的类型均为str（字符串）</p>
<p><code>save()</code> 方法的第二个参数可以指定文件格式，如果你使用非标准的扩展名你必须这样做：</p>
<h3 id="创建-JPEG-缩略图"><a href="#创建-JPEG-缩略图" class="headerlink" title="创建 JPEG 缩略图"></a>创建 JPEG 缩略图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">size = (<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    outfile = os.path.splitext(infile)[<span class="number">0</span>] + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            im = Image.<span class="built_in">open</span>(infile)</span><br><span class="line">            im.thumbnail(size)</span><br><span class="line">            im.convert(<span class="string">&quot;RGB&quot;</span>).save(outfile, <span class="string">&quot;JPEG&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cannot create thumbnail for&quot;</span>, infile)</span><br></pre></td></tr></table></figure>

<p>很重要的一点是这个库不会直接解码或者加载图像栅格数据。当你打开一个文件，只会读取文件头信息用来确定格式，颜色模式，大小等等，文件的剩余部分不会主动处理。这意味着打开一个图像文件的操作十分快速，跟图片大小和压缩方式无关。下面是一个简单的脚本用来快速验证大量图片。</p>
<h3 id="验证图像文件"><a href="#验证图像文件" class="headerlink" title="验证图像文件"></a>验证图像文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(infile) <span class="keyword">as</span> im:</span><br><span class="line">            <span class="built_in">print</span>(infile, im.<span class="built_in">format</span>, <span class="string">&quot;%dx%d&quot;</span> % im.size, im.mode)</span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="图像剪切，粘贴，合并，几何变换等"><a href="#图像剪切，粘贴，合并，几何变换等" class="headerlink" title="图像剪切，粘贴，合并，几何变换等"></a>图像剪切，粘贴，合并，几何变换等</h2><p><code>Image</code> 类包含的方法允许你操作图像部分选区。使用:py:meth:~PIL.Image.Image.crop 方法获取图像的一个子矩形选区。</p>
<h3 id="从图像中复制出一个矩形选区"><a href="#从图像中复制出一个矩形选区" class="headerlink" title="从图像中复制出一个矩形选区"></a>从图像中复制出一个矩形选区</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">box = (<span class="number">100</span>, <span class="number">100</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">region = im.crop(box)</span><br></pre></td></tr></table></figure>

<p>矩形选区有一个4元元组定义，分别表示左、上、右、下的坐标。这个库以左上角为坐标原点，单位是px，所以上诉代码复制了一个 300x300 pixels 的矩形选区。这个选区现在可以被处理并且粘贴到原图。</p>
<h3 id="处理复制的矩形选区并粘贴到原图"><a href="#处理复制的矩形选区并粘贴到原图" class="headerlink" title="处理复制的矩形选区并粘贴到原图"></a>处理复制的矩形选区并粘贴到原图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">region = region.transpose(Image.ROTATE_180)</span><br><span class="line">im.paste(region, box)</span><br></pre></td></tr></table></figure>

<p>当你粘贴矩形选区的时候必须保证尺寸一致。此外，矩形选区不能在图像外。然而你不必保证矩形选区和原图的颜色模式一致，因为矩形选区会被自动转换颜色（参看下面的 颜色变换 部分），下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Rolling an image</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">roll</span>(<span class="params">image, delta</span>):</span><br><span class="line">    <span class="string">&quot;Roll an image sideways&quot;</span></span><br><span class="line"></span><br><span class="line">    xsize, ysize = image.size</span><br><span class="line"></span><br><span class="line">    delta = delta % xsize</span><br><span class="line">    <span class="keyword">if</span> delta == <span class="number">0</span>: <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    part1 = image.crop((<span class="number">0</span>, <span class="number">0</span>, delta, ysize))</span><br><span class="line">    part2 = image.crop((delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part2, (<span class="number">0</span>, <span class="number">0</span>, xsize-delta, ysize))</span><br><span class="line">    image.paste(part1, (xsize-delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>

<h3 id="分离和合并颜色通道"><a href="#分离和合并颜色通道" class="headerlink" title="分离和合并颜色通道"></a>分离和合并颜色通道</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r, g, b = im.split()</span><br><span class="line">im = Image.merge(<span class="string">&quot;RGB&quot;</span>, (b, g, r))</span><br></pre></td></tr></table></figure>

<p>注意，对于单通道图像，<code>split()</code>返回图像本身。</p>
<h3 id="几何变换"><a href="#几何变换" class="headerlink" title="几何变换"></a>几何变换</h3><p><code>PIL.Image.Image</code>类包含了<code>resize()</code>和<code>rotate()</code>方法。前者接受一个元组，给出新的大小，后者接受以逆时针为单位的角度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = im.resize((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">out = im.rotate(<span class="number">45</span>) <span class="comment"># degrees counter-clockwise</span></span><br><span class="line">im1 = im1.rotate(<span class="number">90</span>, PIL.Image.NEAREST, expand = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>要以90度的步骤旋转图像，您可以使用<code>rotate()</code>方法或<code>transpose()</code>方法。后者也可用于围绕其水平或垂直轴翻转图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = im.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">out = im.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">out = im.transpose(Image.ROTATE_90)</span><br><span class="line">out = im.transpose(Image.ROTATE_180)</span><br><span class="line">out = im.transpose(Image.ROTATE_270)</span><br></pre></td></tr></table></figure>

<p><code>transpose()</code>方法和相应的<code>rotate()</code>方法在性能和结果上没有区别。</p>
<h3 id="颜色变换"><a href="#颜色变换" class="headerlink" title="颜色变换"></a>颜色变换</h3><p>Python成像库允许您使用<code>convert()</code>方法在不同色彩表示之间转换图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>).convert(<span class="string">&quot;L&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>该库支持每种受支持的模式与“L”和“RGB”模式之间的转换。要在其他模式之间进行转换，可能必须使用中间图像(通常是“RGB”图像)。</p>
<h3 id="随堂练习"><a href="#随堂练习" class="headerlink" title="随堂练习"></a>随堂练习</h3><blockquote class="blockquote-center">
<p>构建一张PNG格式图像，读取该图片，左右翻转后，侧向平移50个像素，沿顺时针方向旋转70度后保留完整的画幅尺寸，输出为JPEG格式。</p>

</blockquote>


<h2 id="如何将PIL图像转换为NumPy数组？"><a href="#如何将PIL图像转换为NumPy数组？" class="headerlink" title="如何将PIL图像转换为NumPy数组？"></a>如何将PIL图像转换为NumPy数组？</h2><p>从以下URL导入图像并将其转换为numpy数组。<br>URL &#x3D; ‘<a href="https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg">https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg</a>‘</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> PIL, requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import image from URL</span></span><br><span class="line">URL = <span class="string">&#x27;https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg&#x27;</span></span><br><span class="line">response = requests.get(URL)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read it as Image</span></span><br><span class="line">I = Image.<span class="built_in">open</span>(BytesIO(response.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionally resize</span></span><br><span class="line">I = I.resize([<span class="number">150</span>,<span class="number">150</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to numpy array</span></span><br><span class="line">arr = np.asarray(I)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionaly Convert it back to an image and show</span></span><br><span class="line">im = PIL.Image.fromarray(np.uint8(arr))</span><br></pre></td></tr></table></figure>




<h2 id="插值-scipy-interpolate"><a href="#插值-scipy-interpolate" class="headerlink" title="插值 (scipy.interpolate)"></a>插值 (scipy.interpolate)</h2><h3 id="一维插值-interp1d"><a href="#一维插值-interp1d" class="headerlink" title="一维插值 (interp1d)"></a>一维插值 (interp1d)</h3><p>这个 <code>interp1d</code> 中的类 <code>scipy.interpolate</code> 是一种基于固定数据点创建函数的便捷方法，可以使用线性插值在给定数据定义的域内的任何位置计算该函数。通过传递组成数据的一维向量来创建此类的实例。此类的实例定义了一个 <code>__call__</code> 方法，因此可以将其视为在已知数据值之间进行插值以获得未知值的函数(它还具有用于帮助的文档字符串)。边界处的行为可以在实例化时指定。下面的示例演示了它在线性样条插值和三次样条插值中的用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f = interp1d(x, y)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">41</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>, xnew, f(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;cubic&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-1.png" width="75%" alt="" align=center />



<p>插值 <code>interp1d</code> 的方法常见的可以有nearest, previous以及next，其中它们返回沿x轴最近的点、上一个点或下一个点。最近的和次要的可以被认为是因果插值过滤的特例。下面的示例使用与上一个示例中相同的数据演示它们的用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f1 = interp1d(x, y, kind=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;previous&#x27;</span>)</span><br><span class="line">f3 = interp1d(x, y, kind=<span class="string">&#x27;next&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">1001</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(xnew, f1(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>, xnew, f3(xnew), <span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;nearest&#x27;</span>, <span class="string">&#x27;previous&#x27;</span>, <span class="string">&#x27;next&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-2.png" width="80%" alt="" align=center />

<h3 id="多变量数据插值-griddata"><a href="#多变量数据插值-griddata" class="headerlink" title="多变量数据插值 (griddata)"></a>多变量数据插值 (griddata)</h3><p>例如，假设您具有基础函数的多维数据 $F(x,y)$，你只知道若干个点上的值 $[(x[i],y[i])]$，它们不会形成规则的网格。</p>
<p>假设我们要对二维函数 $F(x,y)$ 进行插值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x*(<span class="number">1</span>-x)*np.cos(<span class="number">4</span>*np.pi*x) * np.sin(<span class="number">4</span>*np.pi*y**<span class="number">2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">grid_x, grid_y = np.mgrid[<span class="number">0</span>:<span class="number">1</span>:<span class="number">100j</span>, <span class="number">0</span>:<span class="number">1</span>:<span class="number">200j</span>]</span><br></pre></td></tr></table></figure>

<p>但我们只知道它在1000个数据点的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.random.random((<span class="number">1000</span>, <span class="number">2</span>))</span><br><span class="line">values = func(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>这可以通过以下方式完成 <code>griddata</code> –下面我们将尝试所有的插值方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> griddata</span><br><span class="line"></span><br><span class="line">grid_z0 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">grid_z1 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">grid_z2 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;cubic&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到，所有方法都在一定程度上重现了准确的结果，但对于此光滑函数，三次样条插值提供了最好的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.imshow(func(grid_x, grid_y).T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>,cmap = <span class="string">&#x27;hsv&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;k.&#x27;</span>, ms=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.imshow(grid_z0.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Nearest&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.imshow(grid_z1.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Linear&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.imshow(grid_z2.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic&#x27;</span>)</span><br><span class="line">plt.gcf().set_size_inches(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-3.png" width="80%" alt="" align=center />

<h3 id="样条插值"><a href="#样条插值" class="headerlink" title="样条插值"></a>样条插值</h3><h4 id="一维中的样条插值：程序化"><a href="#一维中的样条插值：程序化" class="headerlink" title="一维中的样条插值：程序化"></a>一维中的样条插值：程序化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三次样条</span></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">2</span>*np.pi+np.pi/<span class="number">4</span>, np.pi/<span class="number">4</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 求一条一维曲线的b-spline样条表示。给定一组数据点(x[i],y[i])，在有限区间上确定光滑样条近似。</span></span><br><span class="line"><span class="comment"># 详细信息请参照：https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splrep.html</span></span><br><span class="line"></span><br><span class="line">xnew = np.arange(<span class="number">0</span>, <span class="number">2</span>*np.pi, np.pi/<span class="number">50</span>)</span><br><span class="line">ynew = interpolate.splev(xnew, tck, der=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 求b-spline样条曲线或它的导数。给定b样条表示的结点和系数，计算平滑多项式及其导数的值。这是对FITPACK的FORTRAN例程splev和splder的包装。</span></span><br><span class="line"><span class="comment"># der 要计算的样条导数的阶数(必须小于或等于k，即样条的阶数)。</span></span><br><span class="line"><span class="comment"># 详细信息请参照：https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splev.html</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;x&#x27;</span>, xnew, ynew, xnew, np.sin(xnew), x, y, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Linear&#x27;</span>, <span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic-spline interpolation&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_00_00.png" width="80%" alt="" align=center />


<h4 id="样条的导数"><a href="#样条的导数" class="headerlink" title="样条的导数"></a>样条的导数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yder = interpolate.splev(xnew, tck, der=<span class="number">1</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(xnew, yder, xnew, np.cos(xnew),<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Derivative estimation from spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_01_00.png" width="80%" alt="" align=center />



<h4 id="样条的所有导数"><a href="#样条的所有导数" class="headerlink" title="样条的所有导数"></a>样条的所有导数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yders = interpolate.spalde(xnew, tck)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(yders[<span class="number">0</span>])):</span><br><span class="line">   plt.plot(xnew, [d[i] <span class="keyword">for</span> d <span class="keyword">in</span> yders], <span class="string">&#x27;--&#x27;</span>, label=<span class="string">f&quot;<span class="subst">&#123;i&#125;</span> derivative&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;All derivatives of a B-spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_02_00.png" width="80%" alt="" align=center />

<h4 id="样条的积分"><a href="#样条的积分" class="headerlink" title="样条的积分"></a>样条的积分</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">integ</span>(<span class="params">x, tck, constant=-<span class="number">1</span></span>):</span><br><span class="line">    x = np.atleast_1d(x)</span><br><span class="line">    out = np.zeros(x.shape, dtype=x.dtype)</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(out)):</span><br><span class="line">        out[n] = interpolate.splint(<span class="number">0</span>, x[n], tck)</span><br><span class="line">    out += constant</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line">yint = integ(xnew, tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(xnew, yint, xnew, -np.cos(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Integral estimation from spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_03_00.png" width="80%" alt="" align=center />

<p>样条的根</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">interpolate.sproot(tck)</span><br><span class="line">array([<span class="number">3.1416</span>])</span><br></pre></td></tr></table></figure>

<p>请注意， <code>sproot</code> 在近似区间的边缘找不到明显的解。如果我们在稍微大一点的间隔上定义样条，我们可以恢复两个根：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(-np.pi/<span class="number">4</span>, <span class="number">2.</span>*np.pi + np.pi/<span class="number">4</span>, <span class="number">21</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line">interpolate.sproot(tck)</span><br><span class="line">array([<span class="number">0.</span>, <span class="number">3.1416</span>])</span><br></pre></td></tr></table></figure>

<p>参数样条</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">.1</span>)</span><br><span class="line">x = np.sin(<span class="number">2</span>*np.pi*t)</span><br><span class="line">y = np.cos(<span class="number">2</span>*np.pi*t)</span><br><span class="line">tck, u = interpolate.splprep([x, y], s=<span class="number">0</span>)</span><br><span class="line">unew = np.arange(<span class="number">0</span>, <span class="number">1.01</span>, <span class="number">0.01</span>)</span><br><span class="line">out = interpolate.splev(unew, tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;x&#x27;</span>, out[<span class="number">0</span>], out[<span class="number">1</span>], np.sin(<span class="number">2</span>*np.pi*unew), np.cos(<span class="number">2</span>*np.pi*unew), x, y, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Linear&#x27;</span>, <span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">1.05</span>, <span class="number">1.05</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Spline of parametrically-defined curve&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_04_00.png" width="80%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在稀疏的20x20网格上定义函数</span></span><br><span class="line">x_edges, y_edges = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">21j</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">21j</span>]</span><br><span class="line">x = x_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(x_edges[:<span class="number">2</span>, <span class="number">0</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">y = y_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(y_edges[<span class="number">0</span>, :<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">z = (x+y) * np.exp(-<span class="number">6.0</span>*(x*x+y*y))</span><br><span class="line">plt.figure()</span><br><span class="line">lims = <span class="built_in">dict</span>(cmap=<span class="string">&#x27;RdBu_r&#x27;</span>, vmin=-<span class="number">0.25</span>, vmax=<span class="number">0.25</span>)</span><br><span class="line">plt.pcolormesh(x_edges, y_edges, z, shading=<span class="string">&#x27;flat&#x27;</span>, **lims)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.title(<span class="string">&quot;Sparsely sampled function.&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-6_00_00.png" width="80%" alt="" align=center />


<p>新的70x70网格上的插值函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xnew_edges, ynew_edges = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">71j</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">71j</span>]</span><br><span class="line">xnew = xnew_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(xnew_edges[:<span class="number">2</span>, <span class="number">0</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">ynew = ynew_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(ynew_edges[<span class="number">0</span>, :<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">tck = interpolate.bisplrep(x, y, z, s=<span class="number">0</span>)</span><br><span class="line">znew = interpolate.bisplev(xnew[:,<span class="number">0</span>], ynew[<span class="number">0</span>,:], tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.pcolormesh(xnew_edges, ynew_edges, znew, shading=<span class="string">&#x27;flat&#x27;</span>, **lims)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.title(<span class="string">&quot;Interpolated function.&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-6_01_00.png" width="80%" alt="" align=center />


<h3 id="随堂练习-1"><a href="#随堂练习-1" class="headerlink" title="随堂练习"></a>随堂练习</h3><blockquote class="blockquote-center">
<p>定义一个三次二元函数，在[-10,10] x [-10,10]定义域范围内随机生成1000个点，并计算函数值。通过插值方法获取每[0.01 x 0.01]间隔的网格点处的函数值。</p>

</blockquote>


<h2 id="空间数据结构和算法-scipy-spatial"><a href="#空间数据结构和算法-scipy-spatial" class="headerlink" title="空间数据结构和算法 (scipy.spatial)"></a>空间数据结构和算法 (scipy.spatial)</h2><p>SciPy通过利用Qhull类库，spatial可以计算三角剖分、Voronoi图和凸包等等。此外，它还包含 KDTree 最近邻点查询的实现，以及各种度量中距离计算的实用程序。</p>
<h3 id="Delaunay三角测量"><a href="#Delaunay三角测量" class="headerlink" title="Delaunay三角测量"></a>Delaunay三角测量</h3><p>Delaunay三角剖分是将一组点细分为一组不重叠的三角形，这样任何三角形的外接圆内都没有点。在实践中，这样的三角剖分往往会避免带有小角度的三角形。</p>
<p>可以使用以下方法计算Delaunay三角剖分 scipy.spatial 具体如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> Delaunay</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1.1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">tri = Delaunay(points)</span><br></pre></td></tr></table></figure>

<p>我们可以把它形象化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.triplot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], tri.simplices)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(points):</span><br><span class="line">    plt.text(p[<span class="number">0</span>]-<span class="number">0.03</span>, p[<span class="number">1</span>]+<span class="number">0.03</span>, j, ha=<span class="string">&#x27;right&#x27;</span>) <span class="comment"># label the points</span></span><br><span class="line"><span class="keyword">for</span> j, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(tri.simplices):</span><br><span class="line">    p = points[s].mean(axis=<span class="number">0</span>)</span><br><span class="line">    plt.text(p[<span class="number">0</span>], p[<span class="number">1</span>], <span class="string">&#x27;#%d&#x27;</span> % j, ha=<span class="string">&#x27;center&#x27;</span>) <span class="comment"># label triangles</span></span><br><span class="line">plt.xlim(-<span class="number">0.5</span>, <span class="number">1.5</span>); plt.ylim(-<span class="number">0.5</span>, <span class="number">1.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-1.png" width="60%" alt="" align=center />


<p>三角剖分的结构按以下方式编码： simplices 属性包含 points 组成三角形的数组。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line">tri.simplices[i,:]</span><br><span class="line"><span class="comment"># array([3, 1, 0], dtype=int32)</span></span><br><span class="line"></span><br><span class="line">points[tri.simplices[i,:]]</span><br><span class="line"><span class="comment"># array([[ 1. ,  1. ],</span></span><br><span class="line"><span class="comment">#        [ 0. ,  1.1],</span></span><br><span class="line"><span class="comment">#        [ 0. ,  0. ]])</span></span><br></pre></td></tr></table></figure>

<p>此外，还可以找到相邻三角形：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tri.neighbors[i]</span><br><span class="line"># array([-1,  0, -1], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这告诉我们这个三角形有#0号三角形作为邻居，但没有其他邻居。此外，它还告诉我们邻居0与三角形的顶点1相对：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points[tri.simplices[i, <span class="number">1</span>]]</span><br><span class="line"><span class="comment"># array([ 0. ,  1.1])</span></span><br></pre></td></tr></table></figure>

<p>事实上，从数字上，我们可以看到情况是这样的。</p>
<p>Qhull还可以对高维点集执行细分以简化(例如，在3-D中细分为四面体)。</p>
<p>共面点</p>
<p>重要的是要注意到，不是 all 由于形成三角剖分的数值精度问题，点必然显示为三角剖分的顶点。请考虑具有重复点的上述内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">tri = Delaunay(points)</span><br><span class="line">np.unique(tri.simplices.ravel())</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>请注意，重复的点#4不会作为三角剖分的顶点出现。这件事已被记录在案：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tri.coplanar</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">0</span>, <span class="number">3</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这意味着点4位于三角形0和顶点3附近，但不包括在三角剖分中。</p>
<p>请注意，这种退化不仅可能是因为重复的点，也可能是由于更复杂的几何原因，即使在乍看起来表现良好的点集中也是如此。</p>
<p>但是，Qhull具有“qj”选项，该选项指示它随机扰乱输入数据，直到解决退化问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tri = Delaunay(points, qhull_options=<span class="string">&quot;QJ Pp&quot;</span>)</span><br><span class="line">points[tri.simplices]</span><br><span class="line">array([[[<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]]])</span><br></pre></td></tr></table></figure>

<p>出现了两个新的三角形。然而，我们看到它们是退化的，面积为零。</p>
<h3 id="凸包"><a href="#凸包" class="headerlink" title="凸包"></a>凸包</h3><p>凸包是包含给定点集中所有点的最小凸对象。</p>
<p>这些值可以通过中的qhull包装器进行计算。 scipy.spatial 具体如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> ConvexHull</span><br><span class="line">rng = np.random.default_rng()</span><br><span class="line">points = rng.random((<span class="number">30</span>, <span class="number">2</span>))   <span class="comment"># 30 random points in 2-D</span></span><br><span class="line">hull = ConvexHull(points)</span><br></pre></td></tr></table></figure>

<p>凸包被表示为一组N个1-D简化，在2-D中表示线段。存储方案与上面讨论的Delaunay三角剖分中的简化完全相同。</p>
<p>我们可以举例说明上述结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> simplex <span class="keyword">in</span> hull.simplices:</span><br><span class="line">    plt.plot(points[simplex,<span class="number">0</span>], points[simplex,<span class="number">1</span>], <span class="string">&#x27;k-&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-2.png" width="60%" alt="" align=center />

<p>同样的情况也可以通过以下方式实现 <code>scipy.spatial.convex_hull_plot_2d</code>。</p>
<h3 id="Voronoi图"><a href="#Voronoi图" class="headerlink" title="Voronoi图"></a>Voronoi图</h3><p>Voronoi图是将空间细分为一组给定点的最近邻域。</p>
<p>使用以下两种方法可以接近此对象scipy.spatial 。首先，可以使用 KDTree 要回答“哪个点最接近这个点”的问题，并这样定义区域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> KDTree</span><br><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                   [<span class="number">2</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">tree = KDTree(points)</span><br><span class="line">tree.query([<span class="number">0.1</span>, <span class="number">0.1</span>])</span><br><span class="line">(<span class="number">0.14142135623730953</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>所以重点是 (0.1, 0.1) 属于区域 0 。在颜色方面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(-<span class="number">0.5</span>, <span class="number">2.5</span>, <span class="number">31</span>)</span><br><span class="line">y = np.linspace(-<span class="number">0.5</span>, <span class="number">2.5</span>, <span class="number">33</span>)</span><br><span class="line">xx, yy = np.meshgrid(x, y)</span><br><span class="line">xy = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dx_half, dy_half = np.diff(x[:<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span>, np.diff(y[:<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">x_edges = np.concatenate((x - dx_half, [x[-<span class="number">1</span>] + dx_half]))</span><br><span class="line">y_edges = np.concatenate((y - dy_half, [y[-<span class="number">1</span>] + dy_half]))</span><br><span class="line">plt.pcolormesh(x_edges, y_edges, tree.query(xy)[<span class="number">1</span>].reshape(<span class="number">33</span>, <span class="number">31</span>), shading=<span class="string">&#x27;flat&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;ko&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-3_00_00.png" width="60%" alt="" align=center />

<p>然而，这并没有给出作为几何对象的Voronoi图。</p>
<p>线和点的表示可以通过中的qhull包装器再次获得 scipy.spatial：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> Voronoi</span><br><span class="line">vor = Voronoi(points)</span><br><span class="line">vor.vertices</span><br><span class="line">array([[<span class="number">0.5</span>, <span class="number">0.5</span>],</span><br><span class="line">       [<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">       [<span class="number">1.5</span>, <span class="number">0.5</span>],</span><br><span class="line">       [<span class="number">1.5</span>, <span class="number">1.5</span>]])</span><br></pre></td></tr></table></figure>

<p>Voronoi顶点表示形成Voronoi区域的多边形边的点集。在本例中，有9个不同的区域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.regions</span><br><span class="line">[[], [-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>], [<span class="number">3</span>, -<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>, <span class="number">0</span>], [<span class="number">3</span>, -<span class="number">1</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>

<p>负值 -1 再次表示无穷远处的一个点。事实上，只有一个地区， [0, 1, 3, 2]，是有界的。请注意，由于与上面的Delaunay三角剖分中类似的数值精度问题，Voronoi区域可能比输入点少。</p>
<p>将分隔区域的脊（二维中的线）描述为与凸面壳片类似的简化集合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.ridge_vertices</span><br><span class="line">[[-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">0</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure>

<p>这些数字表示组成线段的Voronoi顶点的索引。 -1 又是一个无穷远的点-12条直线中只有4条是有界线段，而其他的延伸到无穷远。</p>
<p>Voronoi山脊垂直于输入点之间绘制的线。还记录了每个脊对应的两个点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.ridge_points</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">3</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这些信息加在一起，足以构成完整的图表。</p>
<p>我们可以把它画成如下图。首先，点和Voronoi顶点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.plot(points[:, <span class="number">0</span>], points[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(vor.vertices[:, <span class="number">0</span>], vor.vertices[:, <span class="number">1</span>], <span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">3</span>); plt.ylim(-<span class="number">1</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>绘制有限线段与绘制凸壳一样，但现在我们必须注意无限边：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> simplex <span class="keyword">in</span> vor.ridge_vertices:</span><br><span class="line">    simplex = np.asarray(simplex)</span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">all</span>(simplex &gt;= <span class="number">0</span>):</span><br><span class="line">        plt.plot(vor.vertices[simplex, <span class="number">0</span>], vor.vertices[simplex, <span class="number">1</span>], <span class="string">&#x27;k-&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>延伸到无穷远的山脊需要稍微小心一点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">center = points.mean(axis=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> pointidx, simplex <span class="keyword">in</span> <span class="built_in">zip</span>(vor.ridge_points, vor.ridge_vertices):</span><br><span class="line">    simplex = np.asarray(simplex)</span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">any</span>(simplex &lt; <span class="number">0</span>):</span><br><span class="line">        i = simplex[simplex &gt;= <span class="number">0</span>][<span class="number">0</span>] <span class="comment"># finite end Voronoi vertex</span></span><br><span class="line">        t = points[pointidx[<span class="number">1</span>]] - points[pointidx[<span class="number">0</span>]]  <span class="comment"># tangent</span></span><br><span class="line">        t = t / np.linalg.norm(t)</span><br><span class="line">        n = np.array([-t[<span class="number">1</span>], t[<span class="number">0</span>]]) <span class="comment"># normal</span></span><br><span class="line">        midpoint = points[pointidx].mean(axis=<span class="number">0</span>)</span><br><span class="line">        far_point = vor.vertices[i] + np.sign(np.dot(midpoint - center, n)) * n * <span class="number">100</span></span><br><span class="line">        plt.plot([vor.vertices[i,<span class="number">0</span>], far_point[<span class="number">0</span>]],</span><br><span class="line">                 [vor.vertices[i,<span class="number">1</span>], far_point[<span class="number">1</span>]], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-3_01_00.png" width="60%" alt="" align=center />

<p>也可以使用以下命令创建此图 <code>scipy.spatial.voronoi_plot_2d</code> 。</p>
<p>Vornoi图可以用来创作有趣的创作艺术。尝试使用此设置 mandala 函数来创建您自己的！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> spatial</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mandala</span>(<span class="params">n_iter, n_points, radius</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates a mandala figure using Voronoi tesselations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Number of iterations, i.e. how many times the equidistant points will</span></span><br><span class="line"><span class="string">        be generated.</span></span><br><span class="line"><span class="string">    n_points : int</span></span><br><span class="line"><span class="string">        Number of points to draw per iteration.</span></span><br><span class="line"><span class="string">    radius : scalar</span></span><br><span class="line"><span class="string">        The radial expansion factor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    fig : matplotlib.Figure instance</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    This code is adapted from the work of Audrey Roy Greenfeld [1]_ and Carlos</span></span><br><span class="line"><span class="string">    Focil-Espinosa [2]_, who created beautiful mandalas with Python code.  That</span></span><br><span class="line"><span class="string">    code in turn was based on Antonio Sánchez Chinchón&#x27;s R code [3]_.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    References</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    .. [1] https://www.codemakesmehappy.com/2019/09/voronoi-mandalas.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. [2] https://github.com/CarlosFocil/mandalapy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. [3] https://github.com/aschinchon/mandalas</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.set_axis_off()</span><br><span class="line">    ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>, adjustable=<span class="string">&#x27;box&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    angles = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi * (<span class="number">1</span> - <span class="number">1</span>/n_points), num=n_points) + np.pi/<span class="number">2</span></span><br><span class="line">    <span class="comment"># Starting from a single center point, add points iteratively</span></span><br><span class="line">    xy = np.array([[<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_iter):</span><br><span class="line">        t1 = np.array([])</span><br><span class="line">        t2 = np.array([])</span><br><span class="line">        <span class="comment"># Add `n_points` new points around each existing point in this iteration</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(xy.shape[<span class="number">0</span>]):</span><br><span class="line">            t1 = np.append(t1, xy[i, <span class="number">0</span>] + radius**k * np.cos(angles))</span><br><span class="line">            t2 = np.append(t2, xy[i, <span class="number">1</span>] + radius**k * np.sin(angles))</span><br><span class="line"></span><br><span class="line">        xy = np.column_stack((t1, t2))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the Mandala figure via a Voronoi plot</span></span><br><span class="line">    spatial.voronoi_plot_2d(spatial.Voronoi(xy), ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"><span class="comment"># Modify the following parameters in order to get different figures</span></span><br><span class="line">n_iter = <span class="number">3</span></span><br><span class="line">n_points = <span class="number">6</span></span><br><span class="line">radius = <span class="number">4</span></span><br><span class="line">fig = mandala(n_iter, n_points, radius)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-4.png" width="60%" alt="" align=center />]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 06：NumPy 数据分析进阶</title>
    <url>/PythonLes07/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程是第六周课程的延续，让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="将数组转换为平面一维数组"><a href="#将数组转换为平面一维数组" class="headerlink" title="将数组转换为平面一维数组"></a>将数组转换为平面一维数组</h2><p>问题：将array_of_arrays转换为扁平线性1d数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = np.arange(<span class="number">3</span>)</span><br><span class="line">arr2 = np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">arr3 = np.arange(<span class="number">7</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">array_of_arrays = np.array([arr1, arr2, arr3])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array_of_arrays: &#x27;</span>, array_of_arrays)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">arr_2d = np.array([a <span class="keyword">for</span> arr <span class="keyword">in</span> array_of_arrays <span class="keyword">for</span> a <span class="keyword">in</span> arr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">arr_2d = np.concatenate(array_of_arrays)</span><br><span class="line"><span class="built_in">print</span>(arr_2d)</span><br><span class="line"><span class="comment"># &gt; array_of_arrays:  [array([0, 1, 2]) array([3, 4, 5, 6]) array([7, 8, 9])]</span></span><br><span class="line"><span class="comment"># &gt; [0 1 2 3 4 5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.concatenate()</code>函数，沿现有轴连接数组序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.concatenate((a1, a2, ...), axis=<span class="number">0</span>, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, casting=<span class="string">&quot;same_kind&quot;</span>)</span><br><span class="line"><span class="comment"># Join a sequence of arrays along an existing axis.</span></span><br></pre></td></tr></table></figure>

<p>参数:</p>
<ul>
<li>a1, a2,…: array_like数组序列，必须具有相同的形状，除了待拼接轴对应的维度（默认是第一个维度）。</li>
<li>axis: int, 可选项，数组将沿其连接的轴。如果axis为None，则数组在使用前被平面化。默认为0。</li>
<li>out: ndarray, 可选项，如果提供，则为输出存储的位置。形状必须是正确的，与未指定out参数时concatenate返回的形状相匹配。如果提供，目标数组将具有此</li>
<li>dtype: str or dtype, 可选项，不能和out一起提供。</li>
<li>cast: {‘no’,’equiv’,’safe’,’same_kind’,’unsafe’}, 可选项，控制可能发生的数据强制转换类型。默认为’same_kind’。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = np.array([[<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b), axis=<span class="number">0</span>)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b.T), axis=<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b), axis=<span class="literal">None</span>)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure>


<h2 id="如何在NumPy中为数组生成单热编码？"><a href="#如何在NumPy中为数组生成单热编码？" class="headerlink" title="如何在NumPy中为数组生成单热编码？"></a>如何在NumPy中为数组生成单热编码？</h2><p>在机器学习算法中，我们经常会遇到分类特征，例如：人的性别有男女，祖国有中国，美国，法国等。这些特征值并不是连续的，而是离散的，无序的。通常我们需要对其进行特征数字化。One-Hot编码，又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。</p>
<p>为什么使用单热编码：在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。</p>
<p>计算一次性编码（数组中每个唯一值的虚拟二进制变量）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">np.random.seed(<span class="number">101</span>) </span><br><span class="line">arr = np.random.randint(<span class="number">1</span>,<span class="number">4</span>, size=<span class="number">6</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([2, 3, 2, 2, 2, 1])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输出：</span></span><br><span class="line"><span class="comment"># &gt; array([[ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 1.,  0.,  0.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encodings</span>(<span class="params">arr</span>):</span><br><span class="line">    uniqs = np.unique(arr)</span><br><span class="line">    out = np.zeros((arr.shape[<span class="number">0</span>], uniqs.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(arr):</span><br><span class="line">        out[i, k-<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">one_hot_encodings(arr)</span><br><span class="line"><span class="comment"># &gt; array([[ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 1.,  0.,  0.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">(arr[:, <span class="literal">None</span>] == np.unique(arr)).view(np.int8)</span><br></pre></td></tr></table></figure>

<h2 id="如何创建按分类变量分组的序号？"><a href="#如何创建按分类变量分组的序号？" class="headerlink" title="如何创建按分类变量分组的序号？"></a>如何创建按分类变量分组的序号？</h2><p>创建按分类变量分组的序号。使用以下来自鸢尾属植物物种的样本作为输入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">species = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;str&#x27;</span>, usecols=<span class="number">4</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">species_small = np.sort(np.random.choice(species, size=<span class="number">20</span>))</span><br><span class="line">species_small</span><br><span class="line"><span class="comment"># &gt; array([&#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-setosa&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;&lt;U15&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>([i <span class="keyword">for</span> val <span class="keyword">in</span> np.unique(species_small) <span class="keyword">for</span> i, grp <span class="keyword">in</span> <span class="built_in">enumerate</span>(species_small[species_small==val])])</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<h2 id="如何根据给定的分类变量创建组ID？"><a href="#如何根据给定的分类变量创建组ID？" class="headerlink" title="如何根据给定的分类变量创建组ID？"></a>如何根据给定的分类变量创建组ID？</h2><p>根据给定的分类变量创建组ID。使用以下来自鸢尾属植物物种的样本作为输入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">species = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;str&#x27;</span>, usecols=<span class="number">4</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">species_small = np.sort(np.random.choice(species, size=<span class="number">20</span>))</span><br><span class="line">species_small</span><br><span class="line"><span class="comment"># &gt; array([&#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-setosa&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;&lt;U15&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">output = [np.argwhere(np.unique(species_small) == s).tolist()[<span class="number">0</span>][<span class="number">0</span>] <span class="keyword">for</span> val <span class="keyword">in</span> np.unique(species_small) <span class="keyword">for</span> s <span class="keyword">in</span> species_small[species_small==val]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: For Loop version</span></span><br><span class="line">output = []</span><br><span class="line">uniqs = np.unique(species_small)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> uniqs:  <span class="comment"># uniq values in group</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> species_small[species_small==val]:  <span class="comment"># each element in group</span></span><br><span class="line">        groupid = np.argwhere(uniqs == s).tolist()[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># groupid</span></span><br><span class="line">        output.append(groupid)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># &gt; [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]</span></span><br></pre></td></tr></table></figure>

<h2 id="使用NumPy获取数组中各项排名？"><a href="#使用NumPy获取数组中各项排名？" class="headerlink" title="使用NumPy获取数组中各项排名？"></a>使用NumPy获取数组中各项排名？</h2><p>为给定的数组a创建排名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">a = np.random.randint(<span class="number">20</span>, size=<span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([ 9,  4, 15,  0, 17, 16, 17,  8,  9,  0])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">a.argsort()</span><br><span class="line"><span class="comment"># array([3, 9, 1, 7, 0, 8, 2, 5, 4, 6], dtype=int64)</span></span><br><span class="line"></span><br><span class="line">a.argsort().argsort()</span><br><span class="line"><span class="comment"># array([4, 2, 6, 0, 8, 7, 9, 3, 5, 1], dtype=int64)</span></span><br></pre></td></tr></table></figure>

<h2 id="如何使用NumPy对多维数组中的项进行排名？"><a href="#如何使用NumPy对多维数组中的项进行排名？" class="headerlink" title="如何使用NumPy对多维数组中的项进行排名？"></a>如何使用NumPy对多维数组中的项进行排名？</h2><p>创建与给定数字数组a相同形状的排名数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">a = np.random.randint(<span class="number">20</span>, size=[<span class="number">2</span>,<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># &gt; [[ 9  4 15  0 17]</span></span><br><span class="line"><span class="comment"># &gt;  [16 17  8  9  0]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(a.ravel().argsort().argsort().reshape(a.shape))</span><br><span class="line"><span class="comment"># &gt; [[4 2 6 0 8]</span></span><br><span class="line"><span class="comment"># &gt;  [7 9 3 5 1]]</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.ravel()</code>返回一个连续的扁平数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.ravel(a, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Return a contiguous flattened array. A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.</span></span><br></pre></td></tr></table></figure>

<h2 id="如何在二维NumPy数组的每一行中找到最大值？"><a href="#如何在二维NumPy数组的每一行中找到最大值？" class="headerlink" title="如何在二维NumPy数组的每一行中找到最大值？"></a>如何在二维NumPy数组的每一行中找到最大值？</h2><p>问题：计算给定数组中每行的最大值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">10</span>, [<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([[9, 9, 4],</span></span><br><span class="line"><span class="comment">#        [8, 8, 1],</span></span><br><span class="line"><span class="comment">#        [5, 3, 6],</span></span><br><span class="line"><span class="comment">#        [3, 3, 3],</span></span><br><span class="line"><span class="comment">#        [2, 1, 9]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.amax(a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># np.amax 函数就是 np.max 函数，历史遗留问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line">np.apply_along_axis(np.<span class="built_in">max</span>, arr=a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt; array([9, 8, 6, 3, 9])</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.apply_along_axis()</code>表示沿给定轴向对一维切片应用函数 func1d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numpy.apply_along_axis</span></span><br><span class="line">numpy.apply_along_axis(func1d, axis, arr, *args, **kwargs)</span><br><span class="line"><span class="comment"># Apply a function to 1-D slices along the given axis.</span></span><br></pre></td></tr></table></figure>


<h2 id="如何计算二维NumPy数组每行的最小值与最大值的比值？"><a href="#如何计算二维NumPy数组每行的最小值与最大值的比值？" class="headerlink" title="如何计算二维NumPy数组每行的最小值与最大值的比值？"></a>如何计算二维NumPy数组每行的最小值与最大值的比值？</h2><p>为给定的二维NumPy数组计算每行的最小值与最大值的比值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">10</span>, [<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([[9, 9, 4],</span></span><br><span class="line"><span class="comment">#        [8, 8, 1],</span></span><br><span class="line"><span class="comment">#        [5, 3, 6],</span></span><br><span class="line"><span class="comment">#        [3, 3, 3],</span></span><br><span class="line"><span class="comment">#        [2, 1, 9]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.apply_along_axis(<span class="keyword">lambda</span> x: np.<span class="built_in">min</span>(x)/np.<span class="built_in">max</span>(x), arr=a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([0.44444444, 0.125     , 0.5       , 1.        , 0.11111111])</span></span><br><span class="line"></span><br><span class="line">np.apply_along_axis(<span class="keyword">lambda</span> x: np.<span class="built_in">min</span>(x)/np.<span class="built_in">max</span>(x), arr=a, axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># array([0.22222222, 0.11111111, 0.11111111])</span></span><br></pre></td></tr></table></figure>

<h2 id="如何在NumPy数组中找到重复的记录？"><a href="#如何在NumPy数组中找到重复的记录？" class="headerlink" title="如何在NumPy数组中找到重复的记录？"></a>如何在NumPy数组中找到重复的记录？</h2><p>在给定的NumPy数组中找到重复的条目(第二次出现以后)，并将它们标记为True。第一次出现应该是False的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([0, 0, 3, 0, 2, 4, 2, 2, 2, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Solution</span></span><br><span class="line"><span class="comment"># There is no direct function to do this as of 1.13.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an all True array</span></span><br><span class="line">out = np.full(a.shape[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the index positions of unique elements</span></span><br><span class="line">unique_positions = np.unique(a, return_index=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mark those positions as False</span></span><br><span class="line">out[unique_positions] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment"># &gt; [False  True False  True False False  True  True  True  True]</span></span><br></pre></td></tr></table></figure>

<h2 id="如何找出数字的分组均值？"><a href="#如何找出数字的分组均值？" class="headerlink" title="如何找出数字的分组均值？"></a>如何找出数字的分组均值？</h2><p>在二维数字数组中查找按分类列分组的数值列的平均值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 理想的输出：</span></span><br><span class="line"><span class="comment"># &gt; [[b&#x27;Iris-setosa&#x27;, 3.418],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-versicolor&#x27;, 2.770],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-virginica&#x27;, 2.974]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct way to implement this. Just a version of a workaround.</span></span><br><span class="line">numeric_column = iris[:,<span class="number">1</span>].astype(<span class="string">&#x27;float&#x27;</span>)  <span class="comment"># sepalwidth</span></span><br><span class="line">grouping_column = iris[:,<span class="number">4</span>]  <span class="comment"># species</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List comprehension version</span></span><br><span class="line">[[group_val, numeric_column[grouping_column==group_val].mean()] <span class="keyword">for</span> group_val <span class="keyword">in</span> np.unique(grouping_column)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># For Loop version</span></span><br><span class="line">output = []</span><br><span class="line"><span class="keyword">for</span> group_val <span class="keyword">in</span> np.unique(grouping_column):</span><br><span class="line">    output.append([group_val, numeric_column[grouping_column==group_val].mean()])</span><br><span class="line"></span><br><span class="line">output</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;Iris-setosa&#x27;, 3.418],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-versicolor&#x27;, 2.770],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-virginica&#x27;, 2.974]]</span></span><br></pre></td></tr></table></figure>

<h2 id="如何将PIL图像转换为NumPy数组？"><a href="#如何将PIL图像转换为NumPy数组？" class="headerlink" title="如何将PIL图像转换为NumPy数组？"></a>如何将PIL图像转换为NumPy数组？</h2><p>从以下URL导入图像并将其转换为numpy数组。<br>URL &#x3D; ‘<a href="https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg">https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg</a>‘</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> PIL, requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import image from URL</span></span><br><span class="line">URL = <span class="string">&#x27;https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg&#x27;</span></span><br><span class="line">response = requests.get(URL)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read it as Image</span></span><br><span class="line">I = Image.<span class="built_in">open</span>(BytesIO(response.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionally resize</span></span><br><span class="line">I = I.resize([<span class="number">150</span>,<span class="number">150</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to numpy array</span></span><br><span class="line">arr = np.asarray(I)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionaly Convert it back to an image and show</span></span><br><span class="line">im = PIL.Image.fromarray(np.uint8(arr))</span><br><span class="line">Image.Image.show(im)</span><br></pre></td></tr></table></figure>

<h2 id="删除NumPy数组中所有NaN值"><a href="#删除NumPy数组中所有NaN值" class="headerlink" title="删除NumPy数组中所有NaN值"></a>删除NumPy数组中所有NaN值</h2><p>从一维NumPy数组中删除所有NaN值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,np.nan,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,np.nan])</span><br><span class="line">a[~np.isnan(a)]</span><br><span class="line"><span class="comment"># &gt; array([ 1.,  2.,  3.,  5.,  6.,  7.])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算两个数组之间的欧氏距离"><a href="#计算两个数组之间的欧氏距离" class="headerlink" title="计算两个数组之间的欧氏距离"></a>计算两个数组之间的欧氏距离</h2><p>计算两个数组a和数组b之间的欧氏距离。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">dist = np.linalg.norm(a-b)</span><br><span class="line">dist</span><br><span class="line"><span class="comment"># &gt; 6.7082039324993694</span></span><br></pre></td></tr></table></figure>

<h2 id="在一维数组中找到所有的局部极大值-或峰值-？"><a href="#在一维数组中找到所有的局部极大值-或峰值-？" class="headerlink" title="在一维数组中找到所有的局部极大值(或峰值)？"></a>在一维数组中找到所有的局部极大值(或峰值)？</h2><p>找到一个一维数字数组a中的所有峰值。峰顶是两边被较小数值包围的点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">doublediff = np.diff(np.sign(np.diff(a)))</span><br><span class="line">peak_locations = np.where(doublediff == -<span class="number">2</span>)[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">peak_locations</span><br><span class="line"><span class="comment"># &gt; array([2, 5])</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.diff()</code>函数计算计算沿给定轴的n-th离散差分。</p>
<p>The <code>numpy.sign</code> function returns -1 if x &lt; 0, 0 if x&#x3D;&#x3D;0, 1 if x &gt; 0.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.diff(a, n=<span class="number">1</span>, axis=-<span class="number">1</span>, prepend=&lt;no value&gt;, append=&lt;no value&gt;)[source]</span><br><span class="line"><span class="comment"># Calculate the n-th discrete difference along the given axis.</span></span><br></pre></td></tr></table></figure>

<p>参数说明:</p>
<ul>
<li>a: array_like, 输入数组；</li>
<li>n: int, 可选项，值差的次数。默认值为1，如果为零，则按原样返回输入。</li>
<li>axis: int, 可选项，计算差值的轴，默认是最后一个轴。</li>
<li>diff: ndarray, n-th差值。输出的形状与a相同，除了沿轴的尺寸小n。输出的类型与a的任意两个元素之间的差的类型相同。在大多数情况下，这与a的类型相同。一个值得注意的例外是datetime64，它产生一个timedelta64输出数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">0</span>])</span><br><span class="line">np.diff(x)</span><br><span class="line">array([ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, -<span class="number">7</span>])</span><br><span class="line">np.diff(x, n=<span class="number">2</span>)</span><br><span class="line">array([  <span class="number">1</span>,   <span class="number">1</span>, -<span class="number">10</span>])</span><br><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">10</span>], [<span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>]])</span><br><span class="line">np.diff(x)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line">np.diff(x, axis=<span class="number">0</span>)</span><br><span class="line">array([[-<span class="number">1</span>,  <span class="number">2</span>,  <span class="number">0</span>, -<span class="number">2</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去"><a href="#从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去" class="headerlink" title="从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去"></a>从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去</h2><p>从2d数组a_2d中减去一维数组b_1D，使得b_1D的每一项从a_2d的相应行中减去。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">a_2d = np.array([[<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>]])</span><br><span class="line">b_1d = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(a_2d - b_1d[:,<span class="literal">None</span>])</span><br><span class="line"><span class="comment"># &gt; [[2 2 2]</span></span><br><span class="line"><span class="comment"># &gt;  [2 2 2]</span></span><br><span class="line"><span class="comment"># &gt;  [2 2 2]]</span></span><br></pre></td></tr></table></figure>

<h2 id="查找数组中项的第n次重复索引"><a href="#查找数组中项的第n次重复索引" class="headerlink" title="查找数组中项的第n次重复索引"></a>查找数组中项的第n次重复索引</h2><p>找出x中数字1的第5次重复的索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">n = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1: List comprehension</span></span><br><span class="line">[i <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(x) <span class="keyword">if</span> v == <span class="number">1</span>][n-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2: Numpy version</span></span><br><span class="line">np.where(x == <span class="number">1</span>)[<span class="number">0</span>][n-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; 8</span></span><br></pre></td></tr></table></figure>

<h1 id="将NumPy的datetime-64对象转换为datetime的datetime对象？"><a href="#将NumPy的datetime-64对象转换为datetime的datetime对象？" class="headerlink" title="将NumPy的datetime 64对象转换为datetime的datetime对象？"></a>将NumPy的datetime 64对象转换为datetime的datetime对象？</h1><p>问题：将NumPy的datetime64对象转换为datetime的datetime对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：** a numpy datetime64 object</span></span><br><span class="line">dt64 = np.datetime64(<span class="string">&#x27;2018-02-25 22:10:10&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">dt64.tolist()</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">dt64.astype(datetime)</span><br><span class="line"><span class="comment"># &gt; datetime.datetime(2018, 2, 25, 22, 10, 10)</span></span><br></pre></td></tr></table></figure>

<h2 id="计算NumPy数组的移动平均值"><a href="#计算NumPy数组的移动平均值" class="headerlink" title="计算NumPy数组的移动平均值"></a>计算NumPy数组的移动平均值</h2><p>对于给定的一维数组，计算窗口大小为3的移动平均值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">Z = np.random.randint(<span class="number">10</span>, size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Source: https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moving_average</span>(<span class="params">a, n=<span class="number">3</span></span>) :</span><br><span class="line">    ret = np.cumsum(a, dtype=<span class="built_in">float</span>)</span><br><span class="line">    ret[n:] = ret[n:] - ret[:-n]</span><br><span class="line">    <span class="keyword">return</span> ret[n - <span class="number">1</span>:] / n</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array: &#x27;</span>, Z)</span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">moving_average(Z, n=<span class="number">3</span>).<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:  # Thanks AlanLRH!</span></span><br><span class="line"><span class="comment"># np.ones(3)/3 gives equal weights. Use np.ones(4)/4 for window size 4.</span></span><br><span class="line">np.convolve(Z, np.ones(<span class="number">3</span>)/<span class="number">3</span>, mode=<span class="string">&#x27;valid&#x27;</span>) . </span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; array:  [8 8 3 7 7 0 4 2 5 2]</span></span><br><span class="line"><span class="comment"># &gt; moving average:  [ 6.33  6.    5.67  4.67  3.67  2.    3.67  3.  ]</span></span><br></pre></td></tr></table></figure>

<h2 id="在给定起始点、长度和步骤的情况下创建一个NumPy数组序列"><a href="#在给定起始点、长度和步骤的情况下创建一个NumPy数组序列" class="headerlink" title="在给定起始点、长度和步骤的情况下创建一个NumPy数组序列"></a>在给定起始点、长度和步骤的情况下创建一个NumPy数组序列</h2><p>创建长度为10的NumPy数组，从5开始，在连续的数字之间的步长为3。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">length = <span class="number">10</span></span><br><span class="line">start = <span class="number">5</span></span><br><span class="line">step = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seq</span>(<span class="params">start, length, step</span>):</span><br><span class="line">    end = start + (step*length)</span><br><span class="line">    <span class="keyword">return</span> np.arange(start, end, step)</span><br><span class="line"></span><br><span class="line">seq(start, length, step)</span><br><span class="line"><span class="comment"># &gt; array([ 5,  8, 11, 14, 17, 20, 23, 26, 29, 32])</span></span><br></pre></td></tr></table></figure>

<h2 id="填写不规则系列的NumPy日期中的缺失日期"><a href="#填写不规则系列的NumPy日期中的缺失日期" class="headerlink" title="填写不规则系列的NumPy日期中的缺失日期"></a>填写不规则系列的NumPy日期中的缺失日期</h2><p>给定一系列不连续的日期序列。填写缺失的日期，使其成为连续的日期序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">dates = np.arange(np.datetime64(<span class="string">&#x27;2018-02-01&#x27;</span>), np.datetime64(<span class="string">&#x27;2018-02-25&#x27;</span>), <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(dates)</span><br><span class="line"><span class="comment"># &gt; [&#x27;2018-02-01&#x27; &#x27;2018-02-03&#x27; &#x27;2018-02-05&#x27; &#x27;2018-02-07&#x27; &#x27;2018-02-09&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-11&#x27; &#x27;2018-02-13&#x27; &#x27;2018-02-15&#x27; &#x27;2018-02-17&#x27; &#x27;2018-02-19&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-21&#x27; &#x27;2018-02-23&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution ---------------</span></span><br><span class="line">filled_in = np.array([np.arange(date, (date+d)) <span class="keyword">for</span> date, d <span class="keyword">in</span> <span class="built_in">zip</span>(dates, np.diff(dates))]).reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the last day</span></span><br><span class="line">output = np.hstack([filled_in, dates[-<span class="number">1</span>]])</span><br><span class="line">output</span><br><span class="line"></span><br><span class="line"><span class="comment"># For loop version -------</span></span><br><span class="line">out = []</span><br><span class="line"><span class="keyword">for</span> date, d <span class="keyword">in</span> <span class="built_in">zip</span>(dates, np.diff(dates)):</span><br><span class="line">    out.append(np.arange(date, (date+d)))</span><br><span class="line"></span><br><span class="line">filled_in = np.array(out).reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the last day</span></span><br><span class="line">output = np.hstack([filled_in, dates[-<span class="number">1</span>]])</span><br><span class="line">output</span><br><span class="line"><span class="comment"># &gt; [&#x27;2018-02-01&#x27; &#x27;2018-02-03&#x27; &#x27;2018-02-05&#x27; &#x27;2018-02-07&#x27; &#x27;2018-02-09&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-11&#x27; &#x27;2018-02-13&#x27; &#x27;2018-02-15&#x27; &#x27;2018-02-17&#x27; &#x27;2018-02-19&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-21&#x27; &#x27;2018-02-23&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; array([&#x27;2018-02-01&#x27;, &#x27;2018-02-02&#x27;, &#x27;2018-02-03&#x27;, &#x27;2018-02-04&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-05&#x27;, &#x27;2018-02-06&#x27;, &#x27;2018-02-07&#x27;, &#x27;2018-02-08&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-09&#x27;, &#x27;2018-02-10&#x27;, &#x27;2018-02-11&#x27;, &#x27;2018-02-12&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-13&#x27;, &#x27;2018-02-14&#x27;, &#x27;2018-02-15&#x27;, &#x27;2018-02-16&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-17&#x27;, &#x27;2018-02-18&#x27;, &#x27;2018-02-19&#x27;, &#x27;2018-02-20&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-21&#x27;, &#x27;2018-02-22&#x27;, &#x27;2018-02-23&#x27;], dtype=&#x27;datetime64[D]&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="从给定的一维数组创建步长"><a href="#从给定的一维数组创建步长" class="headerlink" title="从给定的一维数组创建步长"></a>从给定的一维数组创建步长</h2><p>从给定的一维数组arr中，利用步进生成一个二维矩阵，窗口长度为4，步距为2，类似于 [[0,1,2,3], [2,3,4,5], [4,5,6,7]..]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">15</span>) </span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_strides</span>(<span class="params">a, stride_len=<span class="number">5</span>, window_len=<span class="number">5</span></span>):</span><br><span class="line">    n_strides = ((a.size-window_len)//stride_len) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])</span></span><br><span class="line">    <span class="keyword">return</span> np.array([a[s:(s+window_len)] <span class="keyword">for</span> s <span class="keyword">in</span> np.arange(<span class="number">0</span>, n_strides*stride_len, stride_len)])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(gen_strides(np.arange(<span class="number">15</span>), stride_len=<span class="number">2</span>, window_len=<span class="number">4</span>))</span><br><span class="line"><span class="comment"># &gt; [[ 0  1  2  3]</span></span><br><span class="line"><span class="comment"># &gt;  [ 2  3  4  5]</span></span><br><span class="line"><span class="comment"># &gt;  [ 4  5  6  7]</span></span><br><span class="line"><span class="comment"># &gt;  [ 6  7  8  9]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8  9 10 11]</span></span><br><span class="line"><span class="comment"># &gt;  [10 11 12 13]]</span></span><br></pre></td></tr></table></figure>





















<h2 id="本章总结"><a href="#本章总结" class="headerlink" title="本章总结"></a>本章总结</h2><h3 id="数组属性"><a href="#数组属性" class="headerlink" title="数组属性"></a>数组属性</h3><p>在使用NumPy时，你会想知道数组的某些信息。很幸运，NumPy包里边包含了很多便捷的方法，可以给你想要的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Array properties</span></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a)) <span class="comment"># &gt;&gt;&gt;&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(a.dtype) <span class="comment"># &gt;&gt;&gt;int64</span></span><br><span class="line"><span class="built_in">print</span>(a.size) <span class="comment"># &gt;&gt;&gt;25</span></span><br><span class="line"><span class="built_in">print</span>(a.shape) <span class="comment"># &gt;&gt;&gt;(5, 5)</span></span><br><span class="line"><span class="built_in">print</span>(a.itemsize) <span class="comment"># &gt;&gt;&gt;8</span></span><br><span class="line"><span class="built_in">print</span>(a.ndim) <span class="comment"># &gt;&gt;&gt;2</span></span><br><span class="line"><span class="built_in">print</span>(a.nbytes) <span class="comment"># &gt;&gt;&gt;200</span></span><br></pre></td></tr></table></figure>

<p>正如你在上面的代码中看到的，NumPy数组实际上被称为<code>&#39;numpy.ndarray&#39;</code>。</p>
<ul>
<li><p><code>shape</code>属性是数组有多少行和列，上面的数组有5行和5列，所以它的shape是(5, 5)。</p>
</li>
<li><p><code>itemsize</code>属性是每个项占用的字节（Byte）数。这个数组的数据类型是<code>int64</code>，一个<code>int64</code>中有64 bit，1 byte &#x3D; 8 bit，即为8 byte。</p>
</li>
<li><p><code>ndim</code>属性是数组的维数，在本例中为2。</p>
</li>
<li><p><code>nbytes</code>属性是数组中的所有数据消耗掉的字节数。这并不计算数组信息定义开销，因此数组占用的实际内存空间将稍微大一点。</p>
</li>
</ul>
<h3 id="数组索引"><a href="#数组索引" class="headerlink" title="数组索引"></a>数组索引</h3><p>NumPy提供了几种索引数组的方法，包括单元素索引，切片索引，整数数组索引，布尔数组索引等等。</p>
<h4 id="单元素索引"><a href="#单元素索引" class="headerlink" title="单元素索引"></a>单元素索引</h4><p>人们期望的是1-D数组的单元素索引。它的工作方式与其他标准Python序列完全相同。它从0开始计数，并接受从数组末尾开始索引的负索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">2</span>]</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>

<h4 id="切片索引（Slicing）"><a href="#切片索引（Slicing）" class="headerlink" title="切片索引（Slicing）"></a>切片索引（Slicing）</h4><p>与Python列表类似，可以对NumPy数组进行切片。由于数组可能是多维的，因此必须为数组的每个维指定一个切片：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],     <span class="comment"># Create the following rank 2 array with shape (3, 4)</span></span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">b = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]    <span class="comment"># Use slicing to pull out the subarray consisting of the first 2 rows and columns 1 and 2; </span></span><br><span class="line"><span class="built_in">print</span>(b)          <span class="comment"># b is the following array of shape (2, 2):</span></span><br><span class="line">                  <span class="comment"># [[2 3]</span></span><br><span class="line">                  <span class="comment">#  [6 7]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A slice of an array is a view into the same data, so modifying it</span></span><br><span class="line"><span class="comment"># will modify the original array.</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;2&quot;</span></span><br><span class="line">b[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">77</span>     <span class="comment"># b[0, 0] is the same piece of data as a[0, 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;77&quot;</span></span><br></pre></td></tr></table></figure>

<p>你还可以将整数索引与切片索引混合使用。 但是，这样做会产生比原始数组更低级别的数组。 请注意，这与MATLAB处理数组切片的方式完全不同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], </span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two ways of accessing the data in the middle row of the array.</span></span><br><span class="line"><span class="comment"># Mixing integer indexing with slices yields an array of lower rank,</span></span><br><span class="line"><span class="comment"># while using only slices yields an array of the same rank as the</span></span><br><span class="line"><span class="comment"># original array:</span></span><br><span class="line">row_r1 = a[<span class="number">1</span>, :]    <span class="comment"># Rank 1 view of the second row of a</span></span><br><span class="line">row_r2 = a[<span class="number">1</span>:<span class="number">2</span>, :]  <span class="comment"># Rank 2 view of the second row of a</span></span><br><span class="line"><span class="built_in">print</span>(row_r1, row_r1.shape)  <span class="comment"># Prints &quot;[5 6 7 8] (4,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(row_r2, row_r2.shape)  <span class="comment"># Prints &quot;[[5 6 7 8]] (1, 4)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can make the same distinction when accessing columns of an array:</span></span><br><span class="line">col_r1 = a[:, <span class="number">1</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1, col_r1.shape)  <span class="comment"># Prints &quot;[ 2  6 10] (3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(col_r2, col_r2.shape)  <span class="comment"># Prints &quot;[[ 2]</span></span><br><span class="line">                             <span class="comment">#          [ 6]</span></span><br><span class="line">                             <span class="comment">#          [10]] (3, 1)&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="整数数组索引"><a href="#整数数组索引" class="headerlink" title="整数数组索引"></a>整数数组索引</h4><p>使用切片索引到NumPy数组时，生成的数组视图将始终是原始数组的子数组。 相反，整数数组索引允许你使用另一个数组中的数据构造任意数组。 这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># An example of integer array indexing.</span></span><br><span class="line"><span class="comment"># The returned array will have shape (3,) and</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The above example of integer array indexing is equivalent to this:</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">0</span>], a[<span class="number">1</span>, <span class="number">1</span>], a[<span class="number">2</span>, <span class="number">0</span>]]))  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When using integer array indexing, you can reuse the same</span></span><br><span class="line"><span class="comment"># element from the source array:</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Equivalent to the previous integer array indexing example</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">1</span>], a[<span class="number">0</span>, <span class="number">1</span>]]))  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="布尔数组索引"><a href="#布尔数组索引" class="headerlink" title="布尔数组索引"></a>布尔数组索引</h4><p>布尔数组索引允许你选择数组的任意元素。通常，这种类型的索引用于选择满足某些条件的数组元素。下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line">bool_idx = (a &gt; <span class="number">2</span>)   <span class="comment"># Find the elements of a that are bigger than 2;</span></span><br><span class="line">                     <span class="comment"># this returns a numpy array of Booleans of the same</span></span><br><span class="line">                     <span class="comment"># shape as a, where each slot of bool_idx tells</span></span><br><span class="line">                     <span class="comment"># whether that element of a is &gt; 2.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bool_idx)      <span class="comment"># Prints &quot;[[False False]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We use boolean array indexing to construct a rank 1 array</span></span><br><span class="line"><span class="comment"># consisting of the elements of a corresponding to the True values</span></span><br><span class="line"><span class="comment"># of bool_idx</span></span><br><span class="line"><span class="built_in">print</span>(a[bool_idx])  <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can do all of the above in a single concise statement:</span></span><br><span class="line"><span class="built_in">print</span>(a[a &gt; <span class="number">2</span>])     <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="Where-函数"><a href="#Where-函数" class="headerlink" title="Where 函数"></a>Where 函数</h4><p><code>where()</code>函数是一个根据条件返回数组中的值的有效方法。只需要把条件传递给它，它就会返回一个使得条件为真的元素的列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Where</span></span><br><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">b = np.where(a &lt; <span class="number">50</span>) </span><br><span class="line">c = np.where(a &gt;= <span class="number">50</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(b) <span class="comment"># &gt;&gt;&gt;(array([0, 1, 2, 3, 4]),)</span></span><br><span class="line"><span class="built_in">print</span>(c) <span class="comment"># &gt;&gt;&gt;[5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

<h4 id="反转二维数组的列"><a href="#反转二维数组的列" class="headerlink" title="反转二维数组的列"></a>反转二维数组的列</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, ::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; array([[2, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 4, 3],</span></span><br><span class="line"><span class="comment"># &gt;        [8, 7, 6]])</span></span><br></pre></td></tr></table></figure>

<h4 id="交换二维-numpy-数组中的两列"><a href="#交换二维-numpy-数组中的两列" class="headerlink" title="交换二维 numpy 数组中的两列"></a>交换二维 numpy 数组中的两列</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, [<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="comment"># &gt; array([[1, 0, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [4, 3, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [7, 6, 8]])</span></span><br></pre></td></tr></table></figure>


<h4 id="从-1-维元组数组中提取特定列"><a href="#从-1-维元组数组中提取特定列" class="headerlink" title="从 1 维元组数组中提取特定列"></a>从 1 维元组数组中提取特定列</h4><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>


<h3 id="广播-Broadcasting"><a href="#广播-Broadcasting" class="headerlink" title="广播(Broadcasting)"></a>广播(Broadcasting)</h3><p>广播是一种强大的机制，它允许NumPy在执行算术运算时使用不同形状的数组。通常，我们有一个较小的数组和一个较大的数组，我们希望多次使用较小的数组来对较大的数组执行一些操作。</p>
<p>例如，假设我们要向矩阵的每一行添加一个常数向量。我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">vv = np.tile(v, (<span class="number">4</span>, <span class="number">1</span>))   <span class="comment"># Stack 4 copies of v on top of each other</span></span><br><span class="line"><span class="built_in">print</span>(vv)                 <span class="comment"># Prints &quot;[[1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]]&quot;</span></span><br><span class="line">y = x + vv  <span class="comment"># Add x and vv elementwise</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>广播通常会使你的代码更简洁，效率更高，因此你应该尽可能地使用它。</p>
<h3 id="改变数组的形状"><a href="#改变数组的形状" class="headerlink" title="改变数组的形状"></a>改变数组的形状</h3><p>问题：如何将一维数组转换为 2 行的 2 维数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">arr.reshape(<span class="number">2</span>, -<span class="number">1</span>)  <span class="comment"># Setting to -1 automatically decides the number of cols</span></span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">numpy.reshape(a, newshape, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Gives a new shape to an array without changing its data.</span></span><br></pre></td></tr></table></figure>

<h3 id="数组拼接"><a href="#数组拼接" class="headerlink" title="数组拼接"></a>数组拼接</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 垂直叠加两个数组</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.vstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.r_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 水平叠加两个数组</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.hstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.c_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>

<h3 id="随机数产生器"><a href="#随机数产生器" class="headerlink" title="随机数产生器"></a>随机数产生器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution Method 1:</span></span><br><span class="line">rand_arr = np.random.randint(low=<span class="number">5</span>, high=<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>)) + np.random.random((<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># print(rand_arr)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution Method 2:</span></span><br><span class="line">rand_arr = np.random.uniform(<span class="number">5</span>,<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(rand_arr)</span><br><span class="line"><span class="comment"># &gt; [[ 8.50061025  9.10531502  6.85867783]</span></span><br><span class="line"><span class="comment"># &gt;  [ 9.76262069  9.87717411  7.13466701]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.48966403  8.33409158  6.16808631]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.75010551  9.94535696  5.27373226]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8.0850361   5.56165518  7.31244004]]</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 问题：在 iris_2d 数据集中的 20 个随机位置插入 np.nan 值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>


<h2 id="随堂练习"><a href="#随堂练习" class="headerlink" title="随堂练习"></a>随堂练习</h2><blockquote class="blockquote-center">
<ol>
<li>生成一个尺寸为[10,20]的随机数数组a，数值在[-10,10)之间均匀随机分布;</li>
<li>在数组a中的20个随机位置插入NaN;</li>
<li>检索数组a中的NaN值，并替换为在[-20,20)之间均匀随机分布的随机数；</li>
<li>将数组a中大于5的值替换为5，小于-5的值替换为-5.</li>
</ol>

</blockquote>

<h2 id="随堂练习答案"><a href="#随堂练习答案" class="headerlink" title="随堂练习答案"></a>随堂练习答案</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.random.uniform(-<span class="number">10</span>,<span class="number">10</span>,(<span class="number">10</span>,<span class="number">20</span>))</span><br><span class="line">a[np.random.choice((i),<span class="number">20</span>),np.random.choice((j),<span class="number">20</span>)] = np.nan</span><br><span class="line">a[np.isnan(a)] = np.random.uniform(-<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">a = np.clip(a,-<span class="number">5</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：TrainingArguments 中 optim 参数详解</title>
    <url>/AI-optim/</url>
    <content><![CDATA[<p>这份指南详细介绍了 Hugging Face <code>transformers</code> 库中 <code>optim</code> 参数所有可用的选项。该列表直接来源于 <code>transformers</code> 源代码，涵盖了从稳定可靠的基准到内存优化、实验性算法和特定硬件的各类优化器。</p>
<span id="more"></span>
<hr>
<h2 id="优化器分类概览"><a href="#优化器分类概览" class="headerlink" title="优化器分类概览"></a>优化器分类概览</h2><p>为了系统地理解这些选项，我们将它们分为以下几大类：</p>
<p><strong>主流与推荐 (AdamW 家族)</strong>: 训练 Transformer 模型的核心与首选。<br>    * <code>adamw_torch</code>, <code>adamw_torch_fused</code></p>
<p><strong>内存节省型优化器 (核心技术)</strong>: 当显存（VRAM）成为主要瓶颈时，这些技术至关重要。<br><strong>8-bit 量化优化器</strong>: 将优化器状态从32位浮点数压缩到8位整数，极大节省内存。<br>        * <code>adamw_8bit</code> (别名 <code>adamw_bnb_8bit</code>), <code>lion_8bit</code>, <code>rmsprop_8bit</code><br>    * <strong>Paged 优化器</strong>: 一种更先进的内存管理技术，当GPU显存不足时，它能自动将优化器状态“分页”到CPU内存，防止程序因OOM（Out-of-Memory）而崩溃。<br>        * <code>paged_adamw_8bit</code>, <code>paged_lion_8bit</code><br>    * <strong>Adafactor</strong>: 通过数学分解来近似存储优化器状态，是另一种经典的内存节省方案。<br>        * <code>adafactor</code></p>
<p><strong>梯度低秩投影 (GaLore)</strong>: 一种前沿的内存优化技术，尤其适合全参数微调。<br><strong>低内存优化 (LOMO &amp; AdaLOMO)</strong>: 另一种创新的内存节省方法。<br><strong>新型与实验性优化器</strong>: 来自最新研究，可能在特定任务上表现更优。<br><strong>特定硬件&#x2F;库的优化器</strong>: 为特定硬件或旧版库设计。<br><strong>经典与遗留优化器</strong>: 深度学习领域的经典算法。</p>
<hr>
<h2 id="全量选项详细分析"><a href="#全量选项详细分析" class="headerlink" title="全量选项详细分析"></a>全量选项详细分析</h2><h3 id="1-主流与推荐-AdamW-家族"><a href="#1-主流与推荐-AdamW-家族" class="headerlink" title="1. 主流与推荐 (AdamW 家族)"></a>1. 主流与推荐 (AdamW 家族)</h3><p>这是训练现代大模型的起点和最可靠的选择。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖与要求</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_torch</code></strong></td>
<td align="left">PyTorch 标准实现，<strong>默认选项</strong></td>
<td align="left"><strong>最稳定、最通用</strong>，无需额外依赖，行为可预测。</td>
<td align="left">在现代 GPU 上性能非最优。</td>
<td align="left">PyTorch</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_torch_fused</code></strong></td>
<td align="left"><strong>性能之选 (推荐)</strong>，融合内核</td>
<td align="left">在现代 NVIDIA GPU 上<strong>速度显著提升</strong>，通过融合操作减少 GPU 内核启动开销。</td>
<td align="left">需要 PyTorch 2.0 或更高版本。</td>
<td align="left"><code>torch&gt;=2.0</code></td>
</tr>
</tbody></table>
<h3 id="2-内存节省型优化器"><a href="#2-内存节省型优化器" class="headerlink" title="2. 内存节省型优化器"></a>2. 内存节省型优化器</h3><p>当显存不足时，以下技术是你的救星。它们通常可以组合使用。</p>
<h4 id="2-1-8-bit-量化优化器"><a href="#2-1-8-bit-量化优化器" class="headerlink" title="2.1 8-bit 量化优化器"></a>2.1 8-bit 量化优化器</h4><p><strong>技术核心</strong>：使用 <code>bitsandbytes</code> 库将32位的优化器状态（如动量和方差）量化为8位整数，从而<strong>将优化器的内存占用减少约75%</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_8bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">8位量化的 <code>AdamW</code>。<strong>最常用、最推荐的内存节省方案</strong>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left">(<code>adamw_bnb_8bit</code>)</td>
<td align="left"></td>
<td align="left">(这是 <code>adamw_8bit</code> 的一个别名)</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><strong><code>lion_8bit</code></strong></td>
<td align="left">Lion</td>
<td align="left">8位量化的 <code>Lion</code> 优化器。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>rmsprop_8bit</code></strong></td>
<td align="left">RMSprop</td>
<td align="left">8位量化的 <code>RMSprop</code>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left">(<code>rmsprop_bnb_8bit</code>)</td>
<td align="left"></td>
<td align="left">(这是 <code>rmsprop_8bit</code> 的一个别名)</td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="2-2-Paged-优化器"><a href="#2-2-Paged-优化器" class="headerlink" title="2.2 Paged 优化器"></a>2.2 Paged 优化器</h4><p><strong>技术核心</strong>：在8-bit优化的基础上，当GPU显存依然不足时，它能利用NVIDIA的统一内存功能，自动将不常用的优化器状态**“分页”到CPU主内存**，并在需要时再调回GPU。这可以<strong>防止在训练中因显存波动导致的崩溃 (OOM Error)</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>paged_adamw_8bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">结合了8位量化和分页技术，<strong>是目前最稳健的内存优化方案</strong>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>paged_lion_8bit</code></strong></td>
<td align="left">Lion</td>
<td align="left">结合了8位量化和分页技术的 <code>Lion</code> 优化器。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>paged_adamw_32bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">如果你不想使用8位量化但仍想利用分页技术防止崩溃，可以使用这个32位版本。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
</tbody></table>
<h4 id="2-3-Adafactor"><a href="#2-3-Adafactor" class="headerlink" title="2.3 Adafactor"></a>2.3 Adafactor</h4><p><strong>技术核心</strong>：通过数学上的矩阵分解技巧来近似存储优化器状态，从而达到节省内存的目的。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adafactor</code></strong></td>
<td align="left">Google 设计的内存优化器</td>
<td align="left"><strong>显著降低内存占用</strong>，不存储完整的动量信息，且不依赖 <code>bitsandbytes</code> 库。</td>
<td align="left">收敛性有时不如 AdamW 稳定，可能需要更仔细地调整学习率。</td>
<td align="left"><code>transformers</code> 自带</td>
</tr>
</tbody></table>
<h3 id="3-GaLore-Gradient-Low-Rank-Projection"><a href="#3-GaLore-Gradient-Low-Rank-Projection" class="headerlink" title="3. GaLore (Gradient Low-Rank Projection)"></a>3. GaLore (Gradient Low-Rank Projection)</h3><p><strong>技术核心</strong>：一种非常新颖且高效的内存优化技术，它假设梯度矩阵是低秩的，因此只存储和更新梯度的低秩投影，而不是完整的梯度矩阵。这使得<strong>全参数微调的内存消耗可以接近甚至低于LoRA等参数高效微调方法</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>galore_adamw</code></strong></td>
<td align="left">AdamW</td>
<td align="left">将 GaLore 技术应用于 AdamW。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_adafactor</code></strong></td>
<td align="left">Adafactor</td>
<td align="left">将 GaLore 技术应用于 Adafactor，进一步节省内存。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_adamw_8bit</code></strong></td>
<td align="left">AdamW + 8-bit</td>
<td align="left">结合了 GaLore 和8位量化，实现极致的内存节省。</td>
<td align="left"><code>galore_torch</code>, <code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_..._layerwise</code></strong></td>
<td align="left">(所有GaLore变体)</td>
<td align="left">为模型的不同层应用不同的秩，可能比全局秩更高效。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
</tbody></table>
<h3 id="4-LOMO-Low-Memory-Optimization-AdaLOMO"><a href="#4-LOMO-Low-Memory-Optimization-AdaLOMO" class="headerlink" title="4. LOMO (Low-Memory Optimization) &amp; AdaLOMO"></a>4. LOMO (Low-Memory Optimization) &amp; AdaLOMO</h3><p><strong>技术核心</strong>：LOMO通过将梯度计算、梯度收集和参数更新步骤融合成一个步骤，从而避免了存储完整的模型梯度，<strong>极大地节省了内存</strong>。AdaLOMO是其自适应版本。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>lomo</code></strong></td>
<td align="left">低内存优化</td>
<td align="left">将多步融为一步，无需存储完整梯度，内存效率极高。</td>
<td align="left">实验性强，实现较为复杂。</td>
<td align="left"><code>lomo_optim</code></td>
</tr>
<tr>
<td align="left"><strong><code>adalomo</code></strong></td>
<td align="left">带自适应学习率的LOMO</td>
<td align="left">在 LOMO 基础上增加了学习率的自适应调整。</td>
<td align="left">实验性强。</td>
<td align="left"><code>lomo_optim</code></td>
</tr>
</tbody></table>
<h3 id="5-新型与实验性优化器"><a href="#5-新型与实验性优化器" class="headerlink" title="5. 新型与实验性优化器"></a>5. 新型与实验性优化器</h3><p>这些优化器来自最新的学术研究，可能在特定任务上表现更优，但需要更多实验和调整。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心思想</th>
<th align="left">何时使用</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>lion</code></strong> (或 <code>lion_32bit</code>)</td>
<td align="left">简化更新规则（只用动量），由Google提出。</td>
<td align="left">当你乐于探索时。<code>lion</code> 宣称比 AdamW 更省内存、性能更优。通常需要更小的学习率和更大的权重衰减。</td>
</tr>
<tr>
<td align="left"><strong><code>apollo_adamw</code></strong></td>
<td align="left">解耦学习率和权重衰减来改进 AdamW。</td>
<td align="left">当你希望探索可能比标准AdamW收敛更好、性能更优的替代方案时。</td>
</tr>
<tr>
<td align="left"><strong><code>schedule_free_...</code></strong></td>
<td align="left">在训练中自动调整步长。</td>
<td align="left"><strong>当你不想费心设计学习率调度器时</strong>。非常适合快速实验，但最终性能不一定最优。</td>
</tr>
<tr>
<td align="left"><strong><code>grokadamw</code></strong></td>
<td align="left">为复现 “Grokking” 现象而设计。</td>
<td align="left">仅用于学术研究，探索模型在训练后期泛化能力突然提升的现象。</td>
</tr>
</tbody></table>
<h3 id="6-特定硬件-库的优化器"><a href="#6-特定硬件-库的优化器" class="headerlink" title="6. 特定硬件&#x2F;库的优化器"></a>6. 特定硬件&#x2F;库的优化器</h3><table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_torch_xla</code></strong></td>
<td align="left"><strong>仅在 Google TPU 上使用</strong>。</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_torch_npu_fused</code></strong></td>
<td align="left"><strong>仅在华为 Ascend NPU 上使用</strong>。</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_apex_fused</code></strong></td>
<td align="left">仅在 <code>torch&lt;2.0</code> 的旧环境中，配合NVIDIA APEX库使用。已被 <code>adamw_torch_fused</code> 取代。</td>
</tr>
</tbody></table>
<h3 id="7-经典与遗留优化器"><a href="#7-经典与遗留优化器" class="headerlink" title="7. 经典与遗留优化器"></a>7. 经典与遗留优化器</h3><p>这些算法是深度学习的基石，但对于现代 Transformer 模型，通常不是最佳选择。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点与局限</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>sgd</code></strong></td>
<td align="left"><strong>随机梯度下降</strong>。对于Transformer模型这样复杂的损失曲面，SGD收敛极慢且容易陷入局部最优。</td>
</tr>
<tr>
<td align="left"><strong><code>adagrad</code></strong></td>
<td align="left"><strong>适应性梯度算法</strong>。学习率会随时间单调递减，后期可能过小导致训练停滞，不推荐用于Transformer。</td>
</tr>
<tr>
<td align="left"><strong><code>rmsprop</code></strong></td>
<td align="left"><strong>Adagrad的改进版</strong>。缓解了学习率快速下降的问题，但性能和稳定性通常不如AdamW。</td>
</tr>
</tbody></table>
<hr>
<h2 id="终极决策流程"><a href="#终极决策流程" class="headerlink" title="终极决策流程"></a>终极决策流程</h2><ol>
<li><p><strong>【性能优先】</strong> 如果你有现代NVIDIA GPU和PyTorch 2.0+，<strong><code>adamw_torch_fused</code></strong> 是你的不二之选。</p>
</li>
<li><p><strong>【内存优先】</strong> 如果显存不足是首要问题：</p>
<ul>
<li><strong>首选 <code>paged_adamw_8bit</code></strong>。它结合了8位量化和分页，既省内存又防崩溃。</li>
<li>如果想在<strong>全参数微调</strong>时达到LoRA级的内存效率，大胆尝试 <strong><code>galore_adamw_8bit</code></strong>。</li>
<li>如果安装 <code>bitsandbytes</code> 困难，退而求其次选择 <strong><code>adafactor</code></strong>。</li>
</ul>
</li>
<li><p><strong>【简化实验】</strong> 如果你想快速迭代，不想费心设计学习率调度器：</p>
<ul>
<li>尝试 <strong><code>schedule_free_adamw</code></strong>。</li>
</ul>
</li>
<li><p><strong>【探索前沿】</strong> 如果你热衷于尝试最新的研究成果：</p>
<ul>
<li><strong><code>lion</code></strong> 是一个很好的起点，但请准备好调整超参数。</li>
</ul>
</li>
<li><p><strong>【不确定或环境受限】</strong> 如果你不确定选哪个：</p>
<ul>
<li>使用默认的 <strong><code>adamw_torch</code></strong>，它永远是稳定可靠的基准。</li>
</ul>
</li>
<li><p><strong>【特定硬件】</strong> 如果你在TPU或NPU上：</p>
<ul>
<li>分别使用 <strong><code>adamw_torch_xla</code></strong> 或 <strong><code>adamw_torch_npu_fused</code></strong>。</li>
</ul>
</li>
</ol>
<h2 id="官方文档地址"><a href="#官方文档地址" class="headerlink" title="官方文档地址"></a>官方文档地址</h2><p>您可以在 Hugging Face <code>transformers</code> 官方文档的 <code>TrainingArguments</code> 页面找到关于 <code>optim</code> 参数的权威说明。官方文档链接: <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments.optim">https://huggingface.co/docs/transformers/main/en/main_classes&#x2F;trainer#transformers.TrainingArguments.optim</a></p>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>TrainingArguments</tag>
        <tag>Optim</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 08：Python 环境下的数字图像降噪</title>
    <url>/PythonLes09/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Antoni Buades 提出指标 method noise 对数字图像降噪方法的性能进行了评价和比较。他首先针对几个被广泛使用的降噪算法计算并分析了降噪性能。同时，基于图像中所有像素的非局部平均，提出了全新的数字图像降噪算法 Non Local means Algorithm，并通过实验比较了新算法与常用的平滑滤波方法的性能。</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h2 id="课程作业-01，占总成绩30"><a href="#课程作业-01，占总成绩30" class="headerlink" title="课程作业 01，占总成绩30%"></a>课程作业 01，占总成绩30%</h2><blockquote class="blockquote-center">
<p>在二维平面中构建随机 Vornoi 结构，将交界处壁厚设置为随机数，生成Vornoi结构图像。要求：三维平面的像素画幅、Vornoi的初始种子的数密度、交界处壁厚的随机分布范围可设置，作为输入参数集放置在程序的最开始。输出：二维结构图像，并输出各个交界节点、棱边的结构信息至.txt文件。 </p>

</blockquote>

<h3 id="数字图像噪声"><a href="#数字图像噪声" class="headerlink" title="数字图像噪声"></a>数字图像噪声</h3><p>&emsp;&emsp;数字图像的两个主要限制是模糊及噪声（blur &amp; noise）。模糊是图像采集系统的固有性质，同时数字图像对连续信号离散采样的形式必须遵循 Shannon-Nyquist 采样定律。另一种主要的干扰形式是噪声。数字图像中每个像素点的值 $u(i)$ 都是对局部光强测量的结果，通常通过 CCD 及光学聚焦元件实现。CCD 中每个方形探测单元（captor）都将记录曝光时间内探测区域的入射光子数。在光源强度恒定的情况下，每个探测单元每个曝光周期内采集的光子数的概率分布将遵循中心极限定理，在光强均值周围震荡。另外，如果 CCD 没有经过充分冷却就会接收热光子（heat spurious photons），由此产生的扰动通常称为 obscurity noise。</p>
<p>&emsp;&emsp;数字图像降噪方法的目标是从观测到的噪声图像中还原出原始信号，</p>
<p>$$ v(i)&#x3D;u(i)+n(i), \tag{1}\label{1} $$</p>
<p>其中 $v(i)$ 为实测图像，$u(i)$ 为原始信号，$n(i)$ 则是噪声信号。评估图像中噪声水平通常采用信噪比（signal noise ratio, SNR）：</p>
<p>$$ SNR &#x3D; \sigma(u)&#x2F;\sigma(n), \tag{2}\label{2} $$</p>
<p>其中，$\sigma(n)$为噪声信号标准差，$\sigma(u)$表示真实信号的经验标准差，</p>
<p>$$ \sigma(u) &#x3D; \sqrt{\frac{1}{|I|}\sum_i(u(i)- \overline{u} )^2}, \tag{3}\label{3} $$</p>
<p>$$ \overline{u}&#x3D;\frac{1}{|I|}\sum_{i\in I} u(i) \tag{4}\label{4}$$ 为图像的平均灰度值，$|I|$指全图像素数。当噪声模型和参数已知时，噪声的标准差也可以用经验测量法或形式化方法得到。</p>
<p>&emsp;&emsp;迄今为止，图像处理领域已经提出了诸多抑制噪声、还原真实信号的算法。即便它们通常拥有截然不同的数学形式，但都拥有一个共性：平均。这种平均可以在局部进行：高斯滤波器(<a href="https://freddy.cs.technion.ac.il/wp-content/uploads/2018/01/on-gabors-contribution-to-image-enhancement.pdf">Gabor 1994</a>)，各向异性滤波(<a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona-Malik 1990</a>, <a href="https://accedacris.ulpgc.es/bitstream/10553/52821/1/image_selective_smoothing_edge.pdf">Alvarez et al. 1992</a>)，邻域滤波器(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.5808&rep=rep1&type=pdf">Smith et al. 1997</a>)；也可以通过计算variations实现：TV滤波(<a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin-Osher-Fatemi 1992</a>)；或是在频域进行：经验维纳滤波(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>)，小波阈值方法(<a href="https://pdfs.semanticscholar.org/78a5/90a8ac92f02fb48e4e488b6eb00dc7b931eb.pdf">Coiffman-Donoho 1995</a>)。</p>
<h3 id="Method-noise"><a href="#Method-noise" class="headerlink" title="Method noise"></a>Method noise</h3><p>&emsp;&emsp;不妨令 $u$ 表示实测图像，$D_hu$ 表示降噪方法的输出结果，$h$ 为滤波参数。Antoni Buades 定义 method noise 为降噪前后图像之差：</p>
<p>$$ u-D_hu. \tag{5}\label{5} $$</p>
<p>&emsp;&emsp;完美的降噪算法在应用中不应该改变无噪声图像。因此，当图像具有某种规律性时，method noise 理应很小。对理想的降噪算法，Method noise 必须看起来与随机噪声无异，几乎不包含原始信号的结构。因为即便是质量非常高的实测图像，噪声也是不可避免的，计算 method noise 对评估任何降噪算法都是有意义的，而非传统的“添加噪声，再去除噪声”的把戏。</p>
<h2 id="局部平均算法"><a href="#局部平均算法" class="headerlink" title="局部平均算法"></a>局部平均算法</h2><h3 id="高斯滤波-Gaussian-Filtering"><a href="#高斯滤波-Gaussian-Filtering" class="headerlink" title="高斯滤波 (Gaussian Filtering)"></a>高斯滤波 (Gaussian Filtering)</h3><p>&emsp;&emsp;对数字图像进行各向同性过滤，本质上可以归结为图像与各向同性核的卷积。采用数值呈现出高斯分布的卷积核，既是高斯滤波，是图像处理中最常用的操作之一。通俗的讲，高斯滤波就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到（所有的局部平滑滤波方法都是如此）。高斯卷积核：</p>
<p>$$ G_h(x)&#x3D;\frac{1}{4\pi h^2}e^{-\frac{|x|^2}{4h^2}}. \tag{6}\label{6} $$</p>
<p><strong>Theorem 1 (Babor 1960):</strong> 当高斯卷积核的特征尺寸 $h$ 极小时，高斯滤波的 method noise 为：</p>
<p>$$ u-G_h* u&#x3D;-h^2\Delta u+o(h^2). \tag{7}\label{7} $$</p>
<p>&emsp;&emsp;高斯滤波的 method noise 在图像谐波部分几乎为零，而在边缘、纹理区域非常大。因此，高斯滤波在图像的平坦区域相对表现优秀，但在边缘、纹理区域较为模糊（blurred）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img_medianBlur=cv2.medianBlur(img01,<span class="number">5</span>)</span><br><span class="line">font=cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line"></span><br><span class="line"><span class="comment">#均值滤波</span></span><br><span class="line">img_Blur=cv2.blur(img01,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#高斯滤波</span></span><br><span class="line">img_GaussianBlur=cv2.GaussianBlur(img01,(<span class="number">7</span>,<span class="number">7</span>),<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#高斯双边滤波</span></span><br><span class="line">img_bilateralFilter=cv2.bilateralFilter(img01,<span class="number">40</span>,<span class="number">75</span>,<span class="number">75</span>)</span><br></pre></td></tr></table></figure>

<h3 id="各向异性滤波（Anisotropic-Filtering-AF）"><a href="#各向异性滤波（Anisotropic-Filtering-AF）" class="headerlink" title="各向异性滤波（Anisotropic Filtering, AF）"></a>各向异性滤波（Anisotropic Filtering, AF）</h3><p>&emsp;&emsp;各向异性滤波提出之初旨在解决高斯滤波在边缘及纹理区域的模糊问题。该算法通过只在 $Du(\vec x)$ 正交方向上计算图像 $u$ 在 $\vec x$ 处的卷积。这种想法可以追溯到 <a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona &amp; Malik</a>。各向异性滤波算法的定义为：</p>
<p>$$ AF_hu(\vec x)&#x3D;\int G_h(t)u(\vec x+t\frac{Du(\vec x)^\perp}{|Du(\vec x)|})dt, \tag{8}\label{8} $$</p>
<p>在 $\vec x$ 处，当 $Du(\vec x)\neq0$ 时成立。$(x,y)^\perp&#x3D;(-y,x)$，且 $G_h$ 代指方差 $h^2$ 的一维高斯函数。假设原始图像 $u$ 在 $\vec x$ 处二次连续可微（twice continuously differentiable ($C^2$)）,将上式二次泰勒展开（second order Taylor expansion）可以推导出：</p>
<p><strong>Theorem 2:</strong> 当 $Du(\vec x)\neq0$ 时，各向异性滤波 $AF_h$ 的 method noise 为：</p>
<p>$$ u(\vec x)-AF_hu(\vec x)&#x3D;-\frac{1}{2}h^2|Du|curv(u)(\vec x)+o(h^2), \tag{9}\label{9} $$</p>
<p>$curv(u)(\vec x)$ 指局部曲率，即经过 $\vec x$ 点的水平直线上曲率半径的逆（signed inverse）。在图像 $u$ 中局部几乎为一条直线的区域，method noise 几乎为零，而在弯曲的边缘或纹理区域较大。因而，各向异性滤波对直边区域得以保持，而平坦、纹理区域图像精度有所退化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">anisodiff</span>(<span class="params">img,niter=<span class="number">1</span>,kappa=<span class="number">50</span>,gamma=<span class="number">0.1</span>,step=(<span class="params"><span class="number">1.</span>,<span class="number">1.</span></span>),option=<span class="number">1</span>,ploton=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Anisotropic diffusion.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">    imgout = anisodiff(im, niter, kappa, gamma, option)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">            img    - input image</span></span><br><span class="line"><span class="string">            niter  - number of iterations</span></span><br><span class="line"><span class="string">            kappa  - conduction coefficient 20-100 ?</span></span><br><span class="line"><span class="string">            gamma  - max value of .25 for stability</span></span><br><span class="line"><span class="string">            step   - tuple, the distance between adjacent pixels in (y,x)</span></span><br><span class="line"><span class="string">            option - 1 Perona Malik diffusion equation No 1</span></span><br><span class="line"><span class="string">                     2 Perona Malik diffusion equation No 2</span></span><br><span class="line"><span class="string">            ploton - if True, the image will be plotted on every iteration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">            imgout   - diffused image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    kappa controls conduction as a function of gradient.  If kappa is low</span></span><br><span class="line"><span class="string">    small intensity gradients are able to block conduction and hence diffusion</span></span><br><span class="line"><span class="string">    across step edges.  A large value reduces the influence of intensity</span></span><br><span class="line"><span class="string">    gradients on conduction.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma controls speed of diffusion (you usually want it at a maximum of</span></span><br><span class="line"><span class="string">    0.25)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    step is used to scale the gradients in case the spacing between adjacent</span></span><br><span class="line"><span class="string">    pixels differs in the x and y axes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Diffusion equation 1 favours high contrast edges over low contrast ones.</span></span><br><span class="line"><span class="string">    Diffusion equation 2 favours wide regions over smaller ones.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">    P. Perona and J. Malik.</span></span><br><span class="line"><span class="string">    Scale-space and edge detection using ansotropic diffusion.</span></span><br><span class="line"><span class="string">    IEEE Transactions on Pattern Analysis and Machine Intelligence,</span></span><br><span class="line"><span class="string">    12(7):629-639, July 1990.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Original MATLAB code by Peter Kovesi</span></span><br><span class="line"><span class="string">    School of Computer Science &amp; Software Engineering</span></span><br><span class="line"><span class="string">    The University of Western Australia</span></span><br><span class="line"><span class="string">    pk @ csse uwa edu au</span></span><br><span class="line"><span class="string">    &lt;http://www.csse.uwa.edu.au&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Translated to Python and optimised by Alistair Muldal</span></span><br><span class="line"><span class="string">    Department of Pharmacology</span></span><br><span class="line"><span class="string">    University of Oxford</span></span><br><span class="line"><span class="string">    &lt;alistair.muldal@pharm.ox.ac.uk&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    June 2000  original version.</span></span><br><span class="line"><span class="string">    March 2002 corrected diffusion eqn No 2.</span></span><br><span class="line"><span class="string">    July 2012 translated to Python</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    April 2019 - Corrected for Python 3.7 - AvW </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...you could always diffuse each color channel independently if you</span></span><br><span class="line">    <span class="comment"># really want</span></span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">3</span>:</span><br><span class="line">        warnings.warn(<span class="string">&quot;Only grayscale images allowed, converting to 2D matrix&quot;</span>)</span><br><span class="line">        img = img.mean(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output array</span></span><br><span class="line">    img = img.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    imgout = img.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize some internal variables</span></span><br><span class="line">    deltaS = np.zeros_like(imgout)</span><br><span class="line">    deltaE = deltaS.copy()</span><br><span class="line">    NS = deltaS.copy()</span><br><span class="line">    EW = deltaS.copy()</span><br><span class="line">    gS = np.ones_like(imgout)</span><br><span class="line">    gE = gS.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create the plot figure, if requested</span></span><br><span class="line">    <span class="keyword">if</span> ploton:</span><br><span class="line">        <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line">        <span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">        fig = pl.figure(figsize=(<span class="number">20</span>,<span class="number">5.5</span>),num=<span class="string">&quot;Anisotropic diffusion&quot;</span>)</span><br><span class="line">        ax1,ax2 = fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        ax1.imshow(img,interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        ih = ax2.imshow(imgout,interpolation=<span class="string">&#x27;nearest&#x27;</span>,animated=<span class="literal">True</span>)</span><br><span class="line">        ax1.set_title(<span class="string">&quot;Original image&quot;</span>)</span><br><span class="line">        ax2.set_title(<span class="string">&quot;Iteration 0&quot;</span>)</span><br><span class="line"></span><br><span class="line">        fig.canvas.draw()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the diffs</span></span><br><span class="line">        deltaS[:-<span class="number">1</span>,: ] = np.diff(imgout,axis=<span class="number">0</span>)</span><br><span class="line">        deltaE[: ,:-<span class="number">1</span>] = np.diff(imgout,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conduction gradients (only need to compute one per dim!)</span></span><br><span class="line">        <span class="keyword">if</span> option == <span class="number">1</span>:</span><br><span class="line">            gS = np.exp(-(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gE = np.exp(-(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> option == <span class="number">2</span>:</span><br><span class="line">            gS = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gE = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update matrices</span></span><br><span class="line">        E = gE*deltaE</span><br><span class="line">        S = gS*deltaS</span><br><span class="line"></span><br><span class="line">        <span class="comment"># subtract a copy that has been shifted &#x27;North/West&#x27; by one</span></span><br><span class="line">        <span class="comment"># pixel. don&#x27;t as questions. just do it. trust me.</span></span><br><span class="line">        NS[:] = S</span><br><span class="line">        EW[:] = E</span><br><span class="line">        NS[<span class="number">1</span>:,:] -= S[:-<span class="number">1</span>,:]</span><br><span class="line">        EW[:,<span class="number">1</span>:] -= E[:,:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update the image</span></span><br><span class="line">        imgout += gamma*(NS+EW)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ploton:</span><br><span class="line">            iterstring = <span class="string">&quot;Iteration %i&quot;</span> %(ii+<span class="number">1</span>)</span><br><span class="line">            ih.set_data(imgout)</span><br><span class="line">            ax2.set_title(iterstring)</span><br><span class="line">            fig.canvas.draw()</span><br><span class="line">            <span class="comment"># sleep(0.01)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> imgout</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">anisodiff3</span>(<span class="params">stack,niter=<span class="number">1</span>,kappa=<span class="number">50</span>,gamma=<span class="number">0.1</span>,step=(<span class="params"><span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span></span>),option=<span class="number">1</span>,ploton=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    3D Anisotropic diffusion.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">    stackout = anisodiff(stack, niter, kappa, gamma, option)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">            stack  - input stack</span></span><br><span class="line"><span class="string">            niter  - number of iterations</span></span><br><span class="line"><span class="string">            kappa  - conduction coefficient 20-100 ?</span></span><br><span class="line"><span class="string">            gamma  - max value of .25 for stability</span></span><br><span class="line"><span class="string">            step   - tuple, the distance between adjacent pixels in (z,y,x)</span></span><br><span class="line"><span class="string">            option - 1 Perona Malik diffusion equation No 1</span></span><br><span class="line"><span class="string">                     2 Perona Malik diffusion equation No 2</span></span><br><span class="line"><span class="string">            ploton - if True, the middle z-plane will be plotted on every</span></span><br><span class="line"><span class="string">                 iteration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">            stackout   - diffused stack.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    kappa controls conduction as a function of gradient.  If kappa is low</span></span><br><span class="line"><span class="string">    small intensity gradients are able to block conduction and hence diffusion</span></span><br><span class="line"><span class="string">    across step edges.  A large value reduces the influence of intensity</span></span><br><span class="line"><span class="string">    gradients on conduction.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma controls speed of diffusion (you usually want it at a maximum of</span></span><br><span class="line"><span class="string">    0.25)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    step is used to scale the gradients in case the spacing between adjacent</span></span><br><span class="line"><span class="string">    pixels differs in the x,y and/or z axes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Diffusion equation 1 favours high contrast edges over low contrast ones.</span></span><br><span class="line"><span class="string">    Diffusion equation 2 favours wide regions over smaller ones.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">    P. Perona and J. Malik.</span></span><br><span class="line"><span class="string">    Scale-space and edge detection using ansotropic diffusion.</span></span><br><span class="line"><span class="string">    IEEE Transactions on Pattern Analysis and Machine Intelligence,</span></span><br><span class="line"><span class="string">    12(7):629-639, July 1990.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Original MATLAB code by Peter Kovesi</span></span><br><span class="line"><span class="string">    School of Computer Science &amp; Software Engineering</span></span><br><span class="line"><span class="string">    The University of Western Australia</span></span><br><span class="line"><span class="string">    pk @ csse uwa edu au</span></span><br><span class="line"><span class="string">    &lt;http://www.csse.uwa.edu.au&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Translated to Python and optimised by Alistair Muldal</span></span><br><span class="line"><span class="string">    Department of Pharmacology</span></span><br><span class="line"><span class="string">    University of Oxford</span></span><br><span class="line"><span class="string">    &lt;alistair.muldal@pharm.ox.ac.uk&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    June 2000  original version.</span></span><br><span class="line"><span class="string">    March 2002 corrected diffusion eqn No 2.</span></span><br><span class="line"><span class="string">    July 2012 translated to Python</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...you could always diffuse each color channel independently if you</span></span><br><span class="line">    <span class="comment"># really want</span></span><br><span class="line">    <span class="keyword">if</span> stack.ndim == <span class="number">4</span>:</span><br><span class="line">        warnings.warn(<span class="string">&quot;Only grayscale stacks allowed, converting to 3D matrix&quot;</span>)</span><br><span class="line">        stack = stack.mean(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output array</span></span><br><span class="line">    stack = stack.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    stackout = stack.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize some internal variables</span></span><br><span class="line">    deltaS = np.zeros_like(stackout)</span><br><span class="line">    deltaE = deltaS.copy()</span><br><span class="line">    deltaD = deltaS.copy()</span><br><span class="line">    NS = deltaS.copy()</span><br><span class="line">    EW = deltaS.copy()</span><br><span class="line">    UD = deltaS.copy()</span><br><span class="line">    gS = np.ones_like(stackout)</span><br><span class="line">    gE = gS.copy()</span><br><span class="line">    gD = gS.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create the plot figure, if requested</span></span><br><span class="line">    <span class="keyword">if</span> ploton:</span><br><span class="line">        <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line">        <span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">        showplane = stack.shape[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line">        fig = pl.figure(figsize=(<span class="number">20</span>,<span class="number">5.5</span>),num=<span class="string">&quot;Anisotropic diffusion&quot;</span>)</span><br><span class="line">        ax1,ax2 = fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        ax1.imshow(stack[showplane,...].squeeze(),interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        ih = ax2.imshow(stackout[showplane,...].squeeze(),interpolation=<span class="string">&#x27;nearest&#x27;</span>,animated=<span class="literal">True</span>)</span><br><span class="line">        ax1.set_title(<span class="string">&quot;Original stack (Z = %i)&quot;</span> %showplane)</span><br><span class="line">        ax2.set_title(<span class="string">&quot;Iteration 0&quot;</span>)</span><br><span class="line"></span><br><span class="line">        fig.canvas.draw()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the diffs</span></span><br><span class="line">        deltaD[:-<span class="number">1</span>,: ,:  ] = np.diff(stackout,axis=<span class="number">0</span>)</span><br><span class="line">        deltaS[:  ,:-<span class="number">1</span>,: ] = np.diff(stackout,axis=<span class="number">1</span>)</span><br><span class="line">        deltaE[:  ,: ,:-<span class="number">1</span>] = np.diff(stackout,axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conduction gradients (only need to compute one per dim!)</span></span><br><span class="line">        <span class="keyword">if</span> option == <span class="number">1</span>:</span><br><span class="line">            gD = np.exp(-(deltaD/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gS = np.exp(-(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">            gE = np.exp(-(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> option == <span class="number">2</span>:</span><br><span class="line">            gD = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaD/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gS = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">            gE = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update matrices</span></span><br><span class="line">        D = gD*deltaD</span><br><span class="line">        E = gE*deltaE</span><br><span class="line">        S = gS*deltaS</span><br><span class="line"></span><br><span class="line">        <span class="comment"># subtract a copy that has been shifted &#x27;Up/North/West&#x27; by one</span></span><br><span class="line">        <span class="comment"># pixel. don&#x27;t as questions. just do it. trust me.</span></span><br><span class="line">        UD[:] = D</span><br><span class="line">        NS[:] = S</span><br><span class="line">        EW[:] = E</span><br><span class="line">        UD[<span class="number">1</span>:,: ,: ] -= D[:-<span class="number">1</span>,:  ,:  ]</span><br><span class="line">        NS[: ,<span class="number">1</span>:,: ] -= S[:  ,:-<span class="number">1</span>,:  ]</span><br><span class="line">        EW[: ,: ,<span class="number">1</span>:] -= E[:  ,:  ,:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update the image</span></span><br><span class="line">        stackout += gamma*(UD+NS+EW)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ploton:</span><br><span class="line">            iterstring = <span class="string">&quot;Iteration %i&quot;</span> %(ii+<span class="number">1</span>)</span><br><span class="line">            ih.set_data(stackout[showplane,...].squeeze())</span><br><span class="line">            ax2.set_title(iterstring)</span><br><span class="line">            fig.canvas.draw()</span><br><span class="line">            <span class="comment"># sleep(0.01)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stackout</span><br></pre></td></tr></table></figure>

<h3 id="TV滤波（Total-Variation-Minimization）"><a href="#TV滤波（Total-Variation-Minimization）" class="headerlink" title="TV滤波（Total Variation Minimization）"></a>TV滤波（Total Variation Minimization）</h3><p>&emsp;&emsp;全变分图像去噪算法最早由 <a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin, Osher and Fatemi</a>提出。给定一幅实测图像 $v(\vec x)$，该算法将恢复原始信号 $u(\vec x)$ 的问题转化为下式的最小化问题：</p>
<p>$$ TVF_\lambda(v)&#x3D;{\rm arg},\underset{u}{\rm \mathop {min}},TV(u)+\lambda\int|v(\vec x)-u(\vec x)|^2d\vec x, \tag{10}\label{10} $$</p>
<p>其中 $TV(u)$ 为图像 $u$ 的全变分，$\lambda$ 为给定的拉格朗日乘子（Lagrange multiplier）。上述最小化问题的最小值存在且唯一。参数 $\lambda$ 与噪声的统计信息相关，并控制了滤波程度。</p>
<p><strong>Theorem 3:</strong> TV滤波的 method noise 为：</p>
<p>$$ u(\vec x)-TVF_\lambda(u)(\vec x)&#x3D;-\frac{1}{2\lambda}curv(TVF_\lambda(u))(\vec x). \tag{11}\label{11} $$</p>
<p>&emsp;&emsp;在各向异性的情况下，直边由于曲率小而得以保持。但 $\lambda$ 过小时细节及纹理会被过度平滑。</p>
<h3 id="邻域滤波（Neighborhood-Filtering）"><a href="#邻域滤波（Neighborhood-Filtering）" class="headerlink" title="邻域滤波（Neighborhood Filtering）"></a>邻域滤波（Neighborhood Filtering）</h3><p>&emsp;&emsp;我们称邻域滤波为将临近区域内具有相似灰度值的像素取平均以期恢复原始信号的滤波器。<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky(1985)</a>首次提出的方法通过计算空间邻域 $B_\rho(\vec x)$ 内具有相似灰度值像素的平均来恢复信号：</p>
<p>$$ YNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{B_\rho (\vec x)} u(\vec y)e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{12}\label{12} $$</p>
<p>其中，$\vec x\in\Omega$，$C(\vec x)&#x3D;\int_{B_\rho(\vec x)} e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$h$ 为滤波参数。</p>
<p>&emsp;&emsp;较晚提出的邻域滤波算法相较 Yaroslavsky 滤波要更广为人知一些，既 SUSAN 滤波（1995）及双边滤波（1998）。这些滤波算法都引入到参考像素 $\vec x$ 的距离作为权重因子，而非单纯的考虑一个固定范围的邻域，</p>
<p>$$ SNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{\Omega} u(\vec y)e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{13}\label{13} $$</p>
<p>这里 $C(\vec x)&#x3D;\int_{\Omega}e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$\rho$ 为空间滤波参数（spatial filtering parameter）。事实上，$YNF_{h,\rho}$ 与 $SNF_{h,\rho}$ 之间并没有本质区别。如果两个区域的灰度值差异大于 $h$，这些算法都将计算来自于同一区域的像素灰度平均值来恢复参考点的原始信号。因而该算法不会模糊边界区域，这是正是该类算法最核心的用途。</p>
<p>&emsp;&emsp;然而这类算法的问题是，只将单个像素作为参考点，而如若该参考像素恰好被噪声干扰严重，滤波效果将不够鲁棒（robust）。同时，邻域滤波器也会制造人为干扰（artificial shocks），这将会在它的 method noise 中展示出来。</p>
<h2 id="非局部平均算法（Non-Local-Means-Algorithm）"><a href="#非局部平均算法（Non-Local-Means-Algorithm）" class="headerlink" title="非局部平均算法（Non Local Means Algorithm）"></a>非局部平均算法（Non Local Means Algorithm）</h2><p>&emsp;&emsp;Antoni Buades 于 2005 年提出非局部平均数字图像降噪算法（Non Local Algorithm）。给定一幅实测图像 $v&#x3D;\lbrace v(i)|i\in I\rbrace $，像素 $i$ 处的估计值 $NL[v](i)$ 是该图像上所有像素点的加权平均值，</p>
<p>$$ NL(i)&#x3D;\sum_{j\in I}\omega(i,j)v(j), \tag{14}\label{14} $$</p>
<p>这里的权重系数 $\lbrace\omega (i,j)\rbrace_j$ 取决于像素 $i$ 与 $j$ 之间的相似程度，且始终满足如下标准： $0\leq\omega(i,j)\leq 1$ 且 $\sum_{j} \omega(i,j)&#x3D;1$（等价于上文介绍的滤波算法中归一化常量）。</p>
<p>&emsp;&emsp;俩个像素 $(i,j)$ 之间的相似程度取决于邻域灰度矩阵 $v(N_i)$ 及 $v(N_j)$（intensity gray level vectors），这里 $N_k$ 指以像素 $k$ 为中心，给定尺寸的方形邻域。这种相似性被定义为加权欧式距离的递减函数，$\parallel v(N_i)-v(N_j)\parallel_{2,a}^2$，其中 $a&gt;0$ 是高斯卷积核的标准差。欧式距离对噪声邻域的应用引入了如下等式：</p>
<p>$$ E\parallel v(N_i)-v(N_j)\parallel_{2,a}^2 &#x3D; \parallel u(N_i)-u(N_j) \parallel_{2,a}^2+2\sigma^2. \tag{15}\label{15} $$</p>
<p>&emsp;&emsp;这个等式证明了该算法的鲁棒性（robustness）。因为含噪声的实测图像 $v$ 的欧式距离期望恰恰遵循真正的原始信号之间的相似性。</p>
<p>&emsp;&emsp;与 $v(N_i)$ 具有相似灰度邻域的像素在计算平均时的权重因子更大，</p>
<p>$$ \omega(i,j)&#x3D;\frac{1}{Z(i)}e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{16}\label{16} $$</p>
<p>这里，$Z(i)$ 为归一化常量，</p>
<p>$$ Z(i) &#x3D; \sum_j e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{17}\label{17} $$</p>
<p>参数 $h$ 控制滤波程度，它直接影响了指数函数的衰减趋势，进而控制欧式距离对权重因子衰减速度的影响。</p>
<p>&emsp;&emsp;NL-means 算法不仅仅考虑单个像素的灰度值，而是考虑该像素整个邻域的几何构型，这正是 NL-means 算法比邻域滤波更鲁棒的原因。图$(1)$ 也说明了这个问题，像素 $q3$ 与 $p$ 具有完全一致的灰度值，而邻域的几何构型完全不同，导致 NL-means 中的权重因子 $\omega(p,q3)$ 几乎为零。</p>
<img src="https://s21.ax1x.com/2024/05/07/pkEWDxI.jpg" width="45%" alt="" align=center title="图1.  NL-means 算法方案。相似的像素邻域将提供更大的权重，如 $\omega(p,q1), \omega(p,q2)$，而不相似的邻域提供的权重几乎为零，如 $\omega(p,q3)$。"/>

<p>&nbsp;<br>&emsp;&emsp;NL-means 算法最终的数学形式：</p>
<p>$$ NL(x)&#x3D;\frac{1}{C(x)} \int_{\Omega} e^{-\cfrac{(G_a * |v(x+.)-v(y+.)|^2)(0)}{h^2}}v(y)dy, \tag{18}\label{18} $$</p>
<p>$x\in\Omega$，$C(x)&#x3D;\int_{\Omega} {\rm exp}\lbrack -\frac{(G_a* |u(x+.)-u(z+.)|^2)(0)}{h^2}\rbrack dz$ 为归一化常量，$G_a$ 为高斯核，$h$ 控制过滤程度。</p>
<p>&emsp;&emsp;NL-means 算法的中心思想是：像素 $x$ 处的信息恢复，是由整幅图像内所有邻域与像素 $x$ 邻域相似的点取平均得到的。与局部滤波算法或频域滤波算法相比，NL-means 算法的主要区别在于可以系统地运用整幅图像中所有可能自预测局部结构的信息。</p>
<h2 id="Non-local-means-方法代码实现"><a href="#Non-local-means-方法代码实现" class="headerlink" title="Non-local means 方法代码实现"></a>Non-local means 方法代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_nl_means, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">astro = img_as_float(data.astronaut())</span><br><span class="line">astro = astro[<span class="number">30</span>:<span class="number">180</span>, <span class="number">150</span>:<span class="number">300</span>]</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.08</span></span><br><span class="line">noisy = random_noise(astro, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># estimate the noise standard deviation from the noisy image</span></span><br><span class="line">sigma_est = np.mean(estimate_sigma(noisy, channel_axis=-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;estimated noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">patch_kw = <span class="built_in">dict</span>(patch_size=<span class="number">5</span>,      <span class="comment"># 5x5 patches</span></span><br><span class="line">                patch_distance=<span class="number">6</span>,  <span class="comment"># 13x13 search area</span></span><br><span class="line">                channel_axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm</span></span><br><span class="line">denoise = denoise_nl_means(noisy, h=<span class="number">1.15</span> * sigma_est, fast_mode=<span class="literal">False</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm, sigma provided</span></span><br><span class="line">denoise2 = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">False</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm</span></span><br><span class="line">denoise_fast = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, fast_mode=<span class="literal">True</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm, sigma provided</span></span><br><span class="line">denoise2_fast = denoise_nl_means(noisy, h=<span class="number">0.6</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">True</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>),sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;noisy&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(denoise)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(slow)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(denoise2)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(slow, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(astro)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;original\n(noise free)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(denoise_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(fast)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(denoise2_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(fast, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print PSNR metric for each case</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(astro, noisy)</span><br><span class="line">psnr = peak_signal_noise_ratio(astro, denoise)</span><br><span class="line">psnr2 = peak_signal_noise_ratio(astro, denoise2)</span><br><span class="line">psnr_fast = peak_signal_noise_ratio(astro, denoise_fast)</span><br><span class="line">psnr2_fast = peak_signal_noise_ratio(astro, denoise2_fast)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (noisy) = <span class="subst">&#123;psnr_noisy:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow) = <span class="subst">&#123;psnr:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow, using sigma) = <span class="subst">&#123;psnr2:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast) = <span class="subst">&#123;psnr_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast, using sigma) = <span class="subst">&#123;psnr2_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h2 id="实验及讨论"><a href="#实验及讨论" class="headerlink" title="实验及讨论"></a>实验及讨论</h2><p>&emsp;&emsp;本节将针对以下三点比较 Non Local Means 算法与局部平滑滤波的性能： method noise，视觉效果，均方差（mean square error）。这里均方差指修复图像与真实图像的欧几里得差异（Euclidean difference）。</p>
<p>&emsp;&emsp;在实现 NL-means 算法时，我们将相似邻域的搜索范围约束在一个较大的 $S\times S$ pixels 区域内。在所有的实验中均固定该搜索范围为 $21\times 21$ pixels，并指定邻域 $N_i$ 范围为 $7\times 7$ pixels。不妨设输入图像的像素数为 $N^2$，那么该算法的时间复杂度约为 $21^2\times 7^2 \times N^2$。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWwPH.jpg">https://s21.ax1x.com/2024/05/07/pkEWwPH.jpg</a>“ width&#x3D;”70%” alt&#x3D;”” align&#x3D;center &#x2F; title&#x3D;”图2.  NL-means 权重分布。每组中左图中心像素为参考像素点 $x$，每组中右图为权重因子分布，由黑至白对应从0到1。”&#x2F;&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;$7\times 7$ pixels 的邻域范围已经足够大，能够确保算法对噪声是鲁棒的；也足够小，让细节及纹理得以保持。滤波参数 $h$ 被设置为 $10\sigma$，这里 $\sigma$ 为人工添加高斯白噪声的标准差。由于指数权重的快速衰减，距离中心较远像素的权重几乎为零，这发挥了自动剔除远处像素的作用。Non Local means 算法的权重分布见图$(2)$。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEW0Gd.jpg">https://s21.ax1x.com/2024/05/07/pkEW0Gd.jpg</a>“ width &#x3D; 80% div align&#x3D;center &#x2F; title&#x3D;”图3.  对自然图像的降噪实验。从左至右：含噪声的实测图像（噪声标准差 35），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;在前面的段落中，我们明确的计算了各种局部平滑滤波方法的 method noise 理论值。图$(4)$ 的可视化实验证明了前文中公式的正确性。图$(4)$ 对比了数种降噪方法对含噪声lena图像运算的 method noise，噪声为高斯白噪声，标准差 2.5，滤波参数 $h$ 均相同。Method noise 能更好的协助判断降噪算法的性能及局限，因为被移除或改变的纹理、细节将被 method noise 醒目的展示出来。对比图$(4)$ 中数种降噪算法，NL-means 算法的 method noise 几乎无法察觉任何几何纹理。图$(2)$ 可以解释这一现象，因为 NL-means 算法选取的权重因子完全适应图像局部及非局部的几何结构。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWysP.jpg">https://s21.ax1x.com/2024/05/07/pkEWysP.jpg</a>“ width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图4.  降噪算法的method noise。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。视觉实验验证了第二节的计算公式。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;由于算法本身的性质，纹理及周期性结构是 NL-means 算法最适用的情况。因为对任意像素 $i$，纹理图像或周期性图像中将可以找到大量与该像素具有相似邻域的点，如图$(2.e)$。图$(3)$ 展示了局部平滑滤波器及 NL-means 算法对自然纹理的平滑效果。</p>
<p>&emsp;&emsp;自然图像同样含有足够的信息冗余会被 NL-means 恢复。平坦区域内部将呈现出大量相似的几何结构，见图$(2.a)$。直边界、或弯曲边界将被筛选出一条结构相似的像素线，见图$(2. b)，(2.c)$。并且，NL-means 将会在很远的位置寻找到与参考点相似的结构，如图$(2.f)$。图$(5)$ 展示了一次对自然图像的可视化实验，这组结果与图$(4)$ 是相对应的。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWBRA.jpg">https://s21.ax1x.com/2024/05/07/pkEWBRA.jpg</a>“ width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图5.  对自然图像的降噪实验。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;最后，表$(1)$ 展示了本文介绍的降噪方法的均方差。这种数值测量方法是最客观的，因为它不依赖于任何肉眼视觉上的解释。然而，这个误差在实际问题中是不可计算的（原始信号是未知的），小的均方误差并不能保证高的视觉质量。因此，以上讨论的标准似乎是比较算法性能的必要条件。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWsMt.jpg">https://s21.ax1x.com/2024/05/07/pkEWsMt.jpg</a>“ width &#x3D; 35% div align&#x3D;center &#x2F; title&#x3D;”表1.  均方误差表。均方误差越小，降噪后越接近原始图像。”&gt;</p>
<p>&nbsp;<br><img src="https://s21.ax1x.com/2024/05/07/pkEWgZ8.jpg" width = "60%" title="图6.  多种滤波方法对周期性图像应用结果。从左到右、从上到下：含噪声图像（标准差 35）；高斯滤波；TV滤波；邻域滤波；维纳滤波（ideal filter）；Hard TIWT；DCT 经验维纳滤波；NL-means 算法。" align=center /></p>
<p>&nbsp;<br><img src="https://s21.ax1x.com/2024/05/07/pkEW6qf.jpg" width = "40%" title = "图7.  多种滤波方法对自然图像应用结果。从左到右、从上至下：含噪声图像（标准差 25）；DCT 经验维纳滤波；Hard TIWT；NL-means 算法。"  align=center /></p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>&emsp;&emsp;Non-local means 方法 C 语言实现：<a href="http://www.ipol.im/pub/art/2011/bcm_nlm/">http://www.ipol.im/pub/art/2011/bcm_nlm&#x2F;</a></p>
<h2 id="其他滤波器"><a href="#其他滤波器" class="headerlink" title="其他滤波器"></a>其他滤波器</h2><h3 id="Top-hat-filter"><a href="#Top-hat-filter" class="headerlink" title="Top-hat filter"></a>Top-hat filter</h3><p>使用Top-hat滤波器去除灰度图像中的小目标：这个例子展示了如何从灰度图像中移除小物体。顶帽变换是一种从给定图像中提取小元素和细节的操作。这里我们使用白色顶帽变换，它被定义为输入图像与其(数学形态学)开口之间的差异。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> color, morphology</span><br><span class="line"></span><br><span class="line">image = color.rgb2gray(data.hubble_deep_field())[:<span class="number">500</span>, :<span class="number">500</span>]</span><br><span class="line"></span><br><span class="line">footprint = morphology.disk(<span class="number">1</span>)</span><br><span class="line">res = morphology.white_tophat(image, footprint)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">3</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;White tophat&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(res, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">&#x27;Complementary&#x27;</span>)</span><br><span class="line">ax[<span class="number">2</span>].imshow(image - res, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h3 id="小波傅里叶变换"><a href="#小波傅里叶变换" class="headerlink" title="小波傅里叶变换"></a>小波傅里叶变换</h3><p>小波去噪依赖于图像的小波表示。高斯噪声倾向于用小波域中的小值来表示，并且可以通过将低于给定阈值的系数设置为零(硬阈值)或将所有系数缩小到给定数量的零(软阈值)来去除。<br>在这个例子中，我们展示了两种不同的小波系数阈值选择方法:BayesShrink和VisuShrink。</p>
<img src="https://scikit-image.org/docs/stable/_images/sphx_glr_plot_denoise_wavelet_001.png" width="80%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_wavelet, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">original = img_as_float(data.chelsea()[<span class="number">100</span>:<span class="number">250</span>, <span class="number">50</span>:<span class="number">300</span>])</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.12</span></span><br><span class="line">noisy = random_noise(original, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">5</span>), sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.gray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Estimate the average noise standard deviation across color channels.</span></span><br><span class="line">sigma_est = estimate_sigma(noisy, channel_axis=-<span class="number">1</span>, average_sigmas=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Due to clipping in random_noise, the estimate will be a bit smaller than the</span></span><br><span class="line"><span class="comment"># specified sigma.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Estimated Gaussian noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">im_bayes = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;BayesShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">im_visushrink = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># VisuShrink is designed to eliminate noise with high probability, but this</span></span><br><span class="line"><span class="comment"># results in a visually over-smooth appearance.  Repeat, specifying a reduction</span></span><br><span class="line"><span class="comment"># in the threshold by factors of 2 and 4.</span></span><br><span class="line">im_visushrink2 = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est / <span class="number">2</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">im_visushrink4 = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est / <span class="number">4</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute PSNR as an indication of image quality</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(original, noisy)</span><br><span class="line">psnr_bayes = peak_signal_noise_ratio(original, im_bayes)</span><br><span class="line">psnr_visushrink = peak_signal_noise_ratio(original, im_visushrink)</span><br><span class="line">psnr_visushrink2 = peak_signal_noise_ratio(original, im_visushrink2)</span><br><span class="line">psnr_visushrink4 = peak_signal_noise_ratio(original, im_visushrink4)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">f&#x27;Noisy\nPSNR=<span class="subst">&#123;psnr_noisy:<span class="number">0.4</span>g&#125;</span>&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(im_bayes)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">f&#x27;Wavelet denoising\n(BayesShrink)\nPSNR=<span class="subst">&#123;psnr_bayes:<span class="number">0.4</span>g&#125;</span>&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(im_visushrink)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink</span><br><span class="line">)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(original)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(im_visushrink2)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;/2$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink2</span><br><span class="line">)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(im_visushrink4)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;/4$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink4</span><br><span class="line">)</span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>denoise</tag>
        <tag>Non Local Means</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 09：Python 环境下的数字图像分割</title>
    <url>/PythonLes10/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>数字图像分割是计算机视觉中的一项基础且关键的任务，其目的是将图像划分成若干个互不相交的区域，使得这些区域内部的像素在某种特性上表现出一致性或相似性，而区域间的像素则表现出明显的差异。</p>
<span id="more"></span>

<h1 id="图像直方图"><a href="#图像直方图" class="headerlink" title="图像直方图"></a>图像直方图</h1><h2 id="计算图像的灰度直方图"><a href="#计算图像的灰度直方图" class="headerlink" title="计算图像的灰度直方图"></a>计算图像的灰度直方图</h2><p>在Python中，统计灰度图像的灰度直方图并绘制，通常可以使用matplotlib库来绘制直方图，以及使用numpy库来处理图像数据。此外，PIL（Python Imaging Library）或其分支Pillow库可以用来读取图像文件。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmBI4s.jpg">https://s21.ax1x.com/2024/05/14/pkmBI4s.jpg</a>“ width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”直方图均衡化演示图像，请将此图存储为’your_image_path.jpg’。”&gt;</p>
<p>以下是一个完整的示例，展示如何使用这些库来统计灰度图像的直方图并绘制：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;L&#x27;</span>)  <span class="comment"># 确保图像是灰度格式</span></span><br><span class="line">gray_array = np.array(image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计灰度直方图</span></span><br><span class="line">histogram = np.histogram(gray_array, bins=<span class="number">256</span>, <span class="built_in">range</span>=(<span class="number">0</span>, <span class="number">255</span>))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Grayscale Histogram&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Pixel Intensity&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.plot(histogram, color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">255</span>])  <span class="comment"># 设置x轴的范围</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>Pillow</code>的<code>Image.open()</code>函数打开图像文件，并使用<code>convert(&#39;L&#39;)</code>确保图像是灰度格式。</li>
<li>使用<code>numpy</code>的<code>array()</code>函数将图像转换为一个二维数组，数组中的每个元素代表一个像素的灰度值。</li>
<li>使用<code>numpy</code>的<code>histogram()</code>函数来计算图像的灰度直方图。bins&#x3D;256表示将灰度范围（0到255）分成256个等大小的箱子，range&#x3D;(0, 255)定义了直方图的范围。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>plot()</code>函数绘制直方图，并通过<code>figure()</code>设置图形的大小，<code>xlim()</code>设置x轴的范围。</li>
</ul>
<h2 id="图像直方图均衡化"><a href="#图像直方图均衡化" class="headerlink" title="图像直方图均衡化"></a>图像直方图均衡化</h2><p>直方图均衡化是图像处理领域中利用图像直方图对对比度进行调整的方法。这种方法通常用来增加许多图像的全局对比度，尤其是当图像的有用数据的对比度相当接近的时候。通过这种方法，亮度可以更好地在直方图上分布。这样就可以用于增强局部的对比度而不影响整体的对比度，直方图均衡化通过有效地扩展常用的亮度来实现这种功能。这种方法对于背景和前景都太亮或者太暗的图像非常有用，这种方法尤其是可以带来X光图像中更好的骨骼结构显示以及曝光过度或者曝光不足照片中更好的细节。这种方法的一个主要优势是它是一个相当直观的技术并且是可逆操作，如果已知均衡化函数，那么就可以恢复原始的直方图，并且计算量也不大。这种方法的一个缺点是它对处理的数据不加选择，它可能会增加背景噪声的对比度并且降低有用信号的对比度。</p>
<p>考虑一个离散的灰度图像${x}$，让 $n_i$ 表示灰度 $i$ 出现的次数，这样图像中灰度为 $i$ 的像素的出现概率是:<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/2085ca8d9ae45213103bff0b9c786ca717e55bba">https://wikimedia.org/api/rest_v1/media/math/render/svg/2085ca8d9ae45213103bff0b9c786ca717e55bba</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>$L$是图像中所有的灰度数（通常为256），$n$是图像中所有的像素数，$p_x(i)$实际上是像素值为$i$的图像的直方图，归一化到$[0,1]$。把对应于 $p_x$ 的累积分布函数，定义为：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/4a4c8dccf53825085974fc78c1612f30b8410bf9">https://wikimedia.org/api/rest_v1/media/math/render/svg/4a4c8dccf53825085974fc78c1612f30b8410bf9</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>是图像的累计归一化直方图。</p>
<p>我们创建一个形式为 $y &#x3D; T(x)$ 的变换，对于原始图像中的每个值它就产生一个$y$，这样$y$的累计概率函数就可以在所有值范围内进行线性化，转换公式定义为：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/1786f939592d82e19d416f548c1e3e23ea5302c8">https://wikimedia.org/api/rest_v1/media/math/render/svg/1786f939592d82e19d416f548c1e3e23ea5302c8</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>对于常数K。CDF的性质允许我们做这样的变换（参见逆分布函数）；定义为<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/9322f34cc135a86f8f58fc0d563be67aa11d685f">https://wikimedia.org/api/rest_v1/media/math/render/svg/9322f34cc135a86f8f58fc0d563be67aa11d685f</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>其中 k 属于区间 [0,L)。注意 T 将不同的等级映射到$0..1$域，为了将这些值映射回它们最初的域，需要在结果上应用下面的简单变换：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/19d4b57f5ee70a919eeafad1c8b8019d89ce77ab">https://wikimedia.org/api/rest_v1/media/math/render/svg/19d4b57f5ee70a919eeafad1c8b8019d89ce77ab</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>上面描述了灰度图像上使用直方图均衡化的方法，但是通过将这种方法分别用于图像RGB颜色值的红色、绿色和蓝色分量，从而也可以对彩色图像进行处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 直方图均衡化</span></span><br><span class="line">    equ_image = cv2.equalizeHist(image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和均衡化后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Equalized Image&#x27;</span>)</span><br><span class="line">    plt.imshow(equ_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。如果图像未正确加载，将打印错误消息。</li>
<li>使用<code>cv2.equalizeHist()</code>函数对图像进行直方图均衡化处理。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和均衡化后的图像。</li>
<li>请确保将<code>image_path</code>变量的值替换为你的灰度图像文件的路径。</li>
</ul>
<p>如果你还没有安装OpenCV库，可以使用pip进行安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>

<p>直方图均衡化对于改善低对比度图像的质量非常有效，它通过拉伸直方图分布到整个范围，从而增加图像的全局对比度。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/13/pkm3Pw6.jpg">https://s21.ax1x.com/2024/05/13/pkm3Pw6.jpg</a>“ width &#x3D; 75% div align&#x3D;center &#x2F; title&#x3D;”直方图均衡化的效果示例。”&gt;</p>
<h1 id="图像分割（Image-Segementation）"><a href="#图像分割（Image-Segementation）" class="headerlink" title="图像分割（Image Segementation）"></a>图像分割（Image Segementation）</h1><h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>边缘检测是图像处理中的一项关键技术，用于识别图像中亮度变化最显著的区域，这些区域通常对应于物体的边界。边缘是图像的重要特征，可以用于后续的图像分割、对象识别和图像理解等多种应用。</p>
<p>以下是一些经典的边缘检测算法：</p>
<ol>
<li><p>Sobel算子：通过计算图像中每个像素点的上下和左右邻居的灰度值差异来得出边缘强度。Sobel算子包括两组3x3的卷积核，分别用于检测水平和垂直边缘。</p>
</li>
<li><p>Prewitt算子：类似于Sobel算子，但是卷积核的系数都是1，这使得Prewitt算子对边缘的响应更加“柔和”。</p>
</li>
<li><p>Roberts算子：是一种简单的2x2卷积核，用于检测边缘。Roberts算子通过检测对角线方向的灰度变化来识别边缘。</p>
</li>
<li><p>Canny边缘检测：这是一个多阶段算法，包括噪声降低、梯度计算、非极大值抑制和滞后阈值。Canny算法被认为是最可靠的边缘检测技术之一。</p>
</li>
<li><p>Laplacian算子：是一个二阶导数算子，用于增强图像的边缘。它对图像进行卷积，以突出图像灰度变化的局部极大值和极小值点。</p>
</li>
<li><p>Marr-Hildreth算子或Gaussian of Difference of Gaussians (DoG)：这些算子使用高斯函数和它们的差分来检测边缘。</p>
</li>
</ol>
<h3 id="Sobel算子"><a href="#Sobel算子" class="headerlink" title="Sobel算子"></a>Sobel算子</h3><p>obel算子是一种用于边缘检测的离散微分算子，它结合了高斯平滑和微分求导。该算子用于计算图像明暗程度近似值，根据图像边缘旁边明暗程度把该区域内超过某个数的特定点记为边缘。Sobel算子在Prewitt算子的基础上增加了权重的概念，认为相邻点的距离远近对当前像素点的影响是不同的，距离越近的像素点对应当前像素的影响越大，从而实现图像锐化并突出边缘轮廓。</p>
<p>Sobel算子的边缘定位更准确，常用于噪声较多、灰度渐变的图像。其算法模板如下式所示，其中$G_x$表示水平方向，$G_y$表示垂直方向。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRnjs.jpg">https://s21.ax1x.com/2024/05/14/pkmRnjs.jpg</a>“ width &#x3D; 40% div align&#x3D;center &#x2F; &gt;</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRmcj.jpg">https://s21.ax1x.com/2024/05/14/pkmRmcj.jpg</a>“ width &#x3D; 20% div align&#x3D;center &#x2F; &gt;</p>
<p>在Python中，可以使用OpenCV库中的<code>cv2.Sobel</code>函数来应用Sobel算子。</p>
<h3 id="Canny-边缘检测"><a href="#Canny-边缘检测" class="headerlink" title="Canny 边缘检测"></a>Canny 边缘检测</h3><p>Canny算法是一种著名的边缘检测技术，由John F. Canny在1986年提出。它是一个多阶段算法，旨在从图像中准确地检测出边缘，同时保持边缘的精确定位。Canny算法的基本步骤包括：首先使用高斯滤波器对图像进行平滑以减少噪声；然后计算图像的梯度幅度和方向；接着应用非极大值抑制步骤来细化边缘，只保留局部最大值；最后，通过滞后阈值方法确定和连接边缘像素，这通常涉及两个阈值：高阈值用于检测强边缘，低阈值用于连接这些强边缘以形成完整的边缘。Canny算法因其出色的性能和对边缘的精确识别而广泛应用于计算机视觉和图像处理领域。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRr4O.jpg">https://s21.ax1x.com/2024/05/14/pkmRr4O.jpg</a>“ width &#x3D; 40% div align&#x3D;center &#x2F; title&#x3D;”边缘检测、图像分割演示图像，请将此图存储为’your_iamge_path_02.jpg’。”&gt;</p>
<p>下面是一个使用OpenCV实现Canny边缘检测的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 使用Canny算法进行边缘检测</span></span><br><span class="line">    edges = cv2.Canny(image, <span class="number">100</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和边缘检测后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Edge Detected Image&#x27;</span>)</span><br><span class="line">    plt.imshow(edges, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。</li>
<li>使用<code>cv2.Canny()</code>函数进行Canny边缘检测。这个函数接受三个参数：输入图像和两个阈值，分别用于连接边缘和检测强边缘。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和边缘检测后的图像。</li>
</ul>
<h2 id="阈值分割"><a href="#阈值分割" class="headerlink" title="阈值分割"></a>阈值分割</h2><p>阈值分割是一种基于像素值的图像处理技术，用于将图像的前景和背景分离。该方法通过设定一个或多个阈值，将像素根据其灰度值分配到不同的类别中。单阈值分割使用一个固定值将图像分为两部分，而多阈值分割则可以用于更细致地将图像分为多个区域。阈值分割简单、快速，适用于目标和背景在灰度上具有明显差异的场景。</p>
<p>以下是使用Python和OpenCV库进行简单阈值分割的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用阈值分割</span></span><br><span class="line">    _, threshold_image = cv2.threshold(image, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和阈值分割后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Thresholded Image&#x27;</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。</li>
<li>使用<code>cv2.threshold()</code>函数进行阈值分割，其中<code>threshold_value</code>是设定的阈值，<code>max_value</code>是二值化图像中前景的灰度值（通常设置为255表示白色）。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和阈值分割后的图像。</li>
</ul>
<h2 id="Top-hat-变换"><a href="#Top-hat-变换" class="headerlink" title="Top-hat 变换"></a>Top-hat 变换</h2><p>Top-hat 变换是一种形态学图像处理技术，用于突出图像中相对于背景的较小目标或细节。Top-hat变换的结果是一个图像，其中包含了原始图像与背景（通过开运算处理的图像）之间的差异。这种变换通常用于分离图像中的小物体或特征，这些物体或特征在背景中可能不那么明显。</p>
<p>以下是使用Python和OpenCV库进行Top-hat分割以提取小目标的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">100</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">131</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">132</span>)</span><br><span class="line">    plt.imshow(tophat, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">133</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Segementation&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>定义用于形态学操作的卷积核。</li>
<li>使用<code>cv2.morphologyEx()</code>函数进行Top-hat变换，其中<code>cv2.MORPH_TOPHAT</code>指定了Top-hat操作。</li>
<li>使用<code>matplotlib.pyplot的subplot()</code>和<code>imshow()</code>函数显示原始图像和Top-hat变换结果。</li>
</ul>
<h2 id="膨胀与腐蚀"><a href="#膨胀与腐蚀" class="headerlink" title="膨胀与腐蚀"></a>膨胀与腐蚀</h2><p>图像膨胀与腐蚀是两种基本的形态学图像处理技术，用于修改图像中物体的轮廓和结构。膨胀操作通过增加物体边界像素来“膨胀”或增厚图像中的前景对象，而腐蚀操作则通过移除物体边界像素来“腐蚀”或减薄前景对象。这两种技术可以用于分离相邻对象、平滑轮廓、填充小孔以及从背景中分离出前景对象。</p>
<p>以下是使用Python和OpenCV库进行膨胀与腐蚀操作的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用膨胀操作</span></span><br><span class="line">    dilation = cv2.dilate(threshold_image, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用腐蚀操作</span></span><br><span class="line">    erosion = cv2.erode(threshold_image, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">141</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">142</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">143</span>)</span><br><span class="line">    plt.imshow(dilation, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;dilation image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">144</span>)</span><br><span class="line">    plt.imshow(erosion, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;erosion image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>函数定义一个卷积核，用于膨胀和腐蚀操作。</li>
<li>使用<code>cv2.dilate()</code>函数对图像进行膨胀操作，<code>iterations</code>&#x3D;1表示膨胀操作应用的次数。</li>
<li>使用<code>cv2.erode()</code>函数对图像进行腐蚀操作，同样可以指定腐蚀的次数。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>imshow()</code>函数显示原始图像、膨胀后的图像和腐蚀后的图像。</li>
</ul>
<p>膨胀和腐蚀是形态学图像处理中非常有用的工具，它们可以单独使用，也可以结合使用，或者与其他图像处理技术结合使用，以实现更复杂的图像分析任务。</p>
<h2 id="开运算与闭运算"><a href="#开运算与闭运算" class="headerlink" title="开运算与闭运算"></a>开运算与闭运算</h2><p>开运算和闭运算是两种用于图像处理的形态学操作。开运算首先进行腐蚀操作，然后是对腐蚀结果进行膨胀，目的是移除小的物体或细节（如噪声），并断开接近的物体。闭运算先进行膨胀操作，然后是腐蚀，目的是填充小的空洞和缝隙，以及平滑较大物体的边界。</p>
<p>以下是使用Python和OpenCV库进行开运算与闭运算的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用开运算</span></span><br><span class="line">    opening = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用闭运算</span></span><br><span class="line">    closing = cv2.morphologyEx(threshold_image, cv2.MORPH_CLOSE, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">141</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">142</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">143</span>)</span><br><span class="line">    plt.imshow(opening, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;opening image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">144</span>)</span><br><span class="line">    plt.imshow(closing, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;closing image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>定义卷积核。</li>
<li>使用<code>cv2.morphologyEx()</code>函数进行开运算和闭运算，其中<code>cv2.MORPH_OPEN和cv2.MORPH_CLOSE</code>分别指定了开运算和闭运算。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像、开运算结果和闭运算结果。</li>
</ul>
<h2 id="Watershed-算法"><a href="#Watershed-算法" class="headerlink" title="Watershed 算法"></a>Watershed 算法</h2><p>Watershed算法是一种基于图像分割的技术，用于在灰度图中区分重叠的物体或不同的区域。它模拟了水文学中的分水岭概念，将图像的灰度值视为地形高度，而将局部最小值（如空洞或凹陷）视为集水盆。</p>
<p>在图像处理中，Watershed算法通常用于将接触或重叠的对象分开，特别适用于分离那些在传统阈值分割中难以区分的相邻对象。算法首先标记图像中的已知区域（这些区域可以是用户定义的或通过其他分割技术获得的），然后模拟水流，让“水”从高到低流入这些区域，直到它们相遇或被边界阻挡。相遇的点形成了算法所说的“分水岭”。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmhpjJ.jpg">https://s21.ax1x.com/2024/05/14/pkmhpjJ.jpg</a>“ width &#x3D; 25% div align&#x3D;center &#x2F; title&#x3D;”watershed分割演示图像，请将此图存储为’water_coins.jpg’。”&gt;</p>
<p>下面我们将看到一个关于如何使用距离变换和分水岭分割相互接触的对象的示例。考虑下面的硬币图片，硬币互相接触。即使你启动它，它也会相互接触。我们从找到硬币的大致估计数开始。为此，我们可以使用Otsu的二值化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;water_coins.jpg&#x27;</span>)</span><br><span class="line">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray,<span class="number">0</span>,<span class="number">255</span>,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)</span><br><span class="line">plt.imshow(thresh)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>现在我们需要去除图像中的任何小的白噪声。为此，我们可以使用形态开口。要去除物体上的任何小孔，我们可以使用形态闭合。所以，现在我们可以确定靠近物体中心的区域是前景，而远离物体的区域是背景。唯一我们不确定的区域是硬币的边界区域。</p>
<p>所以我们需要提取出我们确定它们是硬币的区域。侵蚀移除边界像素。所以不管剩下什么，我们都可以确定是硬币。如果物体不互相接触，那就行了。但由于它们彼此接触，另一个好的选择是找到距离变换并应用适当的阈值。下一步我们需要找到我们确信它们不是硬币的地方。为此，我们扩大了结果。膨胀增加对象边界到背景。这样，我们就可以确定结果中背景中的任何区域都是真实的背景，因为边界区域被移除了。见下图。</p>
<p>剩下的区域是那些我们不知道的区域，无论是硬币还是背景。分水岭算法应该找到它。这些区域通常围绕着硬币的边界，前景和背景相交（甚至两个不同的硬币相交）。我们称之为边界。它可以从sure-bg区域减去sure-fg区域得到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># noise removal</span></span><br><span class="line">kernel = np.ones((<span class="number">3</span>,<span class="number">3</span>),np.uint8)</span><br><span class="line">opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sure background area</span></span><br><span class="line">sure_bg = cv2.dilate(opening,kernel,iterations=<span class="number">3</span>)</span><br><span class="line">plt.imshow(sure_bg)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Finding sure foreground area</span></span><br><span class="line">dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,<span class="number">5</span>)</span><br><span class="line">ret, sure_fg = cv2.threshold(dist_transform,<span class="number">0.7</span>*dist_transform.<span class="built_in">max</span>(),<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Finding unknown region</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line">unknown = cv2.subtract(sure_bg,sure_fg)</span><br><span class="line">plt.imshow(sure_fg)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>看看结果。在阈值图像中，我们得到一些区域的硬币，我们确定的硬币，他们现在分离。（在某些情况下，您可能只对前景分割感兴趣，而不是分离相互接触的对象。在这种情况下，你不需要使用距离变换，只要侵蚀就足够了。侵蚀只是另一种提取前景区域的方法，仅此而已。）</p>
<p>现在我们可以确定哪些是硬币的区域，哪些是背景和全部。因此，我们创建了marker（它是一个与原始图像大小相同的数组，但具有int32数据类型）并标记其中的区域。我们确定的区域（无论是前景还是背景）被标记为任何正整数，但是不同的整数，我们不确定的区域被保留为零。我们用这个 连接组件. 它用0标记图像的背景，然后用从1开始的整数标记其他对象。</p>
<p>但我们知道，如果背景标记为0，流域会将其视为未知区域。所以我们想用不同的整数来标记它。相反，我们将标记未知区域，定义为 <code>unknown</code>，使用0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Marker labelling</span></span><br><span class="line">ret, markers = cv2.connectedComponents(sure_fg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add one to all labels so that sure background is not 0, but 1</span></span><br><span class="line">markers = markers+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, mark the region of unknown with zero</span></span><br><span class="line">markers[unknown==<span class="number">255</span>] = <span class="number">0</span></span><br><span class="line">plt.imshow(markers)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>请参见JET colormap中显示的结果。深蓝色区域显示未知区域。当然硬币有不同的颜色。与未知区域相比，确定背景显示为浅蓝色的剩余区域。</p>
<p>现在我们的标记准备好了。现在是最后一步，应用分水岭。然后标记图像将被修改。边界区域将标记为-1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">markers = cv2.watershed(img,markers)</span><br><span class="line">img[markers == -<span class="number">1</span>] = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">plt.imshow(markers)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>请注意，分水岭算法的结果是一个标记图像，其中每个连通区域被赋予了一个唯一的标记值。通常，这个标记图像可以转换为二值图像以可视化分割结果。</p>
<h1 id="数据拟合"><a href="#数据拟合" class="headerlink" title="数据拟合"></a>数据拟合</h1><p>数据拟合是数据分析和科学计算中的一个重要环节，它涉及到使用数学模型来模拟或预测数据。Python是一个功能强大的编程语言，它提供了许多库来帮助我们进行数据拟合，其中最常用的是NumPy和SciPy库。</p>
<h2 id="线性拟合、多项式拟合"><a href="#线性拟合、多项式拟合" class="headerlink" title="线性拟合、多项式拟合"></a>线性拟合、多项式拟合</h2><p>多项式拟合是使用多项式函数来拟合数据的一种方法。在Python中，我们可以使用numpy库中的polyfit函数或者scipy库中的polyval函数来进行多项式拟合。下面是一个使用numpy进行多项式拟合的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们有一些数据点</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">12</span>, <span class="number">18</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numpy的polyfit进行多项式拟合，这里选择3次多项式</span></span><br><span class="line">p = np.polyfit(x, y, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合系数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;多项式系数:&quot;</span>, p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用拟合系数生成多项式函数</span></span><br><span class="line">polynomial = np.poly1d(p)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xx = np.arange(<span class="number">1</span>,<span class="number">5</span>,<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 生成拟合曲线的y值</span></span><br><span class="line">y_poly = polynomial(xx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据点和拟合曲线</span></span><br><span class="line">plt.scatter(x, y, label=<span class="string">&#x27;Data Points&#x27;</span>)</span><br><span class="line">plt.plot(xx, y_poly, label=<span class="string">&#x27;Polynomial Fit&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>在这个示例中，<code>np.polyfit</code>函数用于计算最佳拟合多项式的系数。参数3表示我们希望得到的是3次多项式（即包含x^3,x^2,x和常数项的多项式）。<code>np.poly1d</code>函数用于根据拟合得到的系数创建一个多项式函数对象，这个对象可以用来计算任意x值的多项式函数值。</p>
<p>最后，我们使用matplotlib库绘制了原始数据点和拟合的多项式曲线。通过调整多项式的阶数，我们可以得到与数据拟合程度不同的多项式曲线。</p>
<h2 id="非线性拟合"><a href="#非线性拟合" class="headerlink" title="非线性拟合"></a>非线性拟合</h2><p>指数函数拟合是一种常用的非线性拟合方法，特别适用于数据随时间或空间指数增长或衰减的情况。在Python中，我们可以使用scipy.optimize.curve_fit函数来实现指数函数的拟合。</p>
<p>下面是一个使用指数函数拟合数据的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义指数函数模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exponential_func</span>(<span class="params">x, a, b, c</span>):</span><br><span class="line">    <span class="keyword">return</span> a * np.exp(-b * x) + c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一些模拟数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">0</span>, <span class="number">4</span>, <span class="number">100</span>)  <span class="comment"># x值从0到4，生成100个点</span></span><br><span class="line">y_data = <span class="number">5</span> * np.exp(-<span class="number">0.5</span> * x_data) + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, x_data.size)  <span class="comment"># y值是指数函数加上一些噪声</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用curve_fit进行指数函数拟合</span></span><br><span class="line">params, _ = curve_fit(exponential_func, x_data, y_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合参数</span></span><br><span class="line">a, b, c = params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;拟合参数: a = <span class="subst">&#123;a&#125;</span>, b = <span class="subst">&#123;b&#125;</span>, c = <span class="subst">&#123;c&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用拟合参数生成拟合数据</span></span><br><span class="line">y_fit = exponential_func(x_data, *params)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据点和拟合曲线</span></span><br><span class="line">plt.scatter(x_data, y_data, label=<span class="string">&#x27;Data Points&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(x_data, y_fit, label=<span class="string">&#x27;Exponential Fit&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Exponential Function Fitting&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>我们首先定义了一个指数函数模型exponential_func，它具有三个参数a、b和c。</p>
<p>然后，我们生成了一些模拟的指数增长数据，并添加了一些正态分布的噪声。</p>
<p>使用curve_fit函数进行指数函数拟合。这个函数将我们的指数函数模型和数据作为输入，并返回最佳拟合参数。</p>
<p>我们打印出拟合得到的参数，并使用这些参数生成了拟合的y值。</p>
<p>最后，我们使用matplotlib库绘制了原始数据点和拟合的指数曲线。</p>
<p>请注意，指数函数拟合的准确性很大程度上取决于数据的质量和模型的选择。在实际应用中，你可能需要尝试不同的模型和参数来找到最佳的拟合结果。</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 10：Python 环境下的数字图像目标检测</title>
    <url>/PythonLes11/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>计算机视觉中的“目标检测”是指使用计算机视觉技术来识别图像或视频帧中的对象，并确定它们的位置。目标检测系统通常包括一个预处理步骤，用于改善图像质量，然后是特征提取，用于从图像中提取有用的信息。接下来，一个分类器会被用来确定图像中是否存在特定的对象。最后，一个定位器会提供一个边界框或更精确的轮廓来标记对象的位置。目标检测在自动驾驶、视频监控、医疗成像和许多其他应用中都有广泛的应用。</p>
<span id="more"></span>

<h1 id="课程作业-占总成绩25"><a href="#课程作业-占总成绩25" class="headerlink" title="课程作业 占总成绩25%"></a>课程作业 占总成绩25%</h1><p>给你一个长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成。字符串表示你在一条原点为 0 的数轴上的若干次移动。</p>
<p>你的初始位置就在原点（0），第 i 次移动过程中，你可以根据对应字符选择移动方向：</p>
<p>如果 <code>moves[i] = &#39;L&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向左移动一个单位距离<br>如果 <code>moves[i] = &#39;R&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向右移动一个单位距离<br>移动 n 次之后，请你找出可以到达的距离原点 最远 的点，并返回 从原点到这一点的距离 。</p>
<h1 id="Harris-角点检测算法"><a href="#Harris-角点检测算法" class="headerlink" title="Harris 角点检测算法"></a>Harris 角点检测算法</h1><img src="https://s21.ax1x.com/2024/05/21/pkKzHiV.jpg" width="50%" alt="PMI航空泡沫材料" align=center />

<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;harristest.png&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#result is dilated for marking the corners, not important</span></span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Threshold for an optimal value, it may vary depending on the image.</span></span><br><span class="line">img[dst&gt;<span class="number">0.01</span>*dst.<span class="built_in">max</span>()]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line"></span><br><span class="line">image = Image.fromarray(cv.cvtColor(img,cv.COLOR_BGR2RGB))  </span><br><span class="line">image.show()</span><br></pre></td></tr></table></figure>

<img src="https://opencv24-python-tutorials.readthedocs.io/en/latest/_images/sift_keypoints.jpg" width="70%" alt="Harris 角点检测示例1" align=center />

<img src="https://s21.ax1x.com/2024/05/21/pkM9qRf.png" width="70%" alt="Harris 角点检测示例2" align=center />

<img src="https://s21.ax1x.com/2024/05/21/pkMCPJ0.png" width="70%" alt="Harris 角点检测示例3" align=center />

<p>通常，我们依据以下方式判断二维图像中的三种特征区域：</p>
<p>(1)平坦区域：以该点为中心沿任意方向的图像灰度梯度均较小。</p>
<p>(2)角点区域：以该点为中心沿任意方向的图像灰度梯度均较大。</p>
<p>(3)棱边区域：以该点为中心沿特定方向的图像灰度梯度较大，沿其正交方向图像灰度梯度较小。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzIZn.jpg" width="70%" alt="图像平坦区域、棱边区域与角点区域" align=center />

<p>这与上图中展示的三种区域的典型示例相匹配。Harris提出针对含有独特纹理特征的二维图像，利用基于其局部自相关函数的角点检测算子。它可以准确地检测出图像结构中的角点、棱边以及平坦区域。局部自相关性的定义为：<br>\begin{equation}<br>\label{harrisS1}<br>e(x,y) &#x3D; \sum_{x_i,y_i} W(x_i,y_i)[I(x_i+\Delta x,y_i+\Delta y)-I(x_i,y_i)]^2,<br>\end{equation}<br>这里$I(x_i,y_i)$为二维图像的灰度值，$W(x_i,y_i)$为以点$(x,y)$为中心的高斯函数在点$(x_i,y_i)$处的取值，高斯函数的半高全宽直接决定了检测算子的影响区域半径。$(\Delta x,\Delta y)$为$(x,y)$点指向$(x_i,y_i)$点的二维矢量。</p>
<p>将公式\ref{harrisS1}泰勒展开并保留到一阶分量有：<br>\begin{equation}<br>e(x,y) &#x3D; \hat{S} \begin{bmatrix} \sum_{x_i,y_i} W\cdot I_x^2 &amp; \sum_{x_i,y_i} W\cdot I_x\cdot I_y \\ \sum_{x_i,y_i} W\cdot I_x\cdot I_y &amp; \sum_{x_i,y_i} W\cdot I_y^2 \end{bmatrix} \hat{S}^T &#x3D; \hat{S}\cdot E(x,y)\cdot\hat{S}^T,<br>\end{equation}<br>这里$\hat{S} &#x3D; (\Delta x,\Delta y)$表示偏移矢量，$I_x,I_y$分别为初始二维图像$I(x,y)$沿$x,y$两个方向的偏微分。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzoaq.jpg" width="40%" alt="自相关特征值空间粗线给出角点、棱边、平坦区域分类，细线为响应函数等高线" align=center />

<p>Harris与Stephens教授提出可以通过分析矩阵$E$的一对特征值$\alpha,\beta$的特性来判别角点、棱边和平坦区域，这对特征值包含了足够的与邻域特征有关的局部结构信息。例如，当位于角点区域时，特征值$\alpha,\beta$均较大；而当位于棱边区域时，特征值$\alpha,\beta$总有一个较大而另一个较小；当位于平坦区域时，特征值$\alpha,\beta$均极小。根据这样的特性，Harris提出角点判别指标：<br>\begin{equation}<br>h(x,y) &#x3D; {\rm Det}(E)-k\cdot {\rm Tr}(E)^2 &#x3D; \alpha\beta - k\cdot(\alpha\beta)^2,<br>\end{equation}<br>这里，$k$为自适应参数。判别指标$h(x,y)$的等高线通过图\ref{harris02}中的细线表示，根据上图判断，$h(x,y)$值接近0时，为平坦区域；$h(x,y)$值大于0时，为角点区域；$h(x,y)$值小于0时，为棱边区域。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzTI0.jpg" width="95%" alt="棱边切分技术流程效果图。(a)二值化后的切片图；(b)harris角点判别指标的二维分布；(c)在判别指标二维分布中寻找正值区域的极值点；(d)分离极值点球形邻域（绿色区域）；(e)PMI泡沫原始三维结构；(f)棱边切分技术效果图；(g)胞元尺度上的棱边切分效果。" align=center />

<p>Harris教授提出的方法在二维自然图像中能够获得优异的准确性与鲁棒性。然而当我们面临三维结构图像时，逻辑出现了本质的不同。在三维空间中，区域的分类出现了四种情况，分别是：孔隙、胞壁、棱边、角点区域，它们分别对应于3、2、1和0个维度的平移不变性。当我们考虑如何分离这四种区域时，我们可以从Harris指标的形式出发将其扩展至三维空间；或是从三维灰度图像出发，将三维图像分解为一幅幅二维图像并在二维图像中处理问题。这里作者选择了第二种方案，并取得了有效的结果。</p>
<h2 id="Corner-with-SubPixel-Accuracy"><a href="#Corner-with-SubPixel-Accuracy" class="headerlink" title="Corner with SubPixel Accuracy"></a>Corner with SubPixel Accuracy</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;chessboard2.jpg&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find Harris corners</span></span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line">ret, dst = cv.threshold(dst,<span class="number">0.01</span>*dst.<span class="built_in">max</span>(),<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">dst = np.uint8(dst)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find centroids</span></span><br><span class="line">ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># define the criteria to stop and refine the corners</span></span><br><span class="line">criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, <span class="number">100</span>, <span class="number">0.001</span>)</span><br><span class="line">corners = cv.cornerSubPix(gray,np.float32(centroids),(<span class="number">5</span>,<span class="number">5</span>),(-<span class="number">1</span>,-<span class="number">1</span>),criteria)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Now draw them</span></span><br><span class="line">res = np.hstack((centroids,corners))</span><br><span class="line">res = np.int0(res)</span><br><span class="line">img[res[:,<span class="number">1</span>],res[:,<span class="number">0</span>]]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line">img[res[:,<span class="number">3</span>],res[:,<span class="number">2</span>]] = [<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>]</span><br><span class="line"> </span><br><span class="line">cv.imwrite(<span class="string">&#x27;subpixel5.png&#x27;</span>,img)</span><br></pre></td></tr></table></figure>

<img src="https://docs.opencv.org/4.x/subpixel3.png" width="40%"  align=center />

<h1 id="尺度不变特征变换匹配（SIFT）算法"><a href="#尺度不变特征变换匹配（SIFT）算法" class="headerlink" title="尺度不变特征变换匹配（SIFT）算法"></a>尺度不变特征变换匹配（SIFT）算法</h1><p>尺度不变特征变换匹配（Scale Invariant Feature Transform, SIFT）算法，是David G. Lowe[1]在1999年提出的高效区域检测算法，2004年[2]完善。SIFT算法将图像中检测到的特征点用128维的特征向量进行描述。其本质是在不同的空间尺度上查找特征点，并计算特征点方向。SIFT算法所查找到的特征点是一些十分突出的局部结构，对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是目前领域内非常成熟稳定的局部特征检测算法。</p>
<!-- more -->

<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><ul>
<li><a href="https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html">OpenCV: Introduction to SIFT (Scale-Invariant Feature Transform)</a></li>
</ul>
<figure class="highlight python"><figcaption><span>sift.py, For feature keypoints extraction</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># reading the image</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert to greyscale</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT feature extractor</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect features from the image</span></span><br><span class="line">keypoints, descriptors = sift.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># draw the detected key points</span></span><br><span class="line">sift_image = cv2.drawKeypoints(gray, keypoints, img)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, sift_image)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;table-sift.jpg&quot;</span>, sift_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>feature_match.py, For feature matching</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># read the images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">&#x27;book.jpg&#x27;</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert images to grayscale</span></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT object</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect SIFT features in both images</span></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># create feature matcher</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># match descriptors of both images</span></span><br><span class="line">matches = bf.<span class="keyword">match</span>(descriptors_1,descriptors_2)</span><br><span class="line"><span class="comment"># sort matches by distance</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"><span class="comment"># draw first 50 matches</span></span><br><span class="line">matched_img = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:<span class="number">50</span>], img2, flags=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, matched_img)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;matched_images.jpg&quot;</span>, matched_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>




<h2 id="逻辑框架"><a href="#逻辑框架" class="headerlink" title="逻辑框架"></a>逻辑框架</h2><p>Lowe教授将SIFT算法分解为如下四步：</p>
<blockquote>
<ol>
<li><strong>尺度空间极值检测</strong>：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li><strong>特征点精确定位</strong>：在每个候选的位置上，通过精细拟合模型确定位置和尺度。特征点的选择依赖它们的稳定程度。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li><strong>方向确定</strong>：基于图像局部梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li><strong>特征点描述</strong>：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li>
</ol>
</blockquote>
<h2 id="SIFT算法原理"><a href="#SIFT算法原理" class="headerlink" title="SIFT算法原理"></a>SIFT算法原理</h2><h3 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h3><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p>
<h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。二维空间高斯函数：</p>
<p>\begin{equation}<br>G(x_i,y_i,\sigma)&#x3D;\frac{1}{2\pi\sigma^2}{\rm exp}\left[-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\right]<br>\end{equation}</p>
<p>尺度空间为：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;G(x,y,\sigma)*I(x,y)<br>\end{equation}</p>
<p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma&#x3D;0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大约$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)^2$的矩阵就可以保证相关像素影响。</p>
<h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：</p>
<blockquote>
<ol>
<li>使用低通滤波器（LPF）平滑图像；</li>
<li>平滑图像降采样（通常</li>
</ol>
</blockquote>
<p> 该方式能得到系列尺寸缩小的图片。尺度空间表达和金字塔分辨率表达的明显区别有：</p>
<blockquote>
<ol>
<li>尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；</li>
<li>金字塔多分辨率表达每层分辨率减少固定比率。</li>
</ol>
</blockquote>
<p>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p>
<h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（5$*$5）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xox4Te.png" width="90%" alt="Fig.1 高斯金字塔与高斯差分金字塔。" align=center /></p>
<p>高斯金字塔的构建过程：</p>
<blockquote>
<ol>
<li>先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>将$\sigma$乘以一个比例系数$k$，得到新的平滑因子$\sigma&#x3D;k*\sigma_{old}$，用它来平滑第1组第2层图像，结果图像作为第3层。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为$\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。这样反复执行，就可以得到一共$O$组，每组$L$层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子是前一层图像平滑因子的$k$倍；在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</li>
</ol>
</blockquote>
<h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}<br>\end{equation}</p>
<p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p>
<p>\begin{align}<br>L_i &amp;&#x3D; G_i-Up(G_{i+1})\otimes g \<br>&amp;&#x3D;G_i - PyrUp(G_{i+1}) \<br>\end{align}</p>
<p>式中，$G_i$表示高斯金字塔中第层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p>
<h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示：</p>
<p>\begin{equation}<br>\sigma\nabla^2G &#x3D; \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}<br>\end{equation}</p>
<p>因此，有：</p>
<p>\begin{equation}<br>G(x,y,k\sigma) - G(x,y,\sigma) \approx (k-1)\sigma^2\nabla^2G<br>\end{equation}</p>
<p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。</p>
<h3 id="空间极值点检测"><a href="#空间极值点检测" class="headerlink" title="空间极值点检测"></a>空间极值点检测</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoxIFH.png" width="40%" alt="Fig.2 空间极值点检测。" align=center /></p>
<p>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时$S$在3到5之间。当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p>
<p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p>
<h3 id="特征点精确定位"><a href="#特征点精确定位" class="headerlink" title="特征点精确定位"></a>特征点精确定位</h3><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p>
<h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoz3nK.png" width="60%" alt=" " align=center /></p>
<p>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x,y)$。设$X_0 &#x3D; (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p>
<p>\begin{equation}<br>f(\left[\begin{matrix}x\y\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\y_0\\sigma_0\end{matrix}\right]) + \left[\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right] + \frac{1}{2}\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]^{\rm T}\left[\begin{matrix}<br>\frac{\partial^2 f}{\partial x^2}               &amp; \frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial x \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial y^2}               &amp; \frac{\partial^2 f}{\partial y \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial \sigma} &amp; \frac{\partial^2 f}{\partial y \partial \sigma} &amp; \frac{\partial^2 f}{\partial \sigma^2}          \<br>\end{matrix}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]<br>\end{equation}</p>
<p>若写成矢量形式，则为：</p>
<p>\begin{equation}<br>f(X) &#x3D; f(X_0）+\frac{\partial f^{\rm T}}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^{\rm T}\frac{\partial^2 f}{\partial X^2}(X-X_0)<br>\end{equation}</p>
<p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X}&#x3D;X-X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有：</p>
<p>\begin{equation}<br>\hat{X} &#x3D; -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}<br>\end{equation}</p>
<p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。</p>
<p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p>
<p>\begin{equation}<br>f(\hat{X}) &#x3D; f(X_0) + \frac{1}{2}\frac{\partial f^{\rm T}}{\partial X} \hat{X}<br>\end{equation}</p>
<p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p>
<h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p>
<p>\begin{equation}<br>H &#x3D; \left[\begin{matrix}D_{xx}(x,y)&amp;D_{xy}(x,y)\D_{xy}(x,y)&amp;D_{yy}(x,y)\end{matrix}\right]<br>\end{equation}</p>
<p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha &#x3D; \gamma\beta$，有如下公式：</p>
<p>\begin{align}<br>{\rm Tr}(H) &#x3D; \alpha +\beta\<br>{\rm Det}(H) &#x3D; \alpha\beta<br>\end{align}</p>
<p>其中${\rm Tr}(H)$表示矩阵的迹，${\rm Det}(H)$表示的矩阵的行列式。首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：<br>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &#x3D; \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} &#x3D; \frac{(\gamma+1)^2}{\gamma}<br>\end{equation}</p>
<p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p>
<p>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &lt; \frac{(\gamma_0+1)^2}{\gamma_0}<br>\end{equation}</p>
<p>Lowe论文中阈值为10。</p>
<h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p>
<h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像：</p>
<p>\begin{equation}<br>L(x,y) &#x3D; G(x,y,\sigma)\otimes I(x,y)<br>\end{equation}</p>
<p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下：</p>
<p>\begin{align}<br>m(x,y)      &amp;&#x3D; \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \<br>\theta(x,y) &amp;&#x3D; {\rm arctan}\left[\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right]<br>\end{align}</p>
<h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。</p>
<p>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma&#x3D;0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSeDf.png" width="60%" alt=" " align=center /></p>
<h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值80%能量的峰值时，则将这个方向认为是该特征点的辅方向。所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有15%特征点具有多方向，但这些点对匹配的稳定性至为关键。获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r&#x3D;2.5\sigma$），箭头表示主方向。具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSYrV.png" width="60%" alt=" " align=center /></p>
<h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p>
<h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d^2$个子区域，每个子区域尺寸为$m\sigma$个像元（$d&#x3D;4$，$m&#x3D;3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\sqrt{2}m\sigma(d+1)&#x2F;2$，如下图所示：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTco9A.png" width="35%" alt=" " align=center /></p>
<h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转角，即旋转为特征点的方向。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTc7ct.png" width="60%" alt=" " align=center /></p>
<p>旋转后区域内采样点新的坐标为：</p>
<p>\begin{equation}<br>\begin{pmatrix} x’ \ y’\end{pmatrix} &#x3D; \begin{pmatrix} cos\theta &amp; -sin\theta \ sin\theta &amp; cos\theta\end{pmatrix} \begin{pmatrix} x \ y\end{pmatrix}<br>\end{equation}</p>
<h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d^2$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d^2$，即16个子区域，所以最终共有128个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTcqnf.png" width="60%" alt=" " align=center /></p>
<p>对特征矢量需要加权处理，加权采用$m\sigma d&#x2F;2$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p>
<p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Lowe, David G. “Object recognition from local scale-invariant features.” Proceedings of the seventh IEEE international conference on computer vision. Vol. 2. Ieee, 1999.<br>[2] Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 13：课程作业及评分标准</title>
    <url>/PythonLes14/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>课程作业总结及评分标准。</p>
<span id="more"></span>

<h2 id="课程作业-01-Score-30"><a href="#课程作业-01-Score-30" class="headerlink" title="课程作业 01 (Score: 30%)"></a>课程作业 01 (Score: 30%)</h2><p>在二维平面中构建随机 Vornoi 结构，将交界处壁厚设置为随机数，生成Vornoi结构图像。要求：三维平面的像素画幅、Vornoi的初始种子的数密度、交界处壁厚的随机分布范围可设置，作为输入参数集放置在程序的最开始。输出：二维结构图像，并输出各个交界节点、棱边的结构信息至.txt文件。 </p>
<h3 id="评分标准"><a href="#评分标准" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>10 分：生成标准Vornoi结构图形（Graph）</li>
<li>5 分：生成标准Vornoi结构图像（Image）</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：输出各个交界节点、棱边的结构信息至.txt文件</li>
<li>5 分：总结报告完善程度和逻辑性</li>
<li>？ 分：Vornoi结构的节点（Node）位置进行特殊处理避免结构奇异（附加分）</li>
</ul>
<h2 id="课程作业02-Score-25"><a href="#课程作业02-Score-25" class="headerlink" title="课程作业02 (Score: 25%)"></a>课程作业02 (Score: 25%)</h2><p>给你一个长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成。字符串表示你在一条原点为 0 的数轴上的若干次移动。</p>
<p>你的初始位置就在原点（0），第 i 次移动过程中，你可以根据对应字符选择移动方向：</p>
<p>如果 <code>moves[i] = &#39;L&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向左移动一个单位距离<br>如果 <code>moves[i] = &#39;R&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向右移动一个单位距离<br>移动 n 次之后，请你找出可以到达的距离原点 最远 的点，并返回 从原点到这一点的距离 。</p>
<h3 id="评分标准-1"><a href="#评分标准-1" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>8 分：随机生成长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成</li>
<li>7 分：计算可以到达的距离原点最远的点</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：总结报告完善程度和逻辑性</li>
</ul>
<h2 id="课程作业03-Score-25"><a href="#课程作业03-Score-25" class="headerlink" title="课程作业03 (Score: 25%)"></a>课程作业03 (Score: 25%)</h2><p>构建四组二维空间中的随机分布散点，每组散点符合二维高斯分布，高斯分布的中心点与两个方向的标准差均随机产生，且二维高斯分布的中心点落在[[0,100],[0,100]]的方形区域内。</p>
<p>通过K均值聚类分析方法对上述随机散点执行聚类分析，绘制分类结果，并计算K-means聚类分析的准确率。</p>
<h3 id="评分标准-2"><a href="#评分标准-2" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>5 分：构建四组二维空间中的随机分布散点</li>
<li>5 分：K均值聚类分析方法对上述随机散点执行聚类分析</li>
<li>5 分：计算K-means聚类分析的准确率</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：总结报告完善程度和逻辑性</li>
</ul>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 11：Python 环境下的科研论文绘图</title>
    <url>/PythonLes12/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>在Python中进行科研论文绘图，有几个常用的库可以帮助你实现高质量的图表绘制，以满足学术期刊的要求。Matplotlib是Python中一个非常流行的绘图库，它提供了丰富的功能来创建各种图表。但是，默认的Matplotlib样式可能不符合某些期刊的特定要求。为了解决这个问题，可以使用自定义的样式或者样式库来调整图表的外观。SciencePlots是一个专门为科研图表设计的样式库，它提供了多种符合不同期刊发表要求的主题样式。你可以使用这个库来快速设置图表的样式，以满足期刊的标准。</p>
<p>本文总结了 Matplotlib 以及 Seaborn 用的最多的50个图形，掌握这些图形的绘制，对于数据分析的可视化有莫大的作用，强烈推荐大家阅读后续内容。来源：<a href="https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/">https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/</a></p>
<span id="more"></span>

<p>本文所使用示例数据链接：<a href="https://pan.baidu.com/s/15utfb0uuPu32YHv76S4WUw">https://pan.baidu.com/s/15utfb0uuPu32YHv76S4WUw</a>, 提取码：kn6p</p>
<h1 id="有效图表的重要特征"><a href="#有效图表的重要特征" class="headerlink" title="有效图表的重要特征"></a>有效图表的重要特征</h1><ul>
<li>在不歪曲事实的情况下传达正确和必要的信息。</li>
<li>设计简单，您不必太费力就能理解它。</li>
<li>从审美角度支持信息而不是掩盖信息。</li>
<li>信息没有超负荷。</li>
</ul>
<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><p>在代码运行前先引入下面的设置内容。 当然，单独的图表，可以重新设置显示要素。其中设置了不显示warnings（由于版本变动导致的函数变动），图片以嵌入式方式展示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings; warnings.filterwarnings(action=<span class="string">&#x27;once&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the  fontsize and some other elements</span></span><br><span class="line">large = <span class="number">22</span>; med = <span class="number">16</span>; small = <span class="number">12</span></span><br><span class="line">params = &#123;<span class="string">&#x27;axes.titlesize&#x27;</span>: large,</span><br><span class="line">          <span class="string">&#x27;legend.fontsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;figure.figsize&#x27;</span>: (<span class="number">16</span>, <span class="number">10</span>),</span><br><span class="line">          <span class="string">&#x27;axes.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;xtick.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;ytick.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;figure.titlesize&#x27;</span>: large&#125;</span><br><span class="line">plt.rcParams.update(params)</span><br><span class="line"><span class="comment"># plt.style.use(&#x27;seaborn-whitegrid&#x27;)</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print Version</span></span><br><span class="line"><span class="built_in">print</span>(mpl.__version__)  </span><br><span class="line"><span class="built_in">print</span>(sns.__version__)</span><br><span class="line"><span class="number">3.6</span><span class="number">.2</span></span><br><span class="line"><span class="number">0.12</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>


<h1 id="关联-（Correlation）"><a href="#关联-（Correlation）" class="headerlink" title="关联 （Correlation）"></a>关联 （Correlation）</h1><p>关联图表用于可视化2个或更多变量之间的关系。 也就是说，一个变量如何相对于另一个变化。</p>
<h2 id="点线图（Scatter-and-line-plot）"><a href="#点线图（Scatter-and-line-plot）" class="headerlink" title="点线图（Scatter and line plot）"></a>点线图（Scatter and line plot）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f = interp1d(x, y)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">41</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>, xnew, f(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;cubic&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X-axis&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y-axis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Multiple Lines Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-1.png" width="75%" alt="" align=center />

<h3 id="plt-plot-函数"><a href="#plt-plot-函数" class="headerlink" title="plt.plot()函数"></a>plt.plot()函数</h3><p>函数<code>matplotlib.pyplot.plot()</code>将多组数据对绘制为点线图，形如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot(x, y, color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>,linewidth=<span class="number">2</span>, markersize=<span class="number">12</span>)</span><br><span class="line"><span class="comment"># Plot y versus x as lines and/or markers.</span></span><br><span class="line"></span><br><span class="line">plot(x,y,data=obj)</span><br></pre></td></tr></table></figure>
<p>其中</p>
<ul>
<li><code>x,y</code>表示需要绘制的自变量与应变量；</li>
<li><code>color=&#39;green&#39;</code>可以指定该组数据绘制的颜色，可选项包括<code>b g r c m y k w</code>，详见<a href="https://matplotlib.org/stable/users/explain/colors/colors.html#colors-def">此处说明文档</a>。</li>
<li><code>Marker=&#39;o&#39;</code>表示绘制点的形状，可选项包括<code>.  ,  o  v  ^  &lt;  &gt;  1  2  3  4  8  s  p  P  *  h  H  +  x  X  D  d  |  _</code>；</li>
<li><code>linestyle = &#39;dashed&#39;</code>表示线的形状，可选项包括<code>-  --   -.   :</code></li>
</ul>
<p>一种比较特殊的写法是把这些标识组合在一起，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;b&#x27;</span>    <span class="comment"># blue markers with default shape</span></span><br><span class="line"><span class="string">&#x27;or&#x27;</span>   <span class="comment"># red circles</span></span><br><span class="line"><span class="string">&#x27;-g&#x27;</span>   <span class="comment"># green solid line</span></span><br><span class="line"><span class="string">&#x27;--&#x27;</span>   <span class="comment"># dashed line with default color</span></span><br><span class="line"><span class="string">&#x27;^k:&#x27;</span>  <span class="comment"># black triangle_up markers connected by a dotted line</span></span><br></pre></td></tr></table></figure>

<h3 id="单自变量多因变量的情况"><a href="#单自变量多因变量的情况" class="headerlink" title="单自变量多因变量的情况"></a>单自变量多因变量的情况</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">y = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">plt.plot(x, y,<span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line"><span class="comment"># is equivalent to:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># for col in range(y.shape[1]):</span></span><br><span class="line"><span class="comment">#     plt.plot(x, y[:, col])</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h3 id="稍复杂些的情况"><a href="#稍复杂些的情况" class="headerlink" title="稍复杂些的情况"></a>稍复杂些的情况</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span></span><br><span class="line">r0 = <span class="number">0.6</span></span><br><span class="line">x = <span class="number">0.9</span> * np.random.rand(N)</span><br><span class="line">y = <span class="number">0.9</span> * np.random.rand(N)</span><br><span class="line">area = (<span class="number">20</span> * np.random.rand(N))**<span class="number">2</span>  <span class="comment"># 0 to 10 point radii</span></span><br><span class="line">c = np.sqrt(area)</span><br><span class="line">r = np.sqrt(x ** <span class="number">2</span> + y ** <span class="number">2</span>)</span><br><span class="line">area1 = np.ma.masked_where(r &lt; r0, area)</span><br><span class="line">area2 = np.ma.masked_where(r &gt;= r0, area)</span><br><span class="line">plt.scatter(x, y, s=area1, marker=<span class="string">&#x27;^&#x27;</span>, c=c)</span><br><span class="line">plt.scatter(x, y, s=area2, marker=<span class="string">&#x27;o&#x27;</span>, c=c)</span><br><span class="line"><span class="comment"># Show the boundary between the regions:</span></span><br><span class="line">theta = np.arange(<span class="number">0</span>, np.pi / <span class="number">2</span>, <span class="number">0.01</span>)</span><br><span class="line">plt.plot(r0 * np.cos(theta), r0 * np.sin(theta))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_scatter_masked_001.png" width="75%" alt="" align=center />

<h3 id="plt-scatter-函数"><a href="#plt-scatter-函数" class="headerlink" title="plt.scatter()函数"></a>plt.scatter()函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matplotlib.pyplot.scatter(x, y, s=<span class="literal">None</span>, c=<span class="literal">None</span>, marker=<span class="literal">None</span>, cmap=<span class="literal">None</span>, norm=<span class="literal">None</span>, vmin=<span class="literal">None</span>, vmax=<span class="literal">None</span>,</span><br><span class="line"> alpha=<span class="literal">None</span>, linewidths=<span class="literal">None</span>, *, edgecolors=<span class="literal">None</span>, plotnonfinite=<span class="literal">False</span>, data=<span class="literal">None</span>, **kwargs)</span><br><span class="line"><span class="comment"># A scatter plot of y vs. x with varying marker size and/or color.</span></span><br></pre></td></tr></table></figure>

<p>其中，</p>
<ul>
<li>x,y：指定自变量与应变量；</li>
<li>s：标记点的尺寸，如不指定默认值为<code>rcParams[&#39;lines.markersize&#39;] ** 2</code>；</li>
<li>c：标记点的颜色；</li>
<li>marker：标记的形状类别；</li>
<li>cmap：用于将标量数据映射到颜色的Colormap实例或已注册的Colormap名称。如果c为RGB(A)，则忽略此参数。</li>
<li>norm：在使用cmap映射到颜色之前，将标量数据缩放到[0,1]范围的归一化方法。默认情况下，使用线性缩放，将最低值映射为0，最高值映射为1。</li>
<li>alpha：不透明度，取值在[0,1]。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = <span class="number">50</span></span><br><span class="line">x = np.random.rand(N)</span><br><span class="line">y = np.random.rand(N)</span><br><span class="line">colors = np.random.rand(N)</span><br><span class="line">area = (<span class="number">30</span> * np.random.rand(N))**<span class="number">2</span>  <span class="comment"># 0 to 15 point radii</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x, y, s=area, c=colors, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_scatter_001.png" width="75%" alt="" align=center />

<h3 id="极图"><a href="#极图" class="headerlink" title="极图"></a>极图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute areas and colors</span></span><br><span class="line">N = <span class="number">150</span></span><br><span class="line">r = <span class="number">2</span> * np.random.rand(N)</span><br><span class="line">theta = <span class="number">2</span> * np.pi * np.random.rand(N)</span><br><span class="line">area = <span class="number">200</span> * r**<span class="number">2</span></span><br><span class="line">colors = theta</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_001.png" width="75%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line"></span><br><span class="line">ax.set_rorigin(-<span class="number">2.5</span>)</span><br><span class="line">ax.set_theta_zero_location(<span class="string">&#x27;W&#x27;</span>, offset=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_002.png" width="75%" alt="" align=center />


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line"></span><br><span class="line">ax.set_thetamin(<span class="number">45</span>)</span><br><span class="line">ax.set_thetamax(<span class="number">135</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_003.png" width="75%" alt="" align=center />


<h2 id="二维信号的可视化"><a href="#二维信号的可视化" class="headerlink" title="二维信号的可视化"></a>二维信号的可视化</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x*(<span class="number">1</span>-x)*np.cos(<span class="number">4</span>*np.pi*x) * np.sin(<span class="number">4</span>*np.pi*y**<span class="number">2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">grid_x, grid_y = np.mgrid[<span class="number">0</span>:<span class="number">1</span>:<span class="number">100j</span>, <span class="number">0</span>:<span class="number">1</span>:<span class="number">200j</span>]</span><br><span class="line"></span><br><span class="line">np.mgrid[<span class="number">0</span>:<span class="number">5</span>, <span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line">array([[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]],</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]]])</span><br><span class="line"></span><br><span class="line">np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">5j</span>]</span><br><span class="line">array([-<span class="number">1.</span> , -<span class="number">0.5</span>,  <span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">1.</span> ])</span><br></pre></td></tr></table></figure>

<p>但我们只知道它在1000个数据点的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.random.random((<span class="number">1000</span>, <span class="number">2</span>))</span><br><span class="line">values = func(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>这可以通过以下方式完成 <code>griddata</code> –下面我们将尝试所有的插值方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> griddata</span><br><span class="line"></span><br><span class="line">grid_z0 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">grid_z1 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">grid_z2 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;cubic&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到，所有方法都在一定程度上重现了准确的结果，但对于此光滑函数，三次样条插值提供了最好的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.imshow(func(grid_x, grid_y).T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>,cmap = <span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;k.&#x27;</span>, ms=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.imshow(grid_z0.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Nearest&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.imshow(grid_z1.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Linear&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.imshow(grid_z2.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic&#x27;</span>)</span><br><span class="line">plt.gcf().set_size_inches(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-3.png" width="80%" alt="" align=center />


<h2 id="散点图（Scatter-plot）"><a href="#散点图（Scatter-plot）" class="headerlink" title="散点图（Scatter plot）"></a>散点图（Scatter plot）</h2><p>散点图是用于研究两个变量之间关系的经典的和基本的图表。 如果数据中有多个组，则可能需要以不同颜色可视化每个组。 在 matplotlib 中，您可以使用 <code>plt.scatter()</code> 方便地执行此操作。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1QzOe.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import dataset </span></span><br><span class="line">midwest = pd.read_csv(<span class="string">&#x27;midwest_filter.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Data </span></span><br><span class="line"><span class="comment"># Create as many colors as there are unique midwest[&#x27;category&#x27;]</span></span><br><span class="line">categories = np.unique(midwest[<span class="string">&#x27;category&#x27;</span>])</span><br><span class="line">colors = [plt.cm.tab10(i/<span class="built_in">float</span>(<span class="built_in">len</span>(categories)-<span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(categories))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw Plot for Each Category</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, category <span class="keyword">in</span> <span class="built_in">enumerate</span>(categories):</span><br><span class="line">    plt.scatter(<span class="string">&#x27;area&#x27;</span>, <span class="string">&#x27;poptotal&#x27;</span>, data=midwest.loc[midwest.category==category, :], s=<span class="number">20</span>, cmap=colors[i], label=<span class="built_in">str</span>(category))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(xlim=(<span class="number">0.0</span>, <span class="number">0.1</span>), ylim=(<span class="number">0</span>, <span class="number">90000</span>),xlabel=<span class="string">&#x27;Area&#x27;</span>, ylabel=<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Scatterplot of Midwest Area vs Population&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.legend(fontsize=<span class="number">12</span>)    </span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># d:\anaconda3\lib\site-packages\ipykernel\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.</span></span><br><span class="line"><span class="comment">#  and should_run_async(code)</span></span><br></pre></td></tr></table></figure>

<p><code>np.unique()</code>:列表元素去重<br>当前的图表和子图可以使用<code>plt.gcf()</code>和<code>plt.gca()</code>获得,分别表示”Get Current Figure”和”Get Current Axes”，这样可以方便的设置x，y轴显示范围及标签。<br><code>enumerate(sequence, [start=0])</code>函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<h2 id="带边界的气泡图（Bubble-plot-with-Encircling）"><a href="#带边界的气泡图（Bubble-plot-with-Encircling）" class="headerlink" title="带边界的气泡图（Bubble plot with Encircling）"></a>带边界的气泡图（Bubble plot with Encircling）</h2><p>有时，您希望在边界内显示一组点以强调其重要性。 在这个例子中，你从数据框中获取记录，并用下面代码中描述的 encircle() 来使边界显示出来。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1lpeH.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> patches</span><br><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> ConvexHull</span><br><span class="line"><span class="keyword">import</span> warnings; warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: Prepare Data</span></span><br><span class="line">midwest = pd.read_csv(<span class="string">&quot;midwest_filter.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># As many colors as there are unique midwest[&#x27;category&#x27;]</span></span><br><span class="line">categories = np.unique(midwest[<span class="string">&#x27;category&#x27;</span>])</span><br><span class="line">colors = [plt.cm.tab10(i/<span class="built_in">float</span>(<span class="built_in">len</span>(categories)-<span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(categories))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: Draw Scatterplot with unique color for each category</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, category <span class="keyword">in</span> <span class="built_in">enumerate</span>(categories):</span><br><span class="line">    plt.scatter(<span class="string">&#x27;area&#x27;</span>, <span class="string">&#x27;poptotal&#x27;</span>, data=midwest.loc[midwest.category==category, :], </span><br><span class="line">                s=<span class="string">&#x27;dot_size&#x27;</span>, cmap=colors[i], label=<span class="built_in">str</span>(category), edgecolors=<span class="string">&#x27;black&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: Encircling</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/44575681/how-do-i-encircle-different-data-sets-in-scatter-plot</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encircle</span>(<span class="params">x,y, ax=<span class="literal">None</span>, **kw</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ax: ax=plt.gca()</span><br><span class="line">    p = np.c_[x,y]</span><br><span class="line">    hull = ConvexHull(p)</span><br><span class="line">    poly = plt.Polygon(p[hull.vertices,:], **kw)</span><br><span class="line">    ax.add_patch(poly)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select data to be encircled</span></span><br><span class="line">midwest_encircle_data = midwest.loc[midwest.state==<span class="string">&#x27;IN&#x27;</span>, :]                         </span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw polygon surrounding vertices    </span></span><br><span class="line">encircle(midwest_encircle_data.area, midwest_encircle_data.poptotal, ec=<span class="string">&quot;k&quot;</span>, fc=<span class="string">&quot;gold&quot;</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">encircle(midwest_encircle_data.area, midwest_encircle_data.poptotal, ec=<span class="string">&quot;firebrick&quot;</span>, fc=<span class="string">&quot;none&quot;</span>, linewidth=<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(xlim=(<span class="number">0.0</span>, <span class="number">0.1</span>), ylim=(<span class="number">0</span>, <span class="number">90000</span>),xlabel=<span class="string">&#x27;Area&#x27;</span>, ylabel=<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Bubble Plot with Encircling&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.legend(fontsize=<span class="number">12</span>)    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><code>np.r_</code>是按列连接两个矩阵，就是把两矩阵上下相加，要求列数相等，类似于pandas中的concat()。<br><code>np.c_</code>是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()。<br><code>ConvexHull</code>：给定二维平面上的点集，凸包就是将最外层的点连接起来构成的凸多边型，它能包含点集中所有的点。</p>
<h2 id="带线性回归最佳拟合线的散点图-（Scatter-plot-with-linear-regression-line-of-best-fit）"><a href="#带线性回归最佳拟合线的散点图-（Scatter-plot-with-linear-regression-line-of-best-fit）" class="headerlink" title="带线性回归最佳拟合线的散点图 （Scatter plot with linear regression line of best fit）"></a>带线性回归最佳拟合线的散点图 （Scatter plot with linear regression line of best fit）</h2><p>如果你想了解两个变量如何相互改变，那么最佳拟合线就是常用的方法。 下图显示了数据中各组之间最佳拟合线的差异。要禁用分组并仅为整个数据集绘制一条最佳拟合线，请从下面的<code>sns.lmplot()</code>调用中删除<code>hue =&#39;cyl&#39;</code>参数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fXy6.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df_select = df.loc[df.cyl.isin([<span class="number">4</span>,<span class="number">8</span>]), :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">gridobj = sns.lmplot(x=<span class="string">&quot;displ&quot;</span>, y=<span class="string">&quot;hwy&quot;</span>, hue=<span class="string">&quot;cyl&quot;</span>, data=df_select, </span><br><span class="line">                     aspect=<span class="number">1.6</span>, robust=<span class="literal">True</span>, palette=<span class="string">&#x27;tab10&#x27;</span>, </span><br><span class="line">                     scatter_kws=<span class="built_in">dict</span>(s=<span class="number">60</span>, linewidths=<span class="number">.7</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">gridobj.<span class="built_in">set</span>(xlim=(<span class="number">0.5</span>, <span class="number">7.5</span>), ylim=(<span class="number">0</span>, <span class="number">50</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Scatterplot with line of best fit grouped by number of cylinders&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>如果报错<code>No module named &#39;statsmodels&#39;</code>，执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install statsmodels</span><br></pre></td></tr></table></figure>

<h2 id="针对每列绘制线性回归线"><a href="#针对每列绘制线性回归线" class="headerlink" title="针对每列绘制线性回归线"></a>针对每列绘制线性回归线</h2><p>或者，可以在其每列中显示每个组的最佳拟合线。 可以通过在<code>sns.lmplot()</code>中设置<code>col=groupingcolumn</code>参数来实现，如下：</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fbWR.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df_select = df.loc[df.cyl.isin([<span class="number">4</span>,<span class="number">8</span>]), :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Each line in its own column</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">gridobj = sns.lmplot(x=<span class="string">&quot;displ&quot;</span>, y=<span class="string">&quot;hwy&quot;</span>, </span><br><span class="line">                     data=df_select, </span><br><span class="line">                     robust=<span class="literal">True</span>, </span><br><span class="line">                     palette=<span class="string">&#x27;Set1&#x27;</span>, </span><br><span class="line">                     col=<span class="string">&quot;cyl&quot;</span>,</span><br><span class="line">                     scatter_kws=<span class="built_in">dict</span>(s=<span class="number">60</span>, linewidths=<span class="number">.7</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">gridobj.<span class="built_in">set</span>(xlim=(<span class="number">0.5</span>, <span class="number">7.5</span>), ylim=(<span class="number">0</span>, <span class="number">50</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="边缘直方图-（Marginal-Histogram）"><a href="#边缘直方图-（Marginal-Histogram）" class="headerlink" title="边缘直方图 （Marginal Histogram）"></a>边缘直方图 （Marginal Histogram）</h2><p>边缘直方图具有沿 X 和 Y 轴变量的直方图。 这用于可视化 X 和 Y 之间的关系以及单独的 X 和 Y 的单变量分布。 这种图经常用于探索性数据分析（EDA）。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fOQx.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Fig and gridspec</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">grid = plt.GridSpec(<span class="number">4</span>, <span class="number">4</span>, hspace=<span class="number">0.5</span>, wspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the axes</span></span><br><span class="line">ax_main = fig.add_subplot(grid[:-<span class="number">1</span>, :-<span class="number">1</span>])</span><br><span class="line">ax_right = fig.add_subplot(grid[:-<span class="number">1</span>, -<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line">ax_bottom = fig.add_subplot(grid[-<span class="number">1</span>, <span class="number">0</span>:-<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatterplot on main ax</span></span><br><span class="line">ax_main.scatter(<span class="string">&#x27;displ&#x27;</span>, <span class="string">&#x27;hwy&#x27;</span>, s=df.cty*<span class="number">4</span>, c=df.manufacturer.astype(<span class="string">&#x27;category&#x27;</span>).cat.codes, alpha=<span class="number">.9</span>, data=df, cmap=<span class="string">&quot;tab10&quot;</span>, edgecolors=<span class="string">&#x27;gray&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram on the right</span></span><br><span class="line">ax_bottom.hist(df.displ, <span class="number">40</span>, histtype=<span class="string">&#x27;stepfilled&#x27;</span>, orientation=<span class="string">&#x27;vertical&#x27;</span>, color=<span class="string">&#x27;deeppink&#x27;</span>)</span><br><span class="line">ax_bottom.invert_yaxis()</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram in the bottom</span></span><br><span class="line">ax_right.hist(df.hwy, <span class="number">40</span>, histtype=<span class="string">&#x27;stepfilled&#x27;</span>, orientation=<span class="string">&#x27;horizontal&#x27;</span>, color=<span class="string">&#x27;deeppink&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">ax_main.<span class="built_in">set</span>(title=<span class="string">&#x27;Scatterplot with Histograms \n displ vs hwy&#x27;</span>, xlabel=<span class="string">&#x27;displ&#x27;</span>, ylabel=<span class="string">&#x27;hwy&#x27;</span>)</span><br><span class="line">ax_main.title.set_fontsize(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):</span><br><span class="line">    item.set_fontsize(<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">xlabels = ax_main.get_xticks().tolist()</span><br><span class="line">ax_main.set_xticklabels(xlabels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="边缘箱形图-（Marginal-Boxplot）"><a href="#边缘箱形图-（Marginal-Boxplot）" class="headerlink" title="边缘箱形图 （Marginal Boxplot）"></a>边缘箱形图 （Marginal Boxplot）</h2><p>边缘箱图与边缘直方图具有相似的用途。 然而，箱线图有助于精确定位 X 和 Y 的中位数、第25和第75百分位数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fLS1.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Fig and gridspec</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">grid = plt.GridSpec(<span class="number">4</span>, <span class="number">4</span>, hspace=<span class="number">0.5</span>, wspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the axes</span></span><br><span class="line">ax_main = fig.add_subplot(grid[:-<span class="number">1</span>, :-<span class="number">1</span>])</span><br><span class="line">ax_right = fig.add_subplot(grid[:-<span class="number">1</span>, -<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line">ax_bottom = fig.add_subplot(grid[-<span class="number">1</span>, <span class="number">0</span>:-<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatterplot on main ax</span></span><br><span class="line">ax_main.scatter(<span class="string">&#x27;displ&#x27;</span>, <span class="string">&#x27;hwy&#x27;</span>, s=df.cty*<span class="number">5</span>, c=df.manufacturer.astype(<span class="string">&#x27;category&#x27;</span>).cat.codes, alpha=<span class="number">.9</span>, data=df, cmap=<span class="string">&quot;Set1&quot;</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a graph in each part</span></span><br><span class="line">sns.boxplot(df.hwy, ax=ax_right, orient=<span class="string">&quot;v&quot;</span>)</span><br><span class="line">sns.boxplot(df.displ, ax=ax_bottom, orient=<span class="string">&quot;h&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations ------------------</span></span><br><span class="line"><span class="comment"># Remove x axis name for the boxplot</span></span><br><span class="line">ax_bottom.<span class="built_in">set</span>(xlabel=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">ax_right.<span class="built_in">set</span>(ylabel=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Main Title, Xlabel and YLabel</span></span><br><span class="line">ax_main.<span class="built_in">set</span>(title=<span class="string">&#x27;Scatterplot with Histograms \n displ vs hwy&#x27;</span>, xlabel=<span class="string">&#x27;displ&#x27;</span>, ylabel=<span class="string">&#x27;hwy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set font size of different components</span></span><br><span class="line">ax_main.title.set_fontsize(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):</span><br><span class="line">    item.set_fontsize(<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="相关图-（Correllogram）"><a href="#相关图-（Correllogram）" class="headerlink" title="相关图 （Correllogram）"></a>相关图 （Correllogram）</h2><p>相关图用于直观地查看给定数据框（或二维数组）中所有可能的数值变量对之间的相关度量。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fHY9.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Dataset</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.heatmap(df.corr(), xticklabels=df.corr().columns, yticklabels=df.corr().columns, cmap=<span class="string">&#x27;RdYlGn&#x27;</span>, center=<span class="number">0</span>, annot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.title(<span class="string">&#x27;Correlogram of mtcars&#x27;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="矩阵图-（Pairwise-Plot）"><a href="#矩阵图-（Pairwise-Plot）" class="headerlink" title="矩阵图 （Pairwise Plot）"></a>矩阵图 （Pairwise Plot）</h2><p>矩阵图是探索性分析中的最爱，用于理解所有可能的数值变量对之间的关系。 它是双变量分析的必备工具。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1hSTe.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load Dataset</span></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;iris&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.pairplot(df, kind=<span class="string">&quot;scatter&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, plot_kws=<span class="built_in">dict</span>(s=<span class="number">80</span>, edgecolor=<span class="string">&quot;white&quot;</span>, linewidth=<span class="number">2.5</span>))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># &lt;Figure size 800x640 with 0 Axes&gt;</span></span><br></pre></td></tr></table></figure>

<img src="https://s21.ax1x.com/2024/05/28/pk1oUDx.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load Dataset</span></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;iris&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.pairplot(df, kind=<span class="string">&quot;reg&quot;</span>, hue=<span class="string">&quot;species&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># &lt;Figure size 800x640 with 0 Axes&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="偏差-（Deviation）"><a href="#偏差-（Deviation）" class="headerlink" title="偏差 （Deviation）"></a>偏差 （Deviation）</h1><h2 id="发散型条形图-（Diverging-Bars）"><a href="#发散型条形图-（Diverging-Bars）" class="headerlink" title="发散型条形图 （Diverging Bars）"></a>发散型条形图 （Diverging Bars）</h2><p>如果您想根据单个指标查看项目的变化情况，并可视化此差异的顺序和数量，那么散型条形图 （Diverging Bars） 是一个很好的工具。 它有助于快速区分数据中组的性能，并且非常直观，并且可以立即传达这一点。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fjOK.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z, color=df.colors, alpha=<span class="number">0.4</span>, linewidth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(ylabel=<span class="string">&#x27;$Model$&#x27;</span>, xlabel=<span class="string">&#x27;$Mileage$&#x27;</span>)</span><br><span class="line">plt.yticks(df.index, df.cars, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="发散型文本-（Diverging-Texts）"><a href="#发散型文本-（Diverging-Texts）" class="headerlink" title="发散型文本 （Diverging Texts）"></a>发散型文本 （Diverging Texts）</h2><p>发散型文本 （Diverging Texts）与发散型条形图 （Diverging Bars）相似，如果你想以一种漂亮和可呈现的方式显示图表中每个项目的价值，就可以使用这种方法。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fxeO.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">14</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z)</span><br><span class="line"><span class="keyword">for</span> x, y, tex <span class="keyword">in</span> <span class="built_in">zip</span>(df.mpg_z, df.index, df.mpg_z):</span><br><span class="line">    t = plt.text(x, y, <span class="built_in">round</span>(tex, <span class="number">2</span>), horizontalalignment=<span class="string">&#x27;right&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;left&#x27;</span>, </span><br><span class="line">                 verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations    </span></span><br><span class="line">plt.yticks(df.index, df.cars, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Text Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim(-<span class="number">2.5</span>, <span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="发散型包点图-（Diverging-Dot-Plot）"><a href="#发散型包点图-（Diverging-Dot-Plot）" class="headerlink" title="发散型包点图 （Diverging Dot Plot）"></a>发散型包点图 （Diverging Dot Plot）</h2><p>发散型包点图 （Diverging Dot Plot）也类似于发散型条形图 （Diverging Bars）。 然而，与发散型条形图 （Diverging Bars）相比，条的缺失减少了组之间的对比度和差异。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fzwD.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;darkgreen&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">16</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.scatter(df.mpg_z, df.index, s=<span class="number">450</span>, alpha=<span class="number">.6</span>, color=df.colors)</span><br><span class="line"><span class="keyword">for</span> x, y, tex <span class="keyword">in</span> <span class="built_in">zip</span>(df.mpg_z, df.index, df.mpg_z):</span><br><span class="line">    t = plt.text(x, y, <span class="built_in">round</span>(tex, <span class="number">1</span>), horizontalalignment=<span class="string">&#x27;center&#x27;</span>, </span><br><span class="line">                 verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;white&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line"><span class="comment"># Lighten borders</span></span><br><span class="line">plt.gca().spines[<span class="string">&quot;top&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;bottom&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;right&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;left&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line"></span><br><span class="line">plt.yticks(df.index, df.cars)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Dotplot of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$Mileage$&#x27;</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim(-<span class="number">2.5</span>, <span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="带标记的发散型棒棒糖图-（Diverging-Lollipop-Chart-with-Markers）"><a href="#带标记的发散型棒棒糖图-（Diverging-Lollipop-Chart-with-Markers）" class="headerlink" title="带标记的发散型棒棒糖图 （Diverging Lollipop Chart with Markers）"></a>带标记的发散型棒棒糖图 （Diverging Lollipop Chart with Markers）</h2><p>带标记的棒棒糖图通过强调您想要引起注意的任何重要数据点并在图表中适当地给出推理，提供了一种对差异进行可视化的灵活方式。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oJ29.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = <span class="string">&#x27;black&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># color fiat differently</span></span><br><span class="line">df.loc[df.cars == <span class="string">&#x27;Fiat X1-9&#x27;</span>, <span class="string">&#x27;colors&#x27;</span>] = <span class="string">&#x27;darkorange&#x27;</span></span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">16</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z, color=df.colors, alpha=<span class="number">0.4</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.scatter(df.mpg_z, df.index, color=df.colors, s=[<span class="number">600</span> <span class="keyword">if</span> x == <span class="string">&#x27;Fiat X1-9&#x27;</span> <span class="keyword">else</span> <span class="number">300</span> <span class="keyword">for</span> x <span class="keyword">in</span> df.cars], alpha=<span class="number">0.6</span>)</span><br><span class="line">plt.yticks(df.index, df.cars)</span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line">plt.annotate(<span class="string">&#x27;Mercedes Models&#x27;</span>, xy=(<span class="number">0.0</span>, <span class="number">11.0</span>), xytext=(<span class="number">1.0</span>, <span class="number">11</span>), xycoords=<span class="string">&#x27;data&#x27;</span>, </span><br><span class="line">            fontsize=<span class="number">15</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">            bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&#x27;square&#x27;</span>, fc=<span class="string">&#x27;firebrick&#x27;</span>),</span><br><span class="line">            arrowprops=<span class="built_in">dict</span>(arrowstyle=<span class="string">&#x27;-[, widthB=2.0, lengthB=1.5&#x27;</span>, lw=<span class="number">2.0</span>, color=<span class="string">&#x27;steelblue&#x27;</span>), color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add Patches</span></span><br><span class="line">p1 = patches.Rectangle((-<span class="number">2.0</span>, -<span class="number">1</span>), width=<span class="number">.3</span>, height=<span class="number">3</span>, alpha=<span class="number">.2</span>, facecolor=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">p2 = patches.Rectangle((<span class="number">1.5</span>, <span class="number">27</span>), width=<span class="number">.8</span>, height=<span class="number">5</span>, alpha=<span class="number">.2</span>, facecolor=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.gca().add_patch(p1)</span><br><span class="line">plt.gca().add_patch(p2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorate</span></span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="面积图-（Area-Chart）"><a href="#面积图-（Area-Chart）" class="headerlink" title="面积图 （Area Chart）"></a>面积图 （Area Chart）</h2><p>通过对轴和线之间的区域进行着色，面积图不仅强调峰和谷，而且还强调高点和低点的持续时间。 高点持续时间越长，线下面积越大。<br>这里annotate的函数值得学习，台风路径信息的框框或者文字避让算法，都需要用到这个函数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1o15F.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;economics.csv&quot;</span>, parse_dates=[<span class="string">&#x27;date&#x27;</span>]).head(<span class="number">100</span>)</span><br><span class="line">x = np.arange(df.shape[<span class="number">0</span>])</span><br><span class="line">y_returns = (df.psavert.diff().fillna(<span class="number">0</span>)/df.psavert.shift(<span class="number">1</span>)).fillna(<span class="number">0</span>) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.fill_between(x[<span class="number">1</span>:], y_returns[<span class="number">1</span>:], <span class="number">0</span>, where=y_returns[<span class="number">1</span>:] &gt;= <span class="number">0</span>, facecolor=<span class="string">&#x27;green&#x27;</span>, interpolate=<span class="literal">True</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.fill_between(x[<span class="number">1</span>:], y_returns[<span class="number">1</span>:], <span class="number">0</span>, where=y_returns[<span class="number">1</span>:] &lt;= <span class="number">0</span>, facecolor=<span class="string">&#x27;red&#x27;</span>, interpolate=<span class="literal">True</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line">plt.annotate(<span class="string">&#x27;Peak \n1975&#x27;</span>, xy=(<span class="number">94.0</span>, <span class="number">21.0</span>), xytext=(<span class="number">88.0</span>, <span class="number">28</span>),</span><br><span class="line">             bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&#x27;square&#x27;</span>, fc=<span class="string">&#x27;firebrick&#x27;</span>),</span><br><span class="line">             arrowprops=<span class="built_in">dict</span>(facecolor=<span class="string">&#x27;steelblue&#x27;</span>, shrink=<span class="number">0.05</span>), fontsize=<span class="number">15</span>, color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">xtickvals = [<span class="built_in">str</span>(m)[:<span class="number">3</span>].upper()+<span class="string">&quot;-&quot;</span>+<span class="built_in">str</span>(y) <span class="keyword">for</span> y,m <span class="keyword">in</span> <span class="built_in">zip</span>(df.date.dt.year, df.date.dt.month_name())]</span><br><span class="line">plt.gca().set_xticks(x[::<span class="number">6</span>])</span><br><span class="line">plt.gca().set_xticklabels(xtickvals[::<span class="number">6</span>], rotation=<span class="number">90</span>, fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;center&#x27;</span>, <span class="string">&#x27;verticalalignment&#x27;</span>: <span class="string">&#x27;center_baseline&#x27;</span>&#125;)</span><br><span class="line">plt.ylim(-<span class="number">35</span>,<span class="number">35</span>)</span><br><span class="line">plt.xlim(<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Month Economics Return %&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Monthly returns %&#x27;</span>)</span><br><span class="line">plt.grid(alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="排序-（Ranking）"><a href="#排序-（Ranking）" class="headerlink" title="排序 （Ranking）"></a>排序 （Ranking）</h1><h2 id="有序条形图-（Ordered-Bar-Chart）"><a href="#有序条形图-（Ordered-Bar-Chart）" class="headerlink" title="有序条形图 （Ordered Bar Chart）"></a>有序条形图 （Ordered Bar Chart）</h2><p>有序条形图有效地传达了项目的排名顺序。 但是，在图表上方添加度量标准的值，用户可以从图表本身获取精确信息。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1o8C4.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), facecolor=<span class="string">&#x27;white&#x27;</span>, dpi= <span class="number">80</span>)</span><br><span class="line">ax.vlines(x=df.index, ymin=<span class="number">0</span>, ymax=df.cty, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate Text</span></span><br><span class="line"><span class="keyword">for</span> i, cty <span class="keyword">in</span> <span class="built_in">enumerate</span>(df.cty):</span><br><span class="line">    ax.text(i, cty+<span class="number">0.5</span>, <span class="built_in">round</span>(cty, <span class="number">1</span>), horizontalalignment=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Bar Chart for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(ylabel=<span class="string">&#x27;Miles Per Gallon&#x27;</span>, ylim=(<span class="number">0</span>, <span class="number">30</span>))</span><br><span class="line">plt.xticks(df.index, df.manufacturer.<span class="built_in">str</span>.upper(), rotation=<span class="number">60</span>, horizontalalignment=<span class="string">&#x27;right&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add patches to color the X axis labels</span></span><br><span class="line">p1 = patches.Rectangle((<span class="number">.57</span>, -<span class="number">0.005</span>), width=<span class="number">.33</span>, height=<span class="number">.13</span>, alpha=<span class="number">.1</span>, facecolor=<span class="string">&#x27;green&#x27;</span>, transform=fig.transFigure)</span><br><span class="line">p2 = patches.Rectangle((<span class="number">.124</span>, -<span class="number">0.005</span>), width=<span class="number">.446</span>, height=<span class="number">.13</span>, alpha=<span class="number">.1</span>, facecolor=<span class="string">&#x27;red&#x27;</span>, transform=fig.transFigure)</span><br><span class="line">fig.add_artist(p1)</span><br><span class="line">fig.add_artist(p2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="棒棒糖图-（Lollipop-Chart）"><a href="#棒棒糖图-（Lollipop-Chart）" class="headerlink" title="棒棒糖图 （Lollipop Chart）"></a>棒棒糖图 （Lollipop Chart）</h2><p>棒棒糖图表以一种视觉上令人愉悦的方式提供与有序条形图类似的目的。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1olUU.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">ax.vlines(x=df.index, ymin=<span class="number">0</span>, ymax=df.cty, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">ax.scatter(x=df.index, y=df.cty, s=<span class="number">75</span>, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Lollipop Chart for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Miles Per Gallon&#x27;</span>)</span><br><span class="line">ax.set_xticks(df.index)</span><br><span class="line">ax.set_xticklabels(df.manufacturer.<span class="built_in">str</span>.upper(), rotation=<span class="number">60</span>, fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;right&#x27;</span>, <span class="string">&#x27;size&#x27;</span>:<span class="number">12</span>&#125;)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():</span><br><span class="line">    ax.text(row.Index, row.cty+<span class="number">.5</span>, s=<span class="built_in">round</span>(row.cty, <span class="number">2</span>), horizontalalignment= <span class="string">&#x27;center&#x27;</span>, verticalalignment=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="包点图-（Dot-Plot）"><a href="#包点图-（Dot-Plot）" class="headerlink" title="包点图 （Dot Plot）"></a>包点图 （Dot Plot）</h2><p>包点图表传达了项目的排名顺序，并且由于它沿水平轴对齐，因此您可以更容易地看到点彼此之间的距离。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oG8J.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">ax.hlines(y=df.index, xmin=<span class="number">11</span>, xmax=<span class="number">26</span>, color=<span class="string">&#x27;gray&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">ax.scatter(y=df.index, x=df.cty, s=<span class="number">75</span>, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Dot Plot for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Miles Per Gallon&#x27;</span>)</span><br><span class="line">ax.set_yticks(df.index)</span><br><span class="line">ax.set_yticklabels(df.manufacturer.<span class="built_in">str</span>.title(), fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;right&#x27;</span>&#125;)</span><br><span class="line">ax.set_xlim(<span class="number">10</span>, <span class="number">27</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="坡度图-（Slope-Chart）"><a href="#坡度图-（Slope-Chart）" class="headerlink" title="坡度图 （Slope Chart）"></a>坡度图 （Slope Chart）</h2><p>坡度图最适合比较给定人&#x2F;项目的“前”和“后”位置。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oYvR.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.lines <span class="keyword">as</span> mlines</span><br><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;gdppercap.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">left_label = [<span class="built_in">str</span>(c) + <span class="string">&#x27;, &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(y)) <span class="keyword">for</span> c, y <span class="keyword">in</span> <span class="built_in">zip</span>(df.continent, df[<span class="string">&#x27;1952&#x27;</span>])]</span><br><span class="line">right_label = [<span class="built_in">str</span>(c) + <span class="string">&#x27;, &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(y)) <span class="keyword">for</span> c, y <span class="keyword">in</span> <span class="built_in">zip</span>(df.continent, df[<span class="string">&#x27;1957&#x27;</span>])]</span><br><span class="line">klass = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> (y1-y2) &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> y1, y2 <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;1952&#x27;</span>], df[<span class="string">&#x27;1957&#x27;</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw line</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/36470343/how-to-draw-a-line-with-matplotlib/36479941</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">newline</span>(<span class="params">p1, p2, color=<span class="string">&#x27;black&#x27;</span></span>):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    l = mlines.Line2D([p1[<span class="number">0</span>],p2[<span class="number">0</span>]], [p1[<span class="number">1</span>],p2[<span class="number">1</span>]], color=<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> p1[<span class="number">1</span>]-p2[<span class="number">1</span>] &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">    ax.add_line(l)</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">14</span>,<span class="number">14</span>), dpi= <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Vertical Lines</span></span><br><span class="line">ax.vlines(x=<span class="number">1</span>, ymin=<span class="number">500</span>, ymax=<span class="number">13000</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">3</span>, ymin=<span class="number">500</span>, ymax=<span class="number">13000</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Points</span></span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;1952&#x27;</span>], x=np.repeat(<span class="number">1</span>, df.shape[<span class="number">0</span>]), s=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;1957&#x27;</span>], x=np.repeat(<span class="number">3</span>, df.shape[<span class="number">0</span>]), s=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Line Segmentsand Annotation</span></span><br><span class="line"><span class="keyword">for</span> p1, p2, c <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;1952&#x27;</span>], df[<span class="string">&#x27;1957&#x27;</span>], df[<span class="string">&#x27;continent&#x27;</span>]):</span><br><span class="line">    newline([<span class="number">1</span>,p1], [<span class="number">3</span>,p2])</span><br><span class="line">    ax.text(<span class="number">1</span>-<span class="number">0.05</span>, p1, c + <span class="string">&#x27;, &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(p1)), horizontalalignment=<span class="string">&#x27;right&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line">    ax.text(<span class="number">3</span>+<span class="number">0.05</span>, p2, c + <span class="string">&#x27;, &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(p2)), horizontalalignment=<span class="string">&#x27;left&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;Before&#x27; and &#x27;After&#x27; Annotations</span></span><br><span class="line">ax.text(<span class="number">1</span>-<span class="number">0.05</span>, <span class="number">13000</span>, <span class="string">&#x27;BEFORE&#x27;</span>, horizontalalignment=<span class="string">&#x27;right&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">18</span>, <span class="string">&#x27;weight&#x27;</span>:<span class="number">700</span>&#125;)</span><br><span class="line">ax.text(<span class="number">3</span>+<span class="number">0.05</span>, <span class="number">13000</span>, <span class="string">&#x27;AFTER&#x27;</span>, horizontalalignment=<span class="string">&#x27;left&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">18</span>, <span class="string">&#x27;weight&#x27;</span>:<span class="number">700</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoration</span></span><br><span class="line">ax.set_title(<span class="string">&quot;Slopechart: Comparing GDP Per Capita between 1952 vs 1957&quot;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(xlim=(<span class="number">0</span>,<span class="number">4</span>), ylim=(<span class="number">0</span>,<span class="number">14000</span>), ylabel=<span class="string">&#x27;Mean GDP Per Capita&#x27;</span>)</span><br><span class="line">ax.set_xticks([<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&quot;1952&quot;</span>, <span class="string">&quot;1957&quot;</span>])</span><br><span class="line">plt.yticks(np.arange(<span class="number">500</span>, <span class="number">13000</span>, <span class="number">2000</span>), fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Lighten borders</span></span><br><span class="line">plt.gca().spines[<span class="string">&quot;top&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;bottom&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;right&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;left&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="哑铃图-（Dumbbell-Plot）"><a href="#哑铃图-（Dumbbell-Plot）" class="headerlink" title="哑铃图 （Dumbbell Plot）"></a>哑铃图 （Dumbbell Plot）</h2><p>哑铃图表传达了各种项目的“前”和“后”位置以及项目的等级排序。 如果您想要将特定项目&#x2F;计划对不同对象的影响可视化，那么它非常有用。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oNK1.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.lines <span class="keyword">as</span> mlines</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;health.csv&quot;</span>)</span><br><span class="line">df.sort_values(<span class="string">&#x27;pct_2014&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Func to draw line segment</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">newline</span>(<span class="params">p1, p2, color=<span class="string">&#x27;black&#x27;</span></span>):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    l = mlines.Line2D([p1[<span class="number">0</span>],p2[<span class="number">0</span>]], [p1[<span class="number">1</span>],p2[<span class="number">1</span>]], color=<span class="string">&#x27;skyblue&#x27;</span>)</span><br><span class="line">    ax.add_line(l)</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"><span class="comment"># Figure and Axes</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">14</span>,<span class="number">14</span>), facecolor=<span class="string">&#x27;#f7f7f7&#x27;</span>, dpi= <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Vertical Lines</span></span><br><span class="line">ax.vlines(x=<span class="number">.05</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.10</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.15</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.20</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Points</span></span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;index&#x27;</span>], x=df[<span class="string">&#x27;pct_2013&#x27;</span>], s=<span class="number">50</span>, color=<span class="string">&#x27;#0e668b&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;index&#x27;</span>], x=df[<span class="string">&#x27;pct_2014&#x27;</span>], s=<span class="number">50</span>, color=<span class="string">&#x27;#a3c4dc&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Line Segments</span></span><br><span class="line"><span class="keyword">for</span> i, p1, p2 <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;index&#x27;</span>], df[<span class="string">&#x27;pct_2013&#x27;</span>], df[<span class="string">&#x27;pct_2014&#x27;</span>]):</span><br><span class="line">    newline([p1, i], [p2, i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoration</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f7f7f7&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&quot;Dumbell Chart: Pct Change - 2013 vs 2014&quot;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(xlim=(<span class="number">0</span>,<span class="number">.25</span>), ylim=(-<span class="number">1</span>, <span class="number">27</span>), ylabel=<span class="string">&#x27;Mean GDP Per Capita&#x27;</span>)</span><br><span class="line">ax.set_xticks([<span class="number">.05</span>, <span class="number">.1</span>, <span class="number">.15</span>, <span class="number">.20</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;5%&#x27;</span>, <span class="string">&#x27;15%&#x27;</span>, <span class="string">&#x27;20%&#x27;</span>, <span class="string">&#x27;25%&#x27;</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;5%&#x27;</span>, <span class="string">&#x27;15%&#x27;</span>, <span class="string">&#x27;20%&#x27;</span>, <span class="string">&#x27;25%&#x27;</span>])    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>数据科学：t-SNE 的原理与应用</title>
    <url>/Tsne/</url>
    <content><![CDATA[<p><img src="https://upload.wikimedia.org/wikipedia/commons/9/94/T-SNE_visualisation_of_word_embeddings_generated_using_19th_century_literature.png"></p>
<div align="center">使用 19 世纪文献生成的词嵌入的 T-SNE 可视化</div>

<p>t 分布随机邻域嵌入(t-SNE) 是一种统计方法，通过为每个数据点在二维或三维地图中赋予一个位置来可视化高维数据。它是一种非线性降维技术，用于在二维或三维低维空间中嵌入高维数据以进行可视化。具体而言，它通过二维或三维点对每个高维对象进行建模，这样相似的对象由附近的点建模，而不同的对象则以高概率由远处的点建模。<br>t-SNE 算法包括两个主要阶段。首先，t-SNE 在高维对象对上构建一个概率分布，这样相似的对象被分配更高的概率，而不同的点被分配更低的概率。其次，t-SNE 在低维图中的点上定义一个相似的概率分布，并最小化两个分布之间关于图中点位置的Kullback-Leibler 散度（<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL 散度</a>）。<br>对于包含n 个元素的数据集，t-SNE 的运行时间为$O(n^2)$，空间为$O( n^2)$。</p>
<span id="more"></span>

<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>给定一组高维数据对象$x_i$,…,$x_N$,t-SNE计算$x_i$与$x_j$的相似度成正比的概率</p>
<p>$$<br>p_{i|j} &#x3D; \frac{\exp\left(-|x_i - x_j|^2 &#x2F; 2 \sigma_i^2\right)}{\sum_{k \neq i} \exp\left(-|x_i - x_k|^2 &#x2F; 2 \sigma_i^2\right)}( i\neq j)<br>$$</p>
<p>其中$\sigma_i$是以数据点$x_i$为中心的高斯方差,$|x_i - x_j|$表示数据$x_i$与$x_j$的<a href="https://en.wikipedia.org/wiki/Euclidean_distance">欧式距离</a>,且定义$p_{i|i}$&#x3D;0;$p_{i|j}$表示$x_i$按照其概率密度的比例并以$x_i$为高斯中心选择$x_j$作为邻居的条件概率;<br>且有定义$p_{ij} &#x3D; \frac{p_{j|i} + p_{i|j}}{2N}$。<br>t-SNE旨在学习一个映射,通过该映射,高维数据$x_i$,…,$x_N$将映射为对应的低维数据$y_i$,…,$y_N$(维数一般为2或者3),该低维数据之间计算所得相似度$q_{ij}$尽可能接近$p_{ij}$。$q_{ij}$定义如下:</p>
<p>$$<br>q_{ij} &#x3D; \frac{(1+|y_i - y_j|^2 )^{-1}}{\sum_{k}\sum_{l \neq k}(1+|y_k - y_l|^2 )^{-1}}( i\neq j)<br>$$</p>
<p>为了得到逼近高维数据之间计算得到相似度的低维数据，我们需要通过梯度下降（当前采用的主流方法为Barnes-Hut算法）的方法最小化P分布与Q分布的KL散度：</p>
<p>$$<br>KL(P||Q) &#x3D; \sum_{i \neq j}p_{ij}\log \frac{p_{ij}}{q_{ij}}<br>$$</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>案例选取一个长度为3072随机生成的二维信号，通过t-SNE计算并使用matplotlib库进行绘制,使用python进行t-SNE计算的库主要有sklearn.manifold.TSNE、<a href="https://github.com/KlugerLab/pyFIt-SNE/tree/master">fitsne</a>、<a href="https://github.com/CannyLab/tsne-cuda">tsnecuda</a>三个。<br>测试算法时笔者的测试平台的相关配置信息如下：<br><img src="https://i.postimg.cc/DZyT1pwM/cpuinfo.png"><br>上述命令得到的信息依次是：CPU逻辑核数与型号信息、CPU物理个数、每个物理CPU的核数、总CPU逻辑个数（总CPU逻辑个数 &#x3D; 物理CPU个数 x 每个物理CPU的核数 x 超线程数）。<br>GPU信息如下所示：<br><img src="https://i.postimg.cc/W3Ww4zyH/gpuinfo.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> set_seed</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> fitsne <span class="keyword">import</span> FItSNE</span><br><span class="line"><span class="keyword">from</span> tsnecuda <span class="keyword">import</span> TSNE <span class="keyword">as</span> CudaTSNE</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quzheng</span>(<span class="params">num:<span class="built_in">float</span></span>):</span><br><span class="line">    <span class="keyword">if</span> num&lt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> math.floor(num)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> math.ceil(num)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#sure result can repeat</span></span><br><span class="line">    seed = <span class="number">1234</span></span><br><span class="line">    setup_seed(seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gen random 2d data</span></span><br><span class="line">    m = <span class="number">2</span></span><br><span class="line">    n = <span class="number">3072</span> </span><br><span class="line">    data1 = np.random.uniform(-<span class="number">100</span>, <span class="number">100</span>, size=(n, <span class="number">1</span>)).astype(np.float32) <span class="comment">#random data range (-100,100),type is float32</span></span><br><span class="line">    data2 = np.random.uniform(-<span class="number">100</span>, <span class="number">100</span>, size=(n, <span class="number">1</span>)).astype(np.float32) <span class="comment">#random data range (-100,100),type is float32</span></span><br><span class="line">  </span><br><span class="line">    data = np.column_stack((data1, data2))</span><br><span class="line">    origin_data = data.copy()</span><br><span class="line">  </span><br><span class="line">    data_dict = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    tsne = TSNE(n_components = <span class="number">2</span>,perplexity=<span class="number">30</span>,verbose=<span class="number">1</span>,max_iter=<span class="number">2000</span>,random_state=seed,init=<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    tsne_data = tsne.fit_transform(data)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;tsne&#x27;</span>] = tsne_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    fit_tsne_data = FItSNE(data.astype(np.float64), perplexity=<span class="number">30</span>, max_iter=<span class="number">2000</span>,fft_not_bh=<span class="literal">True</span>,rand_seed=seed,initialization=<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;fit-tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;fit-tsne&#x27;</span>] = fit_tsne_data</span><br><span class="line"></span><br><span class="line">    cuda_tsne = CudaTSNE(n_iter=<span class="number">2000</span>, verbose=<span class="number">1</span>, perplexity=<span class="number">30</span>,random_seed=seed)</span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    cuda_tsne_data = cuda_tsne.fit_transform(data)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cuda-tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;cuda-tsne&#x27;</span>] = cuda_tsne_data</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">    xy_min_max_list =  <span class="built_in">list</span>(<span class="built_in">map</span>(quzheng,reduce(<span class="keyword">lambda</span> x,y:[<span class="built_in">min</span>(x[<span class="number">0</span>],y[<span class="number">0</span>]),<span class="built_in">min</span>(x[<span class="number">1</span>],y[<span class="number">1</span>]),<span class="built_in">max</span>(x[<span class="number">2</span>],y[<span class="number">2</span>]),<span class="built_in">max</span>(x[<span class="number">3</span>],y[<span class="number">3</span>])],<span class="built_in">map</span>(<span class="keyword">lambda</span> x:[np.<span class="built_in">min</span>(x[:,<span class="number">0</span>]),np.<span class="built_in">min</span>(x[:,<span class="number">1</span>]),np.<span class="built_in">max</span>(x[:,<span class="number">0</span>]),np.<span class="built_in">max</span>(x[:,<span class="number">1</span>])],data_dict.values()))))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;get xy_range is &quot;</span>,xy_min_max_list)</span><br><span class="line">    x_min = xy_min_max_list[<span class="number">0</span>]</span><br><span class="line">    y_min = xy_min_max_list[<span class="number">1</span>]</span><br><span class="line">    x_max = xy_min_max_list[<span class="number">2</span>]</span><br><span class="line">    y_max = xy_min_max_list[<span class="number">3</span>]</span><br><span class="line">  </span><br><span class="line">    plt.figure(figsize=(<span class="number">32</span>, <span class="number">24</span>))</span><br><span class="line">    plt.suptitle(<span class="string">f&quot;Tsne Test&quot;</span>,fontsize=<span class="number">40</span>,    <span class="comment"># 字体大小</span></span><br><span class="line">                fontweight=<span class="string">&#x27;bold&#x27;</span>,  <span class="comment"># 字体粗细</span></span><br><span class="line">                fontstyle=<span class="string">&#x27;italic&#x27;</span>,  <span class="comment"># 字体风格（斜体）</span></span><br><span class="line">                color=<span class="string">&#x27;blue&#x27;</span>   <span class="comment"># 字体颜色</span></span><br><span class="line">            )</span><br><span class="line">    keys_list = <span class="built_in">list</span>(data_dict.keys())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(keys_list)):</span><br><span class="line">        sample = data_dict[keys_list[i]]</span><br><span class="line">        ax = plt.subplot(<span class="number">1</span>,<span class="built_in">len</span>(keys_list),i+<span class="number">1</span>)</span><br><span class="line">        ax.xaxis.set_major_locator(MultipleLocator(<span class="number">25</span>))  <span class="comment"># x轴主刻度间隔为25</span></span><br><span class="line">        ax.yaxis.set_major_locator(MultipleLocator(<span class="number">25</span>))  <span class="comment"># y轴主刻度间隔为25</span></span><br><span class="line">        ax.scatter(sample[:, <span class="number">0</span>], sample[:, <span class="number">1</span>], s=<span class="number">5</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line">        ax.set_title(<span class="string">f&#x27;<span class="subst">&#123;keys_list[i]&#125;</span>&#x27;</span>)</span><br><span class="line">        ax.set_ylim(y_min,y_max)</span><br><span class="line">        ax.set_xlim(x_min,x_max)</span><br><span class="line">        ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>, <span class="string">&#x27;box&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    save_file_path = <span class="string">&quot;./tsne&quot;</span></span><br><span class="line">    plt.savefig(save_file_path,dpi=<span class="number">300</span>)</span><br><span class="line">    plt.close()</span><br></pre></td></tr></table></figure>
<p>运行得到上述三种算法时间的花销如下：<br><img src="https://i.postimg.cc/BZxNfZZ4/tsne-cost.png"><br><strong>由于tsnecuda底层实现并未采用随机数种子，而是基于当前时间生成的种子,详情参见<a href="https://github.com/CannyLab/tsne-cuda/issues/44">issue</a>所以对于同一数据重复运行也无法得到相同结果</strong><br>上述运行结果可视化如下:<br><img src="https://www.helloimg.com/i/2025/01/13/6784c614828bf.png"></p>
]]></content>
      <categories>
        <category>Data Science</category>
      </categories>
      <tags>
        <tag>Data Science</tag>
        <tag>t-SNE</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：attn_implementation 在性能、显存与可复现性之间做出选择</title>
    <url>/flashattention/</url>
    <content><![CDATA[<p>当您在使用 Hugging Face <code>transformers</code> 库加载模型时，可以通过 <code>attn_implementation</code> 参数来指定底层的注意力（Attention）计算方式。这是一个至关重要的参数，直接影响了模型的训练和推理速度、显存占用以及计算结果的可复现性。</p>
<p>您在调试中发现 <code>flash_attention_2</code> 是随机性的来源，这是一个非常典型的例子，说明了前沿的性能优化有时会以牺牲一些可预测性为代价。理解不同选项的优缺点，可以帮助您根据具体需求（高性能、低显存、严格复现等）做出最优决策。</p>
<span id="more"></span>
<hr>
<h2 id="可选项对比分析"><a href="#可选项对比分析" class="headerlink" title="可选项对比分析"></a>可选项对比分析</h2><p>以下是 <code>attn_implementation</code> 的主要可选项及其详细的优缺点对比：</p>
<table>
<thead>
<tr>
<th>选项 (Option)</th>
<th>优点 (Pros)</th>
<th>缺点 (Cons)</th>
<th>适用场景 (Best For)</th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>flash_attention_2</code></strong></td>
<td><strong>极致的速度和显存优化</strong>：通过分块计算避免生成完整的 N x N 注意力矩阵，是目前公认最快的实现。</td>
<td><strong>硬件要求高</strong> (NVIDIA Ampere&#x2F;Hopper 架构，如 A100&#x2F;H100)。<strong>需要额外安装</strong> (<code>pip install flash-attn</code>)。<strong>潜在的可复现性问题</strong> (其自定义CUDA内核可能引入细微的数值不确定性)。</td>
<td><strong>生产环境中的高性能训练和推理</strong>。当追求极致性能且硬件支持时是首选。</td>
</tr>
<tr>
<td><strong><code>sdpa</code></strong></td>
<td><strong>PyTorch 原生集成</strong> (无需额外安装，需要 <code>torch&gt;=2.0</code>)。<strong>非常好的性能和显存效率</strong>，性能通常非常接近 Flash Attention。<strong>官方支持，未来趋势</strong>。</td>
<td><strong>需要较新版本的 PyTorch</strong> (<code>&gt;=2.0</code>)。在顶级硬件上，性能可能微弱于专门优化的 <code>flash_attention_2</code>。</td>
<td><strong>现代 PyTorch 环境下的通用选择</strong>。这是目前<strong>最佳的平衡点</strong>，也是最被推荐的默认选项。</td>
</tr>
<tr>
<td><strong><code>eager</code></strong></td>
<td><strong>最高的兼容性和可复现性</strong>：这是 PyTorch 的标准、原始实现，行为最可预测。<strong>无需任何特殊软硬件</strong>。<strong>是理解算法和调试的基准</strong>。</td>
<td><strong>速度最慢，显存占用最大</strong>：因为它会完整地实例化一个巨大的注意力分数矩阵，对于长序列很容易导致显存溢出 (OOM)。</td>
<td><strong>调试、教学、确保严格的比特级可复现性</strong>，或在不支持优化的旧硬件上运行。</td>
</tr>
<tr>
<td><strong><code>bettertransformer</code></strong></td>
<td>在 <code>sdpa</code> 出现之前的原生优化方案，利用了 PyTorch 的 <code>nn.TransformerEncoderLayer</code> 内核。比 <code>eager</code> 更快、更省显存。</td>
<td><strong>已被 <code>sdpa</code> 全面取代</strong>。功能、性能和未来的支持都不如 <code>sdpa</code>。在某些模型或 <code>transformers</code> 新版本中可能不再被支持。</td>
<td><strong>遗留选项</strong>。主要用于无法使用 <code>torch&gt;=2.0</code> 的旧项目，用于获得一些基础优化。</td>
</tr>
</tbody></table>
<hr>
<h2 id="为什么-Flash-Attention-会引入不确定性？"><a href="#为什么-Flash-Attention-会引入不确定性？" class="headerlink" title="为什么 Flash Attention 会引入不确定性？"></a>为什么 Flash Attention 会引入不确定性？</h2><p><code>flash-attn</code> 库的实现依赖于高度优化的、由开发者手写的 CUDA 内核。为了压榨出每一分性能，这些内核在计算方式上（例如浮点数的累加顺序、并行计算的划分等细节）可能与 PyTorch 的标准实现 (<code>eager</code>) 有所不同。</p>
<p>虽然这些算法在数学上是等价的，但在精度有限的计算机上，这些微小的实现差异会导致浮点数计算结果的细微偏差。当这些偏差在深度神经网络的多层传播中不断累积时，最终就会导致输出结果产生肉眼可见的不同。您遇到的情况很可能是某个特定的 PyTorch &#x2F; CUDA &#x2F; <code>flash-attn</code> 版本组合触发了这种行为。</p>
<hr>
<h2 id="我现在应该用哪个？——-最佳实践推荐"><a href="#我现在应该用哪个？——-最佳实践推荐" class="headerlink" title="我现在应该用哪个？—— 最佳实践推荐"></a>我现在应该用哪个？—— 最佳实践推荐</h2><p>对于目前的情况，<strong><code>sdpa</code> (Scaled Dot Product Attention) 是最佳选择。</strong></p>
<p>它完美地平衡了性能和可复现性的需求：</p>
<ul>
<li><strong>性能</strong>: <code>sdpa</code> 利用了 PyTorch 内置的、高度优化的注意力后端。它底层也可能调用类似 Flash Attention 的内核，但由 PyTorch 团队维护和保证其行为，性能与 <code>flash_attention_2</code> 非常接近，远超 <code>eager</code> 模式。</li>
<li><strong>易用性</strong>: 它是 PyTorch 2.0+ 的一部分，您<strong>无需安装任何额外依赖</strong>。</li>
<li><strong>可复现性</strong>: 作为 PyTorch 的原生组件，它的行为通常比外部的自定义库更加稳定和可预测。在配置了确定性算法的环境下，它的可复现性通常要比 <code>flash_attention_2</code> 好得多。</li>
</ul>
<h3 id="如何应用-sdpa"><a href="#如何应用-sdpa" class="headerlink" title="如何应用 sdpa"></a>如何应用 <code>sdpa</code></h3><p>您只需要在加载模型的代码中修改 <code>attn_implementation</code> 参数即可：</p>
<pre><code class="language-python">model = AutoModelForCausalLM.from_config(
    config,
    torch_dtype=torch.bfloat16,
    # 将 &quot;eager&quot; 或 &quot;flash_attention_2&quot; 替换为 &quot;sdpa&quot;
    attn_implementation=&quot;sdpa&quot; 
)
</code></pre>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
        <tag>NVIDIA - large language models</tag>
      </tags>
  </entry>
  <entry>
    <title>《Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow, Third Edition》 全书第三章：分类</title>
    <url>/Hands-On_ML_Sec3/</url>
    <content><![CDATA[<p>Geron教授所著的该书第一章中已经简要介绍了监督学习任务是回归（预测数值）和分类（预测类别）。在第二章中探索了一个预测加州地区房价的回归任务，并测试了如线性回归、决策树和随机森林等算法。现在我们将注意力转向分类系统。</p>
<span id="more"></span>

<h2 id="MNIST-数据集"><a href="#MNIST-数据集" class="headerlink" title="MNIST 数据集"></a>MNIST 数据集</h2><p>MNIST 数据集是一组美国高中生及人口普查局员工手写的70,000个数字图像。每个图像都标有它代表的数字。这个集合已经在机器学习领域被大量研究以至于通常称之为机器学习的“hello world”。以下代码为使用 Scikit-Learn 获取 MNIST 数据集的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_openml</span><br><span class="line">mnist = fetch_openml(<span class="string">&#x27;mnist_784&#x27;</span>,as_frame=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>sklearn.datasets 包主要包含三种类型的函数：fetch_*函数（例如fetch_openml()）用来下载现实生活中的数据集；load_*函数用来加载与Scikit-Learn捆绑的本地微型数据集；make_*函数用于生成测试数据集。生成的数据集通常包含输入数据和目标分类的元组(X,y),两者均为NumPy数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X, y = mnist.data, mnist.target</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X.shape</span><br><span class="line">(<span class="number">70000</span>, <span class="number">784</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, ..., <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.shape</span><br><span class="line">(<span class="number">70000</span>,)</span><br></pre></td></tr></table></figure>

<p>共70000张图片，每张图片有784&#x3D;28*28个像素。使用 Matplotlib 的 imshow() 函数，令 cmap&#x3D;“binary” 来获取灰度颜色图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_digit</span>(<span class="params">image_data</span>):</span><br><span class="line">    image = image_data.reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">    plt.imshow(image,cmap=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">some_digit = X[<span class="number">0</span>]</span><br><span class="line">plot_digit(some_digit)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>这看起来像一个5，实际上标签的结果也印证了这一点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[<span class="number">0</span>]</span><br><span class="line"><span class="string">&#x27;5&#x27;</span></span><br></pre></td></tr></table></figure>

<p>分离训练集与测试集：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]</span><br></pre></td></tr></table></figure>

<h2 id="训练二元分类器"><a href="#训练二元分类器" class="headerlink" title="训练二元分类器"></a>训练二元分类器</h2><p>现在让我们简化这个问题，只尝试识别一个数字——例如，数字5。这个“5检测器”将是二元分类器的一个例子，能够区分两个类别，5和非5。首先，我们将为这个分类任务创建目标向量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train_5 = (y_train == <span class="string">&#x27;5&#x27;</span>)</span><br><span class="line">y_test_5 = (y_test == <span class="string">&#x27;5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>现在让我们选择一个分类器并训练它。一个好的起点是使用ScikitLearn的随机梯度下降（Stochastic Gradient Descent, SGD）分类器，SGDClassifier类。这个分类器能够有效地处理非常大的数据集。这部分是因为SGD独立地处理训练实例，每次处理一个，这也使得SGD非常适合在线学习。让我们创建一个SGDClassifier并在整个训练集上训练它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">sgd_clf.fit(X_train, y_train_5)</span><br></pre></td></tr></table></figure>

<p>现在我们可以用它来检测数字5的图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</span><br><span class="line">array([ <span class="literal">True</span>])</span><br></pre></td></tr></table></figure>

<p>分类器猜测该图像代表5（True）。看起来它在这个特殊情况下猜对了！现在，我们来评估一下这个模型的性能。</p>
<h2 id="模型性能评估"><a href="#模型性能评估" class="headerlink" title="模型性能评估"></a>模型性能评估</h2><p>评估分类器通常比评估回归器要棘手得多，所以我们将在本章的大部分时间里讨论这个话题。有许多可用的绩效衡量标准：</p>
<h3 id="使用交叉验证测量精度"><a href="#使用交叉验证测量精度" class="headerlink" title="使用交叉验证测量精度"></a>使用交叉验证测量精度</h3><p>评估模型的一个好方法是使用交叉验证函数 cross_val_score() 来评估我们的 SGDClassifier 模型，使用三次的 k-fold 交叉验证。k-fold 交叉验证意味着将训练集分成k个折叠（在本例中为3个），然后训练模型 k 次，每次进行不同的折叠进行评估：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.95035</span>, <span class="number">0.96035</span>, <span class="number">0.9604</span>])</span><br></pre></td></tr></table></figure>

<p>所有交叉验证的准确率（预测正确的比率）都在95%以上？这看起来很神奇，不是吗？好吧，在你太兴奋之前，让我们看看一个虚拟分类器，它只对最常见的类中的每个图像进行分类，在这种情况下是负类（即非5）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.dummy <span class="keyword">import</span> DummyClassifier</span><br><span class="line">dummy_clf = DummyClassifier()</span><br><span class="line">dummy_clf.fit(X_train, y_train_5)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">any</span>(dummy_clf.predict(X_train))) <span class="comment"># prints False: no 5s detected_</span></span><br></pre></td></tr></table></figure>

<p>你能猜出这个模型的精度吗？让我们来看看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(dummy_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.90965</span>, <span class="number">0.90965</span>, <span class="number">0.90965</span>])</span><br></pre></td></tr></table></figure>

<p>没错，准确率超过90%！这很简单，因为只有大约10%的图像是5，所以如果你总是猜测图像不是5，你将有90%的时间是正确的。这说明了为什么准确率通常不是分类器的首选性能度量，特别是当您处理倾斜的数据集。评估分类器性能的更好方法是查看混淆矩阵。</p>
<h3 id="混淆矩阵（Confusion-Matrix-CM）"><a href="#混淆矩阵（Confusion-Matrix-CM）" class="headerlink" title="混淆矩阵（Confusion Matrix, CM）"></a>混淆矩阵（Confusion Matrix, CM）</h3><p>混淆矩阵的一般思想是对于所有A&#x2F;B对计算A类实例被分类为B类的次数。例如，要知道分类器混淆8和0图像的次数，您可以查看混淆矩阵的第8行第0列。要计算混淆矩阵，首先需要有一组预测，以便将它们与实际目标进行比较。您可以对测试集进行预测，但是现在最好不要碰它（请记住，您只希望在项目的最后使用测试集，一旦您有了准备启动的分类器）。相反，你可以使用 cross_val_predict() 函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line">y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>就像 cross_val_score（）函数一样，cross_val_predict（）执行k-fold交叉验证，但它不是返回评估分数，而是返回对每个测试 fold 所做的预测。这意味着您可以对训练集中的每个实例进行干净的预测（这里的“干净”是指“样本外”：模型对训练期间从未见过的数据进行预测）。现在可以使用 confusion_matrix() 函数获得混淆矩阵了。只需将目标类 y_train_5 和预测类 y_train_pred 传递给它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix </span><br><span class="line">&gt;&gt;&gt;cm = confusion_matrix(y_train_5, y_train_pred) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cm</span><br><span class="line">array([[<span class="number">53892</span>, <span class="number">687</span>],</span><br><span class="line">	[<span class="number">1891</span>, <span class="number">3530</span>]])</span><br></pre></td></tr></table></figure>

<p>混淆矩阵中的每一行表示一个实际的类，而每一列表示一个预测的类。该矩阵的第一行考虑非5图像（阴性类）：其中53,892张被正确分类为非5（称为真阴性），而其余687张被错误分类为5（假阳性，也称为I型错误）。第二行考虑5的图像（阳性类）：1,891被错误地分类为非5（假阴性，也称为II型错误），而其余3,530被正确分类为5（真阳性）。一个完美的分类器只会有真正和真负，所以它的混淆矩阵只会在它的主对角线上（从左上到右下）有非零值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_perfect_predictions = y_train_5 <span class="comment"># pretend we reached perfection </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>confusion_matrix(y_train_5, y_train_perfect_predictions) </span><br><span class="line">array([[<span class="number">54579</span>, <span class="number">0</span>],</span><br><span class="line">	[ <span class="number">0</span>, <span class="number">5421</span>]])</span><br></pre></td></tr></table></figure>

<h3 id="准确率和召回率"><a href="#准确率和召回率" class="headerlink" title="准确率和召回率"></a>准确率和召回率</h3><p>混淆矩阵为您提供了大量信息，但有时您可能更喜欢更简洁的度量。一个有趣的问题是阳性预测的准确性；这被称为分类器的准确率（Precision）。</p>
<p>$$ {\rm Precision} &#x3D; \frac{\rm TP}{\rm TP+FP} \tag{3-1}\label{3-1}$$</p>
<p>其中，TP 表示真阳性数，FP 表示假阳性数。</p>
<p>获得完美准确率的一个简单方法是创建一个分类器，它总是做出负面预测，除了对它最自信的实例进行一个单一的正面预测。如果这一个预测是正确的，那么分类器有100%的精度（精度&#x3D; 1&#x2F;1 &#x3D; 100%）。显然，这样的分类器不是很有用，因为它会忽略除一个阳性实例外的所有实例。因此，精度通常与另一个名为召回率的指标一起使用，也称为灵敏度或真阳性率（True Position Rate, TPR）：这是分类器正确检测到的阳性实例的比率。</p>
<p>$$ {\rm Recall} &#x3D; \frac{\rm TP}{\rm TP+FN} \tag{3-2}\label{3-2}$$</p>
<p>其中，FN 是假阴性的数量。</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPnQhV.jpg" alt="图 3-3: 图示的混淆矩阵显示了真阴性（左上）、假阳性（右上）、假阴性（左下）和真阳性（右下）的示例。
"><figcaption aria-hidden="true">图 3-3: 图示的混淆矩阵显示了真阴性（左上）、假阳性（右上）、假阴性（左下）和真阳性（右下）的示例。
</figcaption></figure></p>
<blockquote class="blockquote-center">
<p>简单的说，准确率代表用户得到模型判断为真的样本中确实是真的比率，召回率代表确实为真的样本被模型判断为真的比率。准确率与召回率均较高代表模型达到了优秀的性能，只有单一指标优秀不代表模型性能好。 </p>

</blockquote>

<p>Scikit-Learn 提供了几个函数来计算分类器指标，包括准确率和召回率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>precision_score(y_train_5, y_train_pred) <span class="comment"># == 3530/ (687 + 3530)</span></span><br><span class="line"><span class="number">0.8370879772350012</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recall_score(y_train_5, y_train_pred) <span class="comment"># == 3530 /(1891 + 3530)</span></span><br><span class="line"><span class="number">0.6511713705958311</span></span><br></pre></td></tr></table></figure>

<p>现在我们的5检测器看起来不像我们在考虑它的准确率时那么闪亮了。当它声称图像代表5时，正确率只有83.7%。此外，它只能检测到65.1%的5。将准确率和召回率组合成一个称为 ${\rm F}_1$ 分数的指标通常很方便，特别是当您需要一个指标来比较两个分类器时。F1分数是准确率和召回率的调和平均值。常规均值对所有值一视同仁，而调和均值对低值给予更多的权重。因此，只有在召回率和准确率都很高的情况下，分类器才会得到很高的${\rm F}_1$分数。</p>
<p>$$ {\rm F}_1 &#x3D; \frac{2}{\frac{1}{\rm Precision}+\frac{1}{\rm Recall}} &#x3D; \frac{\rm TP}{\rm TP+\frac{FN+FP}{2}} \tag{3-3}\label{3-3} $$</p>
<p>要计算 ${\rm F}_1$分数只需调用 f1_score() 函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_train_pred)</span><br><span class="line"><span class="number">0.7325171197343846</span></span><br></pre></td></tr></table></figure>

<p>F1分数倾向于具有相似精度和召回率的分类器。这并不总是你想要的：在某些情况下，你最关心的是准确性，而在其他情况下，你真正关心的是召回率。例如，如果你训练一个分类器来检测对孩子安全的视频，你可能更喜欢一个分类器，它会拒绝许多好的视频（低召回率），但只保留安全的视频（高精度），而不是一个具有更高召回率的分类器，但会让一些非常糟糕的视频出现在你的产品中（在这种情况下，你甚至可能想要添加一个人工管道来检查分类器的视频选择）。另一方面，假设你训练一个分类器来检测监视图像中的商店扒手：如果你的分类器只有30%的准确率，只要它有99%的召回率，这可能是好的（当然，保安会得到一些错误的警报，但几乎所有的商店扒手都会被抓住）。不幸的是，你不能两全其美：提高精确度会降低召回率，反之亦然。这被称为精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）。</p>
<h3 id="精确度-召回率权衡（precision-recall-trade-off）"><a href="#精确度-召回率权衡（precision-recall-trade-off）" class="headerlink" title="精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）"></a>精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）</h3><p>为了理解这种权衡，让我们看看 SGDClassifier 是如何做出分类决策的。对于每个实例，它根据决策函数计算一个分数。如果该分数大于阈值，则将实例分配给正类；否则它会把它赋值给负类。图 3-4 给出了分数从左边最低到右边最高的几个数字。假设决策阈值位于中间的箭头（在两个5之间）：你会发现在该值的右边有4个真阳性，和1个假阳性。但在6个真实的5中,分类器只检测到4个。如果你提高阈值,假阳性（6）成为一个真正的阴性，从而增加的精度(在本例中高达100%)，但一个真正的5的成为假阴性，召回率降低到50%。相反，降低阈值会增加召回率，降低准确率。</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPMB90.jpg" alt="图 3-4: 精度&#x2F;召回权衡：图像根据分类器得分进行排序，高于所选决策阈值的图像被认为是正面的；阈值越高，召回率越低，但（通常）精度越高"><figcaption aria-hidden="true">图 3-4: 精度/召回权衡：图像根据分类器得分进行排序，高于所选决策阈值的图像被认为是正面的；阈值越高，召回率越低，但（通常）精度越高</figcaption></figure></p>
<p>Scikit-Learn 不能让你直接设置阈值，但它可以让你访问它用来做出预测的决策分数。你可以调用分类器的predict() 方法，而不是调用它的 decision_function() 方法，它会为每个实例返回一个分数，然后使用你想要基于这些分数进行预测的任何阈值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line">&gt;&gt;&gt;y_scores</span><br><span class="line">array([<span class="number">2164.22030239</span>])</span><br><span class="line">&gt;&gt;&gt;threshold = <span class="number">0</span></span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred = (y_scores &gt; threshold) </span><br><span class="line">array([<span class="literal">True</span>])</span><br></pre></td></tr></table></figure>

<p>SGDClassifier 使用 0 为阈值，因此前面的代码返回与predict() 方法相同的结果。让我们提高阈值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;threshold = <span class="number">3000</span> </span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred = (y_scores &gt; threshold) </span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred </span><br><span class="line">array([<span class="literal">False</span>])</span><br></pre></td></tr></table></figure>

<p>这证实了提高阈值会降低召回。图像实际上代表一个5，当阈值为0时，分类器会检测到它，但当阈值增加到3000时，它会错过它。如何决定使用哪个阈值？首先，使用cross_val_predict() 函数获取训练集中所有实例的分数，但这次指定要返回决策分数而不是预测分类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>，method=<span class="string">&quot;decision_function&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>有了这些分数，使用 precision_recall_curve() 函数来计算所有可能阈值的精度和召回率（该函数添加的最后精度为0，最后召回率为1，对应于无限阈值），最后，使用Matplotlib绘制精度和召回率作为阈值的函数（图3-5）。让我们显示我们选择的阈值3000：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"></span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br><span class="line"></span><br><span class="line">plt.plot(thresholds, precisions[:-<span class="number">1</span>], <span class="string">&quot;b--&quot;</span>, label=<span class="string">&quot;Precision&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.plot(thresholds, recalls[:-<span class="number">1</span>], <span class="string">&quot;g-&quot;</span>, label=<span class="string">&quot;Recall&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.vlines(thresholds, <span class="number">0</span>, <span class="number">1.0</span>, <span class="string">&quot;k&quot;</span>, <span class="string">&quot;dotted&quot;</span>, label=<span class="string">&quot;threshold&quot;</span>)</span><br><span class="line">[...] <span class="comment"># beautify the figure: add grid, legend, axis, labels, and circles </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPQPbQ.jpg" alt="图 3-5：精确率和召回率对决策阈值的影响"><figcaption aria-hidden="true">图 3-5：精确率和召回率对决策阈值的影响</figcaption></figure></p>
<p>此外该图还呈现了一个有趣的现象，当阈值提高时，准确率偶尔会下降，而召回率一定随阈值提高而单调下降。</p>
<p>在3000这个阈值下，准确率接近90%，召回率约为50%。另一种选择良好的精度&#x2F;召回率权衡的方法是直接绘制精度与召回率的关系，如图3-6所示：</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPQkUs.jpg" alt="图 3-6：准确率 vs 召回率"><figcaption aria-hidden="true">图 3-6：准确率 vs 召回率</figcaption></figure></p>
<p>你可以看到，准确度在 80% 的召回率左右开始急剧下降。您可能希望在下降之前选择一个准确率&#x2F;召回率权衡-例如，在60% 左右召回。当然，选择取决于您的项目。假设你的目标是90% 的准确率，你可以用第一张图找到你需要使用的阈值，但这不是很精确。或者，您可以搜索至少提供90%精度的最低阈值。为此，您可以使用 NumPy 数组的 argmax() 方法。这将返回最大值的第一个索引，在本例中意味着第一个 True 值。</p>
<h3 id="受试者操作特征（ROC）曲线"><a href="#受试者操作特征（ROC）曲线" class="headerlink" title="受试者操作特征（ROC）曲线"></a>受试者操作特征（ROC）曲线</h3><p>受试者操作特征（Receiver Operating Characteristic, ROC）曲线是二值分类器的另一个常用工具。它与精确率&#x2F;召回率曲线非常相似，但ROC曲线不是绘制精确率与召回率的关系，而是绘制真阳性率（召回率的另一个名称）与假阳性率（False Positive Rate, FPR）的关系。FPR（也称为fall-out）是指False事件被错误地归类为True事件的比率。它等于1-真阴性率（True Negative Rate, TNR），即正确归类为阴性的阴性实例的比率。TNR也被称为特异性。因此，ROC曲线绘制敏感性（召回率）与1-特异性。为了绘制ROC曲线，首先使用roc_curve() 函数计算各种阈值的 TPR 和 FPR：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>

<p>然后，您可以使用 Matplotlib 绘制FPR与TPR的关系。下面的代码生成图3-7中的图。为了找到对应于90%精度的点，我们需要查找所需阈值的索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">idx_for_threshold_at_90 = (thresholds &lt;= threshold_for_90_precision).argmax()</span><br><span class="line">tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]</span><br><span class="line"></span><br><span class="line">plt.plot(fpr, tpr, linewidth=<span class="number">2</span>, label=<span class="string">&quot;ROC curve&quot;</span>) </span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;k:&#x27;</span>, label=<span class="string">&quot;Random classifier&#x27;s ROC curve&quot;</span>) </span><br><span class="line">plt.plot([fpr_90], [tpr_90], <span class="string">&quot;ko&quot;</span>, label=<span class="string">&quot;Threshold for 90% precision&quot;</span>) </span><br><span class="line">[...] <span class="comment"># beautify the figure: add labels, grid, legend, arrow, and text </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/13/pEPbgLd.png" alt="图3-7  在所有可能的阈值下绘制假阳性率与真阳性率的ROC曲线；黑色圆圈突出了所选择的比例（90%的准确率和48%的召回率）。"><figcaption aria-hidden="true">图3-7  在所有可能的阈值下绘制假阳性率与真阳性率的ROC曲线；黑色圆圈突出了所选择的比例（90%的准确率和48%的召回率）。</figcaption></figure></p>
<p>这里存在一个权衡：召回率（TPR）越高，分类器产生的假阳性（FPR）越多。虚线表示纯随机分类器的ROC曲线；一个好的分类器会尽可能远离那条线（朝向左上角）。比较分类器的一种方法是测量曲线下面积（Area Under the Curve, AUC）。一个完美的分类器的ROC AUC等于1，而一个纯粹随机的分类器的ROC AUC等于0.5。Scikit-Learn 提供了一个函数来估计ROC AUC：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores)</span><br><span class="line"><span class="number">0.9604938554008616</span></span><br></pre></td></tr></table></figure>

<p>现在让我们创建一个 RandomForestClassifier，我们可以将其PR曲线和${\rm F}_1$分数与 SGDClassifier 进行比较：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier </span><br><span class="line">forest_clf = RandomForestClassifier(random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<p>precision_recall_curve() 函数需要每个实例的标签和分数，因此我们需要训练随机森林分类器并使其为每个实例分配分数。但是 RandomForestClassifier 类没有 decision_function() 方法，因为它的工作方式（我们将在第7章中介绍）。幸运的是，它有一个 predict_proba() 方法，返回每个实例的类概率，我们可以只使用正类的概率作为分数，所以它会工作得很好。我们可以调用 cross_val_predict() 函数来使用交叉验证训练 RandomForestClassifier，并使其预测每个图像的类别概率，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=<span class="number">3</span>, method=<span class="string">&quot;predict_proba&quot;</span>)</span><br><span class="line">&gt;&gt;&gt;y_probas_forest[:<span class="number">2</span>] </span><br><span class="line">array([[<span class="number">0.11</span>, <span class="number">0.89</span>],</span><br><span class="line">    [<span class="number">0.99</span>, <span class="number">0.01</span>]])</span><br></pre></td></tr></table></figure>

<p>让我们看看训练集中前两张图像的类概率。该模型预测第一张图像为正的概率为89%，预测第二张图像为负的概率为99%。因为每个图像要么是正的，要么是负的，每一行的概率加起来是100%。</p>
<p>这些是估计的概率，不是实际的概率。例如，如果你看一下所有被模型分类为阳性的图像，估计概率在50%到60%之间，大约94%的图像实际上是阳性的。因此，在这种情况下，模型估计的概率太低了——但模型也可能过于自信。sklearn calibration package 包含工具来校准估计的概率，使它们更接近实际概率。请参阅本章笔记本中的额外材料部分了解更多细节。</p>
<p>第二列包含正类的估计概率，因此让我们将它们传递给precision_recall_curve()函数，并绘制PR曲线（图3-8）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_scores_forest = y_probas_forest[:, <span class="number">1</span>] </span><br><span class="line">precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve( y_train_5, y_scores_forest)</span><br><span class="line"></span><br><span class="line">plt.plot(recalls_forest, precisions_forest, <span class="string">&quot;b-&quot;</span>, linewidth=<span class="number">2</span>, label=<span class="string">&quot;Random Forest&quot;</span>)</span><br><span class="line">plt.plot(recalls, precisions, <span class="string">&quot;--&quot;</span>, linewidth=<span class="number">2</span>, label=<span class="string">&quot;SGD&quot;</span>) </span><br><span class="line">[...] <span class="comment"># beautify the figure: add labels, grid, and legend </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/16/pEFyTEQ.png" alt="图 3-8：PR曲线比较：随机森林分类器优于SGD分类器，因为它的PR曲线更接近右上角，并且具有更大的AUC"><figcaption aria-hidden="true">图 3-8：PR曲线比较：随机森林分类器优于SGD分类器，因为它的PR曲线更接近右上角，并且具有更大的AUC</figcaption></figure></p>
<p>如图3-8所示，RandomForestClassifier的PR曲线看起来比SGDClassifier的要好得多：它更接近右上角。其Fi评分和ROC AUC评分也明显较好：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_pred_forest =y_probas_forest[:, <span class="number">1</span>]&gt;= <span class="number">0.5</span> <span class="comment"># positive proba 2 50% </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_pred_forest)</span><br><span class="line"><span class="number">0.9242275142688446</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores_forest)</span><br><span class="line"><span class="number">0.9983436731328145</span></span><br></pre></td></tr></table></figure>

<p>试着测量准确率和召回率得分：你应该发现99.1%的准确率和86.6%的召回率。还不错！现在您知道了如何训练二元分类器、为您的任务选择适当的指标、使用交叉验证评估分类器、选择适合您需要的精度&#x2F;召回率权衡，以及使用几个指标和曲线来比较不同的模型。</p>
<h2 id="多元分类"><a href="#多元分类" class="headerlink" title="多元分类"></a>多元分类</h2><p>二元分类器区分两个类，而多类分类器（也称为多项分类器）可以区分两个以上的类。一些 Scikit-Learn 分类器（例如 LogisticRegression，RandomForestClassifier 和 GaussianNB）能够本地处理多个类。其他的则是严格的二元分类器（例如 SGDClassifier 和 SVC）。但是，您可以使用各种策略来使用多个二进制分类器执行多类分类。</p>
<p>OvR策略：创建可以将数字图像分类为10类（从0到9）的系统的一种方法是训练10个二进制分类器，每个数字一个（0检测器、1检测器、2检测器等等）。然后，当你想对图像进行分类时，你从该图像的每个分类器中获得决策分数，然后<strong>选择分类器输出最高分数的类</strong>。这被称为一对其余（one-versus-the-rest, OvR）策略，有时也称为一对所有（one-versus-all, OvA）策略。</p>
<p>OvO策略：另一种策略是为每一对数字训练一个二元分类器：一个用于区分0和1，另一个用于区分0和2，另一个用于区分1和2，以此类推。这被称为1对1（one-versus-one, OvO）策略。如果有N个类，你需要训练 Nx(N-1)&#x2F;2 个分类器。对于 MNIST 问题，这意味着要训练 45 个二元分类器！当您想要对图像进行分类时，您必须在所有 45 个分类器中运行图像，并<strong>查看哪个类赢得最多的决斗</strong>。OvO 的主要优点是每个分类器只需要在包含它必须区分的两个类的训练集部分进行训练。</p>
<p>一些算法（如支持向量机分类器）随着训练集的大小缩放得很差。对于这些算法，OvO是首选，因为在小的训练集上训练许多分类器比在大的训练集上训练很少的分类器要快。然而，对于大多数二进制分类算法，OvR 是首选。当您尝试使用二进制分类算法时，Scikit-Learn 会检测一个多类分类任务，它会根据算法自动运行 OvR 或 OvO。让我们使用 sklearn.svm.SVC 类（参见第5章）来尝试使用支持向量机分类器。我们只训练前 2000 张图像，否则将花费很长时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">svm_clf = SVC(random_state=<span class="number">42</span>) </span><br><span class="line">svm_clf.fit(X_train[:<span class="number">2000</span>], y_train[:<span class="number">2000</span>]) <span class="comment"># y_train, not y_train_5</span></span><br></pre></td></tr></table></figure>

<p>这很简单！我们使用从0到9的原始目标类（y_train）来训练SVC，而不是使用5对其余目标类（y_train_5）。由于有10个类（即超过2个），Scikit-Learn使用OvO策略并训练了45个二元分类器。现在让我们对图像做一个预测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;svm_clf.predict([some_digit]) </span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure>

<p>这是正确的!这段代码实际上做了45个预测，每对类一个，它选择了赢得最多决斗的类。如果调用decision_function() 方法，您将看到它为每个实例返回10个分数：每个类一个。每个类的得分等于赢得决斗的次数，加上或减去一个小调整（最大±0.33），以打破平局，基于分类器得分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;some_digit_scores=svm_clf.decision_function([some_digit])</span><br><span class="line">&gt;&gt;&gt;some_digit_scores.<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line">array([[ <span class="number">3.79</span>, <span class="number">0.73</span>, <span class="number">6.06</span>, <span class="number">8.3</span>,-<span class="number">0.29</span>, <span class="number">9.3</span>, <span class="number">1.75</span>, <span class="number">2.77</span>, <span class="number">7.21</span>, <span class="number">4.82</span>]])</span><br></pre></td></tr></table></figure>

<p>最高分9.3分，确实是类别5所对应的分数。</p>
<p>当一个分类器被训练时，它将目标类的列表存储在其classes属性中，按值排序。在MNIST的情况下，classes_ 数组中每个类的索引方便地匹配类本身（例如，索引5处的类恰好是类‘5’），但通常你不会那么幸运；你需要像这样查找类标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>svm_clf.classes_</span><br><span class="line">array(ГO<span class="string">&#x27;, &#x27;</span><span class="number">1</span><span class="string">&#x27;, &#x27;</span><span class="number">2</span><span class="string">&#x27;, &#x27;</span><span class="number">3</span><span class="string">&#x27;, &#x27;</span><span class="number">4</span><span class="string">&#x27;, &#x27;</span><span class="number">5</span><span class="string">&#x27;, &#x27;</span><span class="number">6</span><span class="string">&#x27;, &#x27;</span><span class="number">7</span><span class="string">&#x27;, &#x27;</span><span class="number">8</span><span class="string">&#x27;, &#x27;</span><span class="number">9</span><span class="string">&#x27;], dtype=object)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; svm_clf.classes_[class_id] </span></span><br><span class="line"><span class="string">&#x27;</span><span class="number">5</span><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>

<p>如果你想强迫 Scikit-Learn 使用OvO或OvR的测试，你可以使用 onevsonecclassifier 或 OneVsRestClassifier 类。只需创建一个实例并将一个分类器传递给它的构造函数（它甚至不必是二进制分类器）。例如，以下代码使用基于 SVC 的 OvR 策略创建了一个多类分类器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"></span><br><span class="line">ovr_clf = OneVsRestClassifier(SVC(random_state=<span class="number">42</span>)) </span><br><span class="line">ovr_clf.fit(X_train[:<span class="number">2000</span>], y_train[:<span class="number">2000</span>])</span><br></pre></td></tr></table></figure>

<p>让我们做一个预测，并检查训练的分类器的数量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovr_clf.predict([some_digit]) </span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(ovr_clf.estimators_)</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>在多类数据集上训练 SGDClassifier 并使用它进行预测也同样简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">&gt;&gt;&gt;sgd_clf.fit(X_train, y_train)</span><br><span class="line">&gt;&gt;&gt;sgd_clf.predict([some_digit])</span><br><span class="line">array([<span class="string">&#x27;3&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>哎呀，这是不正确的。预测错误确实会发生！这次 Scikit-Learn 在底层使用了OvR策略：因为有10个类，所以它训练了10个二元分类器。decision_function()方法现在每个类返回一个值。让我们看看 SGD 分类器分配给每个类的分数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.decision_function([some_digit]).<span class="built_in">round</span>()</span><br><span class="line">array([[-<span class="number">31893.</span>, -<span class="number">34420.</span>, -<span class="number">9531.</span>, <span class="number">1824.</span>, -<span class="number">22320.</span>, -<span class="number">1386.</span>, -<span class="number">26189.</span>,-<span class="number">16148.</span>, -<span class="number">4604.</span>,-<span class="number">12051.</span>]])</span><br></pre></td></tr></table></figure>

<p>你可以看到分类器对它的预测不是很有信心：几乎所有的分数都是非常负的，而类3的分数是+1824，类5的分数是-1386，并没有落后太多。当然，您需要在多个图像上评估这个分类器。由于每个类中有大致相同数量的图像，因此精度度量很好。像往常一样，你可以使用 cross_val_score() 函数来评估模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.87365</span>, <span class="number">0.85835</span>, <span class="number">0.8689</span> ])</span><br></pre></td></tr></table></figure>

<p>它在所有测试折叠中都超过了85.8%。如果你使用随机分类器，你会得到10%的准确率，所以这不是一个糟糕的分数，但你仍然可以做得更好。简单地缩放输入（如第2章所述）将精度提高到89.1%以上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_scaled = scaler.fit_transform(X_train.astype(<span class="string">&quot;float64&quot;</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>) </span><br><span class="line">array([<span class="number">0.8983</span>, <span class="number">0.891</span> , <span class="number">0.9018</span>])</span><br></pre></td></tr></table></figure>

<h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2>]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 12：聚类分析</title>
    <url>/PythonLes13/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>今天总结了最常见的五种聚类算法。涉及到的算法有：</p>
<ul>
<li>K均值聚类（K-Means Clustering）</li>
<li>层次聚类（Hierarchical Clustering）</li>
<li>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</li>
<li>高斯混合模型（Gaussian Mixture Model，GMM）</li>
<li>谱聚类（Spectral Clustering）</li>
</ul>
<span id="more"></span>

<h2 id="课程作业03-占总成绩25"><a href="#课程作业03-占总成绩25" class="headerlink" title="课程作业03 占总成绩25%"></a>课程作业03 占总成绩25%</h2><p>构建四组二维空间中的随机分布散点，每组散点符合二维高斯分布，高斯分布的中心点与两个方向的标准差均随机产生，且二维高斯分布的中心点落在[[0,100],[0,100]]的方形区域内。</p>
<p>通过K均值聚类分析方法对上述随机散点执行聚类分析，绘制分类结果，并计算K-means聚类分析的准确率。</p>
<h2 id="K均值聚类（K-Means-Clustering）"><a href="#K均值聚类（K-Means-Clustering）" class="headerlink" title="K均值聚类（K-Means Clustering）"></a>K均值聚类（K-Means Clustering）</h2><p>K均值聚类（K-Means Clustering）是一种常用的无监督学习算法，用于将数据集分成K个簇（clusters）。其目标是将相似的数据点归为同一簇，而将不同的数据点分到不同的簇中，从而使得每个簇内的数据点之间的相似度最大，而不同簇之间的相似度最小。</p>
<h3 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h3><p>K均值聚类的核心思想是通过迭代优化的方法，最小化簇内点到簇中心的总距离平方和。</p>
<p>基本步骤如下：</p>
<ol>
<li><p>初始化：随机选择K个点作为初始簇中心。</p>
</li>
<li><p>分配簇：将每个数据点分配到最近的簇中心。</p>
</li>
<li><p>更新簇中心：重新计算每个簇的中心（即簇内所有点的平均值）。</p>
</li>
<li><p>重复：重复步骤2和3，直到簇中心不再发生显著变化或达到预定的迭代次数。</p>
</li>
</ol>
<h3 id="核心公式"><a href="#核心公式" class="headerlink" title="核心公式"></a>核心公式</h3><p>假设数据集为$x_1,x_2,…,x_n$，每个数据点$x_i$有$d$维。簇的中心为$\mu_1,\mu_2,…,\mu_K$。</p>
<ol>
<li><p>距离计算：通常使用欧氏距离：<br>\begin{equation}<br>{\bf dist}(x_i,\mu_k) &#x3D; \Arrowvert x_i-\mu_k\Arrowvert_2 &#x3D; \sqrt{\sum^d_{j&#x3D;1} (x_{ij}-\mu_{kj})^2}<br>\end{equation}</p>
</li>
<li><p>簇分配：将每个点分配到最近的簇中心：<br>\begin{equation}<br>C_k &#x3D; {x_i:\Arrowvert x_i-\mu_k \Arrowvert_2 \leq \Arrowvert x_i - \mu_j\Arrowvert_2, \forall j,1 \leq j \leq K }<br>\end{equation}</p>
</li>
<li><p>更新簇中心：重新计算每个簇的中心：<br>\begin{equation}<br>\mu_k &#x3D; \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i<br>\end{equation}</p>
</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUF3JP.png" width="75%" alt="" align=center />

<h4 id="Python示例代码"><a href="#Python示例代码" class="headerlink" title="Python示例代码"></a>Python示例代码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用KMeans进行聚类</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">4</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line">y_kmeans = kmeans.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_kmeans, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.title(<span class="string">&quot;K-Means Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成了500个二维数据点，分为4个簇。</p>
</li>
<li><p>训练模型：使用KMeans模型进行训练，设定簇数为4。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出簇中心。</p>
</li>
</ol>
<p>大家可以清晰地看到K均值聚类的效果，即每个簇内的数据点被分为同一种颜色，而不同簇的数据点被分为不同颜色，同时簇中心用红色圆点表示。</p>
<h2 id="层次聚类（Hierarchical-Clustering）"><a href="#层次聚类（Hierarchical-Clustering）" class="headerlink" title="层次聚类（Hierarchical Clustering）"></a>层次聚类（Hierarchical Clustering）</h2><p>层次聚类（Hierarchical Clustering）是一种常见的无监督学习算法，旨在通过构建层次树状结构将数据点进行分组。它可以分为两种类型：自底向上的聚合（agglomerative）和自顶向下的分裂（divisive）聚类方法。</p>
<h3 id="核心原理-1"><a href="#核心原理-1" class="headerlink" title="核心原理"></a>核心原理</h3><p>层次聚类的核心思想是通过递归地合并或分裂簇，构建一个层次树（树状图或树状图），表示数据的嵌套分组。这里我们以自底向上的聚合层次聚类为例：</p>
<ol>
<li><p>初始化：将每个数据点视为一个独立的簇。</p>
</li>
<li><p>计算距离：计算所有簇之间的距离矩阵。</p>
</li>
<li><p>合并簇：找到距离最近的两个簇并合并它们。</p>
</li>
<li><p>更新距离矩阵：更新合并后的簇与其他簇之间的距离。</p>
</li>
<li><p>重复：重复步骤3和4，直到所有数据点合并成一个簇。</p>
</li>
</ol>
<h3 id="核心公式-1"><a href="#核心公式-1" class="headerlink" title="核心公式"></a>核心公式</h3><p>假设数据集为$x_1, x_2, …,x_n$，簇之间的距离可以通过多种方式计算，包括最小距离（single linkage）、最大距离（complete linkage）和平均距离（average linkage）等。</p>
<ol>
<li>距离计算：假设簇$A$和簇$B$中的点分别为$a_1, a_2,…,a_p$和$b_1,b_2,…b_q$，则不同的距离计算方法如下：</li>
</ol>
<ul>
<li><p>最小距离（单链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \min_{i,j} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
<li><p>最大距离（全链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \max_{i,j} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
<li><p>平均距离（平均链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \frac{1}{pq} \sum^{p}<em>{i&#x3D;1} \sum^{q}</em>{j&#x3D;1} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
</ul>
<img src="https://s21.ax1x.com/2024/06/11/pkUFMdA.png" width="75%" alt="" align=center />

<h4 id="Python案例"><a href="#Python案例" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">3</span>, random_state=<span class="number">0</span>, cluster_std=<span class="number">0.60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行层次聚类</span></span><br><span class="line">Z = linkage(X, method=<span class="string">&#x27;ward&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制树状图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">dendrogram(Z, truncate_mode=<span class="string">&#x27;lastp&#x27;</span>, p=<span class="number">12</span>, leaf_rotation=<span class="number">90.</span>, leaf_font_size=<span class="number">12.</span>, show_contracted=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Hierarchical Clustering Dendrogram&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Sample index or (Cluster size)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Distance&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成500个二维数据点，分为3个簇。</p>
</li>
<li><p>层次聚类：使用linkage函数进行层次聚类，采用Ward方法计算簇间距离。</p>
</li>
<li><p>绘制树状图：使用dendrogram函数绘制树状图，展示聚类的层次结构。</p>
</li>
</ol>
<p>通过树状图，大家可以清晰地看到层次聚类的合并过程，从最底层的单个数据点逐渐合并到最终的一个簇。树状图的高度表示簇之间的距离，合并越早的簇之间距离越近，合并越晚的簇之间距离越远。</p>
<h2 id="DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）"><a href="#DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）" class="headerlink" title="DBSCAN（Density-Based Spatial Clustering of Applications with Noise）"></a>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</h2><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，可以发现任意形状的簇，同时能够识别出噪声点。与K均值和层次聚类不同，DBSCAN不需要事先指定簇的数量。</p>
<h3 id="核心原理-2"><a href="#核心原理-2" class="headerlink" title="核心原理"></a>核心原理</h3><p>DBSCAN通过在数据点周围划定一个$\varepsilon$半径，计算半径内的数据点数量来定义簇。其基本思想是密度足够高的区域形成簇，而密度较低的区域被认为是噪声。主要步骤如下：</p>
<ol>
<li><p>定义核心点：对于数据集中每个点，如果在其ε半径内的点数大于或等于最小点数（minPts），则该点为核心点。</p>
</li>
<li><p>扩展簇：从核心点出发，将其邻域内的所有点（包括边界点和其他核心点）归入该簇，然后递归地将这些点的邻域内的点也归入该簇。</p>
</li>
<li><p>标记噪声点：如果一个点既不是核心点也不是边界点，则将其标记为噪声点。</p>
</li>
</ol>
<h3 id="核心公式-2"><a href="#核心公式-2" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>邻域定义：对于点$p$，其邻域定义为：<br>\begin{equation}<br>N_{\varepsilon}(p) &#x3D; { q \in D|{\bf dist}(p,q)\leq \varepsilon }<br>\end{equation}</li>
</ol>
<p>其中 $D$ 是数据集，${\bf dist}(p,q)$ 是点 $p$ 和点 $q$ 之间的距离，通常使用欧氏距离。</p>
<ol start="2">
<li>核心点：如果点 $p$ 的邻域包含至少 minPts 个点，则 $p$ 是核心点：<br>\begin{equation}<br>|N_{\varepsilon}(p)| \geq {\bf minPts}<br>\end{equation}</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUF1it.png" width="75%" alt="" align=center />

<h4 id="Python案例-1"><a href="#Python案例-1" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用DBSCAN进行聚类</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.2</span>, min_samples=<span class="number">5</span>)</span><br><span class="line">y_dbscan = dbscan.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_dbscan, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标记噪声点</span></span><br><span class="line">core_samples_mask = np.zeros_like(y_dbscan, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[dbscan.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line">noise_mask = (y_dbscan == -<span class="number">1</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, label=<span class="string">&#x27;Noise&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;DBSCAN Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_moons生成500个二维数据点，这些数据点形成两个半月形簇，并添加了一定的噪声。</p>
</li>
<li><p>训练模型：使用DBSCAN模型进行训练，设置$\varepsilon$为0.2，minPts为5。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出噪声点。</p>
</li>
</ol>
<p>大家可以清晰地看到DBSCAN的聚类效果，两个半月形的簇被正确识别出来，噪声点用红色标注。DBSCAN能够很好地处理复杂形状的簇，并且能够识别出数据中的噪声点。</p>
<h2 id="高斯混合模型（Gaussian-Mixture-Model，GMM）"><a href="#高斯混合模型（Gaussian-Mixture-Model，GMM）" class="headerlink" title="高斯混合模型（Gaussian Mixture Model，GMM）"></a>高斯混合模型（Gaussian Mixture Model，GMM）</h2><p>高斯混合模型（GMM）是一种概率模型，它假设所有的数据点是由若干个不同的高斯分布（即正态分布）组成的混合生成。GMM常用于聚类分析，特别适合于发现复杂数据分布中的潜在群体结构。</p>
<h3 id="核心原理-3"><a href="#核心原理-3" class="headerlink" title="核心原理"></a>核心原理</h3><p>GMM通过期望最大化（EM）算法来估计模型参数。EM算法是一个迭代优化算法，包括两个主要步骤：</p>
<ol>
<li><p>E步（Expectation）：计算给定当前参数下每个数据点属于每个高斯分布的概率（即责任）。</p>
</li>
<li><p>M步（Maximization）：根据计算出的责任，重新估计每个高斯分布的参数（均值、方差和权重）。</p>
</li>
</ol>
<h3 id="核心公式-3"><a href="#核心公式-3" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>高斯混合模型的概率密度函数：<br>\begin{equation}<br>p(x) &#x3D; \sum^{K}_{k &#x3D; 1}\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)<br>\end{equation}</li>
</ol>
<p>其中，$\pi_k$是第$k$个高斯分布的权重，$\mathcal{N}(x|\mu_k,\sum_k)$是第$k$个高斯分布的概率密度函数，其参数为均值$\mu_k$和协方差矩阵$\Sigma_k$。</p>
<ol start="2">
<li>E步（计算责任）：<br>\begin{equation}<br>\gamma_{ik} &#x3D; \frac{\pi_k\mathcal{N}(x|\mu_k,\Sigma_k)}{\sum_{j &#x3D; 1}^{K}\pi_j \mathcal{N}(x|\mu_k,\Sigma_k)}<br>\end{equation}</li>
</ol>
<p>其中，$\gamma_{ik}$是数据点$x_i$属于第$k$个高斯分布的概率。</p>
<ol start="3">
<li>M步（更新参数）：</li>
</ol>
<p>更新权重：<br>\begin{equation}<br>\pi_k &#x3D; \frac{N_k}{N}<br>\end{equation}</p>
<p>其中，$N_k &#x3D; \sum_{i&#x3D;1}^{N} \gamma_{ik}$是第$k$个高斯分布的有效样本数，$N$是数据点总数。</p>
<p>更新均值：<br>\begin{equation}<br>\mu_k &#x3D; \frac{1}{N_k}\sum_{i&#x3D;1}^{N} \gamma_{ik}x_i<br>\end{equation}</p>
<p>更新协方差矩阵：<br>\begin{equation}<br>\Sigma_k &#x3D; \frac{1}{N_k}\sum_{i&#x3D;1}^{N}\gamma_{ik}(x_i-\mu_k)(x_i-\mu_k)^{T}<br>\end{equation}</p>
<img src="https://s21.ax1x.com/2024/06/11/pkUFKZd.png" width="75%" alt="" align=center />


<h4 id="Python案例-2"><a href="#Python案例-2" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">3</span>, random_state=<span class="number">42</span>, cluster_std=<span class="number">0.60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GMM进行聚类</span></span><br><span class="line">gmm = GaussianMixture(n_components=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">gmm.fit(X)</span><br><span class="line">labels = gmm.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, s=<span class="number">40</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.scatter(gmm.means_[:, <span class="number">0</span>], gmm.means_[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>, marker=<span class="string">&#x27;X&#x27;</span>)  <span class="comment"># 标记出中心点</span></span><br><span class="line">plt.title(<span class="string">&quot;Gaussian Mixture Model Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成500个二维数据点，分为3个簇，并添加一定的噪声。</p>
</li>
<li><p>训练模型：使用GaussianMixture模型进行训练，设定簇数为3。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出每个高斯分布的均值。</p>
</li>
</ol>
<p>大家可以看到GMM的聚类效果，每个簇用不同的颜色表示，红色的X标记出每个高斯分布的中心。GMM能够很好地处理复杂的簇结构，并且可以估计每个簇的概率分布。</p>
<h2 id="谱聚类（Spectral-Clustering）"><a href="#谱聚类（Spectral-Clustering）" class="headerlink" title="谱聚类（Spectral Clustering）"></a>谱聚类（Spectral Clustering）</h2><p>谱聚类（Spectral Clustering）是一种基于图论的聚类方法，通过利用数据点之间的相似性构建图，并利用图的谱（特征值和特征向量）进行聚类。它特别适合处理非凸形状的簇，并且能有效处理高维数据。</p>
<h3 id="核心原理-4"><a href="#核心原理-4" class="headerlink" title="核心原理"></a>核心原理</h3><p>谱聚类的核心思想是将数据点看作图中的节点，通过计算节点之间的相似性构建加权图，然后通过图的拉普拉斯矩阵的特征向量将数据映射到低维空间，再在低维空间中进行K均值聚类。</p>
<p>主要步骤如下：</p>
<ol>
<li><p>构建相似度矩阵：计算数据点之间的相似度，构建相似度矩阵。</p>
</li>
<li><p>构建拉普拉斯矩阵：根据相似度矩阵构建图的拉普拉斯矩阵。</p>
</li>
<li><p>计算特征向量：计算拉普拉斯矩阵的前k个特征向量，将数据点映射到低维空间。</p>
</li>
<li><p>聚类：在低维空间中对映射后的数据点进行K均值聚类。</p>
</li>
</ol>
<h3 id="核心公式-4"><a href="#核心公式-4" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>相似度矩阵$W$：<br>\begin{equation}<br>W_{ij} &#x3D; \exp\left(-\frac{\Arrowvert x_i-x_j \Arrowvert^2}{2\sigma^2}\right) \quad {\bf if} \quad \Arrowvert x_i - x_j \Arrowvert \leq \varepsilon, {\bf else} \quad 0<br>\end{equation}</li>
</ol>
<p>其中，$\sigma$是高斯核函数的参数，$\varepsilon$是邻域范围。</p>
<ol start="2">
<li><p>度矩阵$D$：<br>\begin{equation}<br>D_{ij} &#x3D; \sum_{j} W_{ij}<br>\end{equation}</p>
</li>
<li><p>拉普拉斯矩阵$L$：<br>\begin{equation}<br>L &#x3D; D-W<br>\end{equation}</p>
</li>
</ol>
<p>或归一化的拉普拉斯矩阵：<br>\begin{equation}<br>L_{sym} &#x3D; D^{-1&#x2F;2}LD^{-1&#x2F;2}<br>\end{equation}</p>
<ol start="4">
<li><p>特征向量：计算$L$或$L_{sym}$的前$k$个特征向量$u_1,u_2,…,u_k$。</p>
</li>
<li><p>聚类：将每个数据点$x_i$映射到特征向量组成的低维空间，再对这些向量进行$K$均值聚类。</p>
</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUFQII.png" width="75%" alt="" align=center />

<h4 id="Python案例-3"><a href="#Python案例-3" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> SpectralClustering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用谱聚类进行聚类</span></span><br><span class="line">spectral = SpectralClustering(n_clusters=<span class="number">2</span>, affinity=<span class="string">&#x27;nearest_neighbors&#x27;</span>, assign_labels=<span class="string">&#x27;kmeans&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">labels = spectral.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, s=<span class="number">40</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Spectral Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用<code>make_moons</code>生成500个二维数据点，形成两个半月形簇，并添加一定的噪声。</p>
</li>
<li><p>训练模型：使用<code>SpectralClustering</code>模型进行训练，设定簇数为2，使用最近邻相似度计算，标签分配使用K均值。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色。</p>
</li>
</ol>
<p>可以看到谱聚类的效果，两个半月形的簇被正确识别出来，每个簇用不同的颜色表示。谱聚类通过利用数据点之间的相似性构建图结构，并通过图的谱（特征向量）进行聚类，有效地处理了复杂形状的簇结构。</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能：# KL散度 (Kullback-Leibler Divergence) 与交叉熵 (Cross-Entropy)</title>
    <url>/kldivergence/</url>
    <content><![CDATA[<p>KL散度和交叉熵是信息论中两个非常重要的概念，在机器学习，特别是深度学习领域，它们被广泛用作损失函数，以衡量两个概率分布之间的差异。</p>
<ul>
<li><strong>交叉熵 (Cross-Entropy)</strong>：衡量使用“错误的”分布Q来表示来自“正确的”分布P的样本所需要的平均信息量（比特数）。</li>
<li><strong>KL散度 (KL Divergence)</strong>：衡量使用“错误的”分布Q来表示分布P的样本，相对于使用“正确的”分布P自己来表示时，所产生的<strong>额外</strong>信息量。</li>
</ul>
<p>两者在数学上紧密相关，在某些特定场景下（如分类任务的损失函数），最小化交叉熵等价于最小化KL散度。</p>
<h2 id="一、交叉熵-Cross-Entropy"><a href="#一、交叉熵-Cross-Entropy" class="headerlink" title="一、交叉熵 (Cross-Entropy)"></a>一、交叉熵 (Cross-Entropy)</h2><h3 id="1-概念与直觉"><a href="#1-概念与直觉" class="headerlink" title="1. 概念与直觉"></a>1. 概念与直觉</h3><p>想象一下，你需要设计一套编码系统来传输一个地区（分布P）的天气信息（晴、阴、雨）。如果你的编码系统是根据另一个地区（分布Q）的天气历史设计的，那么用这套编码系统来传输P地区的天气信息时，平均每个信息所需要的编码长度就是<strong>交叉熵</strong>。</p>
<ul>
<li>如果分布Q与分布P非常相似，那么这套编码会非常高效，交叉熵就很低。</li>
<li>如果分布Q与分布P差异很大，编码效率就会很低，交叉熵就很高。</li>
</ul>
<p>在机器学习中，我们通常将：</p>
<ul>
<li><strong>P (真实分布)</strong>：看作是数据的真实标签，通常是独热编码（One-Hot Encoding）形式，例如 <code>[0, 1, 0]</code> 表示样本真实属于第2类。</li>
<li><strong>Q (预测分布)</strong>：看作是模型（如通过Softmax层）输出的预测概率，例如 <code>[0.1, 0.7, 0.2]</code>。</li>
</ul>
<p>交叉熵损失函数的目标就是让模型的预测分布Q尽可能地接近真实分布P。</p>
<h3 id="2-数学公式"><a href="#2-数学公式" class="headerlink" title="2. 数学公式"></a>2. 数学公式</h3><p>对于两个离散的概率分布 P 和 Q，其交叉熵定义为：</p>
<p>$$H(P, Q) &#x3D; - \sum_{i} P(i) \log_b Q(i)$$</p>
<p>其中：</p>
<ul>
<li><code>i</code> 代表所有可能的事件（或类别）。</li>
<li><code>P(i)</code> 是事件 <code>i</code> 在真实分布 P 中的概率。</li>
<li><code>Q(i)</code> 是事件 <code>i</code> 在预测分布 Q 中的概率。</li>
<li><code>b</code> 是对数的底，在机器学习中通常使用自然对数 <code>e</code> (即 <code>ln</code>)。</li>
</ul>
<h3 id="3-计算过程-以分类任务为例"><a href="#3-计算过程-以分类任务为例" class="headerlink" title="3. 计算过程 (以分类任务为例)"></a>3. 计算过程 (以分类任务为例)</h3><p>假设我们有一个3分类问题，一个样本的真实标签是“狗”。</p>
<p><strong>步骤 1: 定义 P 和 Q</strong></p>
<ul>
<li><p><strong>真实分布 P (One-Hot)</strong>:</p>
<ul>
<li><code>P = [P(猫), P(狗), P(鱼)] = [0, 1, 0]</code></li>
</ul>
</li>
<li><p><strong>模型预测分布 Q (Softmax输出)</strong>:</p>
<ul>
<li><code>Q = [Q(猫), Q(狗), Q(鱼)] = [0.2, 0.7, 0.1]</code></li>
</ul>
</li>
</ul>
<p><strong>步骤 2: 应用交叉熵公式</strong></p>
<p>$$H(P, Q) &#x3D; - \left( P(猫)\ln Q(猫) + P(狗)\ln Q(狗) + P(鱼)\ln Q(鱼) \right)$$</p>
<p><strong>步骤 3: 代入数值计算</strong></p>
<p>$$H(P, Q) &#x3D; - \left( 0 \cdot \ln(0.2) + 1 \cdot \ln(0.7) + 0 \cdot \ln(0.1) \right)$$</p>
<p>由于真实分布P是独热编码，只有真实标签那一项的 <code>P(i)</code> 是1，其余都是0。这极大地简化了计算：</p>
<p>$$H(P, Q) &#x3D; - \ln(0.7) \approx -(-0.3567) \approx 0.3567$$</p>
<p><strong>重要结论</strong>：在机器学习分类任务中，当真实标签是One-Hot形式时，<strong>交叉熵损失函数简化为对“正确类别”的预测概率取负对数</strong>。</p>
<hr>
<h2 id="二、KL散度-Kullback-Leibler-Divergence"><a href="#二、KL散度-Kullback-Leibler-Divergence" class="headerlink" title="二、KL散度 (Kullback-Leibler Divergence)"></a>二、KL散度 (Kullback-Leibler Divergence)</h2><h3 id="1-概念与直觉-1"><a href="#1-概念与直觉-1" class="headerlink" title="1. 概念与直觉"></a>1. 概念与直觉</h3><p>KL散度，又称<strong>相对熵 (Relative Entropy)</strong>，衡量的是两个概率分布之间的“距离”或“差异”。它量化了当我们用一个近似分布Q来代替真实分布P时，会损失多少信息。</p>
<p>与交叉熵不同，KL散度衡量的是<strong>额外</strong>的编码长度。</p>
<ul>
<li>如果P和Q完全相同，KL散度为0，表示没有信息损失。</li>
<li>P和Q差异越大，KL散度越大。</li>
<li><strong>不对称性</strong>：KL散度一个非常重要的特性是它不具有对称性，即 $D_{KL}(P || Q) \neq D_{KL}(Q || P)$。因此，它不是一个严格意义上的“距离度量”。</li>
</ul>
<h3 id="2-数学公式-1"><a href="#2-数学公式-1" class="headerlink" title="2. 数学公式"></a>2. 数学公式</h3><p>KL散度的定义如下：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log_b \frac{P(i)}{Q(i)}$$</p>
<h3 id="3-计算过程-使用相同例子"><a href="#3-计算过程-使用相同例子" class="headerlink" title="3. 计算过程 (使用相同例子)"></a>3. 计算过程 (使用相同例子)</h3><p><strong>步骤 1: 定义 P 和 Q</strong></p>
<ul>
<li><strong>真实分布 P</strong>: <code>[0, 1, 0]</code></li>
<li><strong>模型预测分布 Q</strong>: <code>[0.2, 0.7, 0.1]</code></li>
</ul>
<p><strong>步骤 2: 应用KL散度公式</strong></p>
<p>$$D_{KL}(P || Q) &#x3D; P(猫)\ln\frac{P(猫)}{Q(猫)} + P(狗)\ln\frac{P(狗)}{Q(狗)} + P(鱼)\ln\frac{P(鱼)}{Q(鱼)}$$</p>
<p><strong>步骤 3: 代入数值计算</strong></p>
<p>由于 <code>P(猫)</code> 和 <code>P(鱼)</code> 为0，这些项对总和的贡献也是0。我们只需计算 <code>P(狗)=1</code> 的那一项。</p>
<blockquote>
<p>注意: 当 <code>P(i)=0</code> 时，<code>P(i) * log(...)</code> 项为0。当 <code>Q(i)=0</code> 而 <code>P(i)≠0</code> 时，KL散度为无穷大。</p>
</blockquote>
<p>$$D_{KL}(P || Q) &#x3D; 1 \cdot \ln\frac{1}{0.7} &#x3D; \ln(1) - \ln(0.7) &#x3D; 0 - \ln(0.7) \approx 0.3567$$</p>
<p>你会发现，在这个特定的例子中，计算出的KL散度值与交叉熵的值完全相同。这并非偶然。</p>
<hr>
<h2 id="三、KL散度与交叉熵的关系"><a href="#三、KL散度与交叉熵的关系" class="headerlink" title="三、KL散度与交叉熵的关系"></a>三、KL散度与交叉熵的关系</h2><p>我们可以通过简单的数学变换揭示两者的深刻联系。</p>
<p>从KL散度的公式开始：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log \frac{P(i)}{Q(i)}$$</p>
<p>使用对数运算法则 $\log(a&#x2F;b) &#x3D; \log(a) - \log(b)$:</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) (\log P(i) - \log Q(i))$$</p>
<p>将求和拆开：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log P(i) - \sum_{i} P(i) \log Q(i)$$</p>
<p>我们发现，这个公式由两部分组成：</p>
<ol>
<li>$- \sum_{i} P(i) \log P(i)$：这是<strong>信息熵 (Entropy)</strong> 的定义，记为 $H(P)$。它衡量的是分布P自身的不确定性。</li>
<li>$- \sum_{i} P(i) \log Q(i)$：这正是<strong>交叉熵 (Cross-Entropy)</strong> 的定义，记为 $H(P, Q)$。</li>
</ol>
<p>于是，我们得到了它们之间的关系式：</p>
<p>$$D_{KL}(P || Q) &#x3D; -H(P) + H(P, Q)$$</p>
<p>移项后得到更清晰的形式：</p>
<p>$$H(P, Q) &#x3D; H(P) + D_{KL}(P || Q)$$</p>
<p><strong>交叉熵 &#x3D; 熵 + KL散度</strong></p>
<h3 id="在机器学习中的意义"><a href="#在机器学习中的意义" class="headerlink" title="在机器学习中的意义"></a>在机器学习中的意义</h3><p>在监督学习中，真实分布P（即数据标签）是固定的，因此它的熵 $H(P)$ 是一个<strong>常数</strong>。</p>
<p>当我们训练模型时，我们的目标是调整模型的参数来最小化损失函数。因为 $H(P)$ 是一个常数，所以<strong>最小化交叉熵 $H(P, Q)$ 就等价于最小化KL散度 $D_{KL}(P || Q)$</strong>。</p>
<p>由于交叉熵的计算比KL散度更简单（它不需要计算 $H(P)$），所以在实践中，分类模型的损失函数几乎总是使用交叉熵。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th align="left">特性</th>
<th align="left">交叉熵 (Cross-Entropy)</th>
<th align="left">KL散度 (KL Divergence)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>全称</strong></td>
<td align="left">Cross-Entropy</td>
<td align="left">Kullback-Leibler Divergence &#x2F; Relative Entropy</td>
</tr>
<tr>
<td align="left"><strong>公式</strong></td>
<td align="left">$H(P, Q) &#x3D; - \sum P(i) \log Q(i)$</td>
<td align="left">$D_{KL}(P</td>
</tr>
<tr>
<td align="left"><strong>直观意义</strong></td>
<td align="left">用Q的编码方案来编码P的平均成本</td>
<td align="left">用Q的编码方案代替P的方案所带来的额外成本</td>
</tr>
<tr>
<td align="left"><strong>对称性</strong></td>
<td align="left">不对称</td>
<td align="left"><strong>不对称</strong> ($D_{KL}(P|Q) \neq D_{KL}(Q|P)$)</td>
</tr>
<tr>
<td align="left"><strong>与熵的关系</strong></td>
<td align="left">$H(P,Q) &#x3D; H(P) + D_{KL}(P|Q)$</td>
<td align="left">$D_{KL}(P|Q) &#x3D; H(P,Q) - H(P)$</td>
</tr>
<tr>
<td align="left"><strong>主要用途</strong></td>
<td align="left">在分类任务中作为<strong>损失函数</strong>。</td>
<td align="left">衡量分布差异，用于变分自编码器(VAE)、策略梯度等。</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Artificial Intelligence</category>
      </categories>
      <tags>
        <tag>Artificial Intelligence</tag>
        <tag>Pytorch - large language models</tag>
      </tags>
  </entry>
  <entry>
    <title>About</title>
    <url>/about/index.html</url>
    <content><![CDATA[<h2 id="Self-Introduction"><a href="#Self-Introduction" class="headerlink" title="Self-Introduction:"></a>Self-Introduction:</h2><p>Hai-Wei Chai&ensp;[柴海伟]</p>
<ul>
<li>2025.04 - Now, Chief Executive Officer of Yance (Chengdu) Artificial Intelligence Technology Co., LTD</li>
<li>2022.06 - 2025.03, Assistant Professor in School of Material Science and Engineering, Southwest Jiaotong University</li>
<li>2019.09 - 2021.12, Doctor of Condensed Matter Physics, in Peac Institute of Multiscale Sciences</li>
<li>2016.09 - 2019.06, Master of Condensed Matter Physics, in Peac Institute of Multiscale Sciences</li>
<li>2012.09 - 2016.06, Bachelor in School of Physical Sciences, University of Science and Technology of China</li>
</ul>
<h2 id="Skills"><a href="#Skills" class="headerlink" title="Skills:"></a>Skills:</h2><ul>
<li>Programming languages: C&#x2F;C++, Matlab, Python, CUDA</li>
<li>Major: X-ray Imaging and Diffraction, Computed Tomography, Machine Learning</li>
<li>OS Platform: Linux, Mac OS, Windows</li>
<li>Language: English, Chinese</li>
</ul>
<h2 id="Contact-details"><a href="#Contact-details" class="headerlink" title="Contact details:"></a>Contact details:</h2><ul>
<li>E-mail: <a href="mailto:&#99;&#x68;&#119;&#57;&#x34;&#48;&#x32;&#64;&#109;&#97;&#105;&#108;&#x2e;&#x75;&#x73;&#x74;&#99;&#46;&#x65;&#x64;&#117;&#x2e;&#x63;&#110;">chw9402@mail.ustc.edu.cn</a></li>
</ul>
<h2 id="My-friends-me-at-USTC-2016"><a href="#My-friends-me-at-USTC-2016" class="headerlink" title="My friends &amp; me at USTC 2016:"></a>My friends &amp; me at USTC 2016:</h2><p><img src="https://s1.ax1x.com/2022/10/19/xsgD7F.jpg"></p>
]]></content>
  </entry>
  <entry>
    <title>数据科学：维格纳准概率分布（Wigner-Ville Distribution，WVD）</title>
    <url>/archive/AI-Wigner-Ville.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAU2JVU.png"></p>
<p>The Wigner distribution, often also Wigner-Ville distribution, is a time-frequency distribution, like the spectrogram, with very interesting properties and a high resolution in both the time and frequency domains. It has the benefits of ideal resolution properties [1] but it also includes signal-dependent interference terms [1] which are mathematical attributes but do not represent pure signal terms.</p>
<span id="more"></span>

<p>waitting ……</p>
<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://github.com/ljbkusters/python-wigner-distribution">https://github.com/ljbkusters/python-wigner-distribution</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>【英语写作】 审稿意见回复方法</title>
    <url>/archive/Exp003-Reply.html</url>
    <content><![CDATA[<p>李海洋关于南中国海钙质砂颗粒力学性能的研究工作去年十月整理成文，投给了 Scientific Report，因为一些特殊原因重新整理整理转投 Powder Technology ，近期终于得到Major revision 的返修意见。李海洋也早在 7 月就毕业入职了，由接下这个方向的师弟和我来纠错、整理、回复审稿意见。本文记录对审稿意见的回复技巧及近期对 Scr. Mater. 及 Powder Technol. 的两份审稿意见回复。</p>
<span id="more"></span>

<h2 id="Reply-for-Powder-Technol-HYLi"><a href="#Reply-for-Powder-Technol-HYLi" class="headerlink" title="Reply for Powder_Technol-HYLi"></a>Reply for Powder_Technol-HYLi</h2><h2 id="Reply-for-Scr-Mater-HWChai"><a href="#Reply-for-Scr-Mater-HWChai" class="headerlink" title="Reply for Scr_Mater-HWChai"></a>Reply for Scr_Mater-HWChai</h2><p><strong>Response to reviewer’s comments:</strong> “Correlation between cell wall buckling and deformation banding in a closed-cell foam” by H. W. Chai, H. Y. Li, X. H. Xiao, J. Y. Huang, and S. N. Luo, manuscript No. SMM-19-733.</p>
<p>&emsp;We appreciate the constructive remarks by the referee and have revised the manuscript accordingly. The comments raised are all addressed as follows. The revision details are marked in red in the revised manuscript. </p>
<h3 id="Reviewer-1"><a href="#Reviewer-1" class="headerlink" title="Reviewer #1"></a>Reviewer #1</h3><p>&emsp;This work investigates deformation dynamics in closed-cell foam of polymethacrylimide under uniaxial compression with in situ x-ray computed tomography and digital volume correlation. It is an interesting topic which it has to more study. The paper is good and well-written, but some issues have to be explained better.</p>
<ol>
<li>What is the difference to calculate mechanical properties in 2D or in 3D system?</li>
</ol>
<p><font color=Blue>Response</font>: It is common to analyze mechanical properties of foams in 2D, e.g. via scanning electron microscopy. However, the microstructures of real foam materials are 3D in nature. There are distinct differences in quantification of the relative density, cell size, cell morphology and cell wall thickness of foams between the 2D and 3D systems, so 3D calculations of mechanical properties should be used if possible.</p>
<ol start="2">
<li>Could Voronoi systems be phenomenological models for representing these morphologies?</li>
</ol>
<p><font color=Blue>Response</font>: Yes, to some extent. The 3D Voronoi technique (<font color=Blue>Okabe et al., 1992</font>) has been widely employed to generate closed-cell foams with irregular cells. It is useful for investigating the effects of structural parameters on the mechanical properties of foams. However, the Voronoi foam system cannot reproduce two characteristics of a real foam: the thickness distribution of walls, and the thickness variations along walls and between walls and edges. In a Voronoi system, wall thickness is normally constant across the sample, and is equal to the edge thickness.</p>
<ol start="3">
<li>What is the real perspective of this approach?</li>
</ol>
<p><font color=Blue>Response</font>: Edge segmentation separates the initial structure of a foam sample into two parts, i.e., edges and walls. The edge and wall morphologies can be quantified, and used to predict deformation processes (e.g., location and temporal sequence of deformation banding) and collapse strength of a foam. They also serve a basis for tailoring local strength and energy absorption of foams. Combined with finite element method analysis, foam structure can be manipulated to study the effect of local heterogeneity or defects on foam deformation. Clarification has been made in the last paragraph.</p>
<ol start="4">
<li>Is it possible to perform a calculation based on beam elastic deformation?</li>
</ol>
<p><font color=Blue>Response</font>: Not in our case. For open-cell foams or some closed-cell foams with large edge volume fractions, the calculation of mechanical properties based on elastic deformation of beams is appropriate. The mechanical support comes mainly from the edges in these foams. However, tomographic images in our case show that cell collapse is generally preceded by elastic buckling of cell walls. The solid fraction of edges in our foams is much lower than that of conventional polymer foams with curved, thin cell walls. Such a difference contributes to the difference in the dominant deformation modes during the collapse stage. Clarification has been made in line 1–5, paragraph 2, page 3, and line 17–23, paragraph 2, page 4.</p>
<ol start="5">
<li>Is it possible to consider Fig. 3a as a system of beams?</li>
</ol>
<p><font color=Blue>Response</font>: Fig. 3a actually shows a $xy$-slice of the tomographic image, and is a cross-section of a 3D structure. In this slice, cell walls become lines while edges become corners or lines (for edges parallel to the $xy$-plane). So it is inappropriate to considered it as a system of beams. Clarification has been made in line 1–3, paragraph 1, page 4.</p>
<ol start="6">
<li>Is tomography representative for studying mechanical properties?</li>
</ol>
<p><font color=Blue>Response</font>: Yes in our case. A previous study (<font color=Blue>Andrews et al., 2001</font>) showed that the mechanical properties of foams are independent of sample size when it is six times greater than the average cell size in both the horizontal and longitudinal directions. Our sample contains over 10 cell layers in both directions and the mechanical properties obtained from tomography are representative. Clarification has been made in line 8–9, the last paragraph, page 1, and line 1, paragraph 1, page 2.</p>
<ol start="7">
<li>How could be solved the homogeneity problem?</li>
</ol>
<p><font color=Blue>Response</font>: See the reply to the preceding comment. In addition, this can also be verified by a good repeatability of stress–strain curves between different samples.</p>
<ol start="8">
<li>Graphical Abstract is not appropriate. It must be more explanatory and immediate.</li>
</ol>
<p><font color=Blue>Response</font>: Thanks for your suggestion. The graphical abstract has been revised.</p>
<h3 id="Reviewer-2"><a href="#Reviewer-2" class="headerlink" title="Reviewer #2"></a>Reviewer #2</h3><p>&emsp;The limitation of the well-known empirical relationships between mechanical properties and relative density of cellular solids [1] has been realised and overcome through taking account of morphological parameters of individual or collective cells for more accurate structure-property correlation [12, 14]. However, these cell-level parameters are not directly linked to the deformation mechanism of base material. Recently, cell-wall parameters have been demonstrated to determine the compressive strength of a virtual 2D foam [<font color=Blue>Materials Sci. Eng. A 688 (2017), 27-39</font>], but no similar work has yet been reported for an actual 3D foam. In such a context, the study presented in this manuscript is a good and timely contribution to the progress in this research field. The manuscript is well written and the characterisation method is solid. The reviewer suggests the following aspects be revised to strengthen the analysis.</p>
<ul>
<li>Fig. 4 shows the distribution of cells with strength index smaller than 0.0037. However, these cells are not fully connected within each band that is indicated in Fig. 4b. In other words, the neighbour cells of the filtered cells within the indicated band have strength index larger than 0.0037, but they are excluded when evaluating the probability to form a band. This treatment is not appropriate, since the cause of the localised deformation band is the collective weakness of all the cells within the band rather than the inclusion of some weak cells in the band. Therefore, the authors should also calculate the strength index values for all the cells within each observed band (i.e. E1, E2, E3, E4 or E5, as shown in Fig. 2a) and then compare the averaged strength index values between different observed bands.</li>
</ul>
<p><font color=Blue>Response</font>: We think that deformation band nucleation is dominated by the weakest cell walls in the band, rather than by the average strength of all walls. The axial stress is uniformly distributed on cell walls and edges across the sample section. When the stress reaches the critical buckling strength of the weakest cell walls, they buckle and change the mechanical (stress, support) state of their neighbors, making these cell walls fragile. The tomographic images also show that buckling occurs firstly in some (rather than all) cell walls in a band, and “propagates” to other walls, rendering all cells in the band collapse approximately at the same time.<br>&emsp;The average values of the buckling strength index for five observed bands (E1–E5) are 0.092, 0.820, 0.137, 0.242 and 0.294, respectively. The results are inconsistent with the temporal sequence of deformation banding, and cannot predict a collapse strength comparable to the experimental measurement. In fact, the cell walls are randomly oriented and those (nearly) perpendicular to the loading direction have large strength indices. These walls can increase the average value of strength index in a band. In addition, the deformation bands are not strictly perpendicular to the loading direction (inclination angle $4^\circ-10^\circ$). Averaging across the sample section along the loading direction or sample height may smooth out the strength index distribution.</p>
<ul>
<li>The authors should attempt to obtain the axial distribution of strength index. A plot for strength index similar to the plot for Minkowski anisotropic index (Fig. S1) should be added.</li>
</ul>
<p><font color=Blue>Response</font>: The distribution of the average buckling strength index of cell walls along the sample height is shown in Fig.R1. The curve from averaging all walls exhibits very large oscillations and does not show clearly the weak zones in the foam sample. Since the walls (nearly) perpendicular to the loading direction have large strength indices, we apply a filter process to exclude walls with $\beta&lt;30^\circ$ ($\beta$ the angle between the loading direction and a wall normal). The wall with a higher $\beta$ is more prone to buckle.<br>&emsp;In this way, the oscillations are reduced, but the distribution curve still does not show obvious features of deformation banding, compared to the 3D distribution of weakest walls. The probable reason is that the deformation bands are not strictly perpendicular to the loading direction (especially band E3). Averaging on the strength index of cell walls across the sample section along the height direction is not appropriate to probe the weak zones of foam sample. This may also be responsible for why the distribution of the Minkowski anisotropic index cannot predict deformation banding.</p>
<img src="https://raw.githubusercontent.com/haiweichai/gallery/master/Exp003/Exp001_image001.jpg" width = 70% div align=center />
<font size=2px>Fig.R1: Distribution of the average buckling strength index $\lambda_{\rm w}$ of cell walls along the sample height direction. Each data point is averaged within a $200\mu m$ segment along the height direction. $\beta$ is the angle between the loading direction and a wall normal. The wall with a higher $\beta$ value is more prone to buckle.</font>

<ul>
<li>Undoubtedly, structure-property correlation based on 3D quantification of the cell walls is more accurate and reliable than that based on 2D structural data. However, 3D data is not always accessible while 2D data can be easily obtained via processing cross-sectional images. Therefore, it is of practical value and interest to evaluate the usefulness of 2D analysis, but such evaluation cannot be possible without 3D results as reference. Given the established 3D correlation by the authors, the reviewer suggests the authors also perform a 2D correlation based on the CT slices and then address the limitation of the 2D analysis. It is indeed necessary because sometimes 2D and 3D analyses may lead to same conclusions (e.g. same location of the weakest site).</li>
</ul>
<p><font color=Blue>Response</font>: The 2D analyses can provide a preliminary estimation of the cell size and solid fraction of foams. In terms of the cell wall thickness, 2D and 3D structural data can give similar results. If cell wall strength is controlled mainly by wall thickness, 2D and 3D analyses may lead to similar conclusions, as demonstrated in the previous work (<font color=Blue>Sun et al., 2017</font>).<br>&emsp;However, the width and height of cell walls cannot be accessed simultaneously in 2D analyses. The width and height distributions of cell walls from 2D analyses are also quite different from those in 3D analyses. Therefore, the 2D analysis is not appropriate for quantifying the cell wall strength in our case. In fact, it is impossible to accurately quantify local structural parameters in two dimensions, which hinders a full understanding of the cell strength of foam samples. In addition, the 2D analyses may lead to different conclusions in different sections.</p>
<ul>
<li>In the caption of Figure 1, “color-coding refers to axial strain” should be “color-coding refers to increments of axial strain”. The crushed cells at a nominal strain of 0.5 (Fig. 1b) are indicated in red which corresponds to a value of zero, so the color code cannot be based on absolute strain.</li>
</ul>
<p><font color=Blue>Response</font>: Thanks for your suggestion. Correction has been made in the caption of Fig.1.</p>
<ul>
<li>The authors could include greater reference to previous work on X-ray imaging of the deformation behaviour of cellular materials and foams, particularly in situ measurements of the deformation.</li>
</ul>
<p><font color=Blue>Response</font>: Thanks for your suggestion. We have added more references on this topic; see Refs. [13], [18] and [27] in the revised manuscript.</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] Okabe, A., Boots, B., Sugihara, K., 1992. Spatial tessellations: concepts and applications of Voronoi diagrams. Wiley, Chichester.<br>[2] Andrews, E. W., et al. “Size effects in ductile cellular solids. Part II: experimental results.” International Journal of Mechanical Sciences 43 (2001): 701-713.<br>[3] Sun, Yongle, et al. “Image-based correlation between the meso-scale structure and deformation of closed-cell foam.” Materials Science and Engineering: A 688 (2017): 27-39.</p>
]]></content>
  </entry>
  <entry>
    <title>【英语写作】 短语</title>
    <url>/archive/Exp002-writing.html</url>
    <content><![CDATA[<p>逐渐培养长期稳定阅读高水平 SCI 文章的习惯，不仅仅能了解专业的理论热点和学术前沿，同时还有益于学习高手写作科技论文时的行文逻辑、方法、技巧。这是对科研能力的培养，对养成独立思考习惯的努力。本文将记录阅读科技论文时发现的生僻短语及专业术语，旨在提高英语写作水平。</p>
<span id="more"></span>

<h2 id="常用短语"><a href="#常用短语" class="headerlink" title="常用短语"></a>常用短语</h2><table>
<thead>
<tr>
<th>短语</th>
<th>译文</th>
</tr>
</thead>
<tbody><tr>
<td>As a consequence, …</td>
<td>因此，结果，因而</td>
</tr>
<tr>
<td>In practice, …</td>
<td>事实上，实际上，在实践中</td>
</tr>
<tr>
<td>be employed primarily as …</td>
<td>主要用于 …</td>
</tr>
</tbody></table>
<h2 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h2><table>
<thead>
<tr>
<th>短语</th>
<th>译文</th>
</tr>
</thead>
<tbody><tr>
<td>twice continuously differentiable ($C^2$)</td>
<td>二次连续可微（$C^2$）</td>
</tr>
<tr>
<td>second order Taylor expansion</td>
<td>二阶泰勒展开</td>
</tr>
<tr>
<td>apparent density</td>
<td>表观密度</td>
</tr>
<tr>
<td>mechanical properties</td>
<td>机械性能，力学性能</td>
</tr>
<tr>
<td>renewable resources</td>
<td>可再生资源</td>
</tr>
<tr>
<td>the base polymer</td>
<td>聚合物基体</td>
</tr>
<tr>
<td>tensile strength</td>
<td>抗拉强度</td>
</tr>
</tbody></table>
]]></content>
  </entry>
  <entry>
    <title>人工智能：百川大模型训练与部署方法</title>
    <url>/archive/Baichuan.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/23/pAdsVL8.png"></p>
<p>Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。 Baichuan 2 在多个权威的中文、英文和多语言的通用、领域 benchmark 上取得同尺寸最佳的效果。技术报告：<a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a>。本次发布包含有 7B、13B 的 Base 和 Chat 版本，并提供了 Chat 版本的 4-bits 量化。所有版本对学术研究完全开放。同时，开发者通过邮件申请并获得官方商用许可后，即可免费商用。</p>
<p>除了训练了 2.6 万亿 Tokens 的 Baichuan2-7B-Base 模型，还公开了在此之前的另外 11 个中间 checkpoints（分别对应训练了约 0.2 ~ 2.4 万亿 Tokens）供社区研究使用，<a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints">https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints</a>。</p>
<span id="more"></span>


<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a></li>
<li><a href="https://www.tizi365.com/topic/9008.html">https://www.tizi365.com/topic/9008.html</a></li>
<li><a href="https://www.tizi365.com/topic/9008.html">https://www.tizi365.com/topic/9008.html</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>数字体图像相关（Digital Volume Correlation, DVC）技术</title>
    <url>/archive/Exp006-DVC.html</url>
    <content><![CDATA[<p>&lt;img src&#x3D;”&#x2F;Exp009_image001.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Digital Volume Correlation&emsp;&emsp;Author: Hai-Wei Chai,  International Journal of Plasticity 102730 (2020).”&gt;</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;高分辨率计算机层析成像技术的发展使获得目标微尺度三维图像成为可能。在目标变形过程的不同时刻拍摄其三维图像，即可使用数字体图像相关（Digital Volume Correlation, DVC）技术[1]测算其位移场及应变场。DVC比较变形前后图像各子区，找到匹配特征进而得到位移场。应变场通常通过计算位移场的梯度得到。要估计位移场，通常需将图像分为许多（可重叠）子区，对于每个子区，在下一时刻图像中寻找一个匹配子集以最小化其差异性或最大化其相关性。所产生的应变场的准确性（mean error）和精确性（standard deviation）很大程度上取决于算法设计与参数选择，如子区尺寸[11]等。</p>
<p>&emsp;&emsp;DVC 技术是数字图像相关（Digital Image Correlation, DIC）技术[2]的三维扩展，然而与DIC技术相比，DVC技术的应用场景对其算法设计工作提出了更加严峻的考验。无论是光学成像或是X射线透射成像，平面图像的采集都非常便捷、快速，而对目标进行三维形貌表征往往需要耗费大量时间，这就导致DIC技术的输入图像序列往往拍摄时间间隔较短，相应的相邻两幅图像间变形幅度较小；而DVC技术的输入体图像序列往往拍摄间隔很大，相邻两幅体图像间变形幅度较大，一定程度上提高了目标追踪的难度。基于同步辐射的动态CT技术允许在亚秒级的时间间隔内连续采集CT图像，能够密切观测目标三维结构演化过程。但与这种表征技术相结合的原位加载手段目前仍然十分有限，且受限于高速相机内存空间往往较小与CT图像极大的存储容量需求间的矛盾，这种技术手段的时间分辨率与连续扫描的时间跨度往往不可兼得，存在一定局限性。面对来自应用场景的挑战，DVC技术仍然存在几个方面有待研究和改进。</p>
<p>&emsp;&emsp;DVC可以应用于任何 micro-CT 图像中提供了足够细节的结构非均匀样品，例如金属[3,4]、木材[5,6]、沙砾[7,8]、骨骼[9,10]等。然而结构精细程度较低的图像是对DVC技术的挑战。骨小梁就是一个典型的例子，它是一种低密度海绵状骨，由于其存在大量极纤细的网状结构，难以对其微细观结构进行精细CT表征[9]，进而DVC技术难以准确追踪并测算其位移场。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://link.springer.com/article/10.1007/BF02323555"><font size = 2px>[1]&nbsp;&nbsp;Bay, B.K. , Smith, T.S. , Fyhrie, D.P. , Saad, M. , 1999. Digital volume correlation: three-dimensional strain mapping using x-ray tomography. Exp. Mech. 39 (3), 217–226.</font></a><br><a href="https://iopscience.iop.org/article/10.1088/0957-0233/20/6/062001/meta"><font size = 2px>[2]&nbsp;&nbsp;Pan, B. , Qian, K. , Xie, H. , Asundi, A. , 2009. Two-dimensional digital image correlation for in-plane displacement and strain measurement: a review. Meas. Sci. Technol. 20 (6), 062001.</font></a><br><a href="https://hal.archives-ouvertes.fr/hal-00848721/document"><font size = 2px>[3]&nbsp;&nbsp;Leclerc, H. , Périé, J.-N. , Hild, F. , Roux, S. , 2012. Digital volume correlation: what are the limits to the spatial resolution? Mech. Ind. 13 (6), 361–371.</font></a><br><a href="https://hal.archives-ouvertes.fr/hal-00848726/file/EXME2013a-ccsd.pdf"><font size = 2px>[4]&nbsp;&nbsp;Morgeneyer, T.F. , Helfen, L. , Mubarak, H. , Hild, F. ,2013. 3D digital volume correla- tion of synchrotron radiation laminography images of ductile crack initiation: an initial feasibility study. Exp. Mech. 53 (4), 543–556.</font></a><br><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-1305.2009.00687.x"><font size = 2px>[5]&nbsp;&nbsp;Forsberg, F. , Sjödahl, M. , Mooser, R. , Hack, E. , Wyss, P. , 2010. Full three-dimensional strain measurements on wood exposed to three-point bending: analysis by use of digital volume correlation applied to synchrotron radiation micro-computed tomography image data. Strain 46 (1), 47–60.</font></a><br><a href="https://link.springer.com/article/10.1007/s10853-012-7100-0"><font size = 2px>[6]&nbsp;&nbsp;Tran, H. , Doumalin, P. , Delisee, C. , Dupre, J.C. , Malvestio, J. , Germaneau, A. , 2013. J. Mater. Sci. 48 (8), 3198–3212.</font></a><br><a href="https://reader.elsevier.com/reader/sd/pii/S0038080613000188?token=360410C7A02B3A281C1F7BF303D28F9DEAA92F606202A37921F16CE0709416B87EA4BFAA169E10C130FE0700ACA1C005"><font size = 2px>[7]&nbsp;&nbsp;Higo, Y. , Oka, F. , Sato, T. , Matsushima, Y. , Kimoto, S. , 2013. Investigation of local- ized deformation in partially saturated sand under triaxial compression using microfocus x-ray ct with digital image correlation. Soils Found. 53 (2), 181–198.</font></a><br><a href="https://link.springer.com/article/10.1007%2Fs11340-014-9915-x"><font size = 2px>[8]&nbsp;&nbsp;Hu, Z. , Du, Y. , Luo, H. , Zhong, B. , Lu, H. , 2014. Internal deformation measurement and force chain characterization of mason sand under confined compression using incremental digital volume correlation. Exp. Mech. 54 (9), 1575–1586.</font></a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S1751616113003159"><font size = 2px>[9]&nbsp;&nbsp;Gillard, F. , Boardman, R. , Mavrogordato, M. , Hollis, D. , Sinclair, I. , Pierron, F. , Browne, M. , 2014. The application of digital volume correlation (DVC) to study the microstructural behaviour of trabecular bone during compression. J. Mech. Behav. Biomed. Mater. 29, 4 80–4 99.</font></a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0021929014000037"><font size = 2px>[10]&nbsp;&nbsp;Roberts, B.C. , Perilli, E. , Reynolds, K.J. , 2014. Application of the digital volume corre- lation technique for the measurement of displacement and strain fields in bone: a literature review. J. Biomech. 47 (5), 923–934.</font></a><br><a href="http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC2613834&blobtype=pdf"><font size = 2px>[11]&nbsp;&nbsp;Liu, L. , Morgan, E.F. , 2007. Accuracy and precision of digital volume correlation in quantifying displacements and strains in trabecular bone. J. Biomech. 40 (15), 3516–3520.</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a></p>
]]></content>
  </entry>
  <entry>
    <title>2019年11月6日上海光源动态CT实验</title>
    <url>/archive/Exp004-PUplan.html</url>
    <content><![CDATA[<p>本团队计划近期赴上海同步辐射源（Shanghai Synchrotron Radiation Facility, SSRF） BL09B 测试线站搭建并测试秒级快速 CT 系统。用于测试的课题为聚氨酯泡沫发泡过程。依靠秒级快速 CT 系统连续观测聚氨酯泡沫发泡过程中三维结构形貌的演化，以及加入不同催化剂、添加剂时结构演化过程的差异。以期揭示聚氨酯泡沫发泡的动力学机理，同时探究催化剂、添加剂等对聚氨酯泡沫发泡成型过程的介入作用。</p>
<p>本次实验已于2019年11月09日圆满结束，感谢张抑扬，谢政良，蒋雪萍，刘子健等的协助。本文列出本次实验详细信息，以备查验。</p>
<span id="more"></span>

<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><p>实验编号|配料方案|视野（${\rm mm}$）|像素尺寸（$${\rm \mu m}$$）|曝光时间（$${\rm \mu s}$$）|幅间隔（$${\rm ms}$$）|转速（$${\rm ^\circ&#x2F;sec}$$）|$${\rm CT}$$间隔（$${\rm sec}$$）|$${\rm CT}$$数|光子能量（$${\rm keV}$$）|$${\rm SSD}$$（$${\rm mm}$$）|$${\rm Filter}$$（$${\rm mmAl}$$）<br>:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|<br>Exp001 |<font color =#e9a3c9 > A01 </font>| 3.79 | 3.70 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp002 |<font color =#e9a3c9 > A01 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp003 |<font color =#e9a3c9 > A02 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp004 |<font color =#e9a3c9 > A03 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp005 |<font color =#e9a3c9 > A04 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp006 |<font color =#e9a3c9 > A05 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp007 |<font color =#e9a3c9 > A06 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp008 |<font color =#e9a3c9 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp009 |<font color =#c2a5cf > B01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp010 |<font color =#c2a5cf > B02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp011 |<font color =#c2a5cf > B03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp012 |<font color =#c2a5cf > B04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp013 |<font color =#c2a5cf > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp014 |<font color =#f4a582 > C01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp015 |<font color =#f4a582 > C02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp016 |<font color =#f4a582 > C03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp017 |<font color =#f4a582 > C04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp018 |<font color =#f4a582 > C01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp019 |<font color =#f4a582 > C02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp020 |<font color =#f4a582 > C03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp021 |<font color =#f4a582 > C04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp022 |<font color =#f4a582 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp023 |<font color =#e9a3c9 > A02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp024 |<font color =#e9a3c9 > A03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp025 |<font color =#e9a3c9 > A04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp026 |<font color =#e9a3c9 > A05 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp027 |<font color =#c2a5cf > B01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp028 |<font color =#c2a5cf > B02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp029 |<font color =#c2a5cf > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST01 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST02 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST03 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 200 | 0.4 | 900 | .2 | 30 | 15 | 310 | ——<br>TEST04 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 200 | 0.4 | 900 | .2 | 30 | 15 | 310 | ——  </p>
<p>&emsp;&emsp;Exp011-Exp012、Exp018-Exp029 构成一套完整对照试验。Exp001 无效；Exp007 及以前所有实验图像质量差；Exp010 及以前所有实验液量不稳；Exp013-Exp017 现场人员 Xie；TEST01 20 mm 大容器成像测试；TEST02 偏心拍法测试；TEST03 450 sec 处 5 Hz 连续 CT；TEST04 50 sec 处 5 Hz 连续 CT。</p>
<p>&emsp;&emsp;考虑到现场实验时光斑高度方向只有 7 mm，配料方案做出略微调整，下表列出详细的配料方案。</p>
<table>
<thead>
<tr>
<th align="center">配料方案</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><font color = #e9a3c9>$${\rm A01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.30\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A05}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A06}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.20\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A07}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.24\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.06\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.06\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.09\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.09\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.12\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.12\ {\rm g}$$</font></td>
</tr>
</tbody></table>
<h2 id="物品清单"><a href="#物品清单" class="headerlink" title="物品清单"></a>物品清单</h2><p>&emsp;&emsp;本次动态 CT 实验的主要研究对象为聚氨酯泡沫发泡的三维结构演化过程。聚氨酯泡沫发泡实验需提前准备发泡原料 PAPI、聚醚多元醇、去离子水，发泡助剂，容器，滴泵等，共需三个托运箱，下表已列出详细的物品清单。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>负责人</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>探测：SA-Z高速相机</td>
<td>张抑扬</td>
<td>1024$\times$1024, 12 bit, 20 $\mu m$</td>
</tr>
<tr>
<td>容器：内径 $$9\ {\rm mm}$$，壁厚 $$1\ {\rm mm}$$，封底</td>
<td>蒋雪萍</td>
<td>定制 PMMA 容器各 $50$ 个，高 $$30\ {\rm mm}$$</td>
</tr>
<tr>
<td>原料（黑）：<a href="https://b2b.baidu.com/land?url=http://www.qianyuwang.com/offer/320595749.html?bdb2b8a2d=3101263341968821723&query=%E5%A4%9A%E4%BA%9A%E7%94%B2%E5%9F%BA%E5%A4%9A%E8%8B%AF%E5%9F%BA%E5%A4%9A%E5%BC%82%E6%B0%B0%E9%85%B8%E9%85%AF+%E6%88%90%E9%83%BD&category=%E5%8C%96%E5%B7%A5%E8%83%BD%E6%BA%90;%E5%8C%96%E5%AD%A6%E8%AF%95%E5%89%82;%E5%85%B6%E4%BB%96%E5%8C%96%E5%AD%A6%E8%AF%95%E5%89%82&iswapurl=&qq-pf-to=pcqq.c2c">多亚甲基多苯基多异氰酸酯 PAPI</a></td>
<td>谢政良</td>
<td>CAS号：9016-87-9；纯度 $98%$</td>
</tr>
<tr>
<td>原料（白）：聚醚多元醇</td>
<td>谢政良</td>
<td>CAS号：9003-11-6；</td>
</tr>
<tr>
<td>原料（白）：去离子水</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>助剂（匀泡剂）：<a href="http://www.maysta.com/pro/detail.aspx?id=1&mtt=0">硅油</a></td>
<td>谢政良</td>
<td>AK8805</td>
</tr>
<tr>
<td><font color=#e9a3c9>助剂（开孔剂）：</font><a href="http://www.maysta.com/pro/detail.aspx?id=7&mtt=0"><font color=#e9a3c9>硅油</font></a></td>
<td>谢政良</td>
<td>AK9903</td>
</tr>
<tr>
<td>助剂（催化剂）：<a href="http://www.adamas-beta.com/productDetail!doProductDetail.action?pm=cat&attr9=5%5Ecmdfafi">辛酸亚锡</a></td>
<td>谢政良</td>
<td>CAS号：301-10-0；纯度 $95%$</td>
</tr>
<tr>
<td>助剂（成核剂）：<a href="https://www.rhawn.cn/products/detail/19617">硬脂酸钙</a></td>
<td>谢政良</td>
<td>上海凛恩科技发展有限公司 R019842</td>
</tr>
<tr>
<td>滴泵：滴泵出液口陶瓷管</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>滴泵：滴泵支架</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>滴泵：滴泵控制系统</td>
<td>王奕超</td>
<td>延长控制线，检验</td>
</tr>
<tr>
<td>滴泵：三维位移台，及转台上位移台</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>其他：铝板，医用注射器，塑料杯，搅拌棒，底部针脚，502胶</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>其他：内六角，机米螺丝，标签纸，记号笔，封泥，鼓气工具</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>其他：回收桶及垃圾袋</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>存储：机械硬盘，移动硬盘，机械硬盘外接盒，SD Card，读卡器</td>
<td>柴海伟</td>
<td></td>
</tr>
</tbody></table>
<h2 id="预实验"><a href="#预实验" class="headerlink" title="预实验"></a>预实验</h2><p>预实验旨在给出如下问题的答案，为现场实验指明配料方案。感谢谢政良、蒋雪平完成此处工作。</p>
<h3 id="PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？"><a href="#PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？" class="headerlink" title="PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？"></a>PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.30\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
</tbody></table>
<p>现象总结：文献报道水分占比将直接影响泡孔占比、宏观密度，恰当的水分占比对调控泡沫结构至关重要。在预实验中我们观察到A，B组分液量控制在$$0.06\ {\rm mL}$$，前三组反应终态大致稳定在9mm高，尚未超出视野范围，前四组反应至$$20\ {\rm min}$$即大致稳定，第五组反应仍未停止。水分对终态宏观密度，胞壁形貌，反应速度等影响显著。</p>
<h3 id="硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？"><a href="#硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？" class="headerlink" title="硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？"></a>硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
</tbody></table>
<p>现象总结：硅油AK8805与PAPI混合即产生大量气泡及絮状物，硅油AK8860与PAPI混合均匀且无气泡、絮状物。经测试，硅油AK8805有明显稳泡效果，加入$$0.2\ {\rm mL}$$时效果最好，加入更多比例效果提升不明显。AK8860现象仍然明显。</p>
<h3 id="硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？"><a href="#硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？" class="headerlink" title="硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？"></a>硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.01\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.01\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.02\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.02\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.04\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.04\ {\rm g}$$</font></td>
</tr>
</tbody></table>
<p>现象总结：硬脂酸钙粉末的细孔效果不明显。硬脂酸钙粉末含量达到$$0.12\ {\rm g}$$时现象明显，更改实验方案。</p>
<h3 id="预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径-6-rm-mm-的容器内，多次重复。"><a href="#预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径-6-rm-mm-的容器内，多次重复。" class="headerlink" title="预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径 $$6\ {\rm mm}$$的容器内，多次重复。"></a>预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径 $$6\ {\rm mm}$$的容器内，多次重复。</h3><p>&emsp;&emsp;支架部件：三维位移台一套；$$300\ {\rm mm\ M6\ }$$支杆 $\times6$，$$200\ {\rm mm\ M6\ }$$支杆 $\times6$，$$100\ {\rm mm\ M4\ }$$支杆 $\times2$，$${\rm M6\ }$$垫脚 $\times1$，压板 $\times1$，$${\rm M6\ }$$机米螺丝$\times10$，$${\rm M6\ }$$六角螺丝$\times5$，$${\rm M4\ }$$机米螺丝$\times3$，$${\rm M3\ }$$六角螺丝$\times2$，弹性垫片$\times2$。</p>
<p>&emsp;&emsp;滴泵部件：滴泵本体；滴泵电源线；滴泵控制线；笔记本电脑；滴泵口转接头；陶瓷管。</p>
<p>&emsp;&emsp;经检验，滴泵及支架运行正常，可以满足实验需求。</p>
<h3 id="滴泵清洗方案"><a href="#滴泵清洗方案" class="headerlink" title="滴泵清洗方案"></a>滴泵清洗方案</h3><p>&emsp;&emsp;滴泵排出所有组分B后，抽取清水$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空液体。重复上述操作$3$次，抽取空气$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空，抽取清水$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空。再抽取空气排空。最后取出陶瓷管吹干，棉签擦干滴泵出口。</p>
<p>&emsp;&emsp;总结：抽水排出三次，抽空气及抽水排出交替进行各三次，最后以抽空气排出收尾，吹干陶瓷管，棉签擦拭滴泵出口。</p>
]]></content>
  </entry>
  <entry>
    <title>Non Local Means 图像降噪算法</title>
    <url>/archive/Exp007-NLM.html</url>
    <content><![CDATA[<p>Antoni Buades 提出指标 method noise 对数字图像降噪方法的性能进行了评价和比较。他首先针对几个被广泛使用的降噪算法计算并分析了降噪性能。同时，基于图像中所有像素的非局部平均，提出了全新的数字图像降噪算法 Non Local means Algorithm，并通过实验比较了新算法与常用的平滑滤波方法的性能。</p>
<span id="more"></span>

<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_nl_means, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">astro = img_as_float(data.astronaut())</span><br><span class="line">astro = astro[<span class="number">30</span>:<span class="number">180</span>, <span class="number">150</span>:<span class="number">300</span>]</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.08</span></span><br><span class="line">noisy = random_noise(astro, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># estimate the noise standard deviation from the noisy image</span></span><br><span class="line">sigma_est = np.mean(estimate_sigma(noisy, channel_axis=-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;estimated noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">patch_kw = <span class="built_in">dict</span>(patch_size=<span class="number">5</span>,      <span class="comment"># 5x5 patches</span></span><br><span class="line">                patch_distance=<span class="number">6</span>,  <span class="comment"># 13x13 search area</span></span><br><span class="line">                channel_axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm</span></span><br><span class="line">denoise = denoise_nl_means(noisy, h=<span class="number">1.15</span> * sigma_est, fast_mode=<span class="literal">False</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm, sigma provided</span></span><br><span class="line">denoise2 = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">False</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm</span></span><br><span class="line">denoise_fast = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, fast_mode=<span class="literal">True</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm, sigma provided</span></span><br><span class="line">denoise2_fast = denoise_nl_means(noisy, h=<span class="number">0.6</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">True</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>),sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;noisy&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(denoise)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(slow)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(denoise2)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(slow, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(astro)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;original\n(noise free)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(denoise_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(fast)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(denoise2_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(fast, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print PSNR metric for each case</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(astro, noisy)</span><br><span class="line">psnr = peak_signal_noise_ratio(astro, denoise)</span><br><span class="line">psnr2 = peak_signal_noise_ratio(astro, denoise2)</span><br><span class="line">psnr_fast = peak_signal_noise_ratio(astro, denoise_fast)</span><br><span class="line">psnr2_fast = peak_signal_noise_ratio(astro, denoise2_fast)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (noisy) = <span class="subst">&#123;psnr_noisy:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow) = <span class="subst">&#123;psnr:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow, using sigma) = <span class="subst">&#123;psnr2:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast) = <span class="subst">&#123;psnr_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast, using sigma) = <span class="subst">&#123;psnr2_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="数字图像噪声"><a href="#数字图像噪声" class="headerlink" title="数字图像噪声"></a>数字图像噪声</h3><p>&emsp;&emsp;数字图像的两个主要限制是模糊及噪声（blur &amp; noise）。模糊是图像采集系统的固有性质，同时数字图像对连续信号离散采样的形式必须遵循 Shannon-Nyquist 采样定律。另一种主要的干扰形式是噪声。数字图像中每个像素点的值 $u(i)$ 都是对局部光强测量的结果，通常通过 CCD 及光学聚焦元件实现。CCD 中每个方形探测单元（captor）都将记录曝光时间内探测区域的入射光子数。在光源强度恒定的情况下，每个探测单元每个曝光周期内采集的光子数的概率分布将遵循中心极限定理，在光强均值周围震荡。另外，如果 CCD 没有经过充分冷却就会接收热光子（heat spurious photons），由此产生的扰动通常称为 obscurity noise。</p>
<p>&emsp;&emsp;数字图像降噪方法的目标是从观测到的噪声图像中还原出原始信号，</p>
<p>$$ v(i)&#x3D;u(i)+n(i), \tag{1}\label{1}$$</p>
<p>其中 $v(i)$ 为实测图像，$u(i)$ 为原始信号，$n(i)$ 则是噪声信号。评估图像中噪声水平通常采用信噪比（signal noise ratio (SNR)）：</p>
<p>$$ SNR &#x3D; \frac{\sigma(u)}{\sigma(n)}, \tag{2}\label{2}$$</p>
<p>其中，$\sigma(n)$为噪声信号标准差，$\sigma(u)$表示真实信号的经验标准差，</p>
<p>$$ \sigma(u) &#x3D; \sqrt{\frac{1}{|I|}\sum_i(u(i)- \overline{u} )^2}, \tag{3}\label{3}$$</p>
<p>$ \overline{u}&#x3D;\frac{1}{|I|}\sum_{i\in I} u(i)$ 为图像的平均灰度值，$|I|$指全图像素数。当噪声模型和参数已知时，噪声的标准差也可以用经验测量法或形式化方法得到。</p>
<p>&emsp;&emsp;迄今为止，图像处理领域已经提出了诸多抑制噪声、还原真实信号的算法。即便它们通常拥有截然不同的数学形式，但都拥有一个共性：平均。这种平均可以在局部进行：高斯滤波器(<a href="https://freddy.cs.technion.ac.il/wp-content/uploads/2018/01/on-gabors-contribution-to-image-enhancement.pdf">Gabor 1994</a>)，各向异性滤波(<a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona-Malik 1990</a>, <a href="https://accedacris.ulpgc.es/bitstream/10553/52821/1/image_selective_smoothing_edge.pdf">Alvarez et al. 1992</a>)，邻域滤波器(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.5808&rep=rep1&type=pdf">Smith et al. 1997</a>)；也可以通过计算variations实现：TV滤波(<a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin-Osher-Fatemi 1992</a>)；或是在频域进行：经验维纳滤波(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>)，小波阈值方法(<a href="https://pdfs.semanticscholar.org/78a5/90a8ac92f02fb48e4e488b6eb00dc7b931eb.pdf">Coiffman-Donoho 1995</a>)。</p>
<h3 id="Method-noise"><a href="#Method-noise" class="headerlink" title="Method noise"></a>Method noise</h3><p>&emsp;&emsp;不妨令 $u$ 表示实测图像，$D_hu$ 表示降噪方法的输出结果，$h$ 为滤波参数。Antoni Buades 定义 method noise 为降噪前后图像之差：</p>
<p>$$ u-D_hu. \tag{4}\label{4}$$</p>
<p>&emsp;&emsp;完美的降噪算法在应用中不应该改变无噪声图像。因此，当图像具有某种规律性时，method noise 理应很小。对理想的降噪算法，Method noise 必须看起来与随机噪声无异，几乎不包含原始信号的结构。因为即便是质量非常高的实测图像，噪声也是不可避免的，计算 method noise 对评估任何降噪算法都是有意义的，而非传统的“添加噪声，再去除噪声”的把戏。</p>
<h2 id="局部平均算法"><a href="#局部平均算法" class="headerlink" title="局部平均算法"></a>局部平均算法</h2><h3 id="高斯滤波-Gaussian-Filtering"><a href="#高斯滤波-Gaussian-Filtering" class="headerlink" title="高斯滤波 (Gaussian Filtering)"></a>高斯滤波 (Gaussian Filtering)</h3><p>&emsp;&emsp;对数字图像进行各向同性过滤，本质上可以归结为图像与各向同性核的卷积。采用数值呈现出高斯分布的卷积核，既是高斯滤波，是图像处理中最常用的操作之一。通俗的讲，高斯滤波就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到（所有的局部平滑滤波方法都是如此）。高斯卷积核：</p>
<p>$$G_h(x)&#x3D;\frac{1}{4\pi h^2}e^{-\frac{|x|^2}{4h^2}}. \tag{5}\label{5}$$</p>
<p><strong>Theorem 1 (Babor 1960):</strong> 当高斯卷积核的特征尺寸 $h$ 极小时，高斯滤波的 method noise 为：</p>
<p>$$ u-G_h* u&#x3D;-h^2\Delta u+o(h^2). \tag{6}\label{6}$$</p>
<p>&emsp;&emsp;高斯滤波的 method noise 在图像谐波部分几乎为零，而在边缘、纹理区域非常大。因此，高斯滤波在图像的平坦区域相对表现优秀，但在边缘、纹理区域较为模糊（blurred）。</p>
<h3 id="各向异性滤波（Anisotropic-Filtering-AF）"><a href="#各向异性滤波（Anisotropic-Filtering-AF）" class="headerlink" title="各向异性滤波（Anisotropic Filtering, AF）"></a>各向异性滤波（Anisotropic Filtering, AF）</h3><p>&emsp;&emsp;各向异性滤波提出之初旨在解决高斯滤波在边缘及纹理区域的模糊问题。该算法通过只在 $Du(\vec x)$ 正交方向上计算图像 $u$ 在 $\vec x$ 处的卷积。这种想法可以追溯到 <a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona &amp; Malik</a>。各向异性滤波算法的定义为：</p>
<p>$$ AF_hu(\vec x)&#x3D;\int G_h(t)u(\vec x+t\frac{Du(\vec x)^\perp}{|Du(\vec x)|})dt, \tag{7}\label{7}$$</p>
<p>在 $\vec x$ 处，当 $Du(\vec x)\neq0$ 时成立。$(x,y)^\perp&#x3D;(-y,x)$，且 $G_h$ 代指方差 $h^2$ 的一维高斯函数。假设原始图像 $u$ 在 $\vec x$ 处二次连续可微（twice continuously differentiable ($C^2$)）,将式\eqref{5}二次泰勒展开（second order Taylor expansion）可以推导出：</p>
<p><strong>Theorem 2:</strong> 当 $Du(\vec x)\neq0$ 时，各向异性滤波 $AF_h$ 的 method noise 为：</p>
<p>$$ u(\vec x)-AF_hu(\vec x)&#x3D;-\frac{1}{2}h^2|Du|curv(u)(\vec x)+o(h^2), \tag{8}\label{8}$$</p>
<p>$curv(u)(\vec x)$ 指局部曲率（<font color=Green>此处存疑</font>），即经过 $\vec x$ 点的水平直线上曲率半径的逆（signed inverse）。在图像 $u$ 中局部几乎为一条直线的区域，method noise 几乎为零，而在弯曲的边缘或纹理区域较大。因而，各向异性滤波对直边区域得以保持，而平坦、纹理区域图像精度有所退化。</p>
<h3 id="TV滤波（Total-Variation-Minimization）"><a href="#TV滤波（Total-Variation-Minimization）" class="headerlink" title="TV滤波（Total Variation Minimization）"></a>TV滤波（Total Variation Minimization）</h3><p>&emsp;&emsp;全变分图像去噪算法最早由 <a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin, Osher and Fatemi</a>提出。给定一幅实测图像 $v(\vec x)$，该算法将恢复原始信号 $u(\vec x)$ 的问题转化为式\eqref{7}的最小化问题：</p>
<p>$$TVF_\lambda(v)&#x3D;{\rm arg},\underset{u}{\rm \mathop {min}},TV(u)+\lambda\int|v(\vec x)-u(\vec x)|^2d\vec x, \tag{9}\label{9}$$</p>
<p>其中 $TV(u)$ 为图像 $u$ 的全变分，$\lambda$ 为给定的拉格朗日乘子（Lagrange multiplier）。上述最小化问题的最小值存在且唯一。参数 $\lambda$ 与噪声的统计信息相关，并控制了滤波程度。</p>
<p><strong>Theorem 3:</strong> TV滤波的 method noise 为：</p>
<p>$$ u(\vec x)-TVF_\lambda(u)(\vec x)&#x3D;-\frac{1}{2\lambda}curv(TVF_\lambda(u))(\vec x). \tag{10}\label{10}$$</p>
<p>&emsp;&emsp;在各向异性的情况下，直边由于曲率小而得以保持。但 $\lambda$ 过小时细节及纹理会被过度平滑。</p>
<h3 id="邻域滤波（Neighborhood-Filtering）"><a href="#邻域滤波（Neighborhood-Filtering）" class="headerlink" title="邻域滤波（Neighborhood Filtering）"></a>邻域滤波（Neighborhood Filtering）</h3><p>&emsp;&emsp;我们称邻域滤波为将临近区域内具有相似灰度值的像素取平均以期恢复原始信号的滤波器。<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky(1985)</a>首次提出的方法通过计算空间邻域 $B_\rho(\vec x)$ 内具有相似灰度值像素的平均来恢复信号：</p>
<p>$$ YNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{B_\rho (\vec x)} u(\vec y)e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{11}\label{11}$$</p>
<p>其中，$\vec x\in\Omega$，$C(\vec x)&#x3D;\int_{B_\rho(\vec x)} e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$h$ 为滤波参数。</p>
<p>&emsp;&emsp;较晚提出的邻域滤波算法相较 Yaroslavsky 滤波要更广为人知一些，既 SUSAN 滤波（1995）及双边滤波（1998）。这些滤波算法都引入到参考像素 $\vec x$ 的距离作为权重因子，而非单纯的考虑一个固定范围的邻域，</p>
<p>$$SNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{\Omega} u(\vec y)e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{12}\label{12}$$</p>
<p>这里 $C(\vec x)&#x3D;\int_{\Omega}e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$\rho$ 为空间滤波参数（spatial filtering parameter）。事实上，$YNF_{h,\rho}$ 与 $SNF_{h,\rho}$ 之间并没有本质区别（<font color=Green>此处存疑</font>）。如果两个区域的灰度值差异大于 $h$，这些算法都将计算来自于同一区域的像素灰度平均值来恢复参考点的原始信号。因而该算法不会模糊边界区域，这是正是该类算法最核心的用途。</p>
<p>&emsp;&emsp;然而这类算法的问题是，只将单个像素作为参考点，而如若该参考像素恰好被噪声干扰严重，滤波效果将不够鲁棒（robust）。同时，邻域滤波器也会制造人为干扰（artificial shocks），这将会在它的 method noise 中展示出来。</p>
<h2 id="非局部平均算法（Non-Local-Means-Algorithm）"><a href="#非局部平均算法（Non-Local-Means-Algorithm）" class="headerlink" title="非局部平均算法（Non Local Means Algorithm）"></a>非局部平均算法（Non Local Means Algorithm）</h2><p>&emsp;&emsp;Antoni Buades 于 2005 年提出非局部平均数字图像降噪算法（Non Local Algorithm）。给定一幅实测图像 $v&#x3D;\lbrace v(i)|i\in I\rbrace $，像素 $i$ 处的估计值 $NL[v](i)$ 是该图像上所有像素点的加权平均值，</p>
<p>$$ NL<a href="i">v</a>&#x3D;\sum_{j\in I}\omega(i,j)v(j), \tag{13}\label{13}$$</p>
<p>这里的权重系数 $\lbrace\omega (i,j)\rbrace_j$ 取决于像素 $i$ 与 $j$ 之间的相似程度，且始终满足如下标准： $0\leq\omega(i,j)\leq 1$ 且 $\sum_{j} \omega(i,j)&#x3D;1$（等价于上文介绍的滤波算法中归一化常量）。</p>
<p>&emsp;&emsp;俩个像素 $(i,j)$ 之间的相似程度取决于邻域灰度矩阵 $v(N_i)$ 及 $v(N_j)$（intensity gray level vectors），这里 $N_k$ 指以像素 $k$ 为中心，给定尺寸的方形邻域。这种相似性被定义为加权欧式距离的递减函数，$\parallel v(N_i)-v(N_j)\parallel_{2,a}^2$，其中 $a&gt;0$ 是高斯卷积核的标准差。欧式距离对噪声邻域的应用引入了如下等式：</p>
<p>$$ E\parallel v(N_i)-v(N_j)\parallel_{2,a}^2 &#x3D; \parallel u(N_i)-u(N_j) \parallel_{2,a}^2+2\sigma^2. \tag{14}\label{14}$$</p>
<p>&emsp;&emsp;这个等式证明了该算法的鲁棒性（robustness）。因为含噪声的实测图像 $v$ 的欧式距离期望恰恰遵循真正的原始信号之间的相似性。</p>
<p>&emsp;&emsp;与 $v(N_i)$ 具有相似灰度邻域的像素在计算平均时的权重因子更大，</p>
<p>$$ \omega(i,j)&#x3D;\frac{1}{Z(i)}e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{15}\label{15}$$</p>
<p>这里，$Z(i)$ 为归一化常量，</p>
<p>$$ Z(i) &#x3D; \sum_j e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{16}\label{16}$$</p>
<p>参数 $h$ 控制滤波程度，它直接影响了指数函数的衰减趋势，进而控制欧式距离对权重因子衰减速度的影响。</p>
<p>&emsp;&emsp;NL-means 算法不仅仅考虑单个像素的灰度值，而是考虑该像素整个邻域的几何构型，这正是 NL-means 算法比邻域滤波更鲁棒的原因。图$(1)$ 也说明了这个问题，像素 $q3$ 与 $p$ 具有完全一致的灰度值，而邻域的几何构型完全不同，导致 NL-means 中的权重因子 $\omega(p,q3)$ 几乎为零。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image001.jpg” width &#x3D; 30% div align&#x3D;center &#x2F; title&#x3D;”图1.  NL-means 算法方案。相似的像素邻域将提供更大的权重，如 $\omega(p,q1), \omega(p,q2)$，而不相似的邻域提供的权重几乎为零，如 $\omega(p,q3)$。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;NL-means 算法最终的数学形式：</p>
<p>$$ NL<a href="x">v</a>&#x3D;\frac{1}{C(x)} \int_{\Omega} e^{-\cfrac{(G_a * |v(x+.)-v(y+.)|^2)(0)}{h^2}}v(y)dy, \tag{17}\label{17}$$</p>
<p>$x\in\Omega$，$C(x)&#x3D;\int_{\Omega} {\rm exp}\lbrack -\frac{(G_a* |u(x+.)-u(z+.)|^2)(0)}{h^2}\rbrack dz$ 为归一化常量，$G_a$ 为高斯核，$h$ 控制过滤程度。</p>
<p>&emsp;&emsp;NL-means 算法的中心思想是：像素 $x$ 处的信息恢复，是由整幅图像内所有邻域与像素 $x$ 邻域相似的点取平均得到的。与局部滤波算法或频域滤波算法相比，NL-means 算法的主要区别在于可以系统地运用整幅图像中所有可能自预测局部结构的信息。</p>
<h2 id="实验及讨论"><a href="#实验及讨论" class="headerlink" title="实验及讨论"></a>实验及讨论</h2><p>&emsp;&emsp;本节将针对以下三点比较 Non Local Means 算法与局部平滑滤波的性能： method noise，视觉效果，均方差（mean square error）。这里均方差指修复图像与真实图像的欧几里得差异（Euclidean difference）。</p>
<p>&emsp;&emsp;在实现 NL-means 算法时，我们将相似邻域的搜索范围约束在一个较大的 $S\times S$ pixels 区域内。在所有的实验中均固定该搜索范围为 $21\times 21$ pixels，并指定邻域 $N_i$ 范围为 $7\times 7$ pixels。不妨设输入图像的像素数为 $N^2$，那么该算法的时间复杂度约为 $21^2\times 7^2 \times N^2$。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image002.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图2.  NL-means 权重分布。每组中左图中心像素为参考像素点 $x$，每组中右图为权重因子分布，由黑至白对应从0到1。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;$7\times 7$ pixels 的邻域范围已经足够大，能够确保算法对噪声是鲁棒的；也足够小，让细节及纹理得以保持。滤波参数 $h$ 被设置为 $10\sigma$，这里 $\sigma$ 为人工添加高斯白噪声的标准差。由于指数权重的快速衰减，距离中心较远像素的权重几乎为零，这发挥了自动剔除远处像素的作用。Non Local means 算法的权重分布见图$(2)$。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image003.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图3.  对自然图像的降噪实验。从左至右：含噪声的实测图像（噪声标准差 35），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;在前面的段落中，我们明确的计算了各种局部平滑滤波方法的 method noise 理论值。图$(4)$ 的可视化实验证明了前文中公式的正确性。图$(4)$ 对比了数种降噪方法对含噪声lena图像运算的 method noise，噪声为高斯白噪声，标准差 2.5，滤波参数 $h$ 均相同。Method noise 能更好的协助判断降噪算法的性能及局限，因为被移除或改变的纹理、细节将被 method noise 醒目的展示出来。对比图$(4)$ 中数种降噪算法，NL-means 算法的 method noise 几乎无法察觉任何几何纹理。图$(2)$ 可以解释这一现象，因为 NL-means 算法选取的权重因子完全适应图像局部及非局部的几何结构。</p>
<p>&lt;img src&#x3D;”Exp002_image004.jpg” width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图4.  降噪算法的method noise。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。视觉实验验证了第二节的计算公式。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;由于算法本身的性质，纹理及周期性结构是 NL-means 算法最适用的情况。因为对任意像素 $i$，纹理图像或周期性图像中将可以找到大量与该像素具有相似邻域的点，如图$(2.e)$。图$(3)$ 展示了局部平滑滤波器及 NL-means 算法对自然纹理的平滑效果。</p>
<p>&emsp;&emsp;自然图像同样含有足够的信息冗余会被 NL-means 恢复。平坦区域内部将呈现出大量相似的几何结构，见图$(2.a)$。直边界、或弯曲边界将被筛选出一条结构相似的像素线，见图$(2. b)，(2.c)$。并且，NL-means 将会在很远的位置寻找到与参考点相似的结构，如图$(2.f)$。图$(5)$ 展示了一次对自然图像的可视化实验，这组结果与图$(4)$ 是相对应的。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image005.jpg” width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图5.  对自然图像的降噪实验。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;最后，表$(1)$ 展示了本文介绍的降噪方法的均方差。这种数值测量方法是最客观的，因为它不依赖于任何肉眼视觉上的解释。然而，这个误差在实际问题中是不可计算的（原始信号是未知的），小的均方误差并不能保证高的视觉质量。因此，以上讨论的标准似乎是比较算法性能的必要条件。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image006.jpg” width &#x3D; 35% div align&#x3D;center &#x2F; title&#x3D;”表1.  均方误差表。均方误差越小，降噪后越接近原始图像。”&gt;</p>
<p>&nbsp;<br>&lt;img src&#x3D;”&#x2F;Exp002_image007.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图6.  多种滤波方法对周期性图像应用结果。从左到右、从上到下：含噪声图像（标准差 35）；高斯滤波；TV滤波；邻域滤波；维纳滤波（ideal filter）；Hard TIWT；DCT 经验维纳滤波；NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&lt;img src&#x3D;”&#x2F;Exp002_image008.jpg” width &#x3D; 40% div align&#x3D;center &#x2F; title &#x3D; “图7.  多种滤波方法对自然图像应用结果。从左到右、从上至下：含噪声图像（标准差 25）；DCT 经验维纳滤波；Hard TIWT；NL-means 算法。”&gt;</p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>&emsp;&emsp;Non-local means 方法 C 语言实现：<a href="http://www.ipol.im/pub/art/2011/bcm_nlm/">http://www.ipol.im/pub/art/2011/bcm_nlm&#x2F;</a></p>
]]></content>
  </entry>
  <entry>
    <title>聚氨酯泡沫制备工艺</title>
    <url>/archive/Exp006-PU-foam.html</url>
    <content><![CDATA[<p>&emsp;&emsp;聚氨酯（Polyurethane, PU）是聚氨基甲酸酯的简称，凡是主链上含有许多重复的 $$ {\rm -NHCOO-} $$ 基团的高分子化合物通称为聚氨酯。多异氰酸酯与多元醇进行化学反应，即可生成聚氨酯。硬质聚氨醋泡沫塑料具有优良的力学性能、较高的比强度、良好的冲击吸能特性及隔音绝热性能，作为结构支撑材料和减震缓冲材料在武器方面有着重要的应用。本文将简单介绍聚氨酯泡沫制备工艺，为本次上海光源开展的动态 CT 实验样品制备提供参考。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;制备聚氨酯所需的主要原料为有机异氰酸酯、多元醇化合物及助剂。用于聚氨酯泡沫塑料制备的有机异氰酸酯通常有：甲苯二异氰酸酯（<strong>TDI</strong>）、二苯基甲烷二异氰酸酯（<strong>MDI</strong>）、<u>多亚甲基多苯基多异氰酸酯（<strong>PAPI</strong>）</u>等。多元醇又分为<u>聚醚多元醇</u>、聚酯多元醇两大类。助剂主要包括：催化剂、发泡剂、泡沫稳定剂、交联剂、阻燃剂、防老剂、填料、颜料等等。聚氨酷泡珠塑料的密度、孔径、软硬程度均可随原料、助剂的种类及配比不同而改变。</p>
<ul>
<li>注：聚合，指单体小分子相互连接成为链状大分子,一般分子量达到 5000 以上，甚至可以达到几千万，形成高分子材料。</li>
</ul>
<p>&emsp;&emsp;工业聚氨酯泡沫黑白料作为一步法制备聚氨酯泡沫的主要原料，白料通常为为组合聚醚多元醇、匀泡剂、交联剂、催化剂、发泡剂等的预混合液，黑料为聚合二苯甲烷二异氰酸酯（<strong>MDI</strong>），因而使用工业聚氨酯泡沫黑白料为原料探究助剂的影响是不可取的。</p>
<h2 id="异氰酸酯的反应特性"><a href="#异氰酸酯的反应特性" class="headerlink" title="异氰酸酯的反应特性"></a>异氰酸酯的反应特性</h2><p>&emsp;&emsp;由于异氰酸酯的化学特性，它不但能和多羟基化合物反应生成氨基甲酸酯，而且还可以和其他具有“活性氢”的化合物反应生成各种相应的化学链节，从而改变聚氨酯的链节结构和性能。人们不断以此为基础，发展聚氨酯的改性手段，有目的的引入各种链节及基团，改变基体聚合物的性能。因此聚氨酯类聚合物有“可缝制的聚合物”之称，日益收到人们的重视。</p>
<h3 id="异氰酸酯与-rm-NH-基反应"><a href="#异氰酸酯与-rm-NH-基反应" class="headerlink" title="异氰酸酯与 ${\rm NH}$ 基反应"></a>异氰酸酯与 ${\rm NH}$ 基反应</h3><h4 id="与胺基（-rm-NH-2-）反应"><a href="#与胺基（-rm-NH-2-）反应" class="headerlink" title="与胺基（${\rm -NH_2}$）反应"></a>与胺基（${\rm -NH_2}$）反应</h4><p>&emsp;&emsp;凡存在 ${\rm -NH_2}$ 基团的化合物，除具有较大的位阻效应外，基本都能与异氰酸酯发生反应（式\eqref{1}）。碱性越强的胺基化合物与异氰酸酯的反应能力越强，例如脂肪族伯胺在 $0\sim25^\circ{\rm C}$ 下即能与异氰酸酯反应生成对应脲类化合物。</p>
<p>$$ {\rm RNCO + R’NH_2 \Longrightarrow RNHCONHR’} {\tag{1}\label{1}}$$</p>
<p>&emsp;&emsp;总的来说，胺基化合物与异氰酸酯的反应活性相较其他一般活性氢化合物要高。与胺基化合物具有同样强碱性的其他含氮化合物，例如联胺等也能很快地与异氰酸酯发生反应（式\eqref{2}）。在聚氨酯制备中，胺基与异氰酸酯的反应是较为重要的反应之一。<br>$$ {\rm RNCO + R’NH!!-!!NH_2 \Longrightarrow RNHCONHNHR’} \tag{2}\label{2}$$</p>
<ul>
<li>注：位阻效应，分子中某些原子或基团彼此接近而引起的空间阻碍，阻碍化学反应的进行。（<font color=Green>不严谨</font>）</li>
</ul>
<h4 id="与酰胺基（-rm-CONH-2-）反应"><a href="#与酰胺基（-rm-CONH-2-）反应" class="headerlink" title="与酰胺基（${\rm -CONH_2}$）反应"></a>与酰胺基（${\rm -CONH_2}$）反应</h4><p>&emsp;&emsp;异氰酸酯可与酰胺基化合物反应生成对应酰基脲化合物（式\eqref{3}）。</p>
<p>$$ {\rm RNCO + R’CONH_2 \Longrightarrow RNHCONHCOR’} \tag{3}\label{3}$$</p>
<p>&emsp;&emsp;由于酰胺基中 $$ {\rm N!!-!!H}$$ 基团上氮原子带有负电荷，降低了其与异氰酸酯的反应速率。因而，在聚氨酯制备中该反应的利用率不高。</p>
<h4 id="与脲基（-rm-NHCONH-）反应"><a href="#与脲基（-rm-NHCONH-）反应" class="headerlink" title="与脲基（${\rm -NHCONH-}$）反应"></a>与脲基（${\rm -NHCONH-}$）反应</h4><p>&emsp;&emsp;此项反应是在高温条件下制备聚氨酯涉及到的重要反应之一。异氰酸酯与脲基化合物反应可生成对应缩二脲（式\eqref{4}）。</p>
<p>$$ {\rm R’NCO + RNHCONHR \Longrightarrow R’N(-CONHR)2} \tag{4}\label{4}$$</p>
<p>&emsp;&emsp;该反应在没有催化剂存在下，一般需在 $100^\circ{\rm C}$ 或更高温度下才能发生。大部分叔胺对此并不呈现较强的催化作用，而强碱和某些金属化合物则具有较强的催化能力。</p>
<h4 id="与氨基甲酸酯（-rm-NHCOO-）反应"><a href="#与氨基甲酸酯（-rm-NHCOO-）反应" class="headerlink" title="与氨基甲酸酯（${\rm -NHCOO-}$）反应"></a>与氨基甲酸酯（${\rm -NHCOO-}$）反应</h4><p>&emsp;&emsp;异氰酸酯与氨基甲酸酯的反应没有与脲基反应那么容易。无催化剂情况下，一般需在 $120\sim140^\circ{\rm C}$下才能得到较为满意的反应速率。在通常的反应条件下，所得最终产物为脲基甲酸酯（式\eqref{5}）。</p>
<p>$$ {\rm RNCO + RNHCOOR’ \Longrightarrow RN(-CONHR)COOR’} \tag{5}\label{5}$$</p>
<p>&emsp;&emsp;此类反应类似异氰酸酯与脲基化合物的反应，一般叔胺类对该反应不起催化作用，只有强碱或某些金属化合物才具有一定的催化作用。在进一步升温后，还将产生其他副反应，在此不做介绍。</p>
<h3 id="异氰酸酯与-rm-OH-基反应"><a href="#异氰酸酯与-rm-OH-基反应" class="headerlink" title="异氰酸酯与 ${\rm OH}$ 基反应"></a>异氰酸酯与 ${\rm OH}$ 基反应</h3><h4 id="与醇类反应"><a href="#与醇类反应" class="headerlink" title="与醇类反应"></a>与醇类反应</h4><p>&emsp;&emsp;此类反应为聚氨酯制备中的主要反应。通常情况，凡与氧原子相连接的氢原子都能与异氰酸酯发生反应，其中最活泼的就是醇类化合物，它可以与异氰酸酯反应生成对应氨基甲酸酯（式\eqref{6}）。</p>
<p>$$ {\rm RNCO + R’OH   \Longrightarrow RNHCOOR’} \tag{6}\label{6}$$</p>
<p>&emsp;&emsp;醇类化合物与其他化合物一样，其化学结构中的位阻效应会对反应带来较大的影响。在 $25\sim30^\circ{\rm C}$ 下，伯醇和异氰酸酯即可立即反应；而同样情况下，仲醇的反应速率只有伯醇的 $0.3$ 倍；叔醇的反应速率则更慢，仅有伯醇的 $0.005$ 倍。又如三苯基甲醇由于位阻效应更大，甚至于异氰酸酯不发生反应。</p>
<p>&emsp;&emsp;一般的强碱和较为缓和的碱性化合物，以及许多金属化合物都能对此反应呈现较强的催化作用，而酸性条件则能减弱反应。通常在聚氨酯泡沫塑料、弹性体、涂料等的制备中，带有多羟基的低聚物和异氰酸酯反应时，不同酸、碱催化剂的相应催化效果十分明显。此外，很多金属化合物对羟基和异氰酸酯的反应呈现较高的催化效果。根据催化活性不同，大致排列顺序如下：铋、铅、锡、三乙胺、强碱、钛、铁、锑、铀、镉、钴、铝、汞、锌、镍、二烷基胺、锶、钼、钒、铜、锰、锆等化合物及三烷基磷等。砷、硼、钙、钡等化合物对此过程不起催化作用。</p>
<ul>
<li>注：醇类化合物根据羟基（${\rm -OH}$）所连接碳原子的类型，分为伯醇、仲醇、叔醇。</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>结构简式</th>
</tr>
</thead>
<tbody><tr>
<td>伯醇</td>
<td>与羟基相连的碳原子上连有一个碳（或取代基）的醇</td>
<td>$$ {\rm R!!-!!CH2!!-!!OH} $$</td>
</tr>
<tr>
<td>仲醇</td>
<td>与羟基相连的碳原子上连有两个碳（或取代基）的醇</td>
<td>$$ {\rm R1!!-!!CH(R2)!!-!!OH} $$</td>
</tr>
<tr>
<td>叔醇</td>
<td>与羟基相连的碳原子上连有三个碳（或取代基）的醇</td>
<td>$$ {\rm R1!!-!!C(R2)(R3)!!-!!OH} $$</td>
</tr>
</tbody></table>
<h4 id="与水反应"><a href="#与水反应" class="headerlink" title="与水反应"></a>与水反应</h4><p>&emsp;&emsp;异氰酸酯与水的反应活性和它与仲醇的反应活性相当，如果水和仲醇二者同时溶于反应介质和异氰酸酯反应，二者反应活性几乎相等。然而异氰酸酯与水反应的生成物不如氨基甲酸酯那么简单，它第一步加成反应先生成不稳定的氨基甲酸，然后立即分解，放出二氧化碳，生成对应胺基化合物（式\eqref{7}）。</p>
<p>$$ {\rm RNCO + H_2O \Longrightarrow RNHCOOH \Longrightarrow RNH_2 + CO_2\uparrow} \tag{7}\label{7}$$</p>
<p>&emsp;&emsp;该胺基又进一步与异氰酸酯反应生成对应脲类化合物（式\eqref{1}），这一反应速率甚至高于式\eqref{7}。</p>
<p>$$ {\rm R’NCO + RNH_2 \Longrightarrow R’NHCONHR} $$</p>
<p>&emsp;&emsp;因此，完整的反应为 $ 2 {\rm mol}$ 异氰酸酯基团与 $ 1 {\rm mol}$ 水发生反应，生成 $ 1 {\rm mol}$ 对应脲类化合物并放出 $ 1 {\rm mol}$ 二氧化碳（式\eqref{8}）。</p>
<p>$$ {\rm 2RNCO + H_2O \Longrightarrow RNHCONHR + CO_2\uparrow} \tag{8}\label{8}$$</p>
<p>&emsp;&emsp;这个反应是聚氨酯泡沫塑料制造过程中最关键的反应之一，它能使多异氰酸酯或两个以上端基带有异氰酸酯的预聚体进行链增长或交联反应，从而形成聚合物。同时，反应中产生的二氧化碳气体也是制造泡沫塑料气孔关键。</p>
<p>&emsp;&emsp;在聚氨酯的反应体系中，水和异氰酸酯是不互溶的，因而二者反应速度极慢，一般需要合适的溶剂或乳化剂存在下充分混合才能顺利进行反应。叔胺、碱性物质及某些金属化合物对此反应都有较强的催化作用。</p>
<p>&emsp;&emsp;大多数异氰酸酯都能与水反应生成脲类化合物。然而也有例外，例如苯环上带有硝基的芳香族异氰酸酯和水反应，则仅能生成胺而不容易得到脲。其主要原因是具有足够量的带负电荷的硝基会减弱胺基的碱性。同时，在胺基的邻位上带有的硝基也会因位阻效应而降低反应速率。这样，胺基与异氰酸酯的反应活性远低于水与异氰酸酯。典型的如 $3,5-$二硝基苯异氰酸酯与水反应所得到的是胺、脲混合物。而 $2,4-$二硝基或 $2,4,6-$三硝基苯异氰酸酯和水反应仅能得到较高收率的胺，很少得到或基本没有脲。相反，在邻位上带有正电荷（如甲基）的芳香族异氰酸酯和水反应，则会加强其反应选择性，例如 $ 2 {\rm mol}$ 的甲苯二异氰酸酯（<strong>TDI</strong>）和 $1{\rm mol}$ 水反应则能得到极高收率的相应取代脲（式\eqref{9}）。</p>
<p>$$ Markdown 不支持含苯环的有机化学方程式 \tag{9}\label{9}$$</p>
<p>&emsp;&emsp;异氰酸酯和水的反应在聚氨酯化学中非常重要，这是制造二氧化碳发泡型泡沫中必不可少的步骤。同时，在储藏、运输过程中这也是需要尽量避免的副反应，必须密封贮藏，以免和水蒸气发生反应。</p>
<h4 id="与酚类反应"><a href="#与酚类反应" class="headerlink" title="与酚类反应"></a>与酚类反应</h4><p>&emsp;&emsp;酚类与脂肪族醇类相比，具有一定酸度，因而与异氰酸酯的反应活性较醇类远弱。大部分异氰酸酯与酚类的反应（式\eqref{10}）在 $50\sim75^\circ {\rm C}$ 时极为缓慢，通常需加入叔胺或其他催化剂来加速反应。</p>
<p>$$ {\rm RNCO + ArOH   \Longrightarrow RNHCOOAr} \tag{10}\label{10}$$</p>
<p>&emsp;&emsp;在苯环上带有负电荷取代基的酚类都能抑制它与异氰酸酯的反应，其主要原因是由于这些基团会减弱羟基的碱度。</p>
<ul>
<li>注：酚（phenol），结构简式为 ${\rm ArOH}$，是芳香烃环上的氢被羟基取代的一类芳香族化合物。一般使用 ${\rm Ar}$ 表示芳香基团，${\rm Ph}$ 表示苯基。</li>
</ul>
<h3 id="异氰酸酯其他重要反应"><a href="#异氰酸酯其他重要反应" class="headerlink" title="异氰酸酯其他重要反应"></a>异氰酸酯其他重要反应</h3><h4 id="二聚反应"><a href="#二聚反应" class="headerlink" title="二聚反应"></a>二聚反应</h4><p>同时芳香族异氰酸酯和不饱和化合物反应时，自身容易发生二聚反应，形成二聚体。脂肪族异氰酸酯在一般条件下不生成二聚体而生成三聚体。某些芳香族异氰酸酯如 $4,4’-$二苯甲烷二异氰酸酯，即使在无催化剂环境下，长期放置也会逐渐产生二聚体。而邻位具有取代基的大部分芳香族异氰酸酯则会阻碍自身二聚化。</p>
<p>&emsp;&emsp;二聚体在加热情况下，一般能分解为异氰酸酯单体。此外，异氰酸酯二聚体还能和活性氢化合物直接反应，二期所用催化剂与单体异氰酸酯所用催化剂基本相同。甲苯二异氰酸酯（<strong>TDI</strong>）二聚体在聚氨酯制备中常用作交联剂，在常温下贮藏稳定性远好于单体异氰酸酯，它可以和活性氢化合物在室温下混合，而在加热和催化剂存在下分解为异氰酸酯单体，进行所需反应。</p>
<p>&emsp;&emsp;另一种异氰酸酯的二分子缩合体也引起人们较大的兴趣，两个异氰酸酯基团融合为 $${\rm -N!!&#x3D;!!C!!&#x3D;!!N-}$$ 基团，它是以 $2,4,6-$三（二乙基胺基）对称三嗪等为催化剂，缩合后放出二氧化碳，生成碳化二亚胺的反应。以苯基异氰酸酯为例，收率可达 $90 %$ 左右。</p>
<p>$$ {\rm 2Ar!!-!!NCO \underset{催化剂}{\overset{&gt;40^\circ C}\Longrightarrow} Ar!!-!!N!!&#x3D;!!C!!&#x3D;!!N!!-!!Ar + CO_2\uparrow}$$</p>
<p>&emsp;&emsp;利用这个反应，可将常温下为固态的二苯基甲烷二异氰酸酯（<strong>MDI</strong>）制成含有碳化二亚胺的液态 <strong>MDI</strong>。由液态 <strong>MDI</strong> 制得的聚氨酯制品具有良好的耐焰性和低发烟密度，他可作为整皮模塑泡沫塑料的多异氰酸酯原料。</p>
<p>$$ {\rm n OCN-Ar-CH_2-Ar-NCO \underset{催化剂}{\overset{300^\circ C, 45 min}\Longrightarrow} \lbrack!!!-!N!&#x3D;!C!&#x3D;!N!-!Ar!-!CH_2!-!Ar!-!!!\rbrack_n}$$</p>
<p>&emsp;&emsp;碳化二亚胺还能抑制聚酯的湿老化，提高聚氨酯的耐水性，因此根据需要，可以在聚氨酯分子中引入碳化二亚胺链节，作为结构型的改性手段。</p>
<h4 id="三聚反应"><a href="#三聚反应" class="headerlink" title="三聚反应"></a>三聚反应</h4><p>&emsp;&emsp;脂肪族与芳香族异氰酸酯在适当条件下都能形成三聚体，得到的是含有异氰脲酸酯环的衍生物。这类反应是异氰酸酯和不饱和化合物加成反应的另一特例。生成的异氰脲酸酯杂环很稳定，在 $150\sim200^\circ{\rm C}$ 下不分解。和其他反应一样，位阻效应对三聚反应也有较大影响，如叔丁基异氰酸酯就不易发生三聚反应，芳香族异氰酸酯在邻位基团上有取代基时也不易发生三聚反应。</p>
<h4 id="与羧基反应"><a href="#与羧基反应" class="headerlink" title="与羧基反应"></a>与羧基反应</h4><p>&emsp;&emsp;羧基（${\rm -COOH}$）中也具有 ${\rm -OH}$ 基，因而也能与异氰酸酯反应，其反应能力根据酸度不同而不同，一般而言，它的反应活性低于伯醇、水。</p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>&emsp;&emsp;异氰酸酯除与 ${\rm -NH}$ 基、${\rm -OH}$ 基发生反应外，还将与带有活性氢的硫基（${\rm -SH}$）化合物发生反应，与羟基过程类似，只是反应活性较弱。</p>
<p>&emsp;&emsp;异氰酸酯是一类反应性极高的化合物，这是由他本身的化学结构决定的，它具有较多的不饱和基团 $ {\rm -N&#x3D;C&#x3D;O} $，除能和许多化合物进行加成反应外，还可本身加热或在催化剂作用下发生自聚及脱碳（存疑）等反应：</p>
<p>$$ {\rm RNCO + R’NH_2 \Longrightarrow RNHCONHR’}$$<br>$$ {\rm RNCO + R’OH   \Longrightarrow RNHCOOR’}$$<br>$$ {\rm RNCO + ArOH   \Longrightarrow RNHCOOAr}$$<br>$$ {\rm 2RNCO + HOH   \Longrightarrow RNHCONHR + CO_2}$$<br>$$ {\rm RNCO + R’SH   \Longrightarrow RNHCOSR’} $$<br>$$ {\rm RNCO + R’COOH \Longrightarrow RNHCOR’ + CO_2} $$<br>$$ {\rm \qquad\qquad\qquad\qquad\qquad\qquad\qquad\ or \Longrightarrow RNHCONHR + \lgroup R’CO\rgroup_2O + CO_2} $$<br>$$ {\rm RNCO + HCN \Longrightarrow RNHCOCN} $$<br>$$ {\rm RNCO + NH_2OH \Longrightarrow RNHCONHOH} $$<br>$$ {\rm RNCO + NH_3 \Longrightarrow RNHCONH_2} $$<br>$$ {\rm RNCO + CH_2(CN)COOR’ \Longrightarrow RNHCOCH(CN)COOR’} $$<br>$$ {\rm RNCO + R’CH_2NO_2 \Longrightarrow RNHCOCHR’NO_2} $$</p>
<p>&emsp;&emsp;异氰酸酯自聚及其他反应：</p>
<p>$$　{\rm RNCO + ArNO \Longrightarrow RN!!&#x3D;!!OAr + NO_2} $$<br>$$ {\rm RNCO + ArCHO \Longrightarrow RN!!&#x3D;!!CHAr + CO_2} $$<br>$$ {\rm RNCO + Ar_2CS \Longrightarrow RN!!&#x3D;!!CAr_2 + COS} $$<br>$$ {\rm 2RNCO \overset{\bigtriangleup}\Longrightarrow RN!!&#x3D;!!C!!&#x3D;!!NR + CO_2} $$</p>
<h2 id="聚氨酯泡沫塑料的合成原理"><a href="#聚氨酯泡沫塑料的合成原理" class="headerlink" title="聚氨酯泡沫塑料的合成原理"></a>聚氨酯泡沫塑料的合成原理</h2><h3 id="基本反应"><a href="#基本反应" class="headerlink" title="基本反应"></a>基本反应</h3><p>在聚氨酯泡沫塑料的成型过程中，主要的反应如下：</p>
<ul>
<li>异氰酸酯与羟基反应  多异氰酸酯与多元醇反应生成聚氨酯：</li>
</ul>
<p>$$ {\rm nOCN!!-!!R!!-!!NCO + nHO!!-!!R’!!-!!OH \Longrightarrow \lbrack!!-!!\overset{O} {\overset{\Vert} C}NH!!-!!R!!-!!NH!!-\overset{O} {\overset{\Vert} C}!!-!!O!!-!!R’!!-!!O!!-!!\rbrack_n}$$</p>
<ul>
<li>异氰酸酯与谁反应  带有异氰酸酯基团的化合物和水反应，先生成不稳定的氨基甲酸，而后分解为胺与二氧化碳：</li>
</ul>
<p>$$ {\rm RNCO + H_2O \Longrightarrow RNHCOOH \Longrightarrow RNH_2 + CO_2\uparrow}$$</p>
<p>而后，胺基进一步和异氰酸酯基团反应生成含脲基的聚合物：</p>
<p>$$ {\rm R-NCO + R’-NH_2 \Longrightarrow R-\overset{H} {\overset{\vert} N}- \overset{O} {\overset{\Vert} C} - \overset{H} {\overset{\vert} N} - R’}$$</p>
<p>上述两项反应都属链增长反应，后者还生成二氧化碳。通常在无催化剂情况下，异氰酸酯与胺基反应速率很快，所以在反应中不但使过量的水</p>
<h3 id="硬质聚氨酯泡沫成型工艺"><a href="#硬质聚氨酯泡沫成型工艺" class="headerlink" title="硬质聚氨酯泡沫成型工艺"></a>硬质聚氨酯泡沫成型工艺</h3><h4 id="模塑发泡"><a href="#模塑发泡" class="headerlink" title="模塑发泡"></a>模塑发泡</h4><p>&emsp;&emsp;模塑发泡是通过手工配料然后在一定容积的模具中封闭发泡的一种成型工艺。通过这种工艺可以对制品的形状和密度进行控制。首先将聚醚与匀泡剂、催化剂和发泡剂等助剂按配比均匀混合（白料），然后将按配比称取的 <strong>PAPI</strong>（黑料）加入聚醚与助剂的混合物中，高速搅拌后将混合均匀的物料倒入模具中发泡，发泡完成并冷却一段时间后在 $100^\circ{\rm C}$ 烘箱中熟化 $$4\ {\rm h}$$。聚醚组分和 PAPI 组分的温度调节为 $24^\circ{\rm C}$，模具温度调节为 $42^\circ{\rm C}$。</p>
<h4 id="自由发泡"><a href="#自由发泡" class="headerlink" title="自由发泡"></a>自由发泡</h4><p>&emsp;&emsp;自由发泡是发泡过程在开放容器中完成的一种合成工艺。制品的密度由发泡剂的用量和反应条件决定。与模塑发泡的配料过程相似，首先将聚醚与匀泡剂、催化剂和发泡剂等助剂按配比在一次性纸杯中混合均匀，再将按配比称取的 <strong>PAPI</strong> 加入纸杯，用搅拌器搅拌 $$1\ {\rm min}$$，发泡过程在纸杯中进行，经充分反应待泡沫自然冷却后制备即告完成。环境温度为室温 $28\sim 31^\circ{\rm C}$。</p>
<h3 id="助剂"><a href="#助剂" class="headerlink" title="助剂"></a>助剂</h3><h4 id="匀泡剂"><a href="#匀泡剂" class="headerlink" title="匀泡剂"></a>匀泡剂</h4><p>&emsp;&emsp;匀泡剂一般是硅表面活性剂（silicone surfactant，或称为硅油），用于稳定液体泡沫，是聚氨酯泡沫合成中的关键因素。匀泡剂对水在体系中的溶解度没有影响，但是当水的用量大于其在体系中的溶解度时，匀泡剂可以显著改善水的分散。另外，匀泡剂的种类和浓度对体系中的各种化学反应动力学没有影响。</p>
<p>&emsp;&emsp;匀泡剂最重要的特性是能够降低制备过程中体系的表面张力，表面张力在泡孔结构的形成过程中占有重要地位。它有利于稳定气泡，使小气泡更稳定的存在，并且还可以改善水或其它发泡剂在体系中的分散，因此匀泡剂的使用有利于降低的孔径及分布。不同种类和用量的匀泡剂对降低表面张力和分散发泡剂所起的作用是不完全相同的，因此将导致不同的泡沫塑料孔径和孔径分布。</p>
<p>&emsp;&emsp;对于所有三种匀泡剂，当用量低于份时，孔径随匀泡剂用量的增大而快速下降；当用量高于份时，孔径随匀泡剂用量的增加不再发生明显变化，维持在一个较低的孔径水平上。三种匀泡剂对孔径的影响规律大体上相同，但是也有一些不同特点硅油降低孔径的能力强于另外两种匀泡剂硅油 JSY1020 的用量在多于份以后孔径有明显增大的趋势，另外两种匀泡剂在此范围基本没有引起孔径的增大。</p>
<p>&emsp;&emsp;当匀泡剂在较低和中间用量范围时，随着匀泡剂用量的增加，发泡过程中的液体泡沫体系表面张力降低，有利于小气泡的稳定存在，并减少泡孔间的合并行为，使得整体泡沫的孔径得到降低。当匀泡剂用量增加到一定程度，体系中的匀泡剂浓度增加到足以使匀泡剂覆盖所有气一液介面，表面张力降到最低而当匀泡剂用量较高时，的整体孔径增大，并且呈现如图所示的局部泡孔粗大深色区域、局部泡孔细密浅色区域的现象。原因是匀泡剂用量大于其在聚醚组分中的溶解度而发生聚集，在发泡过程中不能快速移动到气一液界面，从而不能有效稳定气泡，造成较大泡孔的出现，甚至引起泡沫的塌陷。</p>
<p>&emsp;&emsp;匀泡剂的用量还与的闭开孔率有关,表所列为组样品的闭孔率测试结果,该组采用三乙醇胺作为催化剂,在一份范围内变化匀泡剂的用量制备。由表中的数据可以发现,组样品整体的闭孔率较低,并随匀泡剂用量的增加而提高。</p>
]]></content>
  </entry>
  <entry>
    <title>实验室显微CT建设</title>
    <url>/archive/Exp005-labCT.html</url>
    <content><![CDATA[<p>为配合同步辐射CT技术的研发，本团队计划 2020 年内完成实验室显微CT平台的搭建工作。实验室显微CT的主要特色是能够对目标试样内部的三维形貌进行无损表征，建设完成后，除其基本表征功能外，仍可为诸多研发工作提供便利： (1)同步辐射超快X射线成像系统中将使用的光学器件、机电设备等可以首先使用这套系统进行试错、标定。 (2)原本需在同步辐射进行测试的样品，可首先使用这套系统进行预实验，检验同步辐射实验的可行性。 (3)诸多同步辐射成像、CT相关的后处理算法也可首先使用这套系统进行验证性实验，如 XPIV、XDIC、XDVC 等。</p>
<p>目前，实验室显微CT平台建设已提上日程，本文将记录实验室CT建设过程中的详细信息。</p>
<span id="more"></span>

<h2 id="微焦点X射线源"><a href="#微焦点X射线源" class="headerlink" title="微焦点X射线源"></a>微焦点X射线源</h2><p>&emsp;&emsp;目前所用射线源产自 X-RAY WorX GmbH 公司，型号 <a href="https://www.x-ray-worx.com/index.php/en/microfocus-x-ray-tubes-overview/microfocus-transmission-tubes/product-line-tcnf">XWT-190-TCNF</a>。该公司 2010 年 2 月始建于 Hanover。这家德国高科技公司主营开发生产开放式、高分辨率的微焦点X射线源，用于无损X射线检测及计算机层析成像。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image003.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”Microfocus X-ray tube XWT-160-TCNF”&gt;</p>
<p>XWT-190-TCNF 微焦点X射线源有如下数条亮点：</p>
<ul>
<li>为半导体、电子元件、复合材料等的X射线成像效果提供了极致的 JIMA card 分辨能力</li>
<li>内置射线管头液体冷却装置，极大提高焦点位置稳定性，焦点运动范围$\pm 1\ \mu m$</li>
<li>内置自动排气阀，延长真空部件的使用寿命</li>
</ul>
<p>XWT-190-TCNF 微焦点X射线源的详细参数如下：</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image004.bmp” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Technical Details of Microfocus X-ray tube XWT-190-TCNF”&gt;</p>
<h2 id="PIXIS-2048B-相机"><a href="#PIXIS-2048B-相机" class="headerlink" title="PIXIS 2048B 相机"></a>PIXIS 2048B 相机</h2><p>&emsp;&emsp;来自普林斯顿仪器公司（Princeton Instruments, PI）的 <a href="http://www.princetoninstruments.com.cn/userfiles/files/assetLibrary/Datasheets/Princeton_Instruments_PIXIS_2048_eXcelon-N5_1-10_22_14.pdf">PIXIS 2048 系列相机</a>是专为定量科学成像而设计的全集成低噪声相机。背照型（B）提供近$95%$的可见光波段量子效率（Quantum efficiency）。利用PI独家设计的XP冷却技术，可提供$-55^\circ C$冷却，极大抑制暗电流。外壳采用全金属密封设计，提供行业内唯一终身真空质保。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image005.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Control software interface”&gt;</p>
<p>PIXIS 2048B 相机的详细参数如下：</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image006.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Technical Details of PIXIS 2048B”&gt;</p>
<h2 id="8-3维位移台"><a href="#8-3维位移台" class="headerlink" title="8+3维位移台"></a>8+3维位移台</h2><p>&emsp;&emsp;考虑到锥束CT扫描前必备的几何校正环节，实验室CT系统共需两套位移台，分别为样品下的八维载物台，及相机下三维位移台，均采购自日本KOHZU公司，详细参数见下表：</p>
<table>
<thead>
<tr>
<th align="center">轴号</th>
<th align="center">八维载物台@Z轴</th>
<th align="center">八维载物台@XY轴</th>
<th align="center">八维载物台@uv轴</th>
<th align="center">八维载物台@旋转轴</th>
</tr>
</thead>
<tbody><tr>
<td align="center">型号</td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/z-stage/motorized-z-stage/product/424/3/ZA07A-W201/1279/">ZA07A-W201</a></td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1%2C2/YA07A-R102/1265/">YA07A-R102</a></td>
<td align="center"><a href="https://www.kohzuchina.com/products/positioning-stages/swivel-tilt-stage/motorized-swivel-stage/product/76/5,20/SA07A-RL01/1292/">SA07A-RL01</a></td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/rotation-stage/motorized-rotation-stage/product/426/4/RA07A-W01/1243/">RA07A-W01</a></td>
</tr>
<tr>
<td align="center">行程</td>
<td align="center">$\pm$ 4 mm</td>
<td align="center">$\pm$ 10 mm</td>
<td align="center">$\pm$ 8$^\circ$ &amp; $\pm$10$^\circ$</td>
<td align="center">$\pm$ 135$^\circ$(@360$^\circ$)</td>
</tr>
<tr>
<td align="center">例图</td>
<td align="center"><img src="/Exp012_image007.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image008.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image009.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image010.jpg" width = 100% div align=center /></td>
</tr>
<tr>
<td align="center">轴号</td>
<td align="center"><strong>八维载物台@xy轴</strong></td>
<td align="center"><strong>三维位移台@XY轴</strong></td>
<td align="center"><strong>三维位移台@Z轴</strong></td>
<td align="center"><strong>PCIe1040&#x2F;1020控制器</strong></td>
</tr>
<tr>
<td align="center">型号</td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1%2C2/YA05A-R101/1259/">YA05A-R101</a></td>
<td align="center"><a href="https://www.kohzu.co.jp/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1,2/YA10A-R1/442/">YA10A-R1</a></td>
<td align="center"><a href="http://www.himotion.co.kr/kor/download/pdf/0106.pdf">ZA10A-V1</a></td>
<td align="center">王奕超</td>
</tr>
<tr>
<td align="center">行程</td>
<td align="center">$\pm$ 7.5 mm</td>
<td align="center">$\pm$ 12.5 mm</td>
<td align="center">$\pm$ 5 mm</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">例图</td>
<td align="center"><img src="/Exp012_image011.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image012.jpg" width = 80% div align=center /></td>
<td align="center"><img src="/Exp012_image013.bmp" width = 100% div align=center /></td>
<td align="center">&lt;img src&#x3D;”&#x2F;Exp012_image014.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; &gt;</td>
</tr>
</tbody></table>
<h2 id="闪烁体及可见光光路"><a href="#闪烁体及可见光光路" class="headerlink" title="闪烁体及可见光光路"></a>闪烁体及可见光光路</h2><p>&emsp;&emsp;闪烁体是 X 射线成像探测器的重要组成部分，它将入射 X 射线转换为可见光，再由可见光成像探测器接收成像。闪烁体的厚度对成像的空间分辨能力、图像衬度有较大的影响，选取合适的厚度的闪烁体，与探测器物镜（数值孔径）等实验条件达到最理想的匹配，将有助于获得高质量的 X 射线成像结果。</p>
<h2 id="成像几何校正"><a href="#成像几何校正" class="headerlink" title="成像几何校正"></a>成像几何校正</h2><p>&emsp;&emsp;不妨令探测器中心与射线源的连线为基线，定义为Z轴，如下图，探测器自身纵向阵列在Z轴法平面上的投影定义为Y轴，根据右手坐标系法则确定X轴。在理想的成像几何下，探测器平面理应与Z轴严格垂直，且样品旋转轴应与Y轴严格重合。然而，实际实验中往往会偏离理想成像几何，几何偏差又分为如下四种情况：(1)探测器平面绕X轴偏转；(2) 探测器平面绕Y轴偏转；(3) 旋转轴绕Z轴偏转；(4) 旋转轴绕X轴偏转。下图列出了前三种偏转独立发生时所产生的影响。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image015.bmp” width &#x3D; 100% div align&#x3D;mid &#x2F;title&#x3D;”Reconstructed volume in the presence of detector tilt +10° (rotation around X-axis), detector slant +10° (rotation around Y-axis), and detector skew +2° (rotation around Z-axis).”&gt;</p>
<p>&emsp;&emsp;图中可见，(2,3)类几何偏差对重建结果产生了极大的畸变，对检测精密结构三维形貌十分不利，因而必须在进行CT扫描前将成像几何校正至理想情况，并确保在扫描过程中不发生变化。</p>
<p>&emsp;&emsp;(1,2)类几何偏差的校正方法可以等价为如何将射线源在探测器平面上的投影调整至探测器中心处。首先需准备一尺寸适中的标准球（如轴承钢珠），不断横向移动相机并记录相机坐标，采集标准球的投影图像。显然，投影图像理应为圆锥曲线，当投影图像完全在视野内时则必定为椭圆图样，且射线源在探测器平面上的投影恰恰就落在该椭圆的长轴所在直线上。从不同位置多次采集椭圆投影图像，即可确定射线源在探测器平面上的投影坐标。将射线源投影移动至探测器中心处，则(1,2)类几何偏差得以校正。</p>
<p>&emsp;&emsp;(3,4)类几何偏差的校正方法与同步辐射成像下几何校正无异，差异只在于必须在探测器纵向中心层进行几何校正，否则校正无效，细节在此不做赘述，注意需准备医用注射器针尖。</p>
<h2 id="实验操作及数据存储规范"><a href="#实验操作及数据存储规范" class="headerlink" title="实验操作及数据存储规范"></a>实验操作及数据存储规范</h2><h2 id="反卷积算法"><a href="#反卷积算法" class="headerlink" title="反卷积算法"></a>反卷积算法</h2><p>&emsp;&emsp;目前已实现经GPU加速的FDK三维重建算法，基于模拟的测试结果如下，左侧为模拟输入图像，右侧为重建输出图像。后续将逐步拓展，补全领域内主流算法。由于内容过于繁杂，对反卷积算法系统性的总结介绍请见下篇文章，此处只展示测试结果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image018.jpg” width &#x3D; 80% div align&#x3D;mid &#x2F;title&#x3D;”Simulation and Verification of FDK Reconstruction Algorithm.”&gt;</p>
<h2 id="抗干扰算法"><a href="#抗干扰算法" class="headerlink" title="抗干扰算法"></a>抗干扰算法</h2><p>&emsp;&emsp;仅有反卷积算法还远远不够，微焦点源实验室显微CT中将会出现诸多干扰因素，若放任不管直接应用反卷积算法则会得到极糟糕的切片图像，于精确提取、量化分析不利。下表列出了实验室显微CT系统中常常面临的数种干扰因素及大致解决办法，各项具体细节将分别在其他博文中介绍。</p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">成因</th>
<th align="center">特点</th>
<th align="center">解决方案</th>
</tr>
</thead>
<tbody><tr>
<td align="center">椒盐噪声</td>
<td align="center">射线源散射探测像元</td>
<td align="center">随机出现，尺寸极小，强度极高</td>
<td align="center">Remove Outliers</td>
</tr>
<tr>
<td align="center">S1环状伪影</td>
<td align="center">探测器坏点</td>
<td align="center">该像元始终返回固定值</td>
<td align="center">Bicubic Interpolation</td>
</tr>
<tr>
<td align="center">S2环状伪影</td>
<td align="center">闪烁体缺陷</td>
<td align="center">固定存在，尺寸不定</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">S3环状伪影</td>
<td align="center">探测系统非线性相应</td>
<td align="center">投影图像中极难察觉</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">背底震荡</td>
<td align="center">光源输出功率振荡</td>
<td align="center">Sinogram图像呈现大量横向条纹</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">射线硬化</td>
<td align="center">射线源能谱过宽</td>
<td align="center">&emsp;</td>
<td align="center">滤片</td>
</tr>
</tbody></table>
<h2 id="待采购清单"><a href="#待采购清单" class="headerlink" title="待采购清单"></a>待采购清单</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="right">数量</th>
<th align="right">参考价格</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><a href="https://vsp.jd.com/sku/100006476938">内六角全套套装</a></td>
<td align="right">1</td>
<td align="right">75.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100000652973.html">多功能螺丝刀套装</a></td>
<td align="right">1</td>
<td align="right">87.20</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://item.jd.com/30195663980.html#crumb-wrap">分隔收纳盒小号8格</a></td>
<td align="right">5</td>
<td align="right">5.10</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100006890641">干湿表</a></td>
<td align="right">1</td>
<td align="right">49.90</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/8063953">无尘布4寸</a></td>
<td align="right">2</td>
<td align="right">48.45</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/7831134">F型夹具</a></td>
<td align="right">2</td>
<td align="right">15.20</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100001946704">玻璃滴瓶</a></td>
<td align="right">2</td>
<td align="right">45.73</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/5833171">隐形胶带</a></td>
<td align="right">5</td>
<td align="right">8.91</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100011490188.html">胶带切割器</a></td>
<td align="right">1</td>
<td align="right">20.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100014305790.html">压缩空气除尘剂</a></td>
<td align="right">2</td>
<td align="right">79.57</td>
<td align="center">光学元件除尘</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100013533578">小型超声波清洗机</a></td>
<td align="right">1</td>
<td align="right">219.00</td>
<td align="center">闪烁体、试样清洁</td>
</tr>
<tr>
<td align="center">异丙醇</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">射线源阴极栅格罩清洁</td>
</tr>
<tr>
<td align="center">无水乙醇</td>
<td align="right">3</td>
<td align="right">50.00</td>
<td align="center">闪烁体清洁</td>
</tr>
<tr>
<td align="center"><a href="https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1430">THORLABS 607扳手</a></td>
<td align="right">1</td>
<td align="right">200.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100000381447">照明灯</a></td>
<td align="right">1</td>
<td align="right">29.90</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center">Kapton膜</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">闪烁体前防尘</td>
</tr>
<tr>
<td align="center">石墨、铝、铁、铜250um左右薄片</td>
<td align="right">10</td>
<td align="right">50.00</td>
<td align="center">频谱收窄</td>
</tr>
<tr>
<td align="center">XX薄膜</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">闪烁体后防尘</td>
</tr>
<tr>
<td align="center">Kapton管</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">样品容器</td>
</tr>
<tr>
<td align="center">5X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">10X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">20X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">目镜镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">YaG闪烁晶体</td>
<td align="right">1</td>
<td align="right">5000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">LuAG闪烁晶体</td>
<td align="right">1</td>
<td align="right">5000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">3D 分辨率板</td>
<td align="right">1</td>
<td align="right">23000.00</td>
<td align="center">&emsp;</td>
</tr>
</tbody></table>
]]></content>
  </entry>
  <entry>
    <title>Windows Server 2019 + Mint OS 搭建 Tomography 数据分析工作站</title>
    <url>/archive/Exp009-WinServerSetup.html</url>
    <content><![CDATA[<p>为实现多用户同时登录 Tomography 数据分析工作站，避免设备冗余浪费，使用 Windows Server 2019 与 Mint OS 虚拟机的组合是个让人满意的方案。 本文记录配置 Tomography 数据分析工作站时的一些常见问题及相应的解决办法。</p>
<p>本文使用的所有 OS 镜像均下载自 <a href="https://msdn.itellyou.cn/">MSDN</a> 镜像资源站，启动盘制作使用 <a href="https://www.ventoy.net/en/index.html">Ventoy</a> 开源工具包，虚拟机平台使用 VMware Workstation 16.0。</p>
<span id="more"></span>

<h1 id="Windows-Server-2019"><a href="#Windows-Server-2019" class="headerlink" title="Windows Server 2019"></a>Windows Server 2019</h1><h2 id="Windows-Server-2019-Standard-激活"><a href="#Windows-Server-2019-Standard-激活" class="headerlink" title="Windows Server 2019 Standard 激活"></a>Windows Server 2019 Standard 激活</h2><p>以管理员权限运行 Windows PowerShell：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ slmgr /upk</span><br><span class="line">$ slmgr /ipk N69G4-B89J2-4G8F4-WWYCC-J464C</span><br><span class="line">$ slmgr /skms kms.03k.org</span><br><span class="line">$ slmgr /ato</span><br></pre></td></tr></table></figure>

<p>是否成功激活，激活码到期时间可输入以下命令查看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ slmgr /xpr</span><br></pre></td></tr></table></figure>

<h2 id="无法访问共享文件夹的解决办法"><a href="#无法访问共享文件夹的解决办法" class="headerlink" title="无法访问共享文件夹的解决办法"></a>无法访问共享文件夹的解决办法</h2><blockquote>
<ol>
<li>Win+R 快捷键调用 Run，输入 <code>control</code> 调用 Control Panel，Turn Windows features on or off，安装 SMB 1.0&#x2F;CIFS File Sharing Support。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>Win+R 快捷键调用 Run，输入 <code>gpedit.msc</code> 调用 Local Group Policy Editor，Computer Configuration - Administrative Templates - Network - Lanman Workstation - Enable insecure guest logons。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>Windows Defender 防火墙，允许应用或功能通过 Windows Defender 防火墙，允许 SMBDirect 上的文件和打印机共享。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>右键点击 This PC，Add a network location，Choose a custom network location，<code>\\192.168.26.110\APS-data\</code>。</li>
</ol>
</blockquote>
<h2 id="远程桌面连接权限"><a href="#远程桌面连接权限" class="headerlink" title="远程桌面连接权限"></a>远程桌面连接权限</h2><p>与 Windows 10 类似，远程连接权限、防火墙权限、网络共享权限、Remote Desktop Server 权限，共四步骤，此处不做过多介绍。 特别注意每个子账号均需单独开启远程权限。</p>
<h2 id="多用户同时登陆权限"><a href="#多用户同时登陆权限" class="headerlink" title="多用户同时登陆权限"></a>多用户同时登陆权限</h2><p>Windows Server 2019 默认远程桌面连接数上限是 2 位用户，无法容纳更多用户同时登陆，可以通过添加远程桌面授权解决：</p>
<p>参考链接：<a href="https://www.cnblogs.com/laosan007/p/11734283.html">Windows Server 2019 远程桌面服务配置和授权激活</a></p>
<h2 id="Tomography-分析常用软件"><a href="#Tomography-分析常用软件" class="headerlink" title="Tomography 分析常用软件"></a>Tomography 分析常用软件</h2><blockquote>
<ol>
<li>办公类：Chrome浏览器、TIM、Wechat for PC、MobaXterm</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>学术类：Endnote X9、Sublime Text 4、Adobe Acrobat Pro DC</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>工程类：Avizo、OriginPro 9.0、Fiji ImageJ、Matlab、VMware Workstation、Photoshop</li>
</ol>
</blockquote>
<h1 id="VMware-Workstation-Mint-OS"><a href="#VMware-Workstation-Mint-OS" class="headerlink" title="VMware Workstation + Mint OS"></a>VMware Workstation + Mint OS</h1>]]></content>
  </entry>
  <entry>
    <title>X-ray micro-CT 中消除环状伪影的高级技巧</title>
    <url>/archive/Exp008-stripe-remove.html</url>
    <content><![CDATA[<p>同步辐射 X 射线显微 CT 系统的重建图像经常遭受严重的环状伪影（ring artifacts）干扰。在正弦图中这种干扰通常呈直线或条纹状分布。它们往往来自于探测系统的不规则响应，按结构又分为如下几类：全条纹；局部条纹；震荡条纹；无响应条纹。CT 投影图像的预处理算法如变形矫正、相位恢复等都会更进一步的模糊、放大这些干扰条纹。然而目前还没有一种算法能够同时移除上述所有种类的干扰条纹。本文将介绍三种针对性解决这些干扰的算法，所有的步骤都是易于复刻的；不会带来额外的干扰；在实际应用中的效果比其他算法更好。</p>
<p>本文所有工作均由 <a href="https://scholar.google.com/citations?hl=en&user=ob0Q9skAAAAJ">Nghia T. Vo</a> 博士依托 Diamond Light Source, <a href="https://www.diamond.ac.uk/Instruments/Imaging-and-Microscopy/I12/Beamline-Characteristics.html">I12-JEEP线站</a>完成。</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;在同步辐射层析成像系统中X射线平行光穿透试样构成的二维投影图像在 180$^\circ$ 范围内多个角度下被二维X射线探测系统所采集。将所有投影图像的第n行按角度顺序组合在一起就形成了第n行的正弦图像。对该正弦图像进行重构，即可得到样品第n层处的切片图像。探测系统任何无法被白背底校正所消除的缺陷都将在正弦图像中形成竖条纹，进而在其重构出的切片图中产生环状伪影（图(1)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image001.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图1. 探测系统缺陷的影响：(a)正弦图中的条纹伪影；(b)切片图中的环状伪影。”&gt;</p>
<p>&emsp;&emsp;缺陷可能来自于传感器芯片的非线性响应、光学元件污渍（尤其是闪烁体）等等。适用于同步辐射的高质量、高分辨率、耐辐射闪烁体制造始终具有一定的挑战性。长时间高通量的X射线会破坏闪烁体的微观结构，这是因为X射线照射将促使光学元件（镜子、阳极化膜等）表面不断释放粒子并沉积在闪烁体表面，进而影响闪烁体成像质量（图(2)）。虽然在慢速实验中频繁的更换与清洗可以暂时解决这个问题，但在不能中断的时间分辨成像实验中闪烁体仍然可能发生损坏。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image002.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图2. 实验过程中闪烁体的退化：(a)实验开始时；(b)使用数日后。”&gt;</p>
<p>&emsp;&emsp;目前已有许多去环状伪影算法问世。然而，面对同步辐射上采集的海量数据，只有少数低计算成本的算法被集成到层析成像重建软件包中[1-6]。这些算法按原理又可分为两类：实空间方法和频域空间方法。规范化方法（normalization-based methods）[7]及正则化方法（regularization-based methods）[8]非常易用，但只适用于抑制某些特定类型的条纹。傅里叶变换方法（FFT-based methods）[9]及小波傅里叶变换方法（wavelet-FFT-based methods）[10]可以解决更多种类的条纹，但需要调整许多参数以达到最佳效果，较难使用。此外，如果参数选择不合适，该算法还会对图像质量产生很大影响。并且，所有上面提到的算法都有两个共同的缺点：如果图像中存在高频边缘，则会带来额外的条纹伪影；提高滤波强度将会抹去切片图中心区域的原本纹理（void-center artifacts）。其他作用于切片图上的算法[11]在此不做介绍。</p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="典型环状伪影分类"><a href="#典型环状伪影分类" class="headerlink" title="典型环状伪影分类"></a>典型环状伪影分类</h3><p>&emsp;&emsp;比较缺陷像素与邻近完好像素的强度分布特征，可将典型伪影分为如下四类。这里的强度分布指缺陷像素强度值随样品旋转角度变化的分布函数。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_table001.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; &gt;</p>
<p>&emsp;&emsp;无响应条纹S1可能来自于传感器芯片的坏点、遮光的粉尘（黑色块）或闪烁体损伤（白色块）。这些区域对X射线入射强度的变化都无法做出响应，导致正弦图像中出现恒定强度的竖条纹，进而将在切片图中产生醒目的半环。重建算法中的 ramp filter 将更进一步的加强这类条纹的高频边缘（图(1.b)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image003.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图3. 缺陷像素的典型强度分布（红色）与邻近完好像素强度分布（蓝色）对比：(a)无响应条纹S1；(b)全条纹S2；(c)局部条纹S3；(d)震荡条纹S4。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image004.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图4. (a)全条纹S2、局部条纹S3以及震荡条纹S4的实物示范；(b)蓝色子区的放大视图；(c)，(d)，(e) 分别由全条纹、局部条纹、震荡条纹引起的环状伪影。”&gt;</p>
<p>&emsp;&emsp;全条纹S2、局部条纹S3以及震荡条纹S4则来自于探测器的不完美区域，然而这些区域难以通过肉眼从投影图像中分辨出来。图(4.c-e)展示了这三类条纹所造成的重建图像中的环状伪影。图(5.a)展示了长时间使用并发生明显退化的闪烁体所采集的白背景图像。缺陷区域（defective regions, called blobs）从图中可以清晰分辨。经过平场校正的高衬度目标投影图像中，视觉上已经无法明显察觉这些缺陷区域（图(5.b)）。然而更深入的分析表明，认为投影图像与白背景图像间符合简单的线性关系是不严谨的。Nghia T. Vo提出了一种易于实现的技术来分析每个像素的响应系数分布，这有助于迅速的检测探测器隐藏的缺陷区域。以旋转范围为[0$^\circ$,90$^\circ$]的匀质玻璃板作为X射线衰减器，连续采集其在不同角度下时的投影图像，而后对所有像素的测量强度的对数与该角度下X射线穿透厚度进行线性拟合。计算得到各个像素的线性拟合偏差，即可得到如图(5.c)所示的响应系数偏差分布。对于理想探测器，应当得到一幅完全平整的响应系数偏差分布图像。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image005.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图5. 平场校正图与响应系数偏差分布图对比：(a) 白背景图像；(b) 平场校正后投影图像；(c) 响应系数偏差分布；(d,e,f) 分别对应前三幅图像中方框区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;这个简易的方法对检测探测系统的非均匀响应非常有效。令人遗憾的是，所得到的响应系数偏差不能直接用于校正。在实践中，缺陷像素的响应系数取决于信号强度的动态范围和相邻区域（即闪烁体的光散射）的信号强度，而这是由样品的形状和吸收特性决定的，在不同情况下通常存在差异。图(6)展示了在相同条件下扫描的两个样品在同一行探测器上的切片图像，其中样品一（图(6.a)）产生的透射强度动态范围比样品二低得多。图(6)中可见在样本二中存在样本一中没有出现的环状伪影。样品二中的强吸收物质在闪烁体中产生了极暗弱的阴影区域，在某些角度下，阴影覆盖在闪烁体缺陷处，缺陷像素的响应系数与临近正常像素的响应系数偏差变得非常突出，进而产生了局部条纹S3。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image006.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”图6. 局部条纹S3存在与否取决于投影强度的动态范围。 (a) 低动态范围投影强度试样的重建切片；(b) 高动态范围投影强度试样的重建切片。”&gt;</p>
<h3 id="移除小型、中型局部条纹及全条纹"><a href="#移除小型、中型局部条纹及全条纹" class="headerlink" title="移除小型、中型局部条纹及全条纹"></a>移除小型、中型局部条纹及全条纹</h3><p>&emsp;&emsp;从全条纹S2及局部条纹S3的典型强度分布中我们不难发现，相邻像素间强度分布的低频分量差异是这两类环状伪影的主要成因。基于这种差异消除条纹是此处介绍方法的关键。为了使相邻像素的响应系数一致，我们可以沿着正弦图像的水平方向进行平滑滤波变换。然而，这种方法将会引入空心伪影（void-center artifacts），损失重建图像中心区域的细节，顶峰多尺度科学研究所早期的CT分析工作常常遭受此干扰。为避免空心伪影，我们需要测算探测器的响应系数分布及其分布差异，而后才能对其进行平滑滤波变换或使用其他校正方法。表(2)列出了三种从正弦图像中测算响应系数分布并校准图像的方法。</p>
<img src="/Exp005_table002.jpg" width = 100% div align=center />

<p>&emsp;&emsp;虽然实现的方法不同，但是算法1与算法2的思想内核是一致的，它们的核心目标都是均衡相邻像素强度分布的低通分量。算法1的多项式阶数和算法2的窗口大小、类型的选择都是灵活的，最佳参数取决于正弦图特征的复杂程度。我们发现算法1更适用于低通分量可以用五阶以下多项式拟合的正弦图像。步骤2中平滑滤波器的强度应该在移除干扰条纹和损失真实信号间权衡。在算法1和2中有许多滤波方法及参数集的选择，本文将不再赘述此处细节。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image007.jpg” width &#x3D; 95% div align&#x3D;center &#x2F; title&#x3D;”图7. 算法3在示例正弦图像上的应用：(a) 原始正弦图像；(b) 对各列排序后的正弦图像；(c) 横向平滑后的正弦图像；(d) 重新构建的正弦图像；(e) 图(7.a)与图(7.d)的差异。”&gt;</p>
<p>&emsp;&emsp;令人惊讶的是，算法3虽然是最简单的方法，但却非常有效，它特别适用于处理局部条纹S3，而其他公开的方法都提及了处理局部条纹S3的挑战性。图(7)展示了算法3在一幅示例正弦图像上的应用，移除局部条纹后的重建图像上几乎无法察觉任何残留，如图(8)所示。算法3的原理可以通过近似假设来理解：由于透射强度随样品转动角度不断变化，探测系统内相邻区域对相近的入射通量范围进行采样；与样品中代表性的细节尺度相比，探测系统的反常区域（图(5.f)）很小。如果探测系统是理想的，那么相邻像素所探测到的投影强度在一次完整的CT扫描中的动态范围理应是几乎相同的。这意味着，如果将各像素处投影强度分布排序，相邻像素理应呈现一致的分布。在不规则区域较小的假设下，完全可以利用投影强度排序值对不规则区域进行识别、比较和校正，从而实现移除小型条纹。使用平滑滤波器是最简单的校正方法，但是在样品内锐利的边缘处将会产生伪影（图(7.e)）。边界处的artifacts将会导致重建图像中样品边缘处的环状伪影，然而，这相较于其他去环状伪影算法的副作用已经小得多了。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image008.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图8. 使用算法3前后重构图像对比：(a) 图(7.a)对应重建图像;(b) 根据图(7.d)对应重建图像;(c) (a) 中红色框放大视图;(d) (b)中红色框放大视图。”&gt;</p>
<p>&emsp;&emsp;算法3不仅在移除中小型局部条纹时非常有效，还可以替代算法1、2步骤2中的平滑滤波器。由于平滑滤波器而带来的额外风险，算法1、2只能用于移除中小型条纹。下一节将介绍针对大型条纹的处理方法，其中算法3仍然发挥着关键作用。</p>
<h3 id="移除大型条纹"><a href="#移除大型条纹" class="headerlink" title="移除大型条纹"></a>移除大型条纹</h3><p>&emsp;&emsp;上节介绍的算法能够在不显著影响其他区域的情况下校正中小型条纹。实际上，它甚至可以有选择地只应用于有缺陷的像素处。但在实践中，当使用低强度平滑滤波器时，对正常区域的影响微乎其微，而有选择地应用则极大的提升了工作复杂度，面对同步辐射上采集的海量数据集时很不实用。然而，当面对鲜见的大尺度缺陷区域（宽度大于20像素）时，我们不得不使用高强度平滑滤波器，而对整幅图像应用高强度平滑滤波器又将显著降低图像清晰度，得不偿失。在这种情况下，对缺陷区域选择性的应用强滤波器就显得尤为重要。那么额外的缺陷检测定位方法就必不可少。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image009.jpg” width &#x3D; 90% div align&#x3D;center &#x2F; title&#x3D;”图9. 大型条纹产生的原因及影响。(a) 大尺度缺陷（垂直箭头）及过曝斑点（水平箭头）；(b) 正弦图像中的大型条纹；(c) 重构图像中的环状伪影。”&gt;</p>
<p>&emsp;&emsp;探测器的大尺度缺陷鲜少出现，它们往往会引起全条纹S2及局部条纹S3的出现。这类大尺度缺陷可能来自于闪烁体的受损的大片区域，这些区域受损后将会反射额外的散射光（halo effect）从而形成亮斑（图(9)）。为了准确地从正弦图像中检测这类缺陷，Nghia T. Vo提出了一种一维数组分割算法以分离正缺陷（亮斑）与负缺陷（暗斑），如表(3)所示。</p>
<img src="/Exp005_table003.jpg" width = 100% div align=center />

<p>&emsp;&emsp;$I_0$、$I_1$为一维数组中的最小值与最大值，$F_0$、$F_1$为数组头尾处的拟合值，如图(10.b)所示。结合可调参数$R$，计算下阀值$T_L$与上阀值$T_U$：</p>
<p>$$T_L&#x3D;F_0-(F_1-F_0)\times R&#x2F;2, {\ \rm if\ } (F_0-I_0)&#x2F;(F_1-F_0)&gt;R.　\tag{1}\label{1}$$</p>
<p>$$T_U&#x3D;F_1+(F_1-F_0)\times R&#x2F;2, {\ \rm if\ } (I_1-F_1)&#x2F;(F_1-F_0)&gt;R.　\tag{2}\label{2}$$</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image010.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”图10. 算法4演示。(a) 背景校正后的一维数组。(b) 排序后的一维数组及其中段的线性拟合。”&gt;</p>
<p>&emsp;&emsp;$R$可以理解为缺陷与背景的比值，用户可以修改$R$值来调整算法的灵敏度。通常情况下，$R$的取值在3.0以上。算法4在某些情况下也可作为二值化方法使用。算法4即为大型缺陷的检测、定位步骤，以算法4为基础构造移除大型条纹的算法5，如表(4)所示。</p>
<img src="/Exp005_table004.jpg" width = 100% div align=center />

<p>&emsp;&emsp;在算法5的步骤2中，必须去除正弦图像顶部及底部少量像素，这可以避免高频边缘引起的条纹误检测，如图(11)所示。步骤1、2和3有助于抑制部分大型条纹及小的全条纹（图(12.a)）。原理层面上，算法5是一种完全不同于正则化方法的算法。图(12.b)展示了通过算法5的后三步去除剩余局部条纹的效果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image011.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图11. 算法5中步骤2的演示。(a) 排序后的正弦图像，其中高频边缘（箭头所示）将会导致条纹误检测；(b) 对图(11.a)应用水平方向的中值滤波。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image012.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图12. 对图(9.c)应用算法5移除大型条纹的结果。(a) 应用步骤1、2和3后的重建切片图像，其中仍存在少量局部条纹（箭头所示）；(b) 完整应用算法5后的重建切片图像；(c) 最终校正后切片图像（图(12.b)）与初始切片图像（图(9.c)）的差异（difference）。”&gt;</p>
<h3 id="移除无响应条纹及震荡条纹"><a href="#移除无响应条纹及震荡条纹" class="headerlink" title="移除无响应条纹及震荡条纹"></a>移除无响应条纹及震荡条纹</h3><p>&emsp;&emsp;无响应条纹S1及震荡条纹S4同样会在重构图像中产生环状伪影及条纹伪影（图(13)）。令人遗憾的是，这些条纹无法通过上文介绍的方法移除。因为这类条纹内的像素值和条纹外像素之间的灰度差异很大，几乎没有相关性。无响应条纹S1及震荡条纹S4间的特征强度分布也不同，无响应条纹S1的低通分量几乎保持不变（图(3.a)），而震荡条纹变化较大（图(3.d)）。这种强度分布的特点可以帮助我们通过如下信息检测此类条纹：正弦图像中横向强度分布与其低通分量间的绝对差的纵向平均（图(14.a)）；规范化上述结果（图(14.b)）；并应用算法4定位条纹。检测到条纹位置后，通过插值方法填充条纹所在位置各像素值，进而移除无响应条纹S1及震荡条纹S4。表(5)展示了移除无响应条纹S1及震荡条纹S4的步骤，即算法6。</p>
<img src="/Exp005_table005.jpg" width = 100% div align=center />

<p>&lt;img src&#x3D;”&#x2F;Exp005_image013.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图13. 无响应条纹S1及震荡条纹S4的影响。(a) 既存在无响应条纹S1（箭头）也存在震荡条纹S4（方框）的正弦图像；(b) 无响应条纹S1及震荡条纹S4导致的环状伪影；(c) 探测系统中导致无响应条纹S1的过曝斑点；(d) 图(13.a)中红色方框的放大视图；(e) 图(13.b)中红色方框的放大视图。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image014.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图14. 算法6中步骤1及步骤2的说明。(a)正弦图横向强度分布的纵向平均与其低通分量间的绝对差值（蓝色曲线）；及其中值滤波后的结果（红色曲线）;(b) 图(14.a)中两条曲线相除的结果。”&gt;</p>
<p>&emsp;&emsp;图(15)展示了对图(13.a)中正弦图应用算法6的结果。过曝斑点可能会在其周围产生非线性的边缘效应，从而产生图(15.a)中的残余大型条纹。因此，算法5必须在算法6之后使用（图(15.c)）。此外，算法6的检测方法对于类似于无响应条纹S1的真实信号（例如呈圆柱形的单一材料样品）可能产生错误判断。在这种情况下，算法5是必不可少的。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image015.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图15. 校正无响应条纹S1及震荡条纹S4的结果。(a) 对图(13.a)应用算法6的结果，仍然存在未完全去除的条纹；(b) 由图(15.a)中正弦图重构所得切片图像；(c) 应用算法5后的重构切片图像；(d) 图(13.b)与图(15.c)的差异。”&gt;</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="去除局部条纹与全条纹方法的比较"><a href="#去除局部条纹与全条纹方法的比较" class="headerlink" title="去除局部条纹与全条纹方法的比较"></a>去除局部条纹与全条纹方法的比较</h3><p>&emsp;&emsp;下文将比较算法1、2、3与四种广泛使用的算法在消除了中小型全条纹S2及局部条纹S3时的表现。用于比较的四种算法分别为：规范化方法（normalization-based method）[7]，正则化方法（regularization-based method）[8]，傅里叶变换方法（FFT-based method）[9]，小波傅里叶变换方法（wavelet-FFT-based method）[10]。下文中为了精简描述，将这四种算法分别称作M1、M2、M3和M4。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image016.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图16. (a) 样品一的正弦图像，拥有高频边缘及低动态范围；(b) 样品二的正弦图像，拥有高频边缘及高动态范围，其中存在强吸收区域（椭圆区域）”&gt;</p>
<p>&emsp;&emsp;在第一组对比测试中，我们对相同条件下扫描两个样品所得的正弦图像应用算法M1、M2、M3、M4以及算法3。这两个样品具有相似的结构和物质组成（嵌入化石的石灰岩），但在探测器的各层中它们的结构不尽相同。样品结构差异也将导致透射强度的动态范围不同（图(16)），高动态范围可能诱发正弦图像中出现局部条纹S3。此外，还需特别注意各去环状伪影算法在相衬成像[12]引起的高频边缘（图(16.a)）处的负面影响。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image017.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图17. 对图(16.a)中正弦图应用不同的算法后的重建结果，箭头标识典型的环状伪影：(a) 平场校正后；(b) M1；(c) M2；(d) M3；(e) M4；(f) 算法3。”&gt;</p>
<p>&emsp;&emsp;对于形状大致近圆的样品一，所有去环状伪影算法的表现都较好（图(17,18)）。各个方法所用的参数如下：M1)高斯滤波，$$\sigma$$&#x3D;11；M2) $$\alpha$$&#x3D;0.005；M3) u&#x3D;30，v&#x3D;0，n&#x3D;10；M4) Daubechies wavelet, order&#x3D;10，level&#x3D;5，$$\sigma$$&#x3D;1；A3)中值滤波，size&#x3D;31。图(17.b-e)中可见其他方法在实际应用中产生了额外的局部环状伪影，而本文介绍的算法3没有在目标内部造成额外的环状伪影，不过还是在边界处产生了一些无关紧要的artifacts（图(17.f)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image018.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图18. 图(17)中重建图像中心区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;对于高长宽比的样品二，即便使用与样品一中完全相同的参数，M1-M4方法仍然表现不佳（图(19.b-e)）。它们不仅无法完美地清除原有的环状伪影，留下了许多局部条纹（图(20)），甚至产生了许多强环状伪影（图(19)中的箭头所示）。使用不同的参数集，可能可以稍稍改善计算结果。然而，这对于在同步辐射上处理海量数据集的需求而言非常低效。对比图(19.f)与图(17.f)可以看出，本文介绍的算法3应用于高动态范围的正弦图时仍然表现良好。然而，在重建图像（图(18,20)）中仍然存在由震荡条纹S4引起的环状伪影。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image019.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图19. 图(16.b)中正弦图应用不同的算法后的重建结果，箭头标识典型的环状伪影：(a) 平场校正后；(b) M1；(c) M2；(d) M3；(e) M4；(f) 算法3。”&gt;</p>
<p>&emsp;&emsp;第一组对比测试的结果表明，对于传统的M1-M4方法，需对不同样品甚至同一样品的不同层使用不同的参数集才能达到最佳效果，然而这在实际应用中极其低效，本文介绍的方法即便使用相同的参数仍然可以得到理想的去环状伪影效果，从而使得高效处理海量数据集成为可能。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image020.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图20. 图(19)中重建图像中心区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;在第二组对比测试中，我们测试了这些算法去除局部条纹S3时的性能。所用样品呈高长宽比的矩形，且长边略微超出视场。这导致光路近似平行于样品长边时样品呈极强的吸收进而形成暗区，产生高动态范围。这直接引起正弦图像中出现局部条纹S3（图(21.a-c)），并在重建图像中产生局部环状伪影（图(21.d-e)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image021.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图21. 高动态范围的入射强度引起的局部条纹S3。 (a) 高长宽比矩形试样的正弦图；(b) 图(21.a)中顶部方框的放大试图；(c) 图(21.a)中底部方框的放大试图；(d) 由图(21.a)中正弦图重建所得切片图像；(e) 图(21.d)中方框的放大视图。”&gt;</p>
<p>&emsp;&emsp;应用M1-M4方法时，使用与第一次测试相同的参数对局部环形伪影几乎没有作用（图(22.a.1-d.1)）。适当的调整参数以达到更强的去环状伪影效果：M1) $$\sigma$$&#x3D;17，c&#x3D;30；M2) $$\alpha$$&#x3D;0.001，c&#x3D;30；M3) u&#x3D;30，v&#x3D;10，n&#x3D;10；M4) order&#x3D;10，level&#x3D;5，$$\sigma$$&#x3D;10。其中，<font color = #ff7f00>使用参数c（chunk）将正弦图划分为多个行块[13]</font>，从而增加算法M1及M2的强度。增强算法M1-M4的强度后均能清除局部环状伪影，但也抹去了重建图像中心区域的细节（void-center artifacts），如图(22.a.2-d.2)所示。然而，本文介绍的算法3在使用窗口大小分别为31和51的中值过滤器时都返回了没有额外干扰的干净图像（图(22.e.1，22.e.2)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image022.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图22. 应用不同参数集的算法M1-M4和算法3后的重建图像。 (a.1) M1；(b.1) M2；(c.1) M3；(d.1) M4；(e.1) A3；(a.2) M1；(b.2) M2；(c.2) M3；(d.2) M4；(e.2) A3。”&gt;</p>
<p>&emsp;&emsp;在第三组对比测试中，我们尝试比较了这些算法应用在一组极具挑战性的数据上时的性能。图(23.a)展示了其对比度极低的正弦图像，<font color = #ff7f00>我们不得不对其使用强低通滤波器[14]以提高其对比度</font>。然而，这种方法不可避免的模糊并扩大了原先存在的条纹（图(23.b)）。面对这一极具挑战性的数据时，我们发现与算法2、算法3相比，算法1提供了最好的结果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image023.jpg” width &#x3D; 62% div align&#x3D;center &#x2F; title&#x3D;”图23. 预处理方法引起的条纹扩大，及应用算法1后的结果。(a,b) 应用预处理方法前后探测器同一排的正弦图像；(c) 由图(23.b)中正弦图重建所得切片图像；(d) 应用算法1中步骤1后的结果，采用三阶多项式；(e) 依靠强二维低通滤波器校正后的正弦图像；(f) 由图(23.e)中正弦图重建所得切片图像。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image024.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图24. 应用M1-M4方法校正环状伪影，箭头标识典型的残余环状伪影。(a) M1（$\sigma$&#x3D;121）；(b) M2（$\alpha$&#x3D;0.00001）；(c) M3（u&#x3D;2，v&#x3D;1，n&#x3D;10）；(d) M4（order&#x3D;11，level&#x3D;3，$\sigma$&#x3D;10）。”&gt;</p>
<h3 id="去除各类条纹的方法组合"><a href="#去除各类条纹的方法组合" class="headerlink" title="去除各类条纹的方法组合"></a>去除各类条纹的方法组合</h3><p>&emsp;&emsp;前面的示例中，只使用了几组带有特定类型条纹的正弦图像用于演示方法的性能。在实践中，我们需要同时处理三维数据集中所有的正弦图像，各种类型的条纹可能出现在各个位置，甚至可能同时存在于同一位置。然而，单一的算法无法同时移除所有种类的条纹。例如，算法3及方法M1-M4无法去除图(18，20)所示的震荡条纹，也无法移除无响应条纹，这类条纹必须使用某种插值方法以填充缺失信息。并且，算法6不能单独使用，必须组合算法5以清理残余条纹。一般情况下，我们需要结合算法6，算法5以及表(2)中某种算法，既确保移除所有种类条纹，又极大抑制了算法导致的额外干扰。本文中介绍各个算法的顺序是基于它们之间相互依赖的顺序。然而，在实践中实际使用它们的顺序应该与文中顺序相反（[6 5 1]，[6 5 2]，或[6 5 3]）。算法1、2、3应在算法5之后使用，否则可能反而放大大型条纹。</p>
<p>&emsp;&emsp;图(25)展示了运用算法[6 5 3]组合处理完整层析数据集的结果。不使用去环状伪影方法的重构结果和使用小波傅里叶变换方法（wavelet-FFT-based method）[10]的重构结果也被展示出来以进行对照。图(25.c)中可见，各类环状伪影被清除殆尽。少量非常大但对比度很低的环状伪影仍然存在，它们来自于探测器中被晕轮效应（halo effect）影响的区域，在实际应用中很难准确检测到这类干扰。算法6中步骤1使用半径30的均值滤波器重建原始信号的低通分量，步骤2中使用尺寸为81的中值滤波器，步骤3中使用的R为3，步骤4中使用线性插值方法；算法5中中值滤波的尺寸与R的取值与算法6完全相同，步骤2中两侧5%的像素被舍弃；算法3中使用尺寸为31的中值滤波器。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image025.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图25. (a) 原始重构图像；(b) 应用小波傅里叶变换方法后的重构切片，参数与图(17.e)相同；(c) 应用算法[6 5 3]组合后的重构图像。”&gt;</p>
<p>&emsp;&emsp;组合算法似乎允许非常宽泛的参数集取值选择。然而，所有的可调参数很大程度上是由探测系统缺陷的尺寸和亮度差异直接决定的，它们分别与平滑滤波器的尺寸和R值相关。这是在同步辐射束线长期实验总结的经验结论，Nghia T. Vo证明此参数集选取标准适用于I12-JEEP线站长期以来采集的大多数层析成像数据[15]。其他参数，如算法6步骤1中均值滤波器的尺寸或算法5步骤2中舍弃边界的百分比，都是非敏感参数，对结果影响较小。算法5和算法6可以使用一致的参数集。总之，只有三个关键参数需要调整：算法5与算法6所用的平滑滤波器尺寸及R值；以及算法3中平滑滤波器的尺寸。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>&emsp;&emsp;根据探测系统缺陷像素的特征强度分布，本文将X-ray micro-CT中常见的条纹伪影分为四类：局部条纹、全条纹、震荡条纹和无响应条纹。它们分别需要利用不同的算法针对性解决，本文建议将文中介绍的三种算法组合使用，不仅可以移除各类条纹，还可以极大降低算法带来的负面影响。这些算法根据两项核心思想发展而来：（一）基于均衡或平滑相邻像素相应系数的校正方法；（二）基于排序、拟合、阈值的探测器缺陷区域检测方法。</p>
<p>&emsp;&emsp;本文所有方法都是易于学习理解、实现并使用的。在具有高动态范围、难以处理的局部条纹和模糊条纹的数据上，证明了其优于主流方法的性能。对照实验的结果表明，本文介绍的方法在不同样本间应用时无需修改参数，使用方便。</p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>本文介绍的算法与M1-M4方法的Python实现：<a href="https://github.com/nghia-vo/sarepy">https://github.com/nghia-vo/sarepy</a>。</p>
<p>本文使用的示例投影图像及重建图像数据集：<a href="https://doi.org/10.5281/zenodo.1443568">https://doi.org/10.5281/zenodo.1443568</a>。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://arxiv.org/ftp/arxiv/papers/1610/1610.08015.pdf"><font size = 2px>[1]&nbsp;&nbsp;N. Wadeson and M. Basham, “Savu: a Python-based, MPI framework for simultaneous processing of multiple, N-dimensional, large tomography datasets,” (2016)</font></a><br><a href="http://journals.iucr.org/s/issues/2014/05/00/pp5049/pp5049.pdf"><font size = 2px>[2]&nbsp;&nbsp;D. Gürsoy, F. De Carlo, X. Xiao, and C. Jacobsen, “Tomopy: a framework for the analysis of synchrotron tomographic data,” J. Synchrotron Radiat. 21(Pt 5), 1188–1193 (2014).</font></a><br><a href="https://ascimaging.springeropen.com/track/pdf/10.1186/s40679-016-0036-8"><font size = 2px>[3]&nbsp;&nbsp;F. Brun, L. Massimi, M. Fratini, D. Dreossi, F. Billé, A. Accardo, R. Pugliese, and A. Cedola, “SYRMEP Tomo Project: a graphical user interface for customizing CT reconstruction workflows,” Adv. Struct. Chem. Imaging 3(1), 4 (2017).</font></a><br><a href="http://sci-hub.tw/https://doi.org/10.1117/12.893252"><font size = 2px>[4]&nbsp;&nbsp;T. E. Gureyev, Y. Nesterets, D. Ternovski, D. Thompson, S. Wilkins, A. Stevenson, A. Sakellariou, and J. A. Taylor, “Toolbox for advanced X-ray image processing,” Proc. SPIE 8141, 81410B (2011).</font></a><br><a href="https://arxiv.org/pdf/1306.1392"><font size = 2px>[5]&nbsp;&nbsp;A. Mirone, E. Brun, E. Gouillart, P. Tafforeau, and J. Kieffer, “The PyHST2 hybrid distributed code for high speed tomographic reconstruction with iterative reconstruction and a priori knowledge capabilities,” Nucl. Instrum. Methods Phys. Res. B 324, 41–48 (2014).</font></a><br><a href="http://sci-hub.tw/10.1109/HPCC.2012.116"><font size = 2px>[6]&nbsp;&nbsp;M. Vogelgesang, S. Chilingaryan, T. d. Rolo, and A. Kopmann, “UFO: a scalable GPU-based image processing framework for on-line monitoring,” in IEEE International Conference on High Performance Computing and Communication &amp; Embedded Software and Systems (2012) pp. 824–829.</font></a><br><a href="https://www.mcs.anl.gov/research/projects/X-ray-cmt/rivers/tutorial.html"><font size = 2px>[7]&nbsp;&nbsp;M. Rivers, “Tutorial Introduction to X-ray Computed Microtomography Data Processing,”</font></a><br><a href="https://reader.elsevier.com/reader/sd/pii/S089396591000282X?token=8B0E798EF5FAD6E02787BF0198E9AE875C06C7210B90414AFE0F8C9C77E247F5231A50F10F7F85643E2B558522256429"><font size = 2px>[8]&nbsp;&nbsp;S. Titarenko, P. J. Withers, and A. Yagola, “An analytical formula for ring artefact suppression in X-ray tomography,” Appl. Math. Lett. 23(12), 1489–1495 (2010).</font></a><br><a href="http://qmxmt.com/scans/dave/other/papers/xmt%20artefacts/numerical%20removal%20of%20ring%20artifacts%20in%20microtomography.pdf"><font size = 2px>[9]&nbsp;&nbsp;C. Raven, “Numerical Removal of Ring Artifacts in Microtomography,” Rev. Sci. Instrum. 69(8), 2978–2980 (1998).</font></a><br><a href="https://www.osapublishing.org/DirectPDFAccess/48AC7ECE-D00F-B398-27185C39BD3B35FB_179485/oe-17-10-8567.pdf?da=1&id=179485&seq=0&mobile=no"><font size = 2px>[10]&nbsp;&nbsp;B. Münch, P. Trtik, F. Marone, and M. Stampanoni, “Stripe and ring artifact removal with combined wavelet-Fourier filtering,” Opt. Express 17(10), 8567–8591 (2009).</font></a><br><a href="https://pdfs.semanticscholar.org/4aee/d2da8e4a8bf7d25e5a777bf4b240ac7efd53.pdf"><font size = 2px>[11]&nbsp;&nbsp;J. Sijbers and A. Postnov, “Reduction of ring artefacts in high resolution micro-CT reconstructions,” Phys. Med. Biol. 49(14), N247–N253 (2004).</font></a><br><a href="https://pdfs.semanticscholar.org/1378/e0d19965c975086be524bb7903090e874d3c.pdf"><font size = 2px>[12]&nbsp;&nbsp;A. Snigirev, I. Snigireva, V. Kohn, S. Kuznetsov, and I. Schelokov, “On the possibilities of x-ray phase contrast microimaging by coherent high-energy synchrotron radiation,” Rev. Sci. Instrum. 66(12), 5486–5492 (1995).</font></a><br><a href="https://www.researchgate.net/profile/Valeriy_Titarenko/publication/51082293_Suppression_of_ring_artefacts_when_tomographing_anisotropically_attenuating_samples/links/0deec524021cc213f7000000.pdf"><font size = 2px>[13]&nbsp;&nbsp;S. Titarenko, V. Titarenko, A. Kyrieleis, P. J. Withers, and F. De Carlo, “Suppression of ring artefacts when tomographing anisotropically attenuating samples,” J. Synchrotron Radiat. 18(3), 427–435 (2011).</font></a><br><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1046/j.1365-2818.2002.01010.x"><font size = 2px>[14]&nbsp;&nbsp;D. Paganin, S. C. Mayo, T. E. Gureyev, P. R. Miller, and S. W. Wilkins, “Simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object,” J. Microsc. 206(1), 33–40 (2002).</font></a><br><a href="https://www.nature.com/articles/s41598-018-26644-6.pdf"><font size = 2px>[15]&nbsp;&nbsp;M. Polacci, F. Arzilli, G. La Spina, N. Le Gall, B. Cai, M. E. Hartley, D. Di Genova, N. T. Vo, S. Nonni, R. C. Atwood, E. W. Llewellin, P. D. Lee, and M. R. Burton, “Crystallisation in basaltic magmas revealed via in-situ 4D synchrotron X-ray microtomography,” Sci. Rep. 8(1), 8377 (2018).</font></a></p>
]]></content>
  </entry>
  <entry>
    <title>Kaggle竞赛：基于PyTorch/U-Net算法的表面缺陷检测</title>
    <url>/archive/Exp013-Kaggle01.html</url>
    <content><![CDATA[<p>Kaggle成立于2010年，是进行数据挖掘和预测算法研发的在线平台。除平台功能外，Kaggle官方每年会举办一次大规模竞赛，奖金一百万美元，吸引了广大Data Science爱好者参与其中。从某种角度上，可以把它理解为众包平台。但不同于传统的低层次劳动力需求，Kaggle致力于解决业界难题，不再以学历和工作经验作为唯一的人才评判标准，旨在任用最聪明的人解决世界上最棘手的问题，为顶尖人才和企业之间搭建了一座桥梁。</p>
<p>Kaggle曾公开举办一次<a href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview">钢材表面缺陷检测竞赛</a>，是将深度学习应用于传统目标检测很好的例子。对该赛题和解法的剖析，可以辅助理解深度学习的流程，及其应用于具体问题的套路。</p>
<span id="more"></span>

<h2 id="获取云端Kaggle数据集"><a href="#获取云端Kaggle数据集" class="headerlink" title="获取云端Kaggle数据集"></a>获取云端Kaggle数据集</h2><p>此处引用：<a href="https://github.com/Kaggle/kaggle-api">Kaggle API User Guide</a></p>
<p>To use the Kaggle API, sign up for a Kaggle account at <a href="https://www.kaggle.com/">https://www.kaggle.com</a>. Then go to the ‘Account’ tab of your user profile (<a href="https://www.kaggle.com/%22username%22/account">https://www.kaggle.com/&quot;username&quot;/account</a>) and select ‘Create API Token’. This will trigger the download of kaggle.json, a file containing your API credentials. Place this file in the location ~&#x2F;.kaggle&#x2F;kaggle.json (on Windows in the location C:\Users&quot;Windows-username”\.kaggle\kaggle.json - you can check the exact location, sans drive, with echo %HOMEPATH%). You can define a shell environment variable KAGGLE_CONFIG_DIR to change this location to $KAGGLE_CONFIG_DIR&#x2F;kaggle.json (on Windows it will be %KAGGLE_CONFIG_DIR%\kaggle.json).</p>
<p>For your security, ensure that other users of your computer do not have read access to your credentials. On Unix-based systems you can do this with the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod 600 ~/.kaggle/kaggle.json</span><br></pre></td></tr></table></figure>

<p>在本地计算机环境已经安装Python 3及pip环境后，<code>windows+X</code>打开Windows PowerShell (Administrator)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install kaggle</span><br></pre></td></tr></table></figure>

<p>下载数据集至<code>C:\Windows\system32\</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kaggle competitions download -c severstal-steel-defect-detection</span><br></pre></td></tr></table></figure>

<p>可以发现该数据集包含了赛题中完整的数据集信息：</p>
<ul>
<li>train_images：训练集图像</li>
<li>test_images：测试集图像</li>
<li>train.csv：训练集图像的缺陷标注，有4类缺陷，ClassId &#x3D; [1, 2, 3, 4]</li>
<li>sample_submission.csv：上传文件样例，每个ImageID要有4排，每一排对应一类缺陷</li>
</ul>
<h2 id="Clear-mask-visualization-and-simple-eda"><a href="#Clear-mask-visualization-and-simple-eda" class="headerlink" title="Clear mask visualization and simple eda"></a>Clear mask visualization and simple eda</h2><p>Import modules and define models:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.set_option(<span class="string">&quot;display.max_rows&quot;</span>, <span class="number">101</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># print(os.listdir(&quot;D:/Code/Kaggle/Steel Defect Detection/Data Base/&quot;))</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># matplotlib inline</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.size&quot;</span>] = <span class="number">15</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">input_dir = <span class="string">&quot;D:/Code/Kaggle/Steel Defect Detection/Data Base/severstal-steel-defect-detection/&quot;</span></span><br></pre></td></tr></table></figure>

<p>如检测到有宏包未安装，则使用pip安装，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>

<p>Read all text data:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df = pd.read_csv(os.path.join(input_dir,<span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">sample_df = pd.read_csv(os.path.join(input_dir,<span class="string">&quot;sample_submission.csv&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_df.head())</span><br><span class="line"><span class="built_in">print</span>(sample_df.head())</span><br></pre></td></tr></table></figure>

<p>First, check the number of each class.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">class_dict = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">kind_class_dict = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">no_defects_num = <span class="number">0</span></span><br><span class="line">defects_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(train_df), <span class="number">4</span>):</span><br><span class="line">    img_names = [<span class="built_in">str</span>(i).split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> train_df.iloc[col:col+<span class="number">4</span>, <span class="number">0</span>].values]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (img_names[<span class="number">0</span>] == img_names[<span class="number">1</span>] == img_names[<span class="number">2</span>] == img_names[<span class="number">3</span>]):</span><br><span class="line">        <span class="keyword">raise</span> ValueError</span><br><span class="line">        </span><br><span class="line">    labels = train_df.iloc[col:col+<span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> labels.isna().<span class="built_in">all</span>():</span><br><span class="line">        no_defects_num += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        defects_num += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    kind_class_dict[<span class="built_in">sum</span>(labels.isna().values == <span class="literal">False</span>)] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> idx, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels.isna().values.tolist()):</span><br><span class="line">        <span class="keyword">if</span> label == <span class="literal">False</span>:</span><br><span class="line">            class_dict[idx+<span class="number">1</span>] += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the number of images with no defects: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(no_defects_num))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the number of images with defects: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(defects_num))</span><br></pre></td></tr></table></figure>

<p>the number of images with no defects: 5902<br>the number of images with defects: 6666</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">sns.barplot(x=<span class="built_in">list</span>(class_dict.keys()), y=<span class="built_in">list</span>(class_dict.values()), ax=ax)</span><br><span class="line">ax.set_title(<span class="string">&quot;the number of images for each class&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;class&quot;</span>)</span><br><span class="line">class_dict</span><br></pre></td></tr></table></figure>

<p>defaultdict(int, {1: 897, 3: 5150, 4: 801, 2: 247})</p>
<ul>
<li>There are similar numbers of images with and without defects.</li>
<li>class is imbalanced</li>
</ul>
<h2 id="install-segmentation-models-pytorch"><a href="#install-segmentation-models-pytorch" class="headerlink" title="install segmentation_models_pytorch"></a>install segmentation_models_pytorch</h2><h3 id="install-PyTorch"><a href="#install-PyTorch" class="headerlink" title="install PyTorch"></a>install PyTorch</h3><p>查看CUDA版本，在Windows PowerShell中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p>在<a href="https://pytorch.org/">PyTorch官网</a>下载对应版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117</span><br></pre></td></tr></table></figure>

<h3 id="install-segmentation-models-pytorch-1"><a href="#install-segmentation-models-pytorch-1" class="headerlink" title="install segmentation_models_pytorch"></a>install segmentation_models_pytorch</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install segmentation-models-pytorch</span><br></pre></td></tr></table></figure>

<p>or install latest version from source:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install git+https://github.com/qubvel/segmentation_models.pytorch</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>Scale Invariant Feature Transform 算法</title>
    <url>/archive/Exp012-SIFT.html</url>
    <content><![CDATA[<p>尺度不变特征变换匹配（Scale Invariant Feature Transform, SIFT）算法，是David G. Lowe[1]在1999年提出的高效区域检测算法，2004年[2]完善。SIFT算法将图像中检测到的特征点用128维的特征向量进行描述。其本质是在不同的空间尺度上查找特征点，并计算特征点方向。SIFT算法所查找到的特征点是一些十分突出的局部结构，对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是目前领域内非常成熟稳定的局部特征检测算法。</p>
<span id="more"></span>

<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><ul>
<li><a href="https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html">OpenCV: Introduction to SIFT (Scale-Invariant Feature Transform)</a></li>
</ul>
<figure class="highlight python"><figcaption><span>sift.py, For feature keypoints extraction</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># reading the image</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert to greyscale</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT feature extractor</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect features from the image</span></span><br><span class="line">keypoints, descriptors = sift.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># draw the detected key points</span></span><br><span class="line">sift_image = cv2.drawKeypoints(gray, keypoints, img)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, sift_image)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;table-sift.jpg&quot;</span>, sift_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>feature_match.py, For feature matching</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># read the images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">&#x27;book.jpg&#x27;</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert images to grayscale</span></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT object</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect SIFT features in both images</span></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># create feature matcher</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># match descriptors of both images</span></span><br><span class="line">matches = bf.<span class="keyword">match</span>(descriptors_1,descriptors_2)</span><br><span class="line"><span class="comment"># sort matches by distance</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"><span class="comment"># draw first 50 matches</span></span><br><span class="line">matched_img = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:<span class="number">50</span>], img2, flags=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, matched_img)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;matched_images.jpg&quot;</span>, matched_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>




<h1 id="逻辑框架"><a href="#逻辑框架" class="headerlink" title="逻辑框架"></a>逻辑框架</h1><p>Lowe教授将SIFT算法分解为如下四步：</p>
<blockquote>
<ol>
<li><strong>尺度空间极值检测</strong>：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li><strong>特征点精确定位</strong>：在每个候选的位置上，通过精细拟合模型确定位置和尺度。特征点的选择依赖它们的稳定程度。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li><strong>方向确定</strong>：基于图像局部梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li><strong>特征点描述</strong>：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li>
</ol>
</blockquote>
<h1 id="SIFT算法原理"><a href="#SIFT算法原理" class="headerlink" title="SIFT算法原理"></a>SIFT算法原理</h1><h2 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h2><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p>
<h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。二维空间高斯函数：</p>
<p>\begin{equation}<br>G(x_i,y_i,\sigma)&#x3D;\frac{1}{2\pi\sigma^2}{\rm exp}\left[-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\right]<br>\end{equation}</p>
<p>尺度空间为：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;G(x,y,\sigma)*I(x,y)<br>\end{equation}</p>
<p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma&#x3D;0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大约$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)^2$的矩阵就可以保证相关像素影响。</p>
<h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：</p>
<blockquote>
<ol>
<li>使用低通滤波器（LPF）平滑图像；</li>
<li>平滑图像降采样（通常</li>
</ol>
</blockquote>
<p> 该方式能得到系列尺寸缩小的图片。尺度空间表达和金字塔分辨率表达的明显区别有：</p>
<blockquote>
<ol>
<li>尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；</li>
<li>金字塔多分辨率表达每层分辨率减少固定比率。</li>
</ol>
</blockquote>
<p>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p>
<h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（5$*$5）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xox4Te.png" width="90%" alt="Fig.1 高斯金字塔与高斯差分金字塔。" align=center /></p>
<p>高斯金字塔的构建过程：</p>
<blockquote>
<ol>
<li>先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>将$\sigma$乘以一个比例系数$k$，得到新的平滑因子$\sigma&#x3D;k*\sigma_{old}$，用它来平滑第1组第2层图像，结果图像作为第3层。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为$\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。这样反复执行，就可以得到一共$O$组，每组$L$层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子是前一层图像平滑因子的$k$倍；在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</li>
</ol>
</blockquote>
<h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}<br>\end{equation}</p>
<p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p>
<p>\begin{align}<br>L_i &amp;&#x3D; G_i-Up(G_{i+1})\otimes g \<br>&amp;&#x3D;G_i - PyrUp(G_{i+1}) \<br>\end{align}</p>
<p>式中，$G_i$表示高斯金字塔中第层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p>
<h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示：</p>
<p>\begin{equation}<br>\sigma\nabla^2G &#x3D; \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}<br>\end{equation}</p>
<p>因此，有：</p>
<p>\begin{equation}<br>G(x,y,k\sigma) - G(x,y,\sigma) \approx (k-1)\sigma^2\nabla^2G<br>\end{equation}</p>
<p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。</p>
<h3 id="空间极值点检测"><a href="#空间极值点检测" class="headerlink" title="空间极值点检测"></a>空间极值点检测</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoxIFH.png" width="40%" alt="Fig.2 空间极值点检测。" align=center /></p>
<p>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时$S$在3到5之间。当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p>
<p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p>
<h2 id="特征点精确定位"><a href="#特征点精确定位" class="headerlink" title="特征点精确定位"></a>特征点精确定位</h2><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p>
<h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoz3nK.png" width="60%" alt=" " align=center /></p>
<p>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x,y)$。设$X_0 &#x3D; (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p>
<p>\begin{equation}<br>f(\left[\begin{matrix}x\y\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\y_0\\sigma_0\end{matrix}\right]) + \left[\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right] + \frac{1}{2}\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]^{\rm T}\left[\begin{matrix}<br>\frac{\partial^2 f}{\partial x^2}               &amp; \frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial x \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial y^2}               &amp; \frac{\partial^2 f}{\partial y \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial \sigma} &amp; \frac{\partial^2 f}{\partial y \partial \sigma} &amp; \frac{\partial^2 f}{\partial \sigma^2}          \<br>\end{matrix}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]<br>\end{equation}</p>
<p>若写成矢量形式，则为：</p>
<p>\begin{equation}<br>f(X) &#x3D; f(X_0）+\frac{\partial f^{\rm T}}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^{\rm T}\frac{\partial^2 f}{\partial X^2}(X-X_0)<br>\end{equation}</p>
<p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X}&#x3D;X-X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有：</p>
<p>\begin{equation}<br>\hat{X} &#x3D; -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}<br>\end{equation}</p>
<p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。</p>
<p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p>
<p>\begin{equation}<br>f(\hat{X}) &#x3D; f(X_0) + \frac{1}{2}\frac{\partial f^{\rm T}}{\partial X} \hat{X}<br>\end{equation}</p>
<p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p>
<h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p>
<p>\begin{equation}<br>H &#x3D; \left[\begin{matrix}D_{xx}(x,y)&amp;D_{xy}(x,y)\D_{xy}(x,y)&amp;D_{yy}(x,y)\end{matrix}\right]<br>\end{equation}</p>
<p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha &#x3D; \gamma\beta$，有如下公式：</p>
<p>\begin{align}<br>{\rm Tr}(H) &#x3D; \alpha +\beta\<br>{\rm Det}(H) &#x3D; \alpha\beta<br>\end{align}</p>
<p>其中${\rm Tr}(H)$表示矩阵的迹，${\rm Det}(H)$表示的矩阵的行列式。首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：<br>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &#x3D; \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} &#x3D; \frac{(\gamma+1)^2}{\gamma}<br>\end{equation}</p>
<p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p>
<p>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &lt; \frac{(\gamma_0+1)^2}{\gamma_0}<br>\end{equation}</p>
<p>Lowe论文中阈值为10。</p>
<h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p>
<h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像：</p>
<p>\begin{equation}<br>L(x,y) &#x3D; G(x,y,\sigma)\otimes I(x,y)<br>\end{equation}</p>
<p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下：</p>
<p>\begin{align}<br>m(x,y)      &amp;&#x3D; \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \<br>\theta(x,y) &amp;&#x3D; {\rm arctan}\left[\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right]<br>\end{align}</p>
<h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。</p>
<p>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma&#x3D;0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSeDf.png" width="60%" alt=" " align=center /></p>
<h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值80%能量的峰值时，则将这个方向认为是该特征点的辅方向。所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有15%特征点具有多方向，但这些点对匹配的稳定性至为关键。获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r&#x3D;2.5\sigma$），箭头表示主方向。具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSYrV.png" width="60%" alt=" " align=center /></p>
<h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p>
<h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d^2$个子区域，每个子区域尺寸为$m\sigma$个像元（$d&#x3D;4$，$m&#x3D;3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\sqrt{2}m\sigma(d+1)&#x2F;2$，如下图所示：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTco9A.png" width="35%" alt=" " align=center /></p>
<h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转角，即旋转为特征点的方向。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTc7ct.png" width="60%" alt=" " align=center /></p>
<p>旋转后区域内采样点新的坐标为：</p>
<p>\begin{equation}<br>\begin{pmatrix} x’ \ y’\end{pmatrix} &#x3D; \begin{pmatrix} cos\theta &amp; -sin\theta \ sin\theta &amp; cos\theta\end{pmatrix} \begin{pmatrix} x \ y\end{pmatrix}<br>\end{equation}</p>
<h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d^2$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d^2$，即16个子区域，所以最终共有128个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTcqnf.png" width="60%" alt=" " align=center /></p>
<p>对特征矢量需要加权处理，加权采用$m\sigma d&#x2F;2$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p>
<p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Lowe, David G. “Object recognition from local scale-invariant features.” Proceedings of the seventh IEEE international conference on computer vision. Vol. 2. Ieee, 1999.<br>[2] Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/download/Waline.css</url>
    <content><![CDATA[:root{--waline-font-size: 1rem;--waline-white: #fff;--waline-light-grey: #999;--waline-dark-grey: #666;--waline-theme-color: #FFD5CF;--waline-active-color: #FFD5CF;--waline-color: #444;--waline-bgcolor: #fff;--waline-bgcolor-light: #f8f8f8;--waline-bgcolor-hover: #f0f0f0;--waline-border-color: #ddd;--waline-disable-bgcolor: #f8f8f8;--waline-disable-color: #000;--waline-code-bgcolor: #282c34;--waline-bq-color: #f0f0f0;--waline-avatar-size: 3.25rem;--waline-m-avatar-size: calc(var(--waline-avatar-size) * 9 / 13);--waline-badge-color: #3498db;--waline-badge-font-size: 0.75em;--waline-info-bgcolor: #f8f8f8;--waline-info-color: #999;--waline-info-font-size: 0.625em;--waline-border: 1px solid var(--waline-border-color);--waline-avatar-radius: 50%;--waline-box-shadow: none}[data-waline]{font-size:var(--waline-font-size);text-align:start}[dir=rtl] [data-waline]{direction:rtl}[data-waline] *{box-sizing:content-box;line-height:1.75}[data-waline] p{color:var(--waline-color)}[data-waline] a{position:relative;display:inline-block;color:var(--waline-theme-color);text-decoration:none;word-break:break-word;cursor:pointer}[data-waline] a:hover{color:var(--waline-active-color)}[data-waline] img{max-width:100%;max-height:400px;border:none}[data-waline] hr{margin:.825em 0;border-style:dashed;border-color:var(--waline-bgcolor-light)}[data-waline] code,[data-waline] pre{margin:0;padding:.2em .4em;border-radius:3px;background:var(--waline-bgcolor-light);font-size:85%}[data-waline] pre{overflow:auto;padding:10px;line-height:1.45}[data-waline] pre::-webkit-scrollbar{width:6px;height:6px}[data-waline] pre::-webkit-scrollbar-track-piece:horizontal{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}[data-waline] pre::-webkit-scrollbar-thumb:horizontal{width:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}[data-waline] pre code{padding:0;background:rgba(0,0,0,0);color:var(--waline-color);white-space:pre-wrap;word-break:keep-all}[data-waline] blockquote{margin:.5em 0;padding:.5em 0 .5em 1em;border-inline-start:8px solid var(--waline-bq-color);color:var(--waline-dark-grey)}[data-waline] blockquote>p{margin:0}[data-waline] ol,[data-waline] ul{margin-inline-start:1.25em;padding:0}[data-waline] input[type=checkbox],[data-waline] input[type=radio]{display:inline-block;vertical-align:middle;margin-top:-2px}.wl-btn{display:inline-block;vertical-align:middle;min-width:2.5em;margin-bottom:0;padding:.5em 1em;border:1px solid var(--waline-border-color);border-radius:.5em;background:rgba(0,0,0,0);color:var(--waline-color);font-weight:400;font-size:.75em;line-height:1.5;text-align:center;white-space:nowrap;cursor:pointer;user-select:none;transition-duration:.4s;touch-action:manipulation}.wl-btn:hover,.wl-btn:active{border-color:var(--waline-theme-color);color:var(--waline-theme-color)}.wl-btn:disabled{border-color:var(--waline-border-color);background:var(--waline-disable-bgcolor);color:var(--waline-disable-color);cursor:not-allowed}.wl-btn.primary{border-color:var(--waline-theme-color);background:var(--waline-theme-color);color:var(--waline-white)}.wl-btn.primary:hover,.wl-btn.primary:active{border-color:var(--waline-active-color);background:var(--waline-active-color);color:var(--waline-white)}.wl-btn.primary:disabled{border-color:var(--waline-border-color);background:var(--waline-disable-bgcolor);color:var(--waline-disable-color);cursor:not-allowed}.wl-loading{text-align:center}.wl-loading svg{margin:0 auto}.wl-comment{position:relative;display:flex;margin-bottom:.75em}.wl-close{position:absolute;top:-4px;inset-inline-end:-4px;padding:0;border:none;background:rgba(0,0,0,0);line-height:1;cursor:pointer}.wl-login-info{max-width:80px;margin-top:.75em;text-align:center}.wl-logout-btn{position:absolute;top:-10px;inset-inline-end:-10px;padding:3px;border:none;background:rgba(0,0,0,0);line-height:0;cursor:pointer}.wl-avatar{position:relative;width:var(--waline-avatar-size);height:var(--waline-avatar-size);margin:0 auto;border:var(--waline-border);border-radius:var(--waline-avatar-radius)}@media(max-width: 720px){.wl-avatar{width:var(--waline-m-avatar-size);height:var(--waline-m-avatar-size)}}.wl-avatar img{width:100%;height:100%;border-radius:var(--waline-avatar-radius)}.wl-login-nick{display:block;color:var(--waline-theme-color);font-size:.75em;word-break:break-all}.wl-panel{position:relative;flex-shrink:1;width:100%;margin:.5em;border:var(--waline-border);border-radius:.75em;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow)}.wl-header{display:flex;overflow:hidden;padding:0 4px;border-bottom:2px dashed var(--waline-border-color);border-top-left-radius:.75em;border-top-right-radius:.75em}@media(max-width: 580px){.wl-header{display:block}}.wl-header label{min-width:40px;padding:.75em .5em;color:var(--waline-color);font-size:.75em;text-align:center}.wl-header input{flex:1;width:0;padding:.5em;background:rgba(0,0,0,0);font-size:.625em;resize:none}.wl-header-item{display:flex;flex:1}@media(max-width: 580px){.wl-header-item:not(:last-child){border-bottom:2px dashed var(--waline-border-color)}}.wl-header-1 .wl-header-item{width:100%}.wl-header-2 .wl-header-item{width:50%}@media(max-width: 580px){.wl-header-2 .wl-header-item{flex:0;width:100%}}.wl-header-3 .wl-header-item{width:33.33%}@media(max-width: 580px){.wl-header-3 .wl-header-item{width:100%}}.wl-editor{position:relative;width:calc(100% - 1em);min-height:8.75em;margin:.75em .5em;border-radius:.5em;background:rgba(0,0,0,0);font-size:.875em;resize:vertical}.wl-editor,.wl-input{max-width:100%;border:none;color:var(--waline-color);outline:none;transition:all .25s ease}.wl-editor:focus,.wl-input:focus{background:var(--waline-bgcolor-light)}.wl-preview{padding:0 .5em .5em}.wl-preview h4{margin:.25em;font-weight:bold;font-size:.9375em}.wl-preview .wl-content{min-height:1.25em;padding:.25em;word-break:break-word;hyphens:auto}.wl-preview .wl-content>*:first-child{margin-top:0}.wl-preview .wl-content>*:last-child{margin-bottom:0}.wl-footer{position:relative;display:flex;flex-wrap:wrap;margin:.5em .75em}.wl-actions{display:flex;flex:2;align-items:center}.wl-action{display:inline-flex;align-items:center;justify-content:center;width:1.5em;height:1.5em;margin:2px;padding:0;border:none;background:rgba(0,0,0,0);color:var(--waline-color);font-size:16px;cursor:pointer}.wl-action:hover{color:var(--waline-theme-color)}.wl-action.active{color:var(--waline-active-color)}#wl-image-upload{display:none}#wl-image-upload:focus+label{color:var(--waline-color)}#wl-image-upload:focus-visible+label{outline:-webkit-focus-ring-color auto 1px}.wl-info{display:flex;flex:3;align-items:center;justify-content:flex-end}.wl-info .wl-text-number{color:var(--waline-info-color);font-size:.75em}.wl-info .wl-text-number .illegal{color:red}.wl-info button{margin-inline-start:.75em}.wl-info button svg{display:block;margin:0 auto;line-height:18px}.wl-emoji-popup{position:absolute;top:100%;inset-inline-start:1.25em;z-index:10;max-width:526px;border:var(--waline-border);border-radius:6px;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow);opacity:0;visibility:hidden;transition:transform .2s ease-out,opacity .2s ease-out;transform:scale(0.9, 0.9);transform-origin:0 0}.wl-emoji-popup.display{opacity:1;visibility:visible;transform:none}.wl-emoji-popup button{display:inline-block;vertical-align:middle;width:2em;margin:.125em;padding:0;border-width:0;background:rgba(0,0,0,0);font-size:inherit;line-height:2;text-align:center;cursor:pointer}.wl-emoji-popup button:hover{background:var(--waline-bgcolor-hover)}.wl-emoji-popup .wl-emoji{display:inline-block;vertical-align:middle;max-width:1.5em;max-height:1.5em}.wl-emoji-popup .wl-tab-wrapper{overflow-y:auto;max-height:145px;padding:.5em}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar{width:6px;height:6px}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar-track-piece:vertical{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar-thumb:vertical{width:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}.wl-emoji-popup .wl-tabs{position:relative;overflow-x:auto;padding:0 6px;white-space:nowrap}.wl-emoji-popup .wl-tabs::before{content:" ";position:absolute;top:0;right:0;left:0;z-index:2;height:1px;background:var(--waline-border-color)}.wl-emoji-popup .wl-tabs::-webkit-scrollbar{width:6px;height:6px}.wl-emoji-popup .wl-tabs::-webkit-scrollbar-track-piece:horizontal{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}.wl-emoji-popup .wl-tabs::-webkit-scrollbar-thumb:horizontal{height:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}.wl-emoji-popup .wl-tab{position:relative;margin:0;padding:0 .5em}.wl-emoji-popup .wl-tab.active{z-index:3;border:1px solid var(--waline-border-color);border-top-width:0;border-bottom-right-radius:6px;border-bottom-left-radius:6px;background:var(--waline-bgcolor)}.wl-gif-popup{position:absolute;top:100%;inset-inline-start:1.25em;z-index:10;width:calc(100% - 3em);padding:.75em .75em .25em;border:var(--waline-border);border-radius:6px;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow);opacity:0;visibility:hidden;transition:transform .2s ease-out,opacity .2s ease-out;transform:scale(0.9, 0.9);transform-origin:0 0}.wl-gif-popup.display{opacity:1;visibility:visible;transform:none}.wl-gif-popup input{box-sizing:border-box;width:100%;margin-bottom:10px;padding:3px 5px;border:var(--waline-border)}.wl-gif-popup img{display:block;box-sizing:border-box;width:100%;border-width:2px;border-style:solid;border-color:#fff;cursor:pointer}.wl-gif-popup img:hover{border-color:var(--waline-theme-color);border-radius:2px}.wl-gallery{display:flex;overflow-y:auto;max-height:80vh}.wl-gallery-column{display:flex;flex:1;flex-direction:column;height:-webkit-max-content;height:-moz-max-content;height:max-content}.wl-cards .wl-user{--avatar-size: var(--waline-avatar-size);position:relative;margin-inline-end:.75em}@media(max-width: 720px){.wl-cards .wl-user{--avatar-size: var(--waline-m-avatar-size)}}.wl-cards .wl-user img{width:var(--avatar-size);height:var(--avatar-size);border-radius:var(--waline-avatar-radius);box-shadow:var(--waline-box-shadow)}.wl-cards .wl-user .verified-icon{position:absolute;top:calc(var(--avatar-size)*3/4);inset-inline-start:calc(var(--avatar-size)*3/4);border-radius:50%;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow)}.wl-card-item{position:relative;display:flex;padding:.5em}.wl-card-item .wl-card-item{padding-inline-end:0}.wl-card{flex:1;width:0;padding-bottom:.5em;border-bottom:1px dashed var(--waline-border-color)}.wl-card:first-child{margin-inline-start:1em}.wl-card-item:last-child>.wl-card{border-bottom:none}.wl-card .wl-nick svg{position:relative;bottom:-0.125em;line-height:1}.wl-card .wl-head{overflow:hidden;line-height:1.5}.wl-card .wl-head .wl-nick{position:relative;display:inline-block;margin-inline-end:.5em;font-weight:bold;font-size:.875em;line-height:1;text-decoration:none}.wl-card span.wl-nick{color:var(--waline-dark-grey)}.wl-card .wl-badge{display:inline-block;margin-inline-end:1em;padding:0 .3em;border:1px solid var(--waline-badge-color);border-radius:4px;color:var(--waline-badge-color);font-size:var(--waline-badge-font-size)}.wl-card .wl-time{margin-inline-end:.875em;color:var(--waline-info-color);font-size:.75em}.wl-card .wl-meta{position:relative;line-height:1}.wl-card .wl-meta>span{display:inline-block;margin-inline-end:.25em;padding:2px 4px;border-radius:.2em;background:var(--waline-info-bgcolor);color:var(--waline-info-color);font-size:var(--waline-info-font-size);line-height:1.5}.wl-card .wl-meta>span:empty{display:none}.wl-card .wl-comment-actions{float:right;line-height:1}[dir=rtl] .wl-card .wl-comment-actions{float:left}.wl-card .wl-delete,.wl-card .wl-like,.wl-card .wl-reply,.wl-card .wl-edit{display:inline-flex;align-items:center;border:none;background:rgba(0,0,0,0);color:var(--waline-color);line-height:1;cursor:pointer;transition:color .2s ease}.wl-card .wl-delete:hover,.wl-card .wl-like:hover,.wl-card .wl-reply:hover,.wl-card .wl-edit:hover{color:var(--waline-theme-color)}.wl-card .wl-delete.active,.wl-card .wl-like.active,.wl-card .wl-reply.active,.wl-card .wl-edit.active{color:var(--waline-active-color)}.wl-card .wl-content{position:relative;margin-bottom:.75em;padding-top:.625em;font-size:.875em;line-height:2;word-wrap:break-word}.wl-card .wl-content.expand{overflow:hidden;max-height:8em;cursor:pointer}.wl-card .wl-content.expand::before{content:"";position:absolute;top:0;bottom:3.15em;inset-inline-start:0;z-index:999;display:block;width:100%;background:linear-gradient(180deg, #000, rgba(255, 255, 255, 0.9))}.wl-card .wl-content.expand::after{content:attr(data-expand);position:absolute;bottom:0;inset-inline-start:0;z-index:999;display:block;width:100%;height:3.15em;background:rgba(255,255,255,.9);color:#828586;line-height:3.15em;text-align:center}.wl-card .wl-content>*:first-child{margin-top:0}.wl-card .wl-content>*:last-child{margin-bottom:0}.wl-card .wl-admin-actions{margin:8px 0;font-size:12px;text-align:right}.wl-card .wl-comment-status{margin:0 8px}.wl-card .wl-comment-status .wl-btn{border-radius:0}.wl-card .wl-comment-status .wl-btn:first-child{border-inline-end:0;border-radius:.5em 0 0 .5em}.wl-card .wl-comment-status .wl-btn:last-child{border-inline-start:0;border-radius:0 .5em .5em 0}.wl-card .wl-quote{border-inline-start:1px dashed rgba(237,237,237,.5)}.wl-card .wl-quote .wl-user{--avatar-size: var(--waline-m-avatar-size)}.wl-close-icon{color:var(--waline-border-color)}.wl-content .vemoji,.wl-content .wl-emoji{display:inline-block;vertical-align:baseline;height:1.25em;margin:-0.125em .25em}.wl-content .wl-tex{background:var(--waline-info-bgcolor);color:var(--waline-info-color)}.wl-content span.wl-tex{display:inline-block;margin-inline-end:.25em;padding:2px 4px;border-radius:.2em;font-size:var(--waline-info-font-size);line-height:1.5}.wl-content p.wl-tex{text-align:center}.wl-content .katex-display{overflow:auto hidden;-webkit-overflow-scrolling:touch;padding-top:.2em;padding-bottom:.2em}.wl-content .katex-display::-webkit-scrollbar{height:3px}.wl-content .katex-error{color:red}.wl-count{flex:1;font-weight:bold;font-size:1.25em}.wl-empty{overflow:auto;padding:1.25em;color:var(--waline-color);text-align:center}.wl-operation{text-align:center}.wl-operation button{margin:1em 0}.wl-power{padding:.5em 0;color:var(--waline-light-grey);font-size:var(--waline-info-font-size);text-align:end}.wl-meta-head{display:flex;flex-direction:row;align-items:center;padding:.375em}.wl-sort{margin:0;list-style-type:none}.wl-sort li{display:inline-block;color:var(--waline-info-color);font-size:.75em;cursor:pointer}.wl-sort li.active{color:var(--waline-theme-color)}.wl-sort li+li{margin-inline-start:1em}.wl-reaction{overflow:auto hidden;margin-bottom:1.75em;text-align:center}.wl-reaction img{width:100%;height:100%;transition:all 250ms ease-in-out}.wl-reaction-title{margin:16px auto;font-weight:bold;font-size:18px}.wl-reaction-list{display:flex;flex-direction:row;gap:16px;justify-content:center;margin:0;padding:8px;list-style-type:none}@media(max-width: 580px){.wl-reaction-list{gap:12px}}[data-waline] .wl-reaction-list{margin-inline-start:0}.wl-reaction-item{display:flex;flex-direction:column;align-items:center;cursor:pointer}.wl-reaction-item:hover img,.wl-reaction-item.active img{transform:scale(1.15)}.wl-reaction-img{position:relative;width:42px;height:42px}@media(max-width: 580px){.wl-reaction-img{width:32px;height:32px}}.wl-reaction-loading{position:absolute;top:-4px;inset-inline-end:-5px;width:18px;height:18px;color:var(--waline-theme-color)}.wl-reaction-votes{position:absolute;top:-9px;inset-inline-end:-9px;min-width:1em;padding:2px;border:1px solid var(--waline-theme-color);border-radius:1em;background:var(--waline-bgcolor);color:var(--waline-theme-color);font-weight:700;font-size:.75em;line-height:1}.wl-reaction-item.active .wl-reaction-votes{background:var(--waline-theme-color);color:var(--waline-bgcolor)}.wl-reaction-text{font-size:.875em}.wl-reaction-item.active .wl-reaction-text{color:var(--waline-theme-color)}.wl-content pre,.wl-content pre[class*=language-]{overflow:auto;margin:.75rem 0;padding:1rem 1.25rem;border-radius:6px;background:var(--waline-code-bgcolor);line-height:1.4}.wl-content pre code,.wl-content pre[class*=language-] code{padding:0;border-radius:0;background:rgba(0,0,0,0) !important;color:#bbb;direction:ltr}.wl-content code[class*=language-],.wl-content pre[class*=language-]{background:none;color:#ccc;font-size:1em;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;text-align:left;white-space:pre;word-spacing:normal;word-wrap:normal;word-break:normal;tab-size:4;hyphens:none}.wl-content pre[class*=language-]{overflow:auto}.wl-content :not(pre)>code[class*=language-],.wl-content pre[class*=language-]{background:#2d2d2d}.wl-content :not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.wl-content .token.comment,.wl-content .token.block-comment,.wl-content .token.prolog,.wl-content .token.doctype,.wl-content .token.cdata{color:#999}.wl-content .token.punctuation{color:#ccc}.wl-content .token.tag,.wl-content .token.attr-name,.wl-content .token.namespace,.wl-content .token.deleted{color:#e2777a}.wl-content .token.function-name{color:#6196cc}.wl-content .token.boolean,.wl-content .token.number,.wl-content .token.function{color:#f08d49}.wl-content .token.property,.wl-content .token.class-name,.wl-content .token.constant,.wl-content .token.symbol{color:#f8c555}.wl-content .token.selector,.wl-content .token.important,.wl-content .token.atrule,.wl-content .token.keyword,.wl-content .token.builtin{color:#cc99cd}.wl-content .token.string,.wl-content .token.char,.wl-content .token.attr-value,.wl-content .token.regex,.wl-content .token.variable{color:#7ec699}.wl-content .token.operator,.wl-content .token.entity,.wl-content .token.url{color:#67cdcc}.wl-content .token.important,.wl-content .token.bold{font-weight:bold}.wl-content .token.italic{font-style:italic}.wl-content .token.entity{cursor:help}.wl-content .token.inserted{color:green}.wl-recent-item p{display:inline}.wl-user-list{padding:0;list-style:none}.wl-user-list a,.wl-user-list a:hover,.wl-user-list a:visited{color:var(--waline-color);text-decoration:none}.wl-user-list .wl-user-avatar{position:relative;display:inline-block;overflow:hidden;margin-inline-end:10px;border-radius:4px;line-height:0}.wl-user-list .wl-user-avatar>img{width:var(--waline-user-avatar-size, 48px);height:var(--waline-user-avatar-size, 48px)}.wl-user-list .wl-user-badge{position:absolute;bottom:0;inset-inline-end:0;min-width:.7em;height:1.5em;padding:0 .4em;border-radius:4px;background:var(--waline-info-bgcolor);color:var(--waline-info-color);font-weight:bold;font-size:10px;line-height:1.5em;text-align:center}.wl-user-list .wl-user-item{margin:10px 0}.wl-user-list .wl-user-item:nth-child(1) .wl-user-badge{background:var(--waline-rank-gold-bgcolor, #fa3939);color:var(--waline-white);font-weight:bold}.wl-user-list .wl-user-item:nth-child(2) .wl-user-badge{background:var(--waline-rank-silver-bgcolor, #fb811c);color:var(--waline-white);font-weight:bold}.wl-user-list .wl-user-item:nth-child(3) .wl-user-badge{background:var(--waline-rank-copper-bgcolor, #feb207);color:var(--waline-white)}.wl-user-list .wl-user-meta{display:inline-block;vertical-align:top}.wl-user-list .wl-badge{display:inline-block;vertical-align:text-top;margin-inline-start:.5em;padding:0 .3em;border:1px solid var(--waline-badge-color);border-radius:4px;color:var(--waline-badge-color);font-size:var(--waline-badge-font-size)}.wl-user-wall{padding:0;list-style:none}.wl-user-wall .wl-user-badge,.wl-user-wall .wl-user-meta{display:none}.wl-user-wall .wl-user-item{position:relative;display:inline-block;transition:transform ease-in-out .2s}.wl-user-wall .wl-user-item::before,.wl-user-wall .wl-user-item::after{position:absolute;bottom:100%;left:50%;z-index:10;opacity:0;pointer-events:none;transition:all .18s ease-out .18s;transform:translate(-50%, 4px);transform-origin:top}.wl-user-wall .wl-user-item::before{content:"";width:0;height:0;border:5px solid rgba(0,0,0,0);border-top-color:rgba(16,16,16,.95)}.wl-user-wall .wl-user-item::after{content:attr(aria-label);margin-bottom:10px;padding:.5em 1em;border-radius:2px;background:rgba(16,16,16,.95);color:#fff;font-size:12px;white-space:nowrap}.wl-user-wall .wl-user-item:hover{transform:scale(1.1)}.wl-user-wall .wl-user-item:hover::before,.wl-user-wall .wl-user-item:hover::after{opacity:1;pointer-events:none;transform:translate(-50%, 0)}.wl-user-wall .wl-user-item img{width:var(--waline-user-avatar-size, 48px);height:var(--waline-user-avatar-size, 48px)}/*# sourceMappingURL=waline.css.map */]]></content>
  </entry>
  <entry>
    <title>Scholar</title>
    <url>/scholar/index.html</url>
    <content><![CDATA[<ul>
<li><a href="https://scholar.google.com/citations?hl=en&user=nF5s02gAAAAJ&view_op=list_works&sortby=pubdate">Hai-Wei Chai’s Google Scholar</a></li>
</ul>
<h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><ul>
<li><p>G. D. Lai, H. Niu, K. Li, L. Lu, Y. Cai, Y.L. Bian$^{\ast}$,  <u><strong>H. W. Chai</strong></u>$^{\ast \ast}$, Deformation and damage of an Al&#x2F;PTFE composite under uniaxial compression: An in situ synchrotron X-ray tomography study, <em>Mater. Today Commun.</em>, 47, 112790 (2025). <a href="/download/2025_GDLai_MTC.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>R. C. Pan, B. X. Bie, Y. Cai, N. B. Zhang, L. Z. Chen, Y. X. Zhao, K. Li, H. W. Chai, L. Lu$^{\ast}$, S. N. Luo, Shock compression and spallation of polyamides 6 and 66, <em>Int. J. Mech. Sci.</em>, 291-292, 110127 (2025).</p>
</li>
<li><p>Z. Y. Hu, Y. X. Zhao, J. Xu, R. C. Pan$^{\ast}$, H. W. Chai, H. L. Xie, N. B. Zhang, L. Lu, S. N.  Luo, Shock compression and spallation of ABS and ABS&#x2F;PC blend under plate impact, <em>Eur. J. Mech. A-Solids</em>, 112, 105630 (2025).</p>
</li>
<li><p>S. W. Li, Y. L. Bian, Y. Cai, K. Li, J. Y. Hua$^{\ast}$, <u><strong>H. W. Chai</strong></u>$^{\ast \ast}$, S. N. Luo, Structure, mechanical properties, and finite-element modeling of an Al particle&#x2F;resin composite, <em>Compos. Sci. Technol.</em>, 261, 111043 (2025).</p>
</li>
<li><p>L. Lu, Q. X. Liu, W. D. Wang, Y. S. Liu$^{\ast}$, H. W. Chai, F. Zhao, H. L. Xie, N.B. Zhang, Y. Cai$^{\ast \ast}$, H. Chen, S. N. Luo, Impact response of a high-Nb TiAl alloy fabricated via electron beam melting, <em>J. Alloys Compd.</em>, 1014, 178556 (2025).</p>
</li>
<li><p>J. T. Li, J. Y. Hua, <u><strong>H. W. Chai</strong></u>$^{\ast}$, S. N. Luo, Deformation and damage of intermediate-thickness Mg6Gd3Y0.5Zr plate subjected to high-speed ballistic impact, <em>J. Phys. Conf. Ser.</em>, 2891, 6 (2024). <a href="https://iopscience.iop.org/article/10.1088/1742-6596/2891/6/062024/pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>J. Y. Huang, C. K. Lin, Y. L. Bian, H. L. Xie, <u><strong>H. W. Chai</strong></u>$^{\ast}$, Y. Y. Ding$^{\ast \ast}$, S. N. Luo, Strain rate effects on fragment morphology of ceramic alumina: A synchrotron-based study, <em>Int. J. Mech. Sci.</em>, 280, 109506 (2024). <a href="/download/2024_JYHuang_IJMS.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>G. D. Lai, L. P. Sang, Y. L. Bian, H. L. Xie, J. H. Liu, <u><strong>H. W. Chai</strong></u>$^{\ast}$, Interfacial debonding and cracking in a solid propellant composite under uniaxial tension: An in situ synchrotron X-ray tomography study, <em>Compos. Sci. Technol.</em>, 256, 110743 (2024). <a href="/download/2024_GDLai_CST.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>P. F. Han, D. Fan, Y. Cai, L. Z. Chen, H. L. Xie, H. W. Chai, B. X. Bie$^{\ast}$, S. N. Luo, Shock and spallation behavior of ultrahigh molecular weight polyethylene, <em>Int. J. Mech. Sci.</em>, 267, 108984 (2024). </p>
</li>
<li><p>N. B. Zhang, K. Yang, Y. C. Li, Z. H. Lin, Y. Cai, <u><strong>H. W. Chai</strong></u>$^{\ast}$, H. L. Xie, L. Lu, S. N. Luo, Anisotropic dynamic response of AlSi10Mg fabricated via laser powder bed fusion under plate impact, <em>Mater. Chem. Phys.</em>, 314, 128840 (2024). <a href="/download/2023_NBZhang_Mater.Cr..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. J. Deng, Y. W. Shi, Y. X. Li$^{\ast}$, G. D. Lai, H. W. Chai, H. L. Xie, N. B. Zhang$^{\ast \ast}$, S. N. Luo, In situ synchrotron x-ray imaging and diffraction study of additively manufactured AlSi10Mg alloy under uniaxial tension, <em>Mater. Sci. Eng. A</em>, 886, 145702 (2023). </p>
</li>
<li><p>B. X. Bie, R. C. Pan, J. Xu, H. W. Chai, S. Chen, G. H. Du, Y. L. Bian$^{\ast}$, Y. Cai$^{\ast \ast}$, S. N. Luo, Dynamic compression and fracture of poly (ether-ether-ketone) under plate impact, <em>Int. J. Mech. Sci.</em>, 246, 108138 (2023). </p>
</li>
<li><p><strong>H. W. Chai</strong>, D. Fan, J. C. Yuan, L. Hu$^{\ast}$, G. H. Du, H. L. Xie, Q. J. Feng, W. Zhou, J. Y. Huang$^{\ast \ast}$, Deformation dynamics of a neutron-irradiated aluminum alloy: an in-situ synchrotron tomography study, <em>Acta Mater.</em>, 243, 118493 (2023). <a href="/download/2023_hwchai_Acta_Mater..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>L. Hu, F. C. Wu, X. H. Li, H. W. Chai, J. Y. Huang, Q. J. Feng, W. Zhou, Y. Y. Yu, J. B. Hu$^{\ast}$, Fracture behaviors of long-term low-dose-rate neutron-irradiated Al-Mg-Si alloy, <em>Appl. Phys. Lett.</em>, 121, 18 (2022).</p>
</li>
<li><p>J. C. Cheng, S. P. Zhao, D. Fan, H. W. Chai, S. J. Ye, C. Li, S. N. Luo, Y. Cai$^{\ast}$, J. Y. Huang$^{\ast \ast}$, Multiple ballistic impacts on 2024-T4 aluminum alloy by spheres: Experiments and modelling, <em>J. Mater. Sci. Technol.</em>, 94, 164-174 (2021).</p>
</li>
<li><p><strong>H. W. Chai</strong>, Z. L. Xie$^{\ast}$, Z. D. Feng, S. N. Luo, J. Y. Huang$^{\ast \ast}$, Three-dimensional deformation dynamics of porous titanium under uniaxial compression, <em>Mater. Charact.</em>, 111494 (2021). <a href="/download/2021_hwchai_Mater.Charact..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. L. Bian, H. W. Chai, S. J. Ye, H. L. Xie, X. H. Yao$^{\ast}$, Y. Cai$^{\ast \ast}$, Compression and spallation properties of polyethylene terephthalate under plateimpact loading, <em>Int. J. Mech. Sci.</em>, 211, 106736 (2021).</p>
</li>
<li><p>J. C. Cheng$^\dagger$, <strong>H. W. Chai</strong>$^\ddagger$, G. L. Fan, Z. Q. Li, H. L. Xie, Z. Q. Tan$^{\ast}$, B. X. Bie$^{\ast \ast}$, J. Y. Huang, S. N. Luo, Anisotropic spall behavior of CNT&#x2F;2024Al laminar composite under plate impact, <em>Carbon</em>, 170, 589-599 (2020). <a href="/download/2020_jccheng_Carbon.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Z. H. Dai, L. Lu$^\ast$, <u><strong>H. W. Chai</strong></u>$^{\ast\ast}$, X. H. Xiao, X. L. Gong, S. N. Luo, Anisotropic deformation and damage of a textured magnesium alloy AZ31 under high strain rate loading, <em>Mater. Sci. Eng. A</em>, 789, 139690 (2020). <a href="/download/2020_ZHDai_Mater.Sci.Eng.A.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p><strong>H. W. Chai</strong>, Z. L. Xie, X. H. Xiao, H. L. Xie, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Microstructural characterization and constitutive modelling of deformation of closed-cell foams based on in-situ x-ray tomography, <em>Int. J. Plast.</em>, 131, 102730 (2020). <a href="/download/2020_hwchai_Int.J.Plast..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>H. Y. Li, H. W. Chai, X. H. Xiao, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Fractal breakage of porous sand particles: microstructures and mechanisms, <em>Powder Technol.</em>, 363, 112–121 (2020). <a href="/download/2020_HYL_PowderTechnol.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>S. J. Ye, H. W. Chai, X. H. Xiao, Y. Cai$^{\ast}$, X. H. Yao$^{\ast \ast}$, S. N. Luo, Spallation of Polycarbonate under Plate Impact Loading, <em>J. Appl. Phys.</em>, 126, 085105 (2019). </p>
</li>
<li><p>C. Sen, H. W. Chai, A. M. He, Thomas Tschentscher, Yang Cai$^{\ast}$, S. N. Luo$^{\ast \ast}$, Resolving dynamic fragmentation of liquids at the nanoscale with ultrafast small-angle X-ray scattering. <em>J. Synchrotron Radiat.</em>, 26.5 (2019).</p>
</li>
<li><p><strong>H. W. Chai</strong>, H. Y. Li, X. H. Xiao, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Correlation between Cell Wall Buckling and Deformation Banding in a Closed-Cell Foam, <em>Scr. Mater.</em>, 170, 177-182 (2019). <a href="/download/2019_hwchai_Script._Mater..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. Yao, H. W. Chai, C. Li, B. X. Bie, X. H. Xiao, J. Y. Huang$^{\ast}$, M. L. Qi$^{\ast \ast}$, S. N. Luo$^{\ast \ast \ast}$, Deformation and damage of sintered low-porosity aluminum under planar impact: microstructures and mechanisms, <em>J. Mater. Sci.</em>, 53, 4582-4597 (2018).</p>
</li>
<li><p>C. Li, J. Y. Huang, X. C. Tang, H. W. Chai, X. H. Xiao, Z. D. Feng$^{\ast}$, S. N. Luo$^{\ast \ast}$, Effects of structural anisotropy on deformation and damage of a duplex stainless steel under high strain rate loading, <em>Mater. Sci. Eng. A</em>, 705, 265-272 (2017).</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Support</title>
    <url>/support/index.html</url>
    <content><![CDATA[<h2 id="Tools-for-scholar"><a href="#Tools-for-scholar" class="headerlink" title="Tools for scholar"></a>Tools for scholar</h2><ul>
<li><a href="https://www.overleaf.com/"><font color="#80b1d3">[Link]</font></a>                    &emsp; Overleaf 全球共享的在线LaTeX写作平台</li>
<li><a href="https://colorbrewer2.org/"><font color="#80b1d3">[Link]</font></a>                    &emsp; ColorBrewer 配色方案优化</li>
<li><a href="http://www.mohu.org/info/symbols/symbols.htm"><font color="#80b1d3">[Link]</font></a> &emsp; LaTeX 常用数学符号表示方法</li>
<li><a href="https://www.tablesgenerator.com/"><font color="#80b1d3">[Link]</font></a>             &emsp; LaTeX 表格在线自动生成</li>
</ul>
<h2 id="Tools-for-Vision"><a href="#Tools-for-Vision" class="headerlink" title="Tools for Vision"></a>Tools for Vision</h2><ul>
<li><a href="https://processing.org/"><font color="#80b1d3">[Link]</font></a>                      &emsp; Processing 视觉软件开发开源工具</li>
<li><a href="https://github.com/smartgeometry-ucl/dl4g"><font color="#80b1d3">[Link]</font></a>    &emsp; CreativeAI: Deep Learning for Graphics Tutorial Code</li>
<li><a href="http://lightfield.stanford.edu/lfs.html"><font color="#80b1d3">[Link]</font></a>      &emsp; 斯坦福大学计算机图形实验室光场数据库，提供光场采集设备资料，相机标定以及可视化工具</li>
<li><a href="https://graphics.stanford.edu/courses/cs178/applets/applets.html"><font color="#80b1d3">[Link]</font></a>      &emsp; 斯坦福大学计算机图形实验室的Marc Levoy教授制作的动画仿真，详细介绍了相机参数变化对应的光路变化</li>
<li><a href="https://lightfield-analysis.uni-konstanz.de/"><font color="#80b1d3">[Link]</font></a>      &emsp; HCI光场数据集及解码工具</li>
</ul>
<h2 id="The-big-guys’-website"><a href="#The-big-guys’-website" class="headerlink" title="The big guys’ website"></a>The big guys’ website</h2><ul>
<li><a href="https://cseweb.ucsd.edu//~ravir/"><font color="#80b1d3">[Link]</font></a>             &emsp; Ravi Ramamoorthi 教授，加州大学圣地亚哥分校视觉计算中心主任，计算机视觉领域的大牛</li>
<li><a href="https://cseweb.ucsd.edu//~viscomp/projects/LF/"><font color="#80b1d3">[Link]</font></a>             &emsp; 光场实验室，隶属Ravi Ramamoorthi教授，研究光场领域深度图像获取，三维重建及去除高光等</li>
<li><a href="https://imechanica.org/"><font color="#80b1d3">[Link]</font></a>                      &emsp; iMechanica - web of mechanics and mechanicians</li>
</ul>
<h2 id="Tools-for-Hexo-NexT"><a href="#Tools-for-Hexo-NexT" class="headerlink" title="Tools for Hexo|NexT"></a>Tools for Hexo|NexT</h2><ul>
<li><a href="http://www.ehcoo.com/seo.html"><font color="#80b1d3">[Link]</font></a>                &emsp; Hexo|NexT 搜索引擎SEO检索优化</li>
<li><a href="https://imgse.com/"><font color="#80b1d3">[Link]</font></a>                           &emsp; Imgse 图床与外链服务，全球CDN加速</li>
<li><a href="https://fontawesome.com/start"><font color="#80b1d3">[Link]</font></a>                &emsp; Font Awesome 互联网最受欢迎的开源图标集</li>
<li><a href="http://yearito.cn/posts/hexo-writing-skills.html"><font color="#80b1d3">[Link]</font></a>    &emsp; Markdown 写作技巧</li>
<li><a href="https://serverless-page-bucket-rtsw4b6p-1300965131.cos-website.ap-hongkong.myqcloud.com/"><font color="#80b1d3">[Link]</font></a>    &emsp; Haiwei Chai’s Blog Beta Version</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Tags</title>
    <url>/tags/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
