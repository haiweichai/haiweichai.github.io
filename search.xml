<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>期刊投稿的准备工作及注意事项</title>
    <url>/Exp002-ArticleReply/</url>
    <content><![CDATA[<p><img src="https://updatepublishing.com/journal/public/journals/5/homepageImage_en_US.jpg"></p>
<p>本文以近期返修的Acta Materialia为例，整理归纳SCI学术期刊投稿时需要准备的材料规范与模板及注意事项，包括 Manuscript, Cover Letter, Suggested Reviewers, Graphical Abstract, Highlights, Declaration of Interests, Reply等，以供参考。</p>
<span id="more"></span>

<h2 id="Cover-letter"><a href="#Cover-letter" class="headerlink" title="Cover letter"></a>Cover letter</h2><p>Cover letter是投稿时与Manuscript一同发送给Editor的投稿信件，用几句话简明扼要的交代给Editor本文的内容梗概或对于这次修改的反馈。一封内容简洁明了的Cover Letter会让Editor对论文的第一印象加分不少。在信中需简要列出文章的创新点，并且说明全部作者同意投稿，宣称没有利益冲突，该文章没有在其他期刊发表过等责任声明信息。注意期刊名斜体。在此列出本篇文章首次投稿与第三次返稿时的Cover Letter实例：</p>
<blockquote>
<p>Dear Editor,</p>
</blockquote>
<blockquote>
<p>We would like to submit the above manuscript for your consideration of its publication in <em>Acta Materialia</em>. The work described has not been submitted elsewhere for publication, in whole or in part, and all the authors listed have approved the manuscript that is enclosed.</p>
</blockquote>
<blockquote>
<p>We believe that this manuscript is appealing to general readers of Acta Materialia for its novelty, signicance, and the subject itself. Investigations on nuclear materials from decommissioned reactors can help understand radiation damage and thus reactor aging, but are scarce owing to the diculty in accessing such materials. Using synchrotron tomography, we present firstly in situ, three-dimensional characterizations of deformation dynamics of an LT21 Al alloy after 30 years’ nuclear service under quasi-static uniaxial tension. A new particle tracking analysis technique is proposed to quantify the displacement&#x2F;strain fields and microstructural evolution in the irradiated sample. Nucleation of new pores and growth of initial and newly-nucleated pores occur simultaneously, and contributes approximately equally to damage accumulation in the irradiated LT21 Al before necking occurs. It is interesting to note that nucleation of new pores prefers to occur at the top and bottom ends of precipitates (relative to the tensile direction). Such multiscale data are valuable for development of physics-based models, and for nuclear structural design.</p>
</blockquote>
<blockquote>
<p>We are looking forward to your positive response. Thank you!</p>
</blockquote>
<p>第三次返稿时Cover Letter：</p>
<blockquote>
<p>Dear Prof. Wang,</p>
</blockquote>
<blockquote>
<p>We appreciate the editor for giving us the opportunity to revise our manuscript and the constructive remarks by the reviewers. We have revised the manuscript accordingly following the reviewers’ comments.</p>
</blockquote>
<blockquote>
<p>We would like to submit the revised manuscript for your consideration of its publication in <em>Acta Materialia</em>. The work described has not been submitted elsewhere for publication, in whole or in part, and all the authors listed have approved the manuscript that is enclosed.</p>
</blockquote>
<blockquote>
<p>We are looking forward to your response.</p>
</blockquote>
<h2 id="Suggested-Reviewers"><a href="#Suggested-Reviewers" class="headerlink" title="Suggested Reviewers"></a>Suggested Reviewers</h2><p>推荐审稿人一般选择当前投递文章所研究核心领域内的大牛，通常可以从已发表高水平论文的通讯作者中寻找。本文基于同步辐射原位显微CT技术研究长时低剂量中子辐照对铝合金材料力学性能的影响，推荐审稿人便可从辐照偏析、铝合金、X射线成像与CT三个主题方向寻找审稿人，注意投递力学、材料科学方向期刊时，科学往往高于技术，审稿人推荐勿太过侧重表征分析手段。推荐理由需包含：被推荐者是哪个领域的专家，做了哪些突出的工作，以及和本篇文章所研究内容有着怎样的关联性。合理且充分的推荐理由才能对Editor起到建议作用。在此列出四条示例：</p>
<ul>
<li><p>Prof. Li is an expert in solid mechanics. Using micro computed tomography (CT) and CT-based numerical modelling, he and his group have done excellent work on the structure—property relations of various engineering materials, especially on foams. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Hutchinson is an expert in materials science. He and his group have done cutting-edge work on the property and deformation mechanisms of Al alloys, especially on precipitate hardening. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Wang is an expert in nuclear engineering and materials science. He and his group have done excellent work on radiation-induced microstructural evolution and damage of various metal materials. His expertise is directly related to this manuscript. He is surely suitable and capable of reviewing this manuscript.</p>
</li>
<li><p>Prof. Aydogan is an expert in nuclear engineering. She has done excellent work on radiation effects on microstructures and mechanical properties of various metal materials. Her expertise is directly related to this manuscript. She is surely suitable and capable of reviewing this manuscript.</p>
</li>
</ul>
<h2 id="Graphical-Abstract"><a href="#Graphical-Abstract" class="headerlink" title="Graphical Abstract"></a>Graphical Abstract</h2><p>Graphical Abstract为文章的图形摘要，作者需在极简的图表内高度概括论文中的研究内容和主要创新点，不言自明最为重要，这才能让人快速了解文章的主要创新点。</p>
<p><figure><img src="https://s1.ax1x.com/2022/10/26/xWfINn.png" alt="Graphical Abstract"><figcaption aria-hidden="true">Graphical Abstract</figcaption></figure></p>
<h2 id="Highlights"><a href="#Highlights" class="headerlink" title="Highlights"></a>Highlights</h2><p>Highlights为文章的主要亮点，与Graphical Abstract类似，作者需在极简的文字内归纳总结论文的主要亮点。 Elsevier规范中明确指出Highlights的书写规则：三到五条重点；每条重点只包含85个字元；只包含最重要的发现。Acta Materialia 投稿时不再需要附上Hightlights，但大部分期刊仍然需要，以H. Y. Li, et al. <em>Powder Technol.</em> (2020)为例：</p>
<ul>
<li>First in situ characterization of particle breakage in carbonate sands</li>
<li>Particle shape and intra-granular porosity affects breakage strength</li>
<li>Fractal dimension of crack networks increases with particle breakage extent</li>
<li>Cleavage along initial pores leads to crack branching</li>
</ul>
<h2 id="Response-Letter"><a href="#Response-Letter" class="headerlink" title="Response Letter"></a>Response Letter</h2><p>在期刊投稿中，首次录用的比例相对较小，大部分的文章都会进行小修或大修。无论是小修或大修，都需要按照审稿人意见逐条认真修改并回复。若审稿人问题存在误解或错误，也可进行客观平和的解释澄清。文章审稿意见回复是除Manuscript外最重要的信息，回复与修改质量直接关系到文章接受与否。一般情况下，审稿人的问题会出现几种情况：</p>
<blockquote>
<ol>
<li>文章格式&#x2F;文字&#x2F;图表标记错误<br>Response: We are very sorry for our incorrect writing and it is rectified at Line …. or We are very sorry for our negligence of the explanation.</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>不太同意审稿人的观点，轻度argue（合理修改和把握Argue分寸，即使你要argue也最好罗列一些你的进一步证据，或别的大牛的经典文章）<br>Response: We agree with you that…., however, …… or As Reviewer suggested that It is important to … However.</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>需要补充实验<br>Response: 做这个实验。对审稿人的意见表示赞同（We agree that more study or more data would be useful to）。如果实验结果能说明问题，则要把结果补充到论文中。反之，要展示、分析数据，告知审稿人已做此实验，但没有得到有价值的结果，并阐明原因。<br>没有实验条件，或者不能在短时期内做此实验怎么办？可以向审稿人表示后期如果条件成熟了，可能会进行审稿人说的相关研究，这部分可以写到discussion部分下的subchapter下的future improvement部分。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>论文创新性不强（对于这类关于创新不足的意见，一定要好好回复。一旦不被认可的话就会评判为文章没创新点，一个没有创新的文章，很难被录用。）<br>Response：谢谢您的意见。我们这篇论文原稿的引言部分没有把新意、重要性写清楚；鉴于此，我们已经加强了引言部分，把创新性强调出来。本文的创新性就在于……。首先还是要肯定审稿人说的对，他提出的方法或者已经存在的方法也很好，但本文的核心创新点在于和已经存在的方法不一样。适当的情况下可以比较下优缺点，加一些这方面的总结（觉得自己归纳的不好就别加了，以防弄巧成拙）。</li>
</ol>
</blockquote>
<blockquote>
<ol start="5">
<li>这句话有歧义。审稿人是读者的代表，既然他们会产生误解，那么其他读者也会有误解。因此，可以把涉及的句子重新变换一下，写得清楚一些。<br>Response：谢谢提醒。我们原本的写作的确会引起歧义，现在我们根据审稿人的意见修改如下……</li>
</ol>
</blockquote>
<p>在此列出第一次修改时的Response Letter实例：</p>
<blockquote>
<p><strong>Response to reviewer’s comments:</strong> “Deformation dynamics of a neutron-irradiated aluminum alloy: an <em>in situ</em> synchrotron tomography study” by H. W. Chai, D. Fan, J. C. Yuan, L. Hu, H. L. Xie, G. H. Du, Q. J. Feng, W. Zhou, J. Y. Huang, Ms. Ref. A-21-2294.</p>
</blockquote>
<blockquote>
<p>We appreciate the constructive remarks by the referee and have revised the manuscript accordingly. The comments raised are all addressed as follows. The revision details are marked in red (reviewer #1) and in blue (reviewer #2) in the revised manuscript.</p>
</blockquote>
<blockquote>
<p>Responds to the reviewers’ comments:</p>
</blockquote>
<blockquote>
<h3 id="Reviewer-1"><a href="#Reviewer-1" class="headerlink" title="Reviewer #1"></a>Reviewer #1</h3></blockquote>
<blockquote>
<p>Authors studied the mechanical behavior of an LT21 aluminum alloy form a decommissioned research reactor with in situ synchrotron micro-tomography. They developed particle tracking analysis technique to quantify the geometric features of the precipitates and pores, the history of the pores’ evolution under loading, and the displacement and strain fields. The new analysis technique is very interesting and the analysis is thorough. However, the reviewer found some analysis and conclusions might be questionable. It needs further discussions before the manuscript is accepted for the publication. Below are the questions.</p>
</blockquote>
<blockquote>
<ol>
<li>Although both the pore distribution and pore nucleation probability (Fig.9) show sharper peaks in the mode I region than that in the mode II region, the integrated pore number and the probability in the mode II region are much larger than that in the mode I region. The reviewer feels the authors’ argument of “pore nucleation contributes equally or more to porosity increase in the sample during stable plastic deformation, compared to pore growth” is not convincing. This might be related to the definition of $\xi_i$ in Eq.(16).<br>\begin{equation}<br>\xi_i &#x3D; \frac{(\overline\psi_i-1)V_{b,i-1}}{V_{b,i}-V_{b,i-1}},<br>\end{equation}<br>$\xi_i$ is defined as the ratio between the volumes of co-existing pores in two consecutive deformation stages. Multiplying ($\psi_i$-1) with total pore volume (including both existing and newly nucleated pores) has unclear physical meaning. In the pore analysis, all the pores in each stage were already sorted out according to their belonging regions (mode I and mode II), and pre-existing and newly nucleated pores were also cataloged. Therefore, the volume increases in mode I and mode II regions can be calculated directly. The reviewer suggests authors consider revising Eq.(16) to improve the analysis results.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer. The statements about irradiation-induced Si has been rewritten, see lines 204–205, page 13.</p>
</blockquote>
<blockquote>
<ol start="2">
<li>It would be helpful to provide the ratio between the volumes of the pores in mode I and mode II regions, and the ratio between the volume growths associated to modes I and II, in each stage.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The ratio between the volumes of the pores in mode I and mode II regions, and the ratio between the volume growths associated to modes I and II, in each stage, are calculated and presented in Fig.8d. The total and growth volume of pores in mode I is smaller than that in mode II throughout the deformation process. However, considering that the volume of mode I pore nucleation region is much smaller than that of mode II region, the density of pores in mode I region is much larger than that in mode II region. Clarification has been made in Fig.8d, and lines 410–415, page 27.</p>
</blockquote>
<blockquote>
<ol start="3">
<li>Please describe how the three parameters were chosen in Eq.(13).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. Clarification has been made in lines 446-448, page 29; lines 450–453, page 30.</p>
</blockquote>
<blockquote>
<ol start="4">
<li>In the last paragraph on page 31, it is said the flat segment in Fig.10(b) corresponds to the nucleation mode II. As seen in Fig.9(c), the population of new pores in mode II is much larger than that in mode I. In Fig.10(b), however, the population in the two ends is larger than that in the flat segment. Associating the flat segment in Fig.10(b) to mode II is controversial.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. Fig.9b has been revised to discuss the pore formation in mode I only. The pores involved are confined to the vicinity of the particles (spherical region of a radius of 9 $\mu$m). The U-shaped curves means that the pores are more prone to form at the upper and lower ends of the particles. Clarification has been made in lines 418–423, pages 27–28; lines 426–428, page 29.</p>
</blockquote>
<blockquote>
<ol start="5">
<li>Eq.(9) needs a reference.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Eq.(4) is not cited from a reference and derived as follows according to the theory of probability.<br>Assuming that the sample is infinitely large ($V_{\rm s}\to+\infty$) and contains only one particle, the cumulative probability that a single pore is randomly formed outside a spherical region of radius $L_{\rm b}$, $G_{\rm s}$ can be described as<br>\begin{equation}<br>G_{\rm s}(L_{\rm b}) &#x3D; 1-\frac{4\pi L_{\rm b}^3}{3V_{\rm s}}.<br>\end{equation}<br>As for a multiple-particle system, considering that a single pore randomly formed outside the spherical region of radius $L_{\rm b}$ of each particle are independent events, the cumulative probability of random pore formation for all particles is calculated according to the multiplication rule, as<br>\begin{equation}<br>G_{\rm m}(L_{\rm b}) &#x3D; \lim_{V_{\rm s}\to+\infty}\left(1-\frac{4\pi L_{\rm b}^3}{3V_{\rm s}}\right)^{V_{\rm s}\rho_{\rm a}},<br>\end{equation}<br>where $V_{\rm s}\rho_{\rm a}$ refers to the number of particles, and $\rho_{\rm a}$, the volume density of particles.<br>Then, the cumulative probability of random pore formation inside the spherical region of radius $L_{\rm b}$ of all particles is<br>\begin{equation}<br>G_{\rm II}(L_{\rm b}) &#x3D; 1-G_{\rm m}(L_{\rm b}),<br>\end{equation}<br>and the probability density of pore formation via mode II is the derivation of $G_{\rm II}(L_{\rm b})$ over $L_{\rm b}$.<br>Clarification has been made in lines 391–404, pages 26–27.</p>
</blockquote>
<blockquote>
<ol start="6">
<li>Fig.7 needs color legends.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. The color in Fig.6 refers to particles (blue) and pores (red), respectively. Clarification has been made in the caption of Fig.3a and b, Fig.4c and Fig.6.</p>
</blockquote>
<blockquote>
<ol start="7">
<li>Fig.4(b) is described as volume rendering in the caption but as surface rendering in the context (last paragraph on page 18).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Corrected. See lines 270, page 17.</p>
</blockquote>
<blockquote>
<ol start="8">
<li>What is the typical thickness of $\beta$-AlFeSi? Can $\beta$-AlFeSi be resolved in micro-tomography?</li>
</ol>
<p><font color="#80b1d3">Response</font>: According to the SEM and TEM images, the typical thickness of $\beta$-AlFeSi is 0.5–8 $\mu$m. Thus $\beta$-AlFeSi can be resolved by the micro-CT here. In the CT characterization, the needle-shaped Fe-based particles (elongation index less than 0.4) are taken as $\beta$-AlFeSi. The spatial distribution and equivalent cross-sectional diameter distribution of these particles are presented in Fig.R1. Clarification has been made in lines 217–218, page 14.<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/26/xfiik9.png" width="85%" alt="Fig.R1 (a) Spatial distribution of $\beta$-AlFeSi particles observed by micro-CT technique; (b) A typical $\beta$-AlFeSi particle; (c) Equivalent cross-sectional diameter distribution of $\beta$-AlFeSi particles." align=center /></p>
</blockquote>
<blockquote>
<ol start="9">
<li>It seems that there are correlations in the diameter distributions, sphericities, elongation indices, and flatness indices between pores and particles. Can authors give some discussions on the possible reasons?</li>
</ol>
<p><font color="#80b1d3">Response</font>: Good question. The corresponding statements have been deleted. Since the particles in the sample are not fully accounted (only Fe-based particles), the shape and orientation distributions for the particles are removed.</p>
</blockquote>
<blockquote>
<ol start="10">
<li>On page 12, it is said “Both types of AlFeSi particles exist in the irradiated LT21 Al alloy.” Is this statement made based on Fig.1(a) or 1(b)?</li>
</ol>
<p><font color="#80b1d3">Response</font>: This statement is originally made based on the CT characterizations. Plate-shaped and needle-shaped particles are observed in CT images, and are taken as $\alpha$-AlFeSi and $\beta$-AlFeSi, respectively. In the revised manuscript, TEM images are supplemented to characterize the two types of AlFeSi particles (Fig.2c, g and h). Clarification has been made in lines 216–217, pages 13–14.</p>
</blockquote>
<blockquote>
<ol start="11">
<li>The descriptions of Fig.1(a) in the figure caption and context are different.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. We remade Fig.1 and updated the corresponding description.</p>
</blockquote>
<blockquote>
<ol start="12">
<li>In the total received dose, except of thermal neutrons and fast neutrons, what is the energy distribution of the rest portion of neutrons?</li>
</ol>
<p><font color="#80b1d3">Response</font>: The rest portion of neutrons is labeled intermediate neutrons. The dose of the intermediate neutrons is about $5.40\times10^{20}$ n&#x2F;cm$^{-2}$. Clarification has been made in lines 167–171, pages 11–12.</p>
</blockquote>
<blockquote>
<ol start="13">
<li>In X-ray imaging, the resolution is not defined as pixel size. Please revise the resolution statement on page 9.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The voxel size is 0.87 $\mu$m, and three-dimensional spatial resolution is quantified as about 3 $\mu$m. Clarification has been made in lines 127-128, page 9.</p>
</blockquote>
<blockquote>
<p>Based on the above concerns, the reviewer recommends major revision of the current manuscript.</p>
</blockquote>
<blockquote>
<h3 id="Reviewer-2"><a href="#Reviewer-2" class="headerlink" title="Reviewer #2"></a>Reviewer #2</h3></blockquote>
<blockquote>
<p>This manuscript is an ambitious analysis of the microstructural features underlying the tensile deformation of an irradiated aluminum alloy. The analysis technique, CT construction of the 3D image of internal precipitates and pores using a synchrotron beam is unique for metallographic applications. The paper also employs a number of analysis techniques developed for CT constructions that classify the microstructural characteristics of the defect structures based on size and morphology. This approach adds significant statistical information about the distribution and types of the defect structures and their influence on tensile deformation.</p>
</blockquote>
<blockquote>
<p>The paper covers a number of related areas, but seems extremely lengthy for the sake of presenting the results. There are also a number of gaps in the presentation and analyses that need to be addressed. These are described individually in the following paragraphs.</p>
</blockquote>
<blockquote>
<ol>
<li>The authors do not provide either the material composition or the irradiation temperature conditions. Without this baseline information, it is not possible to interpret many of the results in the study.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The material composition of the unirradiated and irradiated LT21 Al alloys is provided in Tabel.1. The irradiation temperature conditions are provided in the revised manuscript. The target is put in cooling water during irradiation, and the irradiation temperature fluctuates between 20 $^\circ$C and 40 $^\circ$C. Clarification has been made in lines 171–177, page 12, and lines 180–183, page 12.</p>
</blockquote>
<blockquote>
<ol start="2">
<li>The authors do cite a number of relevant studies, but by comparison to a paper by Farrell and King (<a href="https://www.osti.gov/servlets/purl/6886356">https://www.osti.gov/servlets/purl/6886356</a> this is only one of several similar studies by Farrell et al.), the levels of displacement damage (i.e. displacements per atom) and the conversion of Al to Si through the neutron capture reaction are very small. For the stated irradiation conditions, the level of damage should be insignificant. Since the authors provide no information on the unirradiated material or the temperature, it is not possible to determine the whether or not the microstructure is a consequence of the irradiation exposure or just a thermal aging problem. The paper cites 4.3$\times$10$^{20}$ n&#x2F;cm$^2$ ($&gt;$0.1 MeV) or 4.3$\times$10$^{24}$ n&#x2F;m$^2$ ($&gt;$0.1 MeV) might be 0.6 dpa and 0.01% (or 100 ppm) Si formation.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We supplement the EDS, EBSD, XRD and CT characterizations of the material before irradiation and the TEM characterizations on the irradiated material, as presented in Figs.1, 2 and 3. The grain size of the irradiated material is slightly larger than that of the unirradiated material (60 $\mu$m versus 50 $\mu$m). EBSD and EDS characterizations (Fig.1) show that the areal density of Si particles is higher in the irradiated material than in the unirradiated material, probably due to irradiation-induced transmutation and precipitation. In addition, the shape of AlFeSi particles are largely needle-shaped in the irradiated material, while largely plate-shaped in the unirradiated material. CT characterizations (Fig.3) show that the size of pores and particles in the irradiated material becomes larger than that in the unirradiated material. The shape of pores deviates further away from spheres and becomes more anisotropic. The orientations of pores become more aligned in the irradiated material. TEM images along with EDS characterizations show that nanoscale needle-shaped Mg$_2$Si particles appear in the irradiated material. Therefore, long-term irradiation here indeed induces considerable microstructural changes in the LT21 Al alloy. Clarification has been made in lines 184–185, page 12; lines 193–200, page 13; lines 208–231, pages 13–16.</p>
</blockquote>
<blockquote>
<ol start="3">
<li>The authors do mention the resolution of their technique at about 3 $\mu$m or 3$\times$10$^3$ nm, which is large for typical irradiation-induced pores (i.e. voids or bubbles) for low dose irradiations. Since the gas content or possible hydrogen uptake of the material is not known, it is not possible to claim that the pores are irradiation-induced. Again, a comparison with the work of Farrell, voids at the dose level reported here should be smaller than the resolution limit (~3 $\mu$m) for this technique.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We agree that irradiation is unlikely to induce formation of new pores visible to the micro CT, but irradiation induces growth of existed pores and particles in the unirradiated material as revealed by the CT characterizations (Fig.3c). Clarification has been made in lines 235–242, page 16; lines 249–263, pages 16–17.</p>
</blockquote>
<blockquote>
<ol start="4">
<li>The analysis in Figure 1 is also questionable. Since the figures are 2D surface images, there is no way to tell the depth of grains in the third dimension. So the distance from a visible grain boundary in EBSD does not necessarily indicate the real 3D distance from grain boundaries below the surface. This would only be possible with taking several polished sections to remove layer after layer of the surface to reveal grain depths. Further, there are several grains in the figure which are smaller than 100 $\mu$m, so the characterization of distance from the boundary is falsely skewed toward the lower numbers. This probability distribution analysis should be removed.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The probability distribution and the corresponding statements has been removed.</p>
</blockquote>
<blockquote>
<ol start="5">
<li>In addition, the comment about Si clusters former near the grain boundaries needs to be supported by a mechanism. The Si formed during the neutron irradiation is formed uniformly throughout the bulk material. Segregation and clustering at the grain boundaries would require a thermal process or based on radiation-enhanced diffusivity (RED) which is not analyzed here. The comments (near the bottom middle of page 13) “Al to Si particles tend to concentrate near grain boundaries and particle interfaces” is not supported by any analysis.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The comment about Si clusters forming near the grain boundaries has been removed. See lines 196–197, page 13.</p>
</blockquote>
<blockquote>
<ol start="6">
<li>The information in Fig.2 is also suspicious. First, it is unlikely that both the pores and precipitates have the same morphologies and characteristics. The authors are only able to extract precipitate information for the AlFeSi particles (page 14) and only use those for analysis. The removed any useful information about the Mg2Si phase, which is a major contributor to the tensile strengthening process (again see Farrell’s papers).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The shape and orientation distributions for the precipitates are removed and only those for the pores are presented in Fig.7.</p>
</blockquote>
<blockquote>
<ol start="7">
<li>In any case the information presented in Fig.2 is also constrained by the ~3 $\mu$m resolution limit of the technique, and unlikely to be irradiation-induced microstructure.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. We supplement the EDS, EBSD, XRD and CT characterizations of the material before irradiation and the TEM characterizations on the irradiated material, as presented in Figs.1, 2 and 3. Such characterizations show that long-term irradiation here indeed induces considerable microstructural changes in the LT21 Al alloy. Clarification has been made in lines 184–185, page 12; lines 193–200, page 13; lines 208–231, pages 13–16.</p>
</blockquote>
<blockquote>
<ol start="8">
<li>The analysis in Figure 2 and at the bottom of page 14 is also problematic. The technique does not distinguish grain boundaries, so there is no way to determine if the precipitate shape is associated with planar, disk or needle-like growth at the grain boundaries.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer. All discussions about grain boundaries with the micro CT have been removed or corrected. Clarification has been made in lines 249–263, pages 16–17.</p>
</blockquote>
<blockquote>
<ol start="9">
<li>The particle tracking development for analyzing the deformation characteristics is a useful inclusion.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thank you.</p>
</blockquote>
<blockquote>
<ol start="10">
<li>The pore and particle tracking and growth in Fig.4 is useful. However, the authors should show pore void densities at various elevations. The figure seem to indicate that the pore growth initiates near the bottom of the selected volume between 0.09 and 0.14 strain and travels upward as the stain level increases. The authors need to explain the apparent movement of pore growth with increasing strain. This observation is also supported by the information in Figure 5 in the strain field images.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. The pore density distribution is calculated and presented in Fig.R2, and is similar to the porosity distribution shown in Fig.7a. The movement of the pore growth region with increasing strain is attributed to the loading geometry. In the <em>in situ</em> CT experiment, the lower loading collet is fixed while the upper collet moves upwards to load the sample. The field of view for CT is fixed as well. The global deformation of sample thus results in an upward movement of the pore growth region. Nevertheless, the movement of the pore growth region is negligible when necking occurs in the sample. Clarification has been made in lines 131–134, page 9.<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/26/xfiG1P.png" width="50%" alt="Fig.R2 The pore number density distributions along the sample height at different strains." align=center /></p>
</blockquote>
<blockquote>
<ol start="11">
<li>The result of the displacement $u_z$ in Fig.5 are unclear. The authors do now sufficiently explain the meaning of these results. If they are the displacement vectors of the particles, there is no sense in showing very high particle displacement in the upper end of the specimen once necking occurs.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the misunderstanding. Strain localizaitons or high displacement gradients occur in the necking region, instead of displacement localizations. In our loading geometry, the largest displacement always appear at the upper end of sample due to continuous movement of the upper collet. Clarification has been made in capture of Fig.5(a), and lines 280–281, page 19.</p>
</blockquote>
<blockquote>
<ol start="12">
<li>The sections on pore evolution and forward need to be removed. Since the resolution of the process does not account for existing microstructure below ~3 um in diameter, there is no basis for counting pore evolution or pore nucleation. The pores that seem to be ‘nucleated’ are most probably pores that are too small to resolve before the deformation process. Thus, they are not nucleated. The observations in Figure 7 of new pores are probably ones that were below the resolution limit.</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer that pore nucleation cannot be resolved by the micro-CT here. The corresponding statements have been revised or removed. We have stated clearly that only pores larger than 3 $\mu$m (observable) are accounted in the revised manuscript. All the discussions are made on this basis. Clarification has been made in line 303–306, page 20; lines 316–317, page 21; lines 354–356, 361, 364, 365, 372, and 374, page 24.</p>
</blockquote>
<blockquote>
<ol start="13">
<li>Figure 6 a should be remove since there is no sense in the general pore faction once the UTS is reached. Figure 6b could be kept, but again, there should be some information about the shift in the necking region from lower in the sample to its final position. In addition, this figure should be done in absolute numbers not in ‘probablity.’ These are not probabilities (this should be changed in many other places).</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. Fig.6a has been removed. The shift of the necking region is attributed to the loading geometry, as explained in the question 10. The ‘probability’ has been replaced with ‘fraction’ in the corresponding figures and statements.</p>
</blockquote>
<blockquote>
<ol start="14">
<li>The information in Figure 8 shows very little differences between deformed and undeformed or even as a function of strain level. There is no reason to include data for strains beyond 0.09 since 0.14 is past the UTS and the changes should be localized to the neck. The fact that there is no real change at the higher strain levels highlights this problem. The strains above 0.09 should be removed from the plot since they represent very highly localized processes and are washed out over the entire specimen length.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. After UTS occurs in the sample, the structural information of the necking region (0.6 mm to 1.8 mm height range) is used for statistical analysis. Clarification has been made in Fig.7, and lines 335-336, page 23.</p>
</blockquote>
<blockquote>
<ol start="15">
<li>The section on ‘Nucleation of pores’ should be removed since there is no evidence of real nucleation. The information in Fig 9 is not useful without more microstructural information below the ~3 um resolution limit. The peaks could well be due to irradiation-induced small voids which are entirely different from the ‘pores’ described in the graphs</li>
</ol>
<p><font color="#80b1d3">Response</font>: We agree with the reviewer that pore nucleation cannot be resolved by the micro-CT here. Nucleation&#x2F;nucleate has been revised to formation&#x2F;form or removed in the revised manuscript. Formation has been defined to include pores  We have stated clearly that only pores larger than 3 $\mu$m (observable) are accounted in the revised manuscript. All the discussions are made on this basis.</p>
</blockquote>
<blockquote>
<ol start="16">
<li>The very long section nucleation theory should be removed. It also has no basis from the resolution limit of the technique. Fitting data for nucleation in the necking region for strains greater than 0.09 also doesn’t make sense. The authors do not consider the triaxiality of the stress under the high necking strain conditions. Even for lower strain levels, the Poisson’s compressive stresses in the y and z directions are not accounted for. The values in Fig.10 only deviate from the original for strains higher than 0.09, where the model is inappropriate. The fact that the failure is shear oriented, means that the shear strains are dominate, not the normal strains. This is also a failing of the modeling effort. There is also a major objection to showing data down to the 0 um level which occurs in some of the analysis plots.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Sorry for the mistake. The nucleation theory including corresponding formulas and statements has been removed. The data involving distances below 3 $\mu$m are also removed.</p>
</blockquote>
<blockquote>
<ol start="17">
<li>The modeling also does not account for the grain boundary influences on pore nucleation and growth. The authors also invoke dislocation mechanisms to help explain nucleation theory, but there are no measurements here.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. EBSD characterizations on the postmortem irradiated samples have been added to discuss the effects of grain boundaries. The modelling for mode I nucleation has been removed. Clarification has been made in Fig.11, and lines 490–506, pages 32–34.</p>
</blockquote>
<blockquote>
<ol start="18">
<li>The major failing of this paper is that it does not have accompanying microstructural information for the length scales below the synchrotron resolution limit. The paper could be useful if it were combined with a substantial amount of TEM work to look at scales down to the nano-meter range.</li>
</ol>
<p><font color="#80b1d3">Response</font>: Thanks for the suggestion. CT characterization is superior in its 3D and quantitative features, compared to the SEM and TEM which can achieve high resolutions. TEM characterizations on the irradiated sample prior to loading and EBSD characterizations on the postmortem irradiated sample are added in the revised manuscript. See Figs.2 and 11, respectively.</p>
</blockquote>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>以 Acta Materialia 期刊为例，Reference 的书写规范中作者名需以逗号隔开，姓名缩写形如 H. W. Chai，文章标题以逗号结尾，期刊名采用 ISO4 标准期刊缩写，结尾需标注期刊刊号，年份，页码信息。</p>
<p><font size= 2>[1] K. Farrell, J. Bentley, D. N. Braski, Direct observation of radiationinduced coated cavities, Scr. Metall. 11 (3) (1977) 243–248.</font></p>
<h2 id="Declaration-of-Interests"><a href="#Declaration-of-Interests" class="headerlink" title="Declaration of Interests"></a>Declaration of Interests</h2><p>声明本文作者没有已知的竞争经济利益或个人关系，可能会影响本文中所涉及的科研成果。一般只需在第一条中打勾，如存在竞争关系方，可在第二项中注明。</p>
<ul>
<li><p>The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
</li>
<li><p>The authors declare the following financial interests&#x2F;personal relationships which may be considered as potential competing interests.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Scholarship, Writing and Mindset</category>
      </categories>
      <tags>
        <tag>Acta Materialia</tag>
        <tag>Scholarship</tag>
      </tags>
  </entry>
  <entry>
    <title>随笔</title>
    <url>/Exp011-book01/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMXvV.png"></p>
<blockquote class="blockquote-center">
<p>大二时拜访友人，从合肥乘火车哐当哐当摇晃去上海，感叹前路迷蒙自身渺小，途中随笔。如今面临学生向老师的身份骤变，不觉时光如梭，如梦如幻。 </p>

</blockquote>

<p>这些年路大部分都是自己一个人走的，车是一个人坐的，所以常常靠拿着一本书看，好把时间打发过去。去上海的路上，我在火车上看到两个孩子，正巧我在读这本$\lfloor$平凡的世界$\rceil$。这两个孩子一开始友好的互相讲故事，然后开始吹牛，最后小男孩和小女孩竟然吵起了架。</p>
<span id="more"></span>

<p>过早的怀旧或许意味着衰老。但是有些人就喜欢怀旧，同时也喜欢向前生活。我自己还是小孩子的时候，跟别人说话时也会因为一些小事就发脾气吵起来，后来我自己找到了一种方法就是规避，所以从小到现在还跟我关系还不错的就只有几个人，很多人我连名字都忘记了。回来的时候在科大晃了好几天，和朋友老师都吃了饭，在空旷的视野里，本科生活的流逝时时令人不舍。</p>
<p>我想自己最近才把注意力放在一个叫做世界观的东西上。只是现在的我，就像从前的我一样，依然那么狭隘。我常常想着出去走走，去看一些东西，去体会一些东西 ，然后仿佛我的思路会开阔起来。只是偶尔想想这二十年的路，自己思考的其实还是太少。以至于以前茫然的东西，到现在好像还是茫然，以前清楚的东西，现在反而变得糊涂了。</p>
<p>好像Ph.D七年还是很遥远的东西，每次大家一起说这个的事情的时候都会不忘记幽默一下这个只是理论上的数字。跟家里亲戚吃饭，他们都指着我说这个人在某某大学里面。我点了点头，确实某某大学是个让我还算满意的大学，但是他们不在我的世界里，不知道我在关心着什么，又在担心着什么。转眼一想，确实四年的大学生活过得会非常快。</p>
<p>车上的小孩子一直都在吵，然后两家的大人们都笑着在旁边起哄。我有时候觉得小朋友的想法确实很有创意，只是我自己回不到我自己小时候的脑子里。现在记忆最深的，就是一滴墨水滴进清水里的画面，曾经看过一篇文章花了好长的篇幅来描写这个画面，具体的描述已经记不清，后来这种效果被渲染进了电视的广告里。往往这些过程带着一点哲学的韵味，不仅仅是墨水在水里面散开的过程，还有小孩子们在争吵这件事，大人的世界和小孩子的世界有着明显的决裂。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 02：函数、流程控制语句与NumPy初步</title>
    <url>/PythonLes03/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>通过前面两周课程的学习，我们了解了现代科研体系中编程语言的必要作用，而Python等解释型语言由于其便捷易开发的优势又是其中的主力军之一。以及对Python语言的基础知识包括注释、对象类型（数字、字符串、布尔型等）、运算符（位运算符、赋值运算符、逻辑运算符）等。第三周课程我们将学习Python语言编写时的缩进规则、函数的用法、流程控制语句以及NumPy模块的初步使用。</p>
<span id="more"></span>

<h2 id="Python语言缩进规则"><a href="#Python语言缩进规则" class="headerlink" title="Python语言缩进规则"></a>Python语言缩进规则</h2><p>和其它程序设计语言采用大括号 <code>&#123;&#125;</code> 分隔代码块不同，Python 采用代码缩进和冒号来区分代码块之间的层次。 要求严格的代码缩进是Python语法的一大特色，好比C语言中的花括号一样重要。</p>
<p>在 Python 中，对于 $\lfloor$类$\rceil$、$\lfloor$函数$\rceil$、$\lfloor$流程控制语句$\rceil$、$\lfloor$异常处理语句$\rceil$ 等，行尾的冒号和下一行的缩进，表示下一个代码块的开始，而缩进的结束则表示此代码块的结束。</p>
<p>在python中，强制要求缩进，一般使用<code>Tab</code>或<code>Space</code>来进行缩进，且缩进必须要保持一致，否则可能会出缩进的错误。官方规定是缩进四个空格，而<code>Tab</code>键不一定等于四个空格，所以需要设置一个<code>Tab</code>等于四个空格。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dataInfo</span>(<span class="params">filename,showInfor=<span class="literal">False</span></span>):</span><br><span class="line">    f = h5py.File(filename,<span class="string">&quot;r&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:    </span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data&quot;</span>] </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">        dim = arr.shape</span><br><span class="line">        <span class="keyword">if</span> showInfor == <span class="literal">True</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Data dimension is [Theta:Y:X] = [&#x27;</span>, dim[<span class="number">0</span>],<span class="string">&#x27;:&#x27;</span>, dim[<span class="number">1</span>],<span class="string">&#x27;:&#x27;</span>, dim[<span class="number">2</span>],<span class="string">&#x27;]&#x27;</span>)</span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data_white&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> arr.shape[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;There is no white images in this file.&#x27;</span>)</span><br><span class="line">        arr = f[<span class="string">&quot;exchange/data_dark&quot;</span>] </span><br><span class="line">        <span class="keyword">if</span> arr.shape[<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Infor !!!!!&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;There is no dark images in this file.&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> dim    </span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;!!!!! Error !!!!!&#x27;</span>) </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Dataset \&#x27;exchange/data\&#x27; does not exist in the give file.&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>与其他语言不同，Python属于强制缩进的，它这种做法属于双刃剑，有好处也有坏处。</p>
<p>好处是强迫你写出格式化的代码，但没有规定缩进是几个空格还是<code>Tab</code>。按照约定俗成的管理，应该始终坚持使用四个空格的缩进；另一个好处是强迫你写出缩进较少的代码，你会倾向于将一段很长的代码拆分成若干函数，从而得到缩进较少的代码。</p>
<p>坏处就是复制、粘贴功能失效了，当你重构代码时，粘贴过去的代码必须重新检查缩进是否正确；此外，IDE很难像格式化Java代码那样格式化Python代码。</p>
<h3 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h3><blockquote class="blockquote-center">
<p>Python使用缩进来组织代码块，区分$\lfloor$类$\rceil$、$\lfloor$函数$\rceil$、$\lfloor$流程控制语句$\rceil$、$\lfloor$异常处理语句$\rceil$等的层次，请务必遵守约定俗成的习惯，坚持使用4个空格的缩进。在文本编辑器中，需要设置把<code>Tab</code>自动转换为4个空格，确保不混用<code>tab</code>和空格。 </p>

</blockquote>


<h2 id="Python-流程控制语句"><a href="#Python-流程控制语句" class="headerlink" title="Python 流程控制语句"></a>Python 流程控制语句</h2><p>我们可以使用 Python 来执行一些稍复杂的任务。例如，我们可以写一个生成菲波那契子序列的程序，如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Fibonacci series:</span></span><br><span class="line"><span class="comment"># the sum of two elements defines the next</span></span><br><span class="line">a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> b &lt; <span class="number">10</span>:</span><br><span class="line">    <span class="built_in">print</span>(b)</span><br><span class="line">    a, b = b, a+b</span><br></pre></td></tr></table></figure>

<p>这个例子介绍了几个新功能。</p>
<ul>
<li><p>第一行包括了一个 多重赋值：变量 a 和 b 同时获得了新的值 0 和 1 最后一行又使用了一次。在这个演示中，变量赋值前，右边首先完成计算。右边的表达式从左到右计算。</p>
</li>
<li><p>条件（这里是 b &lt; 10 ）为 true 时， while 循环执行。在 Python 中，类似于 C，任何非零整数都是 True；0 是 False。条件也可以是字符串或列表，实际上可以是任何序列；</p>
</li>
<li><p>循环体是缩进的：缩进是 Python 组织语句的方法。</p>
</li>
</ul>
<p>除了这里介绍的 while 语句，Python 还从其它语言借鉴了一些流程控制功能，并有所改变。</p>
<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/while_loop.png" width="40%" alt="while语句逻辑结构" align=center />


<h3 id="if-语句"><a href="#if-语句" class="headerlink" title="if 语句"></a>if 语句</h3><p>也许最有名的是 if 语句。例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please enter an integer: &quot;</span>))</span><br><span class="line">Please enter an integer: <span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>     x = <span class="number">0</span></span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Negative changed to zero&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">elif</span> x == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Zero&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">elif</span> x == <span class="number">1</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;Single&#x27;</span>)</span><br><span class="line"><span class="meta">... </span><span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>     <span class="built_in">print</span>(<span class="string">&#x27;More&#x27;</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可能会有零到多个<code>elif</code>部分，<code>else</code>是可选的。关键字<code>elif</code>是else if的缩写，这个可以有效地避免过深的缩进。&#96;if … elif … elif …&#96;&#96; 序列用于替代其它语言中的 switch 或 case 语句。</p>
<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/if_elif_else.png" width="60%" alt="if ... elif ... else ... 逻辑结构，elif 与 else为可选项" align=center />

<p>我们可以将一个if语句嵌入到另一个if语句中，然后称之为嵌套if语句。事实上，所有的流程控制语句都可以多层嵌套。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="number">67</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> x &gt; <span class="number">10</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Above ten,&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">20</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;and also above 20!&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;but not above 20.&quot;</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;python3 exampleCode.py</span><br><span class="line">&gt;&gt;&gt;Above ten,</span><br><span class="line">&gt;&gt;&gt;<span class="keyword">and</span> also above <span class="number">20</span>!</span><br></pre></td></tr></table></figure>

<h3 id="for-语句"><a href="#for-语句" class="headerlink" title="for 语句"></a>for 语句</h3><p>Python 中的 for 语句和 C 或 Pascal 中的略有不同。通常的循环可能会依据一个等差数值步进过程（如 Pascal），或由用户来定义迭代步骤和中止条件（如 C ），Python 的 for 语句依据任意序列（链表或字符串）中的子项，按它们在序列中的顺序来进行迭代。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Measure some strings:</span></span><br><span class="line"><span class="meta">... </span>words = [<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;window&#x27;</span>, <span class="string">&#x27;defenestrate&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> w <span class="keyword">in</span> words:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(w, <span class="built_in">len</span>(w))</span><br><span class="line">...</span><br><span class="line">cat <span class="number">3</span></span><br><span class="line">window <span class="number">6</span></span><br><span class="line">defenestrate <span class="number">12</span></span><br></pre></td></tr></table></figure>

<img src="https://docs.sunfounder.com/projects/thales-kit/en/latest/_images/for_loop.png" width="45%" alt="for语句逻辑结构" align=center />

<p>在迭代过程中修改迭代序列不安全（只有在使用链表这样的可变序列时才会有这样的情况）。如果你想要修改你迭代的序列（例如，复制选择项），你可以迭代它的复本。使用切割标识就可以很方便的做到这一点:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> w <span class="keyword">in</span> words[:]:  <span class="comment"># Loop over a slice copy of the entire list.</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> <span class="built_in">len</span>(w) &gt; <span class="number">6</span>:</span><br><span class="line"><span class="meta">... </span>        words.insert(<span class="number">0</span>, w)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>words</span><br><span class="line">[<span class="string">&#x27;defenestrate&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;window&#x27;</span>, <span class="string">&#x27;defenestrate&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h3 id="range-函数"><a href="#range-函数" class="headerlink" title="range() 函数"></a>range() 函数</h3><p>如果你需要一个数值序列，内置函数<code>range()</code>会很方便，它生成一个等差级数链表:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i)</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure>

<p><code>range(10)</code>生成了一个包含 10 个值的链表，它用链表的索引值填充了这个长度为 10 的列表，所生成的链表中不包括范围中的结束值。也可以让 range() 操作从另一个数值开始，或者可以指定一个不同的步进值（甚至是负数，有时这也被称为 “步长”）:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">range</span>(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">   <span class="number">5</span> through <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">range</span>(<span class="number">0</span>, <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">   <span class="number">0</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">range</span>(-<span class="number">10</span>, -<span class="number">100</span>, -<span class="number">30</span>)</span><br><span class="line">  -<span class="number">10</span>, -<span class="number">40</span>, -<span class="number">70</span></span><br></pre></td></tr></table></figure>

<p>需要迭代链表索引的话，如下所示结合使用<code>range()</code>和<code>len()</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">&#x27;Mary&#x27;</span>, <span class="string">&#x27;had&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;little&#x27;</span>, <span class="string">&#x27;lamb&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i, a[i])</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span> Mary</span><br><span class="line"><span class="number">1</span> had</span><br><span class="line"><span class="number">2</span> a</span><br><span class="line"><span class="number">3</span> little</span><br><span class="line"><span class="number">4</span> lamb</span><br></pre></td></tr></table></figure>

<p>不过，这种场合可以方便的使用<code>enumerate()</code>。在序列中循环时，索引位置和对应值可以使用<code>enumerate()</code>函数同时得到:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>([<span class="string">&#x27;tic&#x27;</span>, <span class="string">&#x27;tac&#x27;</span>, <span class="string">&#x27;toe&#x27;</span>]):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(i, v)</span><br><span class="line">...</span><br><span class="line"><span class="number">0</span> tic</span><br><span class="line"><span class="number">1</span> tac</span><br><span class="line"><span class="number">2</span> toe</span><br></pre></td></tr></table></figure>

<p>如果你只是打印一个序列的话会发生奇怪的事情:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; print(range(10))</span><br><span class="line">range(0, 10)</span><br></pre></td></tr></table></figure>

<p>在不同方面 range() 函数返回的对象表现为它是一个列表，但事实上它并不是。当你迭代它时，它是一个能够像期望的序列返回连续项的对象；但为了节省空间，它并不真正构造列表。</p>
<p>我们称此类对象是 可迭代的，即适合作为那些期望从某些东西中获得连续项直到结束的函数或结构的一个目标（参数）。我们已经见过的 for 语句就是这样一个迭代器。list() 函数是另外一个（ 迭代器 ），它从可迭代（对象）中创建列表:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>

<p>以后的学习中我们会看到更多返回可迭代（对象）和以可迭代（对象）作为参数的函数。</p>
<h3 id="break-和-continue-语句-以及循环中的-else-子句"><a href="#break-和-continue-语句-以及循环中的-else-子句" class="headerlink" title="break 和 continue 语句, 以及循环中的 else 子句"></a>break 和 continue 语句, 以及循环中的 else 子句</h3><p>break 语句和 C 中的类似，用于跳出最近的一级 for 或 while 循环。</p>
<p>循环可以有一个 else 子句；它在循环迭代完整个列表（对于 for ）或执行条件为 false （对于 while ）时执行，但循环被 break 中止的情况下不会执行。以下搜索素数的示例程序演示了这个过程:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, n):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> n % x == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>            <span class="built_in">print</span>(n, <span class="string">&#x27;equals&#x27;</span>, x, <span class="string">&#x27;*&#x27;</span>, n//x)</span><br><span class="line"><span class="meta">... </span>            <span class="keyword">break</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="comment"># loop fell through without finding a factor</span></span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(n, <span class="string">&#x27;is a prime number&#x27;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="number">2</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">3</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">4</span> equals <span class="number">2</span> * <span class="number">2</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">6</span> equals <span class="number">2</span> * <span class="number">3</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">is</span> a prime number</span><br><span class="line"><span class="number">8</span> equals <span class="number">2</span> * <span class="number">4</span></span><br><span class="line"><span class="number">9</span> equals <span class="number">3</span> * <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>(Yes, 这是正确的代码。看仔细：else 语句是属于 for 循环之中， 不是 if 语句。)</p>
<ul>
<li>与循环一起使用时，else 子句与 try 语句的 else 子句比与 if 语句的具有更多的共同点：try 语句的 else 子句在未出现异常时运行，循环的 else 子句在未出现 break 时运行。</li>
</ul>
<p>continue 语句是从 C 中借鉴来的，它表示循环继续执行下一次迭代:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">10</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> num % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">print</span>(<span class="string">&quot;Found an even number&quot;</span>, num)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">continue</span></span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;Found a number&quot;</span>, num)</span><br><span class="line">Found an even number <span class="number">2</span></span><br><span class="line">Found a number <span class="number">3</span></span><br><span class="line">Found an even number <span class="number">4</span></span><br><span class="line">Found a number <span class="number">5</span></span><br><span class="line">Found an even number <span class="number">6</span></span><br><span class="line">Found a number <span class="number">7</span></span><br><span class="line">Found an even number <span class="number">8</span></span><br><span class="line">Found a number <span class="number">9</span></span><br></pre></td></tr></table></figure>

<h3 id="pass-语句"><a href="#pass-语句" class="headerlink" title="pass 语句"></a>pass 语句</h3><p>pass 语句什么也不做。它用于那些语法上必须要有什么语句，但程序什么也不做的场合，例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span>  <span class="comment"># Busy-wait for keyboard interrupt (Ctrl+C)</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>这通常用于创建最小结构的类:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyEmptyClass</span>:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>另一方面，pass 可以在创建新代码时用来做函数或控制体的占位符。可以让你在更抽象的级别上思考。pass 可以默默的被忽视:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">initlog</span>(<span class="params">*args</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">pass</span>   <span class="comment"># Remember to implement this!</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="本章小结-1"><a href="#本章小结-1" class="headerlink" title="本章小结"></a>本章小结</h3><blockquote class="blockquote-center">
<p>通过本节的学习，我们了解了Python中的流程控制语句，包括if … elif … else …结构，while结构以及for循环的基本使用方法，以及与之配合的range()函数及break\continue语句的使用规则。 </p>

</blockquote>























<h2 id="Python语言中的函数"><a href="#Python语言中的函数" class="headerlink" title="Python语言中的函数"></a>Python语言中的函数</h2><p>在编程中，函数是一种模块化的手段，当它被调用时执行特定功能并提供反馈。可提高代码的利用率，避免重复代码，便于使用，便于维护。Python 中，不仅提供了许多现成可用的内建函数，用户还可以根据自己的需求，定义自己的函数。</p>
<p>函数也属于一种数据类型，可以使用<code>type()</code>查看，内建函数为<code>builtin_function_or_method</code>，自定义函数为<code>function</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">printhello</span>(): <span class="comment"># 自定义函数 test()，并没有实质功能</span></span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(<span class="string">&#x27;Hello world!!!&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(printhello)  <span class="comment"># printhello() 为自定义函数</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;function&#x27;</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">type</span>(<span class="built_in">print</span>)       <span class="comment"># print() 为内建函数</span></span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;builtin_function_or_method&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>本章节将展示如何在Python中定义函数并调用它，这样你就可以把Python应用程序的代码模块化分解，重复利用，精简代码结构。</p>
<h3 id="创建函数"><a href="#创建函数" class="headerlink" title="创建函数"></a>创建函数</h3><p>创建函数也称为定义函数，可以理解为创建一个具有某种用途的工具，通过<code>def</code>关键词及函数标识符（函数对象名）实现，具体的语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">functionName</span>(<span class="params">parameterList</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;comments&#x27;&#x27;&#x27;</span></span><br><span class="line">    functionBody</span><br></pre></td></tr></table></figure>

<p>这里包括四个函数的基本元素：</p>
<ul>
<li>functionName: 函数名称，在调用函数时使用。</li>
<li>parameterlist: 可选参数，用于指定像函数中传递的参数。如果有多个参数，则各参数间使用逗号<code>,</code>分隔；如果不指定，则表示该函数没有输入参数。</li>
<li>comments: 可选参数，标识为函数指定注释。也称为Docstrings（文档字符串），通常用于说明该函数的功能、要传递的参数的作用等等。</li>
<li>functionBody: 函数体，实现函数的功能的具体代码块。如果函数有返回值，可以使用return语句返回。</li>
</ul>
<p>函数体“functionBody”与注释“comments”相对于def关键字必须保持缩进。</p>
<p>按照上面的基本语法，一个向终端输出随机生成的两个变量之和的Python函数示例如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunction</span>():</span><br><span class="line">	a = rand()</span><br><span class="line">	b = rand()</span><br><span class="line">    <span class="built_in">print</span>(a+b)</span><br></pre></td></tr></table></figure>

<p>我们举一个工程应用中具体的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_image</span>(<span class="params">self, geo, angle, iteration</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    VERBOSE:</span></span><br><span class="line"><span class="string">     for j in range(angleblocks):</span></span><br><span class="line"><span class="string">         angle = np.array([alpha[j]], dtype=np.float32)</span></span><br><span class="line"><span class="string">         proj_err = proj[angle_index[j]] - Ax(res, geo, angle, &#x27;ray-voxel&#x27;)</span></span><br><span class="line"><span class="string">         backprj = Atb(proj_err, geo, angle, &#x27;FDK&#x27;)</span></span><br><span class="line"><span class="string">         res += backprj</span></span><br><span class="line"><span class="string">         res[res&lt;0]=0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="variable language_">self</span>.res += <span class="variable language_">self</span>.__bm__ * <span class="number">2</span> * tigre.Atb((<span class="variable language_">self</span>.proj[<span class="variable language_">self</span>.angle_index[iteration]] - tigre.Ax(</span><br><span class="line">        <span class="variable language_">self</span>.res, geo, angle, <span class="string">&#x27;interpolated&#x27;</span>)), geo, angle, <span class="string">&#x27;matched&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_main_iter</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Goes through the main iteration for the given configuration.</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    t = <span class="variable language_">self</span>.__t__</span><br><span class="line">    Quameasopts = <span class="variable language_">self</span>.Quameasopts</span><br><span class="line">    x_rec = copy.deepcopy(<span class="variable language_">self</span>.res)</span><br><span class="line">    lambdaForTv = <span class="number">2</span> * <span class="variable language_">self</span>.__bm__ * <span class="variable language_">self</span>.__lambda__</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.niter):</span><br><span class="line"></span><br><span class="line">        res_prev = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> Quameasopts <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            res_prev = copy.deepcopy(<span class="variable language_">self</span>.res)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.verbose:</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="built_in">str</span>(<span class="variable language_">self</span>.name).upper() +</span><br><span class="line">                      <span class="string">&#x27; &#x27;</span> + <span class="string">&quot;algorithm in progress.&quot;</span>)</span><br><span class="line">                toc = default_timer()</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                tic = default_timer()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Esitmated time until completetion (s): &#x27;</span> +</span><br><span class="line">                      <span class="built_in">str</span>((<span class="variable language_">self</span>.niter - <span class="number">1</span>) * (tic - toc)))</span><br><span class="line">        <span class="built_in">getattr</span>(<span class="variable language_">self</span>, <span class="variable language_">self</span>.dataminimizing)()</span><br><span class="line"></span><br><span class="line">        x_rec_old = copy.deepcopy(x_rec)</span><br><span class="line">        x_rec = im3ddenoise(<span class="variable language_">self</span>.res, <span class="variable language_">self</span>.__numiter_tv__, <span class="number">1.</span> / lambdaForTv)</span><br><span class="line">        t_old = t</span><br><span class="line">        t = (<span class="number">1</span> + np.sqrt(<span class="number">1</span> + <span class="number">4</span> * t ** <span class="number">2</span>)) / <span class="number">2</span></span><br><span class="line">        <span class="variable language_">self</span>.res = x_rec + (t_old - <span class="number">1</span>) / t * (x_rec - x_rec_old)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.error_measurement(res_prev, i)</span><br></pre></td></tr></table></figure>

<p>在Python2.X的版本中，如果定义的函数暂时什么都不做，那么需要使用pass关键字作为点位符，或者添加Docstrings，但不可以直接添加一行单行注释，示例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">functionNull</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;空函数在Python2.x版本中pass是必须的&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">functionNull</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;在Python3.x的时候pass可以写或不写&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h3 id="调用函数"><a href="#调用函数" class="headerlink" title="调用函数"></a>调用函数</h3><p>调用函数也就是执行函数，调用函数的基本语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">functionNmae(parameterValue)</span><br></pre></td></tr></table></figure>

<p>共包括两个基本元素：</p>
<ul>
<li>functionName: 函数名称，要调用的函数名称必须是已经创建好的。</li>
<li>parameterValue: 指定函数需求输入的各个参数的值。如果有多个参数，则各参数间使用逗号<code>,</code>分隔；如函数无需参数输入，也必须写一对小括号在此。</li>
</ul>
<p>例如调用一个向终端输出两个随机变量之和的Python函数示例如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">myfunction</span>():</span><br><span class="line">	a = rand()</span><br><span class="line">	b = rand()</span><br><span class="line">    <span class="built_in">print</span>(a+b)</span><br><span class="line"></span><br><span class="line">myfunction()</span><br></pre></td></tr></table></figure>

<p>在Python中我们可以使用<code>return</code>关键字，从函数中向外反馈一些参数。<code>return</code>语句可以包含一个要执行的表达式。下面的例子演示了<code>return</code>关键字在 Python 中的作用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">multiplyNum</span>(<span class="params">num1</span>):</span><br><span class="line">    <span class="keyword">return</span> num1 * <span class="number">8</span></span><br><span class="line"></span><br><span class="line">result = multiplyNum(<span class="number">8</span>)</span><br><span class="line"><span class="built_in">print</span>(result)      <span class="comment"># 输出：64</span></span><br></pre></td></tr></table></figure>

<h3 id="函数中的参数"><a href="#函数中的参数" class="headerlink" title="函数中的参数"></a>函数中的参数</h3><p>在 Python 中，你也可以定义包含若干参数的函数。这里有三种可用的形式，也可以混合使用。第一种就是规规矩矩的按照位置准确传递参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask_ok</span>(<span class="params">prompt, retries, complaint</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        ok = <span class="built_in">input</span>(prompt)</span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;ye&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;nop&#x27;</span>, <span class="string">&#x27;nope&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        retries = retries - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> retries &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> OSError(<span class="string">&#x27;uncooperative user&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(complaint)</span><br><span class="line"></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;Come on, only yes or no!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="默认参数值"><a href="#默认参数值" class="headerlink" title="默认参数值"></a>默认参数值</h3><p>此外最常用的一种形式是为一个或多个参数指定默认值。这会创建一个可以使用比定义时允许的参数更少的参数调用的函数，例如:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ask_ok</span>(<span class="params">prompt, retries=<span class="number">4</span>, complaint=<span class="string">&#x27;Yes or no, please!&#x27;</span></span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        ok = <span class="built_in">input</span>(prompt)</span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;ye&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> ok <span class="keyword">in</span> (<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;nop&#x27;</span>, <span class="string">&#x27;nope&#x27;</span>):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        retries = retries - <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> retries &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> OSError(<span class="string">&#x27;uncooperative user&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(complaint)</span><br></pre></td></tr></table></figure>

<p>这个函数可以通过几种不同的方式调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 只给出必要的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;Do you really want to quit?&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给出一个可选的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者给出所有的参数:</span></span><br><span class="line">ask_ok(<span class="string">&#x27;OK to overwrite the file?&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;Come on, only yes or no!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这个例子还介绍了<code>in</code>关键字。它测定序列中是否包含某个确定的值。</p>
<p>默认值在函数定义作用域被解析，如下所示:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">arg=i</span>):</span><br><span class="line">    <span class="built_in">print</span>(arg)</span><br><span class="line"></span><br><span class="line">i = <span class="number">6</span></span><br><span class="line">f()      <span class="comment"># 将会输出 5。</span></span><br></pre></td></tr></table></figure>

<p>重要警告: 默认值只被赋值一次。这使得当默认值是可变对象时会有所不同，比如列表、字典或者大多数类的实例。例如，下面的函数在后续调用过程中会累积（前面）传给它的参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a, L=[]</span>):</span><br><span class="line">    L.append(a)</span><br><span class="line">    <span class="keyword">return</span> L</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(f(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[<span class="number">1</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p>如果你不想让默认值在后续调用中累积，你可以像下面一样定义函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">a, L=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> L <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        L = []</span><br><span class="line">    L.append(a)</span><br><span class="line">    <span class="keyword">return</span> L</span><br></pre></td></tr></table></figure>

<h3 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h3><p>函数可以通过 关键字参数 的形式来调用，形如 <code>keyword = value</code>。例如，以下的函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parrot</span>(<span class="params">voltage, state=<span class="string">&#x27;a stiff&#x27;</span>, action=<span class="string">&#x27;voom&#x27;</span>, <span class="built_in">type</span>=<span class="string">&#x27;Norwegian Blue&#x27;</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- This parrot wouldn&#x27;t&quot;</span>, action, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;if you put&quot;</span>, voltage, <span class="string">&quot;volts through it.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- Lovely plumage, the&quot;</span>, <span class="built_in">type</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- It&#x27;s&quot;</span>, state, <span class="string">&quot;!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>接受一个必选参数 (voltage) 以及三个可选参数 (state, action, 和 type)。可以用以下的任一方法调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parrot(<span class="number">1000</span>)                                          <span class="comment"># 1 positional argument</span></span><br><span class="line">parrot(voltage=<span class="number">1000</span>)                                  <span class="comment"># 1 keyword argument</span></span><br><span class="line">parrot(voltage=<span class="number">1000000</span>, action=<span class="string">&#x27;VOOOOOM&#x27;</span>)             <span class="comment"># 2 keyword arguments</span></span><br><span class="line">parrot(action=<span class="string">&#x27;VOOOOOM&#x27;</span>, voltage=<span class="number">1000000</span>)             <span class="comment"># 2 keyword arguments</span></span><br><span class="line">parrot(<span class="string">&#x27;a million&#x27;</span>, <span class="string">&#x27;bereft of life&#x27;</span>, <span class="string">&#x27;jump&#x27;</span>)         <span class="comment"># 3 positional arguments</span></span><br><span class="line">parrot(<span class="string">&#x27;a thousand&#x27;</span>, state=<span class="string">&#x27;pushing up the daisies&#x27;</span>)  <span class="comment"># 1 positional, 1 keyword</span></span><br></pre></td></tr></table></figure>

<p>不过以下几种调用是无效的:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parrot()                     <span class="comment"># required argument missing</span></span><br><span class="line">parrot(voltage=<span class="number">5.0</span>, <span class="string">&#x27;dead&#x27;</span>)  <span class="comment"># non-keyword argument after a keyword argument</span></span><br><span class="line">parrot(<span class="number">110</span>, voltage=<span class="number">220</span>)     <span class="comment"># duplicate value for the same argument</span></span><br><span class="line">parrot(actor=<span class="string">&#x27;John Cleese&#x27;</span>)  <span class="comment"># unknown keyword argument</span></span><br></pre></td></tr></table></figure>

<p>在函数调用中，关键字的参数必须跟随在位置参数的后面。传递的所有关键字参数必须与函数接受的某个参数相匹配 （例如 actor 不是 parrot 函数的有效参数），它们的顺序并不重要。这也包括非可选参数（例如 parrot(voltage&#x3D;1000) 也是有效的）。任何参数都不可以多次赋值。下面的示例由于这种限制将失败:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; def <span class="keyword">function</span>(a):</span></span><br><span class="line">...     pass</span><br><span class="line">...</span><br><span class="line"><span class="meta prompt_">&gt;</span><span class="language-bash">&gt;&gt; <span class="keyword">function</span>(0, a=0)</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in ?</span><br><span class="line">TypeError: function() got multiple values for keyword argument &#x27;a&#x27;</span><br></pre></td></tr></table></figure>

<p>以下为可选阅读：</p>
<p>引入一个形如 <code>**name</code> 的参数时，它接收一个字典（参见 下一小节 ），该字典包含了所有未出现在形式参数列表中的关键字参数。这里可能还会组合使用一个形如 <code>*name</code> （下一小节详细介绍） 的形式参数，它接收一个元组（下一节中会详细介绍），包含了所有没有出现在形式参数列表中的参数值（ <code>*name</code> 必须在 <code>**name</code> 之前出现）。 例如，我们这样定义一个函数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cheeseshop</span>(<span class="params">kind, *arguments, **keywords</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- Do you have any&quot;</span>, kind, <span class="string">&quot;?&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-- I&#x27;m sorry, we&#x27;re all out of&quot;</span>, kind)</span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> arguments:</span><br><span class="line">        <span class="built_in">print</span>(arg)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">40</span>)</span><br><span class="line">    keys = <span class="built_in">sorted</span>(keywords.keys())</span><br><span class="line">    <span class="keyword">for</span> kw <span class="keyword">in</span> keys:</span><br><span class="line">        <span class="built_in">print</span>(kw, <span class="string">&quot;:&quot;</span>, keywords[kw])</span><br></pre></td></tr></table></figure>

<p>它可以像这样调用:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cheeseshop(<span class="string">&quot;Limburger&quot;</span>, <span class="string">&quot;It&#x27;s very runny, sir.&quot;</span>,</span><br><span class="line">           <span class="string">&quot;It&#x27;s really very, VERY runny, sir.&quot;</span>,</span><br><span class="line">           shopkeeper=<span class="string">&quot;Michael Palin&quot;</span>,</span><br><span class="line">           client=<span class="string">&quot;John Cleese&quot;</span>,</span><br><span class="line">           sketch=<span class="string">&quot;Cheese Shop Sketch&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>当然它会按如下内容打印:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">-- Do you have <span class="built_in">any</span> Limburger ?</span><br><span class="line">-- I<span class="string">&#x27;m sorry, we&#x27;</span>re <span class="built_in">all</span> out of Limburger</span><br><span class="line">It<span class="string">&#x27;s very runny, sir.</span></span><br><span class="line"><span class="string">It&#x27;</span>s really very, VERY runny, sir.</span><br><span class="line">----------------------------------------</span><br><span class="line">client : John Cleese</span><br><span class="line">shopkeeper : Michael Palin</span><br><span class="line">sketch : Cheese Shop Sketch</span><br></pre></td></tr></table></figure>

<p>注意在打印关键字参数之前，通过对关键字字典<code>keys()</code>方法的结果进行排序，生成了关键字参数名的列表；如果不这样做，打印出来的参数的顺序是未定义的。</p>
<h3 id="可变参数列表"><a href="#可变参数列表" class="headerlink" title="可变参数列表"></a>可变参数列表</h3><p>最后，一个最不常用的选择是可以让函数调用可变个数的参数。这些参数被包装进一个元组。在这些可变个数的参数之前，可以有零到多个普通的参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">write_multiple_items</span>(<span class="params">file, separator, *args</span>):</span><br><span class="line">    file.write(separator.join(args))</span><br></pre></td></tr></table></figure>

<p>通常，这些 可变 参数是参数列表中的最后一个，因为它们将把所有的剩余输入参数传递给函数。任何出现在<code>*args</code>后的参数是关键字参数，这意味着，他们只能被用作关键字，而不是位置参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">concat</span>(<span class="params">*args, sep=<span class="string">&quot;/&quot;</span></span>):</span><br><span class="line"><span class="meta">... </span>   <span class="keyword">return</span> sep.join(args)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>concat(<span class="string">&quot;earth&quot;</span>, <span class="string">&quot;mars&quot;</span>, <span class="string">&quot;venus&quot;</span>)</span><br><span class="line"><span class="string">&#x27;earth/mars/venus&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>concat(<span class="string">&quot;earth&quot;</span>, <span class="string">&quot;mars&quot;</span>, <span class="string">&quot;venus&quot;</span>, sep=<span class="string">&quot;.&quot;</span>)</span><br><span class="line"><span class="string">&#x27;earth.mars.venus&#x27;</span></span><br></pre></td></tr></table></figure>

<p>另一种形式是<code>**arg</code>作为关键词，表示接受任意多个显式赋值的实际参数，并将其放在一个字典之中。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">bar</span>(<span class="params">param1, **param2</span>):</span><br><span class="line">        <span class="built_in">print</span> param1</span><br><span class="line">        <span class="built_in">print</span> param2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bar(<span class="number">1</span>,a=<span class="number">2</span>,b=<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line">&#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>

<p>当然这两种用法可以同时出现在一个函数之中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, b=<span class="number">10</span>, *args, **kwargs</span>):</span><br><span class="line">        <span class="built_in">print</span> a</span><br><span class="line">        <span class="built_in">print</span> b</span><br><span class="line">        <span class="built_in">print</span> args</span><br><span class="line">        <span class="built_in">print</span> kwargs</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, e=<span class="number">5</span>, f=<span class="number">6</span>, g=<span class="number">7</span>)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span> <span class="number">4</span></span><br><span class="line">&#123;<span class="string">&#x27;e&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;g&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;f&#x27;</span>: <span class="number">6</span>&#125;</span><br></pre></td></tr></table></figure>


<h3 id="参数列表的分拆"><a href="#参数列表的分拆" class="headerlink" title="参数列表的分拆"></a>参数列表的分拆</h3><p>当大家在阅读如《Python从入门到精通》等丛书时，通常会介绍到当我们尝试把元组或字典直接输入给函数，可以分别使用<code>*arg</code>或<code>**arg</code>直接向函数输入。但这是为什么呢？</p>
<p>当你要传递的参数已经是一个列表，但要调用的函数却接受分开一个个的参数值。这时候你要把已有的列表拆开来。例如内建函数<code>range()</code>需要要独立的 start，stop参数。你可以在调用函数时加一个 * 操作符来自动把参数列表拆开:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">3</span>, <span class="number">6</span>))            <span class="comment"># normal call with separate arguments</span></span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>args = [<span class="number">3</span>, <span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(<span class="built_in">range</span>(*args))            <span class="comment"># call with arguments unpacked from a list</span></span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<p>以同样的方式，可以使用 <code>**</code> 操作符分拆关键字参数为字典:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">parrot</span>(<span class="params">voltage, state=<span class="string">&#x27;a stiff&#x27;</span>, action=<span class="string">&#x27;voom&#x27;</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;-- This parrot wouldn&#x27;t&quot;</span>, action, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;if you put&quot;</span>, voltage, <span class="string">&quot;volts through it.&quot;</span>, end=<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;E&#x27;s&quot;</span>, state, <span class="string">&quot;!&quot;</span>)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = &#123;<span class="string">&quot;voltage&quot;</span>: <span class="string">&quot;four million&quot;</span>, <span class="string">&quot;state&quot;</span>: <span class="string">&quot;bleedin&#x27; demised&quot;</span>, <span class="string">&quot;action&quot;</span>: <span class="string">&quot;VOOM&quot;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>parrot(**d)</span><br><span class="line">-- This parrot wouldn<span class="string">&#x27;t VOOM if you put four million volts through it. E&#x27;</span>s bleedin<span class="string">&#x27; demised !</span></span><br></pre></td></tr></table></figure>

<h3 id="Lambda-形式"><a href="#Lambda-形式" class="headerlink" title="Lambda 形式"></a>Lambda 形式</h3><p>出于实际需要，有几种通常在函数式编程语言例如 Lisp 中出现的功能加入到了 Python。通过<code>lambda</code>关键字，可以创建短小的匿名函数。这里有一个函数返回它的两个参数的和： lambda a, b: a+b。 Lambda 形式可以用于任何需要的函数对象。出于语法限制，它们只能有一个单独的表达式。语义上讲，它们只是普通函数定义中的一个语法技巧。类似于嵌套函数定义，lambda 形式可以从外部作用域引用变量:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">make_incrementor</span>(<span class="params">n</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> <span class="keyword">lambda</span> x: x + n</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = make_incrementor(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f(<span class="number">0</span>)</span><br><span class="line"><span class="number">42</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f(<span class="number">1</span>)</span><br><span class="line"><span class="number">43</span></span><br></pre></td></tr></table></figure>


<h3 id="函数中的参数传递深入解析"><a href="#函数中的参数传递深入解析" class="headerlink" title="函数中的参数传递深入解析"></a>函数中的参数传递深入解析</h3><p>在Python中定义一个函数时，可以通过把参数放在括号内将它们传入函数。调用函数时，需要为参数指定一个值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">addNum</span>(<span class="params">num1, num2</span>):</span><br><span class="line">    <span class="built_in">print</span>(num1 + num2)</span><br><span class="line"></span><br><span class="line">addNum(<span class="number">2</span>,<span class="number">4</span>)       <span class="comment"># 输出：6</span></span><br></pre></td></tr></table></figure>

<p>在上面的例子中，我向名为<code>addNum</code>的函数传递了两个参数，该函数将两个参数的和输出至终端。</p>
<h4 id="定位参数、关键字参数"><a href="#定位参数、关键字参数" class="headerlink" title="定位参数、关键字参数"></a>定位参数、关键字参数</h4><p>在Python中，当定义一个函数时，函数接收的参数叫做形式参数（parameters），以下简称形参；当调用一个函数时，调用语句传递给该函数的值叫做实际参数（arguments），以下简称实参。</p>
<p>根据<a href="https://docs.python.org/3/library/inspect.html">$\lfloor$inspect模块$\rceil$</a> 的描述，Python的形参可以分成如下五类：</p>
<ul>
<li><code>POSITIONAL_OR_KEYWORD</code>，默认类型，可通过定位&#x2F;关键字实参传递；</li>
<li><code>VAR_POSITIONAL</code>，定位形参元祖，如<code>*args</code>，捕获剩下的定位实参；</li>
<li><code>KEYWORD_ONLY</code>，在<code>*</code>或<code>*args</code>之后的形参，只能通过关键字实参传递；</li>
<li><code>VAR_KEYWORD</code>，关键字形参字典，如<code>**kwargs</code>，捕获剩下的关键字实参；</li>
<li><code>POSITIONAL_ONLY</code>，只能通过定位实参传递，Python语法暂不支持，只有一些C函数（如divmod）使用。</li>
</ul>
<p>比如定义如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *args</span>):</span><br><span class="line">    <span class="built_in">print</span>(a, args)</span><br></pre></td></tr></table></figure>

<p>其中形参a属于<code>POSITIONAL_OR_KEYWORD</code>，可通过定位&#x2F;关键字实参传递：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span> ()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(a=<span class="number">1</span>)</span><br><span class="line"><span class="number">1</span> ()</span><br></pre></td></tr></table></figure>

<p>满足形参<code>a</code>之后，剩余的定位实参将被<code>*args</code>以元组的形式捕获：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> (<span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>再比如定义如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *args, b, **kwargs</span>):</span><br><span class="line">    <span class="built_in">print</span>(a, args, b, kwargs)</span><br></pre></td></tr></table></figure>

<p>形参b属于KEYWORD_ONLY，因为它在<code>*args</code>之后定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>满足形参b之后，剩余的关键字实参将被<code>**kwargs</code>以字典的形式捕获：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>, c=<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;<span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果想定义<code>KEYWORD_ONLY</code>形参，但不想使用<code>VAR_POSITIONAL</code>形参（即<code>*args</code>），则可以在定义函数时单独的<code>*</code>号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a, *, b</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(a, b)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, b=<span class="number">2</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: foo() takes <span class="number">1</span> positional argument but <span class="number">2</span> were given</span><br></pre></td></tr></table></figure>

<h4 id="参数默认值"><a href="#参数默认值" class="headerlink" title="参数默认值"></a>参数默认值</h4><p>在定义函数时，我们可以给形参指定默认值，比如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(a, args, b, kwargs)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">1</span> () <span class="number">2</span> &#123;&#125;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，形参的默认值存储在函数对象的__defaults__和__kwdefaults__属性里，而不是每次调用函数时动态生成，所以最好不要用可变对象充当形参的默认值。下面的例子就是反面教材：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">param=[]</span>):</span><br><span class="line"><span class="meta">... </span>    param.append(<span class="number">1</span>)</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="built_in">id</span>(param), param)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">id</span>(foo.__defaults__[<span class="number">0</span>]), foo.__defaults__[<span class="number">0</span>])</span><br><span class="line"><span class="number">140009169940232</span> []</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">140009169940232</span> [<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo()</span><br><span class="line"><span class="number">140009169940232</span> [<span class="number">1</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<h4 id="获取关于参数的信息"><a href="#获取关于参数的信息" class="headerlink" title="获取关于参数的信息"></a>获取关于参数的信息</h4><p>内省指程序在运行时检查对象类型的一种能力，本节介绍的内容就属于函数内省的范围。假设有如下函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs</span>):</span><br><span class="line">    c = a</span><br><span class="line">    <span class="built_in">print</span>(c, args, b, kwargs)</span><br></pre></td></tr></table></figure>

<p>就像上一节中提到的，<code>foo</code>函数有<code>__defaults__</code>、<code>__kwdefaults__</code>属性，用于记录定位参数和关键字参数的默认值；有<code>__code__</code>属性，存储函数编译后的字节码信息，其中就包括参数的名称。通过这些属性，我们可以获取关于函数参数的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__defaults__</span><br><span class="line">(<span class="number">1</span>,)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__kwdefaults__</span><br><span class="line">&#123;<span class="string">&#x27;b&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_varnames  <span class="comment"># 参数&amp;局部变量名称</span></span><br><span class="line">(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;args&#x27;</span>, <span class="string">&#x27;kwargs&#x27;</span>, <span class="string">&#x27;c&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_argcount  <span class="comment"># 定位参数数量</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>foo.__code__.co_kwonlyargcount  <span class="comment"># 仅限关键字参数数量</span></span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>但这样还是太原始、太不方便了。幸好，我们有更好的选择：Python内置的inspect模块。下面这个例子就提取了<code>foo</code>函数的签名，然后获取函数的参数信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> inspect <span class="keyword">import</span> signature</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sig = signature(foo)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sig</span><br><span class="line">&lt;Signature (a=<span class="number">1</span>, *args, b=<span class="number">2</span>, **kwargs)&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name, param <span class="keyword">in</span> sig.parameters.items():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;<span class="built_in">str</span>(param.kind):&lt;<span class="number">21</span>&#125;</span> : <span class="subst">&#123;param.name:&lt;<span class="number">6</span>&#125;</span> = <span class="subst">&#123;param.default&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">POSITIONAL_OR_KEYWORD : a      = <span class="number">1</span></span><br><span class="line">VAR_POSITIONAL        : args   = &lt;<span class="keyword">class</span> <span class="string">&#x27;inspect._empty&#x27;</span>&gt;</span><br><span class="line">KEYWORD_ONLY          : b      = <span class="number">2</span></span><br><span class="line">VAR_KEYWORD           : kwargs = &lt;<span class="keyword">class</span> <span class="string">&#x27;inspect._empty&#x27;</span>&gt;</span><br></pre></td></tr></table></figure>

<p>同时，inspect.Signature对象还有一个bind方法，该方法可以将一些对象绑定到函数的形参上，就像Python解释器在调用函数时做的那样。通过这种方法，框架可以在真正执行函数前验证参数，就像下面这个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>bound = sig.bind(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, c=<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name, value <span class="keyword">in</span> bound.arguments.items():</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name:&lt;<span class="number">6</span>&#125;</span> = <span class="subst">&#123;value&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">a      = <span class="number">1</span></span><br><span class="line">args   = (<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">kwargs = &#123;<span class="string">&#x27;c&#x27;</span>: <span class="number">3</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>bound = sig.bind(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, a=<span class="number">4</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File ...</span><br><span class="line">TypeError: multiple values <span class="keyword">for</span> argument <span class="string">&#x27;a&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="函数参数传递"><a href="#函数参数传递" class="headerlink" title="函数参数传递"></a>函数参数传递</h4><p>说起函数参数传递，可能就有人想起了引用传递、值传递……忘掉这两个概念，来看看下面两个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo1</span>(<span class="params">param: <span class="built_in">list</span></span>):</span><br><span class="line">    param += [<span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">arg1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">foo1(arg1)</span><br><span class="line"><span class="built_in">print</span>(arg1)  <span class="comment"># 输出[1, 2, 3, 4, 5]</span></span><br></pre></td></tr></table></figure>

<p>内存中有一个<code>list</code>对象（[1, 2, 3]），该对象有两个别名：<code>arg1</code>和<code>param</code>。由于<code>list</code>对象是可变的（mutable），所以可以通过<code>param</code>这个别名修改这个<code>list</code>对象的内容。</p>
<img src="https://www.yooo.ltd/images/2020/07/04/list.webp" width="75%" alt="参数传递示例01" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">foo2</span>(<span class="params">param: <span class="built_in">tuple</span></span>):</span><br><span class="line">    param += (<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">arg2 = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">foo2(arg2)</span><br><span class="line"><span class="built_in">print</span>(arg2)  <span class="comment"># 输出(1, 2, 3)</span></span><br></pre></td></tr></table></figure>

<p>内存中有一个<code>tuple</code>对象（(1, 2, 3)），该对象也有两个别名：<code>arg2</code>和<code>param</code>。但由于<code>tuple</code>对象是不可变的(immutable)，当执行param +&#x3D; (4, 5)时，解释器创建了一个新的<code>tuple</code>对象（(1, 2, 3, 4, 5)），并让<code>param</code>指向这个新的对象，而原来的对象没有被改变。</p>
<img src="https://www.yooo.ltd/images/2020/07/04/tuple.webp" width="75%" alt="参数传递示例02" align=center />

<p>在Python中，参数传递本质上是为已有的对象取了一个函数作用域级别的别名。如果该对象是可变的，那么就可以在函数内修改该对象，这种修改也可以被其它的别名所感知。弄清楚对象、别名的关系，就不会对值传递、引用传递这种说法感到困惑了。</p>
<h2 id="NumPy初步"><a href="#NumPy初步" class="headerlink" title="NumPy初步"></a>NumPy初步</h2><p>NumPy是Python中科学计算的基本软件包。它是一个Python库，提供多维数组对象，各种派生对象（例如蒙版数组和矩阵）以及各种例程，用于对数组进行快速操作，包括数学，逻辑，形状处理，排序，选择，I&#x2F;O，离散傅立叶变换，基本线性代数，基本统计运算，随机模拟等等。</p>
<h3 id="NumPy安装"><a href="#NumPy安装" class="headerlink" title="NumPy安装"></a>NumPy安装</h3><p>安装NumPy的唯一前提是Python本身。而Python官网上的发行版是不包含NumPy模块的。如果你希望以最简单的方式开始使用，建议你使用Anaconda发行版，它包括Python，NumPy和许多其他用于科学计算和数据科学常用的软件包。同时支持Linux、Windows和mac。</p>
<p>如果你没有NumPy，在windows平台的cmd窗口可以通过如下命令执行安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy</span><br></pre></td></tr></table></figure>

<p>默认情况使用国外线路，如果太慢，我们使用清华的镜像就可以:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>Mac 系统的 Homebrew 不包含 NumPy 或其他一些科学计算包，同样可以采用以下方式进行安装。打开终端，输入：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip3 install numpy -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>完成安装后，你可以进行验证：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure>

<p>NumPy的历史可以追溯到90年代中期，它的前身为Numeric（用C语言编写，主要用来调取C++中应用）和Numarray（用于处理高维数组，可灵活的索引、数据类型变换、广播等），2005年出现的NumPy作为继承者，吸取了Numeric中丰富的C API及Numarray的高维数组处理能力，成为Python科学计算生态系统的基础。追根溯源，NumPy是集成在Python编程语言中的向量化运算工具集，如果你是用的是Intel的CPU，它将直接调用MKL库执行C语言的向量计算库，这是目前速度最快的向量计算库。</p>
<p>将大规模向量、矩阵运算交给NumPy如果对数组进行向量化运算，例如全体四则运算、矩阵乘法、求和、按指标求和等，一定要利用NumPy的矩阵运算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(<span class="number">1000000</span>)    <span class="comment"># 创建两个百万维的数组</span></span><br><span class="line">b = np.random.rand(<span class="number">1000000</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">begin = time.time()            <span class="comment"># 分别用np.dot和for循环对两个数组进行点乘</span></span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用np.dot方法(向量化)用的时间:&#123;&#125; ms.&quot;</span>.<span class="built_in">format</span>(<span class="number">1000</span>*(end-begin)))</span><br><span class="line"></span><br><span class="line">c = <span class="number">0</span></span><br><span class="line">begin = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">1000000</span>):</span><br><span class="line">    c += a[i]*b[i]</span><br><span class="line">end = time.time()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用for循环用的时间:&#123;&#125; ms.&quot;</span>.<span class="built_in">format</span>(<span class="number">1000</span>*(end-begin)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">249715.57341423497</span></span><br><span class="line">使用np.dot方法(向量化)用的时间:<span class="number">1.9905567169189453</span> ms.</span><br><span class="line"><span class="number">249715.57341423733</span></span><br><span class="line">使用<span class="keyword">for</span>循环用的时间:<span class="number">1073.1749534606934</span> ms.</span><br></pre></td></tr></table></figure>


<h2 id="Python-代码的性能分析"><a href="#Python-代码的性能分析" class="headerlink" title="Python 代码的性能分析"></a>Python 代码的性能分析</h2><p>我们怎样知道执行某个Python文件、某个函数、某段代码所耗费的总体时间？</p>
<p>作为样例，本文使用slow_func.py来进行性能分析，内容如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)  <span class="comment"># 等待一秒</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> ** <span class="number">24</span>):</span><br><span class="line">        random.random()  <span class="comment"># 生成1600万个随机数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    func1()</span><br><span class="line">    func2()</span><br></pre></td></tr></table></figure>

<p>函数func1和func2的区别在于：CPU在执行func1时基本处在闲置状态，在执行func2()时基本处于忙碌状态。这点会在之后的测试中有所体现。在笔者的测试平台（Ubuntu 18.04+Python 3.6）上，两个函数所耗费的时间均在1s左右。</p>
<h3 id="time命令"><a href="#time命令" class="headerlink" title="time命令"></a>time命令</h3><p>类UNIX平台提供了time命令以统计执行执行命令所花费的时间。当然，这是一个通用型的工具，而不局限于Python。</p>
<p>执行如下shell命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">time python3 slow_func.py</span><br></pre></td></tr></table></figure>

<p>获得如下结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">real	0m1.960s  # 命令执行时间</span><br><span class="line">user	0m0.946s  # 用户态CPU时间</span><br><span class="line">sys 	0m0.008s</span><br></pre></td></tr></table></figure>

<p>根据前两行结果中我们可以得知，slow_func.py从开始到结束共消耗了2秒左右的时间，但实际消耗的用户态CPU时间只有1秒左右。这是因为CPU在执行func1()时处于等待状态（sleep），这段时间里是不消耗CPU时间的。</p>
<h3 id="time库"><a href="#time库" class="headerlink" title="time库"></a>time库</h3><p>Python提供了标准库time来进行关于时间的操作，我们可以通过这个库来测量代码执行所耗费的时间。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> slow_func <span class="keyword">import</span> func1, func2</span><br><span class="line"></span><br><span class="line">start1, start2 = time.perf_counter(), time.process_time()</span><br><span class="line">func1()</span><br><span class="line">func2()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;perf_counter: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(time.perf_counter() - start1))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;process_time: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(time.process_time() - start2))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;获得如下结果：&quot;&quot;&quot;</span></span><br><span class="line">perf_counter: <span class="number">2.1201</span>s</span><br><span class="line">process_time: <span class="number">1.1119</span>s</span><br></pre></td></tr></table></figure>

<p>time.perf_counter()的时间差是代码开始与代码结束两个时间点的时间差，而time.process_time()的时间差是消耗的CPU时间长度，所以得出了不同的结果，这与先前的time命令的原因和结果相类似。</p>
<h3 id="time库-上下文管理器"><a href="#time库-上下文管理器" class="headerlink" title="time库+上下文管理器"></a>time库+上下文管理器</h3><p>上面提到的用time库来测量代码耗时用起来很方便，但如果经常要用到的话写起来也很繁琐。这时我们可以写一个自定义的上下文管理器来避免重复代码。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> contextmanager</span><br><span class="line"></span><br><span class="line"><span class="meta">@contextmanager</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_block</span>(<span class="params">label</span>):  <span class="comment"># 代码块计时上下文管理器</span></span><br><span class="line">    <span class="comment"># 进入上下文</span></span><br><span class="line">    start = time.perf_counter()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">yield</span>  <span class="comment"># 执行代码块</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="comment"># 执行完成后输出代码块耗时</span></span><br><span class="line">        used = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125;: &#123;:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(label, used))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用法</span></span><br><span class="line"><span class="keyword">with</span> time_block(<span class="string">&#x27;sleep&#x27;</span>):</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line">sleep: <span class="number">1.0011</span>s</span><br></pre></td></tr></table></figure>

<h3 id="time库-函数装饰器"><a href="#time库-函数装饰器" class="headerlink" title="time库+函数装饰器"></a>time库+函数装饰器</h3><p>上下文管理器针对的是代码块，如果只想统计函数执行所消耗的时间，用函数装饰器更为方便和快捷。</p>
<p>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_wrap</span>(<span class="params">func</span>):  <span class="comment"># 函数计时装饰器</span></span><br><span class="line"><span class="meta">    @wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        start = time.perf_counter()</span><br><span class="line">        r = func(*args, **kwargs)</span><br><span class="line">        used = time.perf_counter() - start</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&#123;f.__module__&#125;.&#123;f.__name__&#125;: &#123;t:.4f&#125;s&#x27;</span>.<span class="built_in">format</span>(f=func, t=used))</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@time_wrap  </span><span class="comment"># 函数定义时使用装饰器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">slow_func</span>():</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行函数时自动调用装饰器</span></span><br><span class="line">slow_func()</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line">__main__.slow_func: <span class="number">1.0008</span>s</span><br></pre></td></tr></table></figure>

<h3 id="timeit库"><a href="#timeit库" class="headerlink" title="timeit库"></a>timeit库</h3><p>当需要多次重复测量Python代时以获取精确的耗时结果时，我们可以通过循环控制配合上文提到的方法来实现，也可以通过一个更便捷的、适合重复测试的标准库：timeit来实现。</p>
<p>执行如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line">setup = <span class="string">&#x27;from slow_func import func1&#x27;</span></span><br><span class="line"></span><br><span class="line">used = timeit.timeit(<span class="string">&#x27;func1()&#x27;</span>, setup=setup, number=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(used))</span><br><span class="line">获得如下结果：</span><br><span class="line"></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">5.0039</span></span><br></pre></td></tr></table></figure>

<p>timeit库默认使用的计时器为time.perf_counter()，如果想换成测量CPU耗时的计时器，只需要附加上timer参数即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">timer = time.process_time</span><br><span class="line"></span><br><span class="line">used = timeit.timeit(<span class="string">&#x27;func1()&#x27;</span>, timer=timer, setup=setup, number=<span class="number">5</span>)  <span class="comment"># 附加timer参数</span></span><br></pre></td></tr></table></figure>

<h3 id="cProfile"><a href="#cProfile" class="headerlink" title="cProfile"></a>cProfile</h3><p>而在实际的性能分析场景中，目标代码的逻辑往往比较复杂，光靠总体执行耗时并不能帮助我们快速定位性能瓶颈。这个时候就需要请出Python的标准库：cProfile（官方文档）来对代码进行细致的性能分析了。</p>
<h4 id="命令行使用cProfile"><a href="#命令行使用cProfile" class="headerlink" title="命令行使用cProfile"></a>命令行使用cProfile</h4><p>对于单独的Python代码文件来说，通过命令行使用cProfile无疑是最方便的选择。</p>
<p>执行如下shell命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 -m cProfile -s tottime slow_func.py</span><br></pre></td></tr></table></figure>

<p>首先用python3的-m选项调用cProfile模块，然后用cProfile的-s选项让输出结果按tottime进行排序，最后执行slow_func.py文件。</p>
<p>完整调用格式为：<code>python -m cProfile [-o output_file] [-s sort_order] myscript.py</code></p>
<p>得到如下结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">        16778563 function calls (16778520 primitive calls) in 3.176 seconds</span><br><span class="line"></span><br><span class="line">  Ordered by: internal time</span><br><span class="line"></span><br><span class="line">  ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">       1    1.456    1.456    2.172    2.172 slow_func.py:8(func2)</span><br><span class="line">       1    1.001    1.001    1.001    1.001 &#123;built-in method time.sleep&#125;</span><br><span class="line">16777216    0.716    0.000    0.716    0.000 &#123;method &#x27;random&#x27; of &#x27;_random.Random&#x27; objects&#125;</span><br><span class="line">       1    0.001    0.001    0.001    0.001 &#123;built-in method _imp.create_dynamic&#125;</span><br><span class="line">       3    0.000    0.000    0.000    0.000 &#123;built-in method marshal.loads&#125;</span><br><span class="line">       # ...省略后续100多行</span><br></pre></td></tr></table></figure>

<ul>
<li>输出的第1行表明，脚本文件执行中存在1600多万次的函数调用，共耗费3.268秒。<br>** 而根据前一篇文章的测试结果，直接执行该脚本文件只需要2秒左右的时间，那多出来的1秒多花在了哪里？这是因为cProfile需要对每一次函数调用进行监控和记录，由于该文件存在较多的函数调用，所以总执行耗时也就增长了许多了。</li>
<li>第3行表明，下表内容按照internal time（内部执行时间，tottime）排序，这是由执行命令中的-s tottime参数决定的。</li>
<li>第5行为分析结果表的表头，依次为ncalls：调用次数、tottime：内部执行耗时、percall：内部执行耗时&#x2F;调用次数、cumtime：累计执行耗时、percall：累计执行耗时&#x2F;调用次数，以及最后的文件名+行号+函数名称。<br>** tottime和cumtime的区别在于，tottime不包括子函数执行所花费的时间，而cumtime是包括的。</li>
<li>第6行表明，slow_func.py中第8行的func2函数共执行了1次，内部耗时1.456秒，累计耗时2.172秒。</li>
<li>第7行表明，Python内置的sleep函数共执行了一次，耗时1.001秒。</li>
<li>第8行表明，Python内置的random函数共执行了1600多万次，耗时0.716秒。<br>** 由于random函数是被func2函数调用的，所以这0.716秒和func2函数的内部执行耗时1.456秒，共同组成了func2函数的累计执行耗时：2.172秒。</li>
<li>由于是用cProfile分析整个脚本文件，所以许多Python自身所需的函数调用也被展示在了结果里，所以分析结果表才会有100多行的规模。这个问题可以在下一小节中解决。</li>
</ul>
<h3 id="代码里使用cProfile"><a href="#代码里使用cProfile" class="headerlink" title="代码里使用cProfile"></a>代码里使用cProfile</h3><p>从本质上来说，通过命令行使用cProfile相当于在代码里使用cProfile的一个简化操作。而在命令行里分析代码有着明显的局限性：目标代码必须独立成文件、输出格式固定等等。所以，在代码里使用cProfile往往是一个更优的选择。<br>执行如下Python代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cProfile</span><br><span class="line"><span class="keyword">import</span> pstats</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> slow_func <span class="keyword">import</span> func1, func2</span><br><span class="line"></span><br><span class="line">profile = cProfile.Profile()</span><br><span class="line">profile.enable()  <span class="comment"># 分析开始</span></span><br><span class="line">func1()</span><br><span class="line">func2()</span><br><span class="line">profile.disable()  <span class="comment"># 分析结束</span></span><br><span class="line">ram_file = StringIO()</span><br><span class="line">sort_by = <span class="string">&#x27;tottime&#x27;</span></span><br><span class="line">stats = pstats.Stats(profile, stream=ram_file)  <span class="comment"># 读取结果</span></span><br><span class="line">stats.strip_dirs().sort_stats(sort_by).print_stats()  <span class="comment"># 按格式输出至ram_file</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ram_file.getvalue())</span><br></pre></td></tr></table></figure>

<p>代码的核心逻辑是使用cProfile模块的Profile类对代码块进行性能分析，分析完成后使用pstats模块的Stats类将分析结果按一定格式写入至内存文件，最后输出该文件里写入的内容。</p>
<p>实际上这只是一个较为简单的样例，pstats模块还可以获得函数之间的调用关系、将结果持久化、显示文件路径等等，更完整的说明可以参考官方文档。</p>
<p>得到如下结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">        16777220 function calls in 3.225 seconds</span><br><span class="line"></span><br><span class="line">  Ordered by: internal time</span><br><span class="line"></span><br><span class="line">  ncalls  tottime  percall  cumtime  percall filename:lineno(function)</span><br><span class="line">       1    1.517    1.517    2.224    2.224 slow_func.py:8(func2)</span><br><span class="line">       1    1.001    1.001    1.001    1.001 &#123;built-in method time.sleep&#125;</span><br><span class="line">16777216    0.707    0.000    0.707    0.000 &#123;method &#x27;random&#x27; of &#x27;_random.Random&#x27; objects&#125;</span><br><span class="line">       1    0.000    0.000    1.001    1.001 slow_func.py:5(func1)</span><br><span class="line">       1    0.000    0.000    0.000    0.000 &#123;method &#x27;disable&#x27; of &#x27;_lsprof.Profiler&#x27; objects&#125;</span><br></pre></td></tr></table></figure>

<h3 id="cProfile结果可视化"><a href="#cProfile结果可视化" class="headerlink" title="cProfile结果可视化"></a>cProfile结果可视化</h3><p>一般来说，通过以上两个例子就可以获得完善的性能分析报告了。但通过一些可视化工具对<code>cProfile</code>的报告进行二次处理，我们可以更清晰地观察函数之间的调用关系、更轻松地找出性能瓶颈，算是一个不错的辅助手段。在这里只介绍一种可视化工具：JetBrain PyCharm自带的Profile工具。</p>
<p>点击Pycharm中Run菜单里的Profile ‘xxx’项目，即可对当前运行执行方案使用cProfile进行性能分析，如下图：</p>
<img src="https://www.yooo.ltd/images/2019-03-08.01.png" width="45%" align=center />

<p>结果如下图所示。其中，Time对应cProfile中的cumtime，即累计执行耗时；Own Time对应cProfile中的tottime，即内部执行耗时。</p>
<img src="https://www.yooo.ltd/images/2019-03-08.02.png" width="95%" align=center />

<p>&emsp;</p>
<img src="https://www.yooo.ltd/images/2019-03-08.03.png" width="95%" align=center />]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 05：NumPy 数据分析进阶</title>
    <url>/PythonLes06/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程是第五周课程的延续，让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="导入数字和文本的数据集保持文本在numpy数组中完好无损"><a href="#导入数字和文本的数据集保持文本在numpy数组中完好无损" class="headerlink" title="导入数字和文本的数据集保持文本在numpy数组中完好无损"></a>导入数字和文本的数据集保持文本在numpy数组中完好无损</h2><p>问题：导入鸢尾属植物数据集，保持文本不变。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first 3 rows</span></span><br><span class="line">iris[:<span class="number">3</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<p>具体来说，dtype object是一种特殊的数据类型对象，它用于描述NumPy数组中元素的数据类型。通过指定dtype object，可以让NumPy数组支持更多的数据类型，例如复数、日期、字符串等。此外，dtype object还可以用于指定数据类型的大小、字节顺序等属性。</p>
<p>需要注意的是，使用dtype object会使得数组的运算速度变慢，因为每个元素都需要使用Python的解释器来执行运算，而不是使用NumPy的优化运算。因此，只有在必要的情况下才应该使用dtype object，否则应该尽量使用预定义的数据类型来提高数组的运算效率。</p>
<h2 id="从1维元组数组中提取特定列"><a href="#从1维元组数组中提取特定列" class="headerlink" title="从1维元组数组中提取特定列"></a>从1维元组数组中提取特定列</h2><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="将1维元组数组转换为2维NumPy数组"><a href="#将1维元组数组转换为2维NumPy数组" class="headerlink" title="将1维元组数组转换为2维NumPy数组"></a>将1维元组数组转换为2维NumPy数组</h2><p>问题：通过省略鸢尾属植物数据集种类的文本字段，将一维鸢尾属植物数据集转换为二维数组iris_2d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="comment"># Import only the first 4 columns from source url</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算numpy数组的均值，中位数，标准差"><a href="#计算numpy数组的均值，中位数，标准差" class="headerlink" title="计算numpy数组的均值，中位数，标准差"></a>计算numpy数组的均值，中位数，标准差</h2><p>问题：求出鸢尾属植物萼片长度的平均值、中位数和标准差(第1列)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">mu, med, sd = np.mean(sepallength), np.median(sepallength), np.std(sepallength)</span><br><span class="line"><span class="built_in">print</span>(mu, med, sd)</span><br><span class="line"><span class="comment"># &gt; 5.84333333333 5.8 0.825301291785</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.mean(a, axis=<span class="literal">None</span>, dtype=<span class="literal">None</span>, out=<span class="literal">None</span>, keepdims=&lt;no value&gt;, *, where=&lt;no value&gt;)</span><br><span class="line"><span class="comment"># Compute the arithmetic mean along the specified axis.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like数组，其中包含所需平均值的数字。如果a不是数组，则尝试转换。</li>
<li>axis: None或int或int元组，可选参数，计算平均值的轴向。默认值是计算平面化数组的平均值。</li>
<li>dtype: data-type，可选参数，用于计算平均值的类型。对于整数输入，默认值是float64；对于浮点输入，它与输入dtype相同。</li>
<li>out: narray，可选参数，用于放置结果的备用输出数组。默认为None；如果提供，它必须具有与预期输出相同的形状，但如果需要，将强制转换类型。</li>
<li>keepdims: bool，可选参数，如果设置为True，则减少的轴在结果中保留为大小为1的维度。使用此选项，结果将根据输入数组正确广播。如果传递默认值，则keepdim将不会传递给narray子类的mean方法，但任何非默认值将被传递。如果子类的方法没有实现keepdim，将引发任何异常。</li>
<li>where: array_like of bool，可选参数，判断计算平均值的元素。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], </span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">np.mean(a)</span><br><span class="line"><span class="number">2.5</span></span><br><span class="line">np.mean(a, axis=<span class="number">0</span>)</span><br><span class="line">array([<span class="number">2.</span>, <span class="number">3.</span>])</span><br><span class="line">np.mean(a, axis=<span class="number">1</span>)</span><br><span class="line">array([<span class="number">1.5</span>, <span class="number">3.5</span>])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">5</span>, <span class="number">9</span>, <span class="number">13</span>], [<span class="number">14</span>, <span class="number">10</span>, <span class="number">12</span>], [<span class="number">11</span>, <span class="number">15</span>, <span class="number">19</span>]])</span><br><span class="line">np.mean(a)</span><br><span class="line"><span class="number">12.0</span></span><br><span class="line">np.mean(a, where=[[<span class="literal">True</span>], [<span class="literal">False</span>], [<span class="literal">False</span>]])</span><br><span class="line"><span class="number">9.0</span></span><br></pre></td></tr></table></figure>

<h2 id="找到NumPy数组的百分位数"><a href="#找到NumPy数组的百分位数" class="headerlink" title="找到NumPy数组的百分位数"></a>找到NumPy数组的百分位数</h2><p>问题：找到鸢尾属植物数据集的第5和第95百分位数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.percentile(sepallength, q=[<span class="number">5</span>, <span class="number">95</span>])</span><br><span class="line"><span class="comment"># &gt; array([ 4.6  ,  7.255])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.percentile(a, q, axis=<span class="literal">None</span>, out=<span class="literal">None</span>, overwrite_input=<span class="literal">False</span>, method=<span class="string">&#x27;linear&#x27;</span>, keepdims=<span class="literal">False</span>, *, interpolation=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Compute the q-th percentile of the data along the specified axis.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like of real numbers, 可转换为数组的输入数组或对象。</li>
<li>q: array_like of float, 用于计算百分位数的百分比或百分比序列。取值必须在0到100之间。</li>
<li>axis: {int, int的元组，None}，可选参数，计算百分位数的轴向。默认值是沿数组的平面化版本计算百分位数。</li>
<li>overwrite_input: bool，可选参数，如果为True，则允许通过中间计算修改输入数组a，以节省内存。</li>
<li>method: str, 可选参数，此参数指定用于估计百分位数的方法。有许多不同的方法，其中一些是NumPy独有的。请参阅注释以获得解释，包括’inverted_cdf’ ‘averaged_inverted_cdf’ ‘closest_observation’ ‘interpolated_inverted_cdf’ ‘hazen’ ‘weibull’ ‘linear’(默认) ‘median_unbiased’ ‘normal_unbiased’等等。</li>
<li>keepdims: bool，可选如果设置为True，则减少的轴在结果中保留为大小为1的维度。使用此选项，结果将针对原始数组正确广播。</li>
</ul>
<h2 id="查找给定数组是否具有任何空值"><a href="#查找给定数组是否具有任何空值" class="headerlink" title="查找给定数组是否具有任何空值"></a>查找给定数组是否具有任何空值</h2><p>问题：找出iris_2d是否有任何缺失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">np.isnan(iris_2d).<span class="built_in">any</span>()</span><br><span class="line"><span class="comment"># &gt; False</span></span><br></pre></td></tr></table></figure>


<h2 id="在数组中的随机位置插入值"><a href="#在数组中的随机位置插入值" class="headerlink" title="在数组中的随机位置插入值"></a>在数组中的随机位置插入值</h2><p>问题：在iris_2d数据集中的20个随机位置插入np.nan值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到缺失值的位置"><a href="#在NumPy数组中找到缺失值的位置" class="headerlink" title="在NumPy数组中找到缺失值的位置"></a>在NumPy数组中找到缺失值的位置</h2><p>问题：在iris_2d的sepallength中查找缺失值的数量和位置（第1列）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of missing values: \n&quot;</span>, np.isnan(iris_2d[:, <span class="number">0</span>]).<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Position of missing values: \n&quot;</span>, np.where(np.isnan(iris_2d[:, <span class="number">0</span>])))</span><br><span class="line"><span class="comment"># &gt; Number of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  5</span></span><br><span class="line"><span class="comment"># &gt; Position of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  (array([ 39,  88,  99, 130, 147]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="根据两个或多个条件过滤NumPy数组"><a href="#根据两个或多个条件过滤NumPy数组" class="headerlink" title="根据两个或多个条件过滤NumPy数组"></a>根据两个或多个条件过滤NumPy数组</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">condition = (iris_2d[:, <span class="number">2</span>] &gt; <span class="number">1.5</span>) &amp; (iris_2d[:, <span class="number">0</span>] &lt; <span class="number">5.0</span>)</span><br><span class="line">iris_2d[condition]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.8,  3.4,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.4,  1.9,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.1,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.4,  3.3,  1. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.5,  4.5,  1.7]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组中删除包含缺失值的行"><a href="#从NumPy数组中删除包含缺失值的行" class="headerlink" title="从NumPy数组中删除包含缺失值的行"></a>从NumPy数组中删除包含缺失值的行</h2><p>问题：选择没有任何nan值的iris_2d行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct numpy function for this.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">any_nan_in_row = np.array([~np.<span class="built_in">any</span>(np.isnan(row)) <span class="keyword">for</span> row <span class="keyword">in</span> iris_2d])</span><br><span class="line">iris_2d[any_nan_in_row][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: (By Rong)</span></span><br><span class="line">iris_2d[np.<span class="built_in">sum</span>(np.isnan(iris_2d), axis = <span class="number">1</span>) == <span class="number">0</span>][:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5. ,  3.6,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5.4,  3.9,  1.7,  0.4]])</span></span><br></pre></td></tr></table></figure>

<h2 id="找到NumPy数组的两列之间的相关性"><a href="#找到NumPy数组的两列之间的相关性" class="headerlink" title="找到NumPy数组的两列之间的相关性"></a>找到NumPy数组的两列之间的相关性</h2><p>问题：在iris_2d中找出SepalLength（第1列）和PetalLength（第3列）之间的相关性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.corrcoef(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr  </span><br><span class="line">corr, p_value = pearsonr(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Correlation coef indicates the degree of linear relationship between two numeric variables.</span></span><br><span class="line"><span class="comment"># It can range between -1 to +1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The p-value roughly indicates the probability of an uncorrelated system producing </span></span><br><span class="line"><span class="comment"># datasets that have a correlation at least as extreme as the one computed.</span></span><br><span class="line"><span class="comment"># The lower the p-value (&lt;0.01), stronger is the significance of the relationship.</span></span><br><span class="line"><span class="comment"># It is not an indicator of the strength.</span></span><br><span class="line"><span class="comment"># &gt; 0.871754157305</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.corrcoef(x, y=<span class="literal">None</span>, rowvar=<span class="literal">True</span>, bias=&lt;no value&gt;, ddof=&lt;no value&gt;, *, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Return Pearson product-moment correlation coefficients.</span></span><br></pre></td></tr></table></figure>

<img src="https://www.jmp.com/zh_cn/statistics-knowledge-portal/reference-content/correlation-coefficient-formula/_jcr_content/par/image_a25b.img.png/1557786509536.png" width="60%" alt="一维数据相关系数计算方法" align=center />

<p>相关系数 $r$ 是一个介于 -1 和 1 之间的无单位的值。统计显著性以 $p$ 值表示。</p>
<ul>
<li>$r$ 越接近 0，线性关系越弱。</li>
<li>正的 $r$ 值表示正相关，在这种情况下，两个变量的值往往一起增加。</li>
<li>负的 $r$ 值表示负相关，在这种情况下，当一个变量的值增加时，另一个变量的值往往会减少。</li>
<li>值 1 和 -1 都代表“完美”的相关性，分别表示正相关和负相关。两个完美相关的变量会以固定的比率一起变化。我们说，它们有线性关系；当绘制在散点图上时，所有的数据点可以用一条直线连接。</li>
</ul>
<h2 id="在NumPy数组中用0替换所有缺失值"><a href="#在NumPy数组中用0替换所有缺失值" class="headerlink" title="在NumPy数组中用0替换所有缺失值"></a>在NumPy数组中用0替换所有缺失值</h2><p>问题：在NumPy数组中将所有出现的nan替换为0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">iris_2d[np.isnan(iris_2d)] = <span class="number">0</span></span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中查找唯一值的计数"><a href="#在NumPy数组中查找唯一值的计数" class="headerlink" title="在NumPy数组中查找唯一值的计数"></a>在NumPy数组中查找唯一值的计数</h2><p>问题：找出鸢尾属植物物种中的独特值和独特值的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Extract the species column as an array</span></span><br><span class="line">species = np.array([row.tolist()[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the unique values and the counts</span></span><br><span class="line">np.unique(species, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        dtype=&#x27;|S15&#x27;), array([50, 50, 50]))</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.unique(ar, return_index=<span class="literal">False</span>, return_inverse=<span class="literal">False</span>, return_counts=<span class="literal">False</span>, axis=<span class="literal">None</span>, *, equal_nan=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Return Pearson product-moment correlation coefficients.</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.unique()</code>函数返回数组中已排序的唯一元素。除了唯一元素之外，还有三个可选输出:</p>
<ul>
<li>给出唯一值的输入数组的索引</li>
<li>用于重建输入数组的唯一数组的索引</li>
<li>每个唯一值在输入数组中出现的次数</li>
</ul>
<p>输入参数：</p>
<ul>
<li>ar: array_like, 输入数组。除非指定了轴，否则如果它不是1-D，它将被平面化。</li>
<li>return_index: bool, 可选参数，如果为True，还返回ar的索引，从而产生唯一数组。</li>
<li>return_inverse: bool, 可选参数，如果为True，还返回可用于重建ar的唯一数组的索引。</li>
<li>return_counts: bool, 可选参数，如果为True，还返回每个唯一项在ar中出现的次数。</li>
<li>axis: int或None, 可选参数，要操作的轴。如果为None，ar将被扁平化。如果是整数，则由给定轴索引的子数组将被平面化，并被视为具有给定轴的维度的1-D数组的元素。</li>
<li>equal_nan: bool, 可选参数，如果为True，将返回数组中的多个NaN值折叠为一个。</li>
</ul>
<p>返回参数:</p>
<ul>
<li>unique: ndarray，排序后的唯一值。</li>
<li>unique_indices: ndarray, 可选参数，原始数组中唯一值第一次出现的索引。仅当return_index为True时提供。</li>
<li>unique_inverse: ndarray, 可选参数，从unique数组重构原始数组的索引。仅当return_inverse为True时提供。</li>
<li>unique_counts: ndarray, 可选参数，每个唯一值在原始数组中出现的次数。仅当return_counts为True时提供。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.unique([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">np.unique(a)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Return the unique rows of a 2D array</span></span><br><span class="line">a = np.array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;a&#x27;</span>])</span><br><span class="line">u, indices = np.unique(a, return_index=<span class="literal">True</span>)</span><br><span class="line">u</span><br><span class="line">array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line">indices</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">a[indices]</span><br><span class="line">array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reconstruct the input array from the unique values and inverse:</span></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">u, indices = np.unique(a, return_inverse=<span class="literal">True</span>)</span><br><span class="line">u</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">indices</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line">u[indices]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reconstruct the input values from the unique values and counts:</span></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">values, counts = np.unique(a, return_counts=<span class="literal">True</span>)</span><br><span class="line">values</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">counts</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">np.repeat(values, counts)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>])    <span class="comment"># original order not preserved</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到最常见的值"><a href="#在NumPy数组中找到最常见的值" class="headerlink" title="在NumPy数组中找到最常见的值"></a>在NumPy数组中找到最常见的值</h2><p>问题：在鸢尾属植物数据集中找到最常见的花瓣长度值（第3列）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">vals, counts = np.unique(iris[:, <span class="number">2</span>], return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vals[np.argmax(counts)])</span><br><span class="line"><span class="comment"># &gt; b&#x27;1.5&#x27;</span></span><br></pre></td></tr></table></figure>



<h2 id="将数字转换为分类（文本）数组"><a href="#将数字转换为分类（文本）数组" class="headerlink" title="将数字转换为分类（文本）数组"></a>将数字转换为分类（文本）数组</h2><p>问题：将iris_2d的花瓣长度（第3列）加入以形成文本数组，这样如果花瓣长度为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;= 3 --&gt; &#x27;small&#x27;</span><br><span class="line"> 3-5 --&gt; &#x27;medium&#x27;</span><br><span class="line">&#x27;&gt;=5 --&gt; &#x27;large&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bin petallength </span></span><br><span class="line">petal_length_bin = np.digitize(iris[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>), [<span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map it to respective category</span></span><br><span class="line">label_map = &#123;<span class="number">1</span>: <span class="string">&#x27;small&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;medium&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;large&#x27;</span>, <span class="number">4</span>: np.nan&#125;</span><br><span class="line">petal_length_cat = [label_map[x] <span class="keyword">for</span> x <span class="keyword">in</span> petal_length_bin]</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">petal_length_cat[:<span class="number">4</span>]</span><br><span class="line">&lt;<span class="comment"># &gt; [&#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;]</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组的现有列创建新列"><a href="#从NumPy数组的现有列创建新列" class="headerlink" title="从NumPy数组的现有列创建新列"></a>从NumPy数组的现有列创建新列</h2><p>问题：在iris_2d中创建一个新列，其数值通过其他列计算得到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Compute volume</span></span><br><span class="line">sepallength = iris_2d[:, <span class="number">0</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">petallength = iris_2d[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">volume = (np.pi * petallength * (sepallength**<span class="number">2</span>))/<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Introduce new dimension to match iris_2d&#x27;s</span></span><br><span class="line">volume = volume[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the new column</span></span><br><span class="line">out = np.hstack([iris_2d, volume])</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">out[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 38.13265162927291],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 35.200498485922445],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 30.0723720777127],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.6&#x27;, b&#x27;3.1&#x27;, b&#x27;1.5&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 33.238050274980004]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy中进行概率抽样"><a href="#在NumPy中进行概率抽样" class="headerlink" title="在NumPy中进行概率抽样"></a>在NumPy中进行概率抽样</h2><p>问题：随机抽样150组鸢尾属植物的数据，使得’Iris-setosa’的概率是’Iris-versicolor’和’Iris-virginica’的两倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species column</span></span><br><span class="line">species = iris[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 1: Generate Probablistically</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.array([<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>])</span><br><span class="line">species_out = np.random.choice(a, <span class="number">150</span>, p=[<span class="number">0.5</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 2: Probablistic Sampling (preferred)</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">probs = np.r_[np.linspace(<span class="number">0</span>, <span class="number">0.500</span>, num=<span class="number">50</span>), np.linspace(<span class="number">0.501</span>, <span class="number">.750</span>, num=<span class="number">50</span>), np.linspace(<span class="number">.751</span>, <span class="number">1.0</span>, num=<span class="number">50</span>)]</span><br><span class="line">index = np.searchsorted(probs, np.random.random(<span class="number">150</span>))</span><br><span class="line">species_out = species[index]</span><br><span class="line"><span class="built_in">print</span>(np.unique(species_out, return_counts=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;], dtype=object), array([77, 37, 36]))</span></span><br></pre></td></tr></table></figure>

<p>方法2是首选方法，因为它创建了一个索引变量，该变量可用于取样2维表格数据。</p>
<h2 id="在按另一个数组分组时获取数组的第二大值"><a href="#在按另一个数组分组时获取数组的第二大值" class="headerlink" title="在按另一个数组分组时获取数组的第二大值"></a>在按另一个数组分组时获取数组的第二大值</h2><p>问题：物种setosa中第二长的长度数值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species and petal length columns</span></span><br><span class="line">petal_len_setosa = iris[iris[:, <span class="number">4</span>] == <span class="string">b&#x27;Iris-setosa&#x27;</span>, [<span class="number">2</span>]].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the second last value</span></span><br><span class="line">np.unique(np.sort(petal_len_setosa))[-<span class="number">2</span>]</span><br><span class="line"><span class="comment"># &gt; 1.7</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.sort(a, axis=-<span class="number">1</span>, kind=<span class="literal">None</span>, order=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Return a sorted copy of an array.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 待排序的数组。</li>
<li>axis: int或None, 可选参数，排序所沿的轴向。如果为None，则在排序之前对数组进行扁平化。默认值是-1，它沿着最后一个轴排序。</li>
<li>kind: {‘quicksort’, ‘mergesort’, ‘heapsort’, ‘stable’}，可选参数，排序算法。默认值是‘quicksort’。</li>
<li>Order: str或str的列表，可选参数，当a是一个定义了字段的数组时，这个参数指定首先比较哪个字段。可以将单个字段指定为字符串，而不需要指定所有字段，但仍将使用未指定的字段，按照它们在dtype中出现的顺序，以打破关系。</li>
<li>sorted_array: ndarray，返回值，类型和形状与a相同的数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">4</span>],[<span class="number">3</span>,<span class="number">1</span>]])</span><br><span class="line">np.sort(a)                <span class="comment"># sort along the last axis</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">3</span>]])</span><br><span class="line">np.sort(a, axis=<span class="literal">None</span>)     <span class="comment"># sort the flattened array</span></span><br><span class="line">array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">np.sort(a, axis=<span class="number">0</span>)        <span class="comment"># sort along the first axis</span></span><br><span class="line">array([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>


<h2 id="按列对2D数组进行排序"><a href="#按列对2D数组进行排序" class="headerlink" title="按列对2D数组进行排序"></a>按列对2D数组进行排序</h2><p>问题：根据sepallength列对数据集进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sort by column position 0: SepalLength</span></span><br><span class="line"><span class="built_in">print</span>(iris[iris[:,<span class="number">0</span>].argsort()][:<span class="number">20</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;4.3&#x27; b&#x27;3.0&#x27; b&#x27;1.1&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.0&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;2.9&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.5&#x27; b&#x27;2.3&#x27; b&#x27;1.3&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.6&#x27; b&#x27;1.0&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.2&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.9&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.1&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.4&#x27; b&#x27;3.3&#x27; b&#x27;1.0&#x27; b&#x27;Iris-versicolor&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.5&#x27; b&#x27;4.5&#x27; b&#x27;1.7&#x27; b&#x27;Iris-virginica&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.argsort(a, axis=-<span class="number">1</span>, kind=<span class="literal">None</span>, order=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># Returns the indices that would sort an array.</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.argsort()</code>函数与<code>np.sort()</code>函数几乎完全一致，区别在于一个输出为排序后的数值，一个输出为排序后的索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">np.argsort(x)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two-dimensional array:</span></span><br><span class="line">x = np.array([[<span class="number">0</span>, <span class="number">3</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">0</span>)  <span class="comment"># sorts along first axis (down)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line">ind = np.argsort(x, axis=<span class="number">1</span>)  <span class="comment"># sorts along last axis (across)</span></span><br><span class="line">ind</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure>



<h2 id="找到第一次出现的值大于给定值的位置"><a href="#找到第一次出现的值大于给定值的位置" class="headerlink" title="找到第一次出现的值大于给定值的位置"></a>找到第一次出现的值大于给定值的位置</h2><p>问题：在数据集的petalwidth第4列中查找第一次出现的值大于1.0的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: (edit: changed argmax to argwhere. Thanks Rong!)</span></span><br><span class="line">np.argwhere(iris[:, <span class="number">3</span>].astype(<span class="built_in">float</span>) &gt; <span class="number">1.0</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># &gt; 50</span></span><br></pre></td></tr></table></figure>

<h2 id="将大于给定值的所有值替换为给定的截止值"><a href="#将大于给定值的所有值替换为给定的截止值" class="headerlink" title="将大于给定值的所有值替换为给定的截止值"></a>将大于给定值的所有值替换为给定的截止值</h2><p>问题：从数组a中，替换所有大于30为30，替换所有小于10为10。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: Using np.clip</span></span><br><span class="line">np.clip(a, a_min=<span class="number">10</span>, a_max=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>

<p><code>numpy.clip()</code>给定一个区间，区间外的值被裁剪到区间边缘。例如，如果指定了区间[0,1]，则小于0的值变为0，大于1的值变为1。不检查a_min &lt; a_max。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.clip(a, a_min, a_max, out=<span class="literal">None</span>, **kwargs)</span><br><span class="line"><span class="comment"># Clip (limit) the values in an array.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 包含要剪辑的元素的数组。</li>
<li>a_min、a_max: array_like, 或无最小值和最大值。如果是None，则不对相应的边进行裁剪。a_min和a_max只能有一个为None。</li>
<li>out: 可选参数，结果将放置在此数组中。Out必须有合适的形状来容纳输出。</li>
</ul>
<h2 id="从NumPy数组中获取最大n值的位置"><a href="#从NumPy数组中获取最大n值的位置" class="headerlink" title="从NumPy数组中获取最大n值的位置"></a>从NumPy数组中获取最大n值的位置</h2><p>问题：获取给定数组a中前5个最大值的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="built_in">print</span>(a.argsort()[-<span class="number">5</span>:])</span><br><span class="line"><span class="comment"># &gt; [18 7 3 10 15]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Below methods will get you the values.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">a[a.argsort()][-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.sort(a)[-<span class="number">5</span>:]</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>另一种选择</title>
    <url>/Exp012-book02/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUDbcT.png"></p>
<blockquote class="blockquote-center">
<p>“如果必须坠落，就让我坠落。 我将会成为的那个人，一定会接住我。” —— Sheryl Sandberg </p>

</blockquote>

<p>近日梦断魂销之际，友人推荐 Facebook 前首席执行官 Sheryl Sandberg 在丈夫去世的极度悲痛之中所著的$\lfloor$另一种选择$\rceil$。Sheryl Sandberg 敞开心扉，从她发现丈夫猝然倒在健身房的地板上开始，描述了丈夫去世后感受到的极度悲伤与孤独。然而，本书并没有局限于作者的个人经历，而是与 Adam 关于培养复原力的开放性研究结合起来，深入探讨了我们该如何克服人生中的逆境，包括疾病、失业、性侵、自然灾害、战争、暴力等不幸。同时，来自不同群体的案例也揭示了每个人都可以培养及提升内在坚韧的复原力，并且拥有重获快乐的能力。</p>
<p>本文记录于 2025 年春节，一个月前我已辞去中物院成都科学技术发展中心兼职特聘研究员，并决定在学校恢复工作后从西南交通大学辞职。我亲手执行了一次鲜血淋漓的社会性自杀，在即将正式与过去作别之际，特作此文记录我近十年的人生历程。无论是蹉跎往日，还是做出艰难抉择的今天，我都清醒地意识到感情丰富是强者的大忌，但仍无法避免沉沦的命运。或许只有经历过起起伏伏、深刻痛苦的人才能体会 Sheryl Sandberg 的感受，坚持走过坎坷的人才更能理解其中的勇敢、真挚、温暖和希望。</p>
<span id="more"></span>

<h2 id="相遇"><a href="#相遇" class="headerlink" title="相遇"></a>相遇</h2><p>2015年10月，我在中国科大物理学院就读大四，刚刚获得我将为之奋斗九年的研究所提供的保研资格。这份保研资格恰如命运的钥匙一般打开了故事的大门。</p>
<p>我虽然通过中学物理竞赛进入科大，但这样的来历在物理学院实在算不上稀奇。仗着中学时积累的数理基础，有恃无恐地游戏人生三年，英雄联盟打上了王者，平均绩点（Grade Point Average，GPA）也一落千丈。大三的暑假小学期后，学院统计保研资格时，保研线戏剧性地切在我和另一位同学陈森的头顶，我与陈森的GPA并列在保研线下第一。无法直接拿到学校的保研资格，我们不得不寻求能够提供保研资格的研究所作为读博的去处。我先后联系了天文学系的星系宇宙学实验室、近代物理系的磁共振实验室、北京的电子所、上海的应用物理研究所、合肥的等离子体所等。相对不错的研究所都存在约束条件，而能确保录取的去处科研环境都较差。犹豫不决之际，我求助了大三时打了一些零工的串节磁镜KMAX实验室的孙玄教授。孙玄教授告诉我，他的一位朋友罗教授，在美国深造多年，刚刚回国在成都创办研究所，可以提供保研名额，科研能力很强，建议我到这里试试。</p>
<p>于是机缘巧合的，我与陈森、力学院的张森共同来到了罗老师的电话面试会议。我后来了解到团队希望招聘一位力学院的学生承担有限元仿真的研究工作，两位物理学院的学生分别探索小角X射线散射（Small Angle X-ray Scattering，SAXS）及层析成像（Computed Tomography，CT）方向。然而罗老师团队面试时只争取到了两个保研名额。三选二的较量中，综合素质较强的陈森在电话面试的表现上远胜于我，我第一次落败。现场组织面试的秘书向我表示罗老师希望三人都被录取，回去后将会争取额外的名额，行与不行一周内都将通知我。在等待的时间里，我马上飞往北京求见电子所的某位长江学者，在得到认可的答复后我终于得到片刻安心，回到合肥。一周后，我接到了来自成都的电话，电话那头的苟雪老师告知我罗老师团队争取到了额外的名额，我可以加入团队，希望我能尽快给出答复。我仍然记得罗老师在电话面试时说，你如果加入，可以获得前往美国顶级实验室做实验的机会，再考虑孙玄老师对我说的话，我当即决定加入团队。</p>
<p>关于研究方向的分配问题，力学院的张森当然是承担有限元仿真工作。大约是考虑我过去简单探索的$\lfloor$磁共振成像反卷积重建方法$\rceil$与CT方向的契合程度，我最终被确定在CT方向上，而陈森则被安排承担SAXS方向相关工作。</p>
<p>2016年1月，在我完成了最后一门课程$\lfloor$广义相对论$\rceil$的期末考试后，鄂俊成师兄招呼我和陈森年前来成都学习适应，于是我立即买票赶往成都。但临近春节，合肥直达成都的火车票早已售空，我只好买了一张合肥到汉口转成都的车票。夜间到达汉口站后，还需要等待天亮后发车的动车，我不得不在汉口站内硬捱到早晨上车。那一夜，汉口站内泡面的香气、无人值守但仍亮着灯的周黑鸭店铺、穿着邋遢席地而睡的赶路人、小孩的哭闹声以及站外不断呼唤着的“宾馆走不走”“宾馆走不走”的吆喝声，陪伴着即将迎接未知新生或激动、或忐忑、或慌张的我的情景，在往后的人生中无数次出现在我的梦境里。</p>
<p>“从成都的火车北站下车，出火车北站后向右走会看到人行天桥楼梯，上到天桥后买票乘坐任意一路快速公交向西两站后在西南交通大学站下车。找到西南交通大学的大门，我会到这里来接你。”鄂俊成师兄在QQ上对我如是说。在学校的大门口我第一次见到了至今仍然崇拜的鄂俊成师兄，第一眼看上去相貌不算出众，但却有远胜于外表的自信溢出身形。跟着鄂师兄进入大门，穿过一段环形公路，经印有西南交大校训的高楼和形似巴普洛夫楼的老楼间的小路，走进另一栋老楼机械馆的大门，穿过一段破败的长廊后乘电梯来到四楼，眼前仿佛电影里的现代化办公实验环境让人眼前一亮。</p>
<p>到达实验室已经是下午四点多，鄂师兄向我介绍了黄佳伟师兄，同样来自科大物理学院，是比我大一届的师兄。由于陈森所在的微电子系的最后一门期末考试比天文学系早了一周，陈森早已在研究所报道。简单拜会罗老师后，我和陈森两人在交大北门外的$\lfloor$很牛的馆子$\rceil$吃了一顿晚饭，并买好床上用品，在眷诚斋15栋办理好入住。西南交大为研究所学生预留了两间宿舍，但师兄们都在校外租了房子，只有陈森和我两个人住在宿舍。那时眷诚斋还没有安装空调和暖气，只有挂在宿舍中央的一个小风扇。第一个冬天着实把在合肥享受惯了暖气的我俩冻的够呛。</p>
<p>安顿好生活问题后，第二天来到实验室，鄂师兄向我明确了后续的研究方向并交给我一台高性能服务器。我仍然记得它的配置是双路Intel Xeon E5-2678v3，搭载了一块Nvidia Geforce GTX970 4G以及128GB DDR4内存。最初我将它配置成Windows与Linux的双系统，Linux侧负责CT数据的重建，而Windows侧负责图像分析与数据挖掘任务。在接下来的半年时间里，这台服务器作为我唯一拥有的，陪伴我度过了最艰难的混沌阶段。半年后我拥有了性能更强的服务器时，这台设备被我制作成专用于CT重建的Linux服务器供远程使用。直至2019年夏天，一位我十分重视的成员刘昕加入CT组，当时有限的计算设备已远不够大家分配，我只好将这台Linux服务器重置后交给刘昕作为他专人专用的图形工作站。而这台设备的CT重建任务被我制作为模块化的Linux虚拟机分发到了每个人的图形工作站上取代。2022年夏天刘昕毕业时，我最初的这台机器已经太老太落伍了，没办法再将它交给后来的同学们。整理备份好刘昕读书时的研究数据后，我将它布置在中物院成科中心机房里，自此之后再没有人使用过它。</p>
<p>我与罗书璇相识于2016年春节前夕，研究所内李博老师的婚礼宴席上。在婚礼的前一天夜里，陈森和我在宿舍里笨拙地商量第二天随份子钱应该随多少才合适呢？我仍然记得我们以一种朴素的直觉敲定了最后的数字。两百元似乎太少，而再高一些的四百元显然不是吉利的数字，如果更高的五百元对于我们这样的穷学生来说就太奢侈了。基于这样的考虑，三百元是个再合适不过的数字了。夜深人静时，离开母校来到陌生地方的隐隐不安尚未散去，想到第二天的婚礼无疑将是我第一次以个人名义参与社会活动，便暗暗涌起浓重的仪式感，我的人生似乎正式迈入下一阶段了。</p>
<p>婚礼当天，PIMS的大部分师兄师姐们都来了，但独独罗老师没有到场，席间听师兄们说罗老师似乎从不参加大家的婚礼。也好在罗老师没有到场，婚礼现场气氛相当不错。现场除用餐区域外还有棋牌室台球室等等娱乐活动室，午宴完后，大家分散在各个房间消遣，我并不爱好玩这些，但也只好随着大家进到一间棋牌室。西南交大的师姐们旋即占下一个麻将桌，不过她们三人要凑成一桌还有空缺，便招呼恰巧在旁边吃瓜的我和罗书璇一起玩。我和罗书璇同时极力推脱说确实不会玩麻将，但师姐们盛情难却，让我和罗书璇既然不会玩就凑在一起打一副牌好了，规则由她们开局时指导。时至十年后提笔的今天，这仍然是我唯一一次坐上麻将桌。四川麻将规则很简单确实一学就会，我们玩了好一会儿，期间我和罗书璇除了打哪张牌以外没有过多交流。大约是几位师姐倦乏了或是到时间该回实验室工作了，下午我们便散了场，我和罗书璇也互相留下了联系方式。</p>
<p>那时我和罗书璇都青春年少，彼此爱慕大概是难免的事情。此时我初来乍到还不了解罗书璇的身份，但当天不久之后陈森便告诉我，罗书璇正是罗老师的侄女。婚礼过后就是春节假期，我们都各自回家，但我和罗书璇线上频繁地保持着联系，春节过后回到成都，我们很自然地成了情侣。</p>
<p>我十分清楚，这是我在完全了解真相的情况下采取的鲁莽行动。年少时的我天真的以为，这样的关系也许对我有益，我最初便对这段关系抱有不切实际的期待。因此，最终即便为我的人生带来毁灭，由我来吞下终局的苦果，我也无有怨言。如同一场数值仿真模拟实验，往后十年牵扯的人、事、物以及相互关联在此刻皆已定型，只是身在局中的我们在最初都没有办法准确观测到而无法概览全局及其走向。但数值仿真模拟的初始条件设置好开始运行后，滚滚列车的演化方向又有谁能左右？包括罗老师在内我们的性格、处事方式在最初便注定了悲剧，往后的故事只是这场数值仿真模拟搬进现实里的一段段放映而已。</p>
<h2 id="相知"><a href="#相知" class="headerlink" title="相知"></a>相知</h2><p>2016年初的春节假期过后，按照惯例已获保研的学生应当在大四下学期前往去向单位开始研究工作，我大学生涯的最后时光也应当在我未来的研究所度过，于是我准备动身前往成都。但旋即收到由学校发来的邮件：</p>
<blockquote>
<p><font color="#B5B5B5">各位在校外做毕设的同学：</font><br/><br><font color="#B5B5B5">今天主讲「天体力学和天体测量」课程的陈老师告诉我，有六位同学在校外做毕设，缺席该课程的授课。如果不来上课，他明确表示肯定给不及格。教学秘书陆老师的意思，要尊重主讲老师的权威，建议大家克服困难，每周坚持回来上课;拿不到此学分，就无法毕业。没有毕业证，国外大学会拒绝给办理研究生入学手续。解决方法:一是每周乘火车往返听课，一周一次课，学校和天文系无法报销路费，看校外导师是否同意帮助报销;二是转回科大，在校内联系导师做毕设。</font><br/></p>
</blockquote>
<p>科大物理学院的细分专业选择安排在大三上学期，前两年均为物理学通修课程，细分专业分流后各专业课程基本分配在第三学年，到大四时就很少有必修课程了。天体物理专业最初由天体物理中心演化而来，由于成系较晚，所以在教学设置上尚有瑕疵。大四下学期竟然还会排期一门必修课程，实在让人吃惊。我只能尝试邮件联系了校内几位相关老师寻求折中方案，但均遭拒绝。</p>
<p>没有办法，我再次动身前往合肥，直接找到该课程授课老师的办公室。因为半年前我曾完整地学习过他讲授的「恒星物理」课程，陈老师似乎对我有些印象。我当面向陈老师说明了我的来意，我通过增补名额只能保研去往校外的研究所，每周从成都往返合肥确实困难，实在无法参加「天体力学和天体测量」课程的线下学习，并说明我会在成都独自完成该课程内容的学习并在六月如期参加期末考试。陈老师终于接受了我的提案。</p>
<p>解决完此事后，趁此机会我在学校多逗留了两天，和过去的朋友们聚会并做道别。往日朝夕相处的朋友此刻往后便天南海北，而我又是最初离开的一个，实在感伤。收拾好心情，我便收拾好必备物品再次出发飞往成都，正式踏上了我的博士生涯，我的噩梦。</p>
<p>最初，研究所每月给我和陈森发放500元生活补贴，这些钱即便是十年前在成都作为学生生活也远远不够，而此时我也不愿意再问家里拿钱，好在过去打网吧赛和做高中生家教积攒下来的约1万元勉强能够支撑我生活加谈恋爱到研究生正式入学。</p>
<p>再次来到实验室正式开始工作，鄂俊成师兄交给我一批2015年12月从 Argonne 国家实验室先进光子源（Advanced Photon Source, APS）采集到的同步辐射显微CT实验数据，这批数据是在时任 2-BM 线站 Beamline Scientist 的肖教授协助下采集完成的，一并带回来的还有一份十分简略的由肖教授手写基于 <em>TomoPy</em> 开源工具集的重构程序。团队要求我尽快处理这一批数据，每个数据有对应的项目&#x2F;研究题目，按照对应责任人的需求产出分析结果。</p>
<p>然而此时，CT在团队里仍然是一个崭新的细分方向，哪怕是雏形的解决路径都尚未建立，我只得从头开始摸索一切。</p>
<p>最初，原始的CT实验数据是由一系列投影图像构成的，肖教授手写基于 <em>TomoPy</em> 开源工具集的重构程序正是用于将投影数据重建为切片数据，但还有些诸如中心校准等参数调节的步骤。最初的这份程序只有最基础的重建功能，所有参数调节均需要手操，每一发实验数据也均需要单独填写一整套参数后执行运算。当我接手这项任务时，我的第一个想法是实现重构流程的自动化。</p>
<p>那时，相比数学和理论我不算擅长和喜欢 Coding，提笔时回忆起来很奇怪，现如今融入我的血液的技能在那时仍很生疏。</p>
<p>###################################### 代补充 ######################################</p>
<p>2019年4月，对聚甲基丙烯酰亚胺（Polymethacrylimide，PMI）航空泡沫结构性能关系研究的工作初具雏形，黄俊宇老师带领我开始论文写作，以及论文最后对力学问题进行建模分析的拔高。某天晚上，他和我在综合楼6楼我的学生区办公桌旁一起推导公式至深夜。我们两并排坐在两个工位上一起默默地做着自己的那部分任务。长久的安静气氛中，忽然腾的一下，他几乎从椅子上弹起来，吓了我一大跳，大喊了一声说：</p>
<blockquote>
<p><font color="#B5B5B5"> 我简直是个天才！</font><br/></p>
</blockquote>
<p>我才发现原来是他把这份力学本构模型的公式设计成了和CT结构自洽的样子，当然那时仍是雏形，后来当晚的工作变成了 <a href="/download/2019_hwchai_Script._Mater..pdf">H. W. Chai et. al, <em>Scr. Mater.</em> 2019</a> 中的Eq. 1 和 <a href="/download/2020_hwchai_Int.J.Plast..pdf">H. W. Chai et. al, <em>Int. J. Plast.</em> 2020</a> 中的 Eq. 19。</p>
<p>我十分珍视，这个瞬间成为了我生命中仅有的体验，被我收藏在心底。因为黄老师和我如同积木的嵌合体一样，他擅长的事情我不擅长，而我拿手的事情黄老师也不太在行，所以我和黄老师过去的合作通常是各自完成自己的那一部分再拼接在一起，极少有这样就一件具体的事情在一起执行的体验。往前和往后十年时至今日，除了很碎片的一些时候，我都未曾拥有过真正传授我知识的人，我曾经十分渴望。</p>
<p>2019年的夏天，有一天我回到家中，发现罗书璇和我的妹妹正在聊天，说到很多成都的事情，也说到了我的导师正是她的叔叔。我大发雷霆，我曾经明确地强调我不愿以后再和成都的事情有所牵连，决不允许和成都外的人透露此事。我们以后一起去沿海地区工作，我不愿意曾经在裙带关系的阴霾下的过往故事伴随将来的生活里。</p>
<p>2019年9月，在黄俊宇老师的支持下，对PMI泡沫结构性能关系研究的工作在被 <em>Acta Mater.</em> 拒稿后投稿在了力学顶刊 <em>Int. J. Plast.</em> 上，只经过一轮修改后便在2020年3月接收。这份工作标志着两层含义。</p>
<p>对CT方向，它标志着从四年前的一无所有到跨时间尺度的实验表征能力和完备的数据挖掘解读能力的成型。以这篇 <em>Int. J. Plast.</em> 的工作为蓝本，对各种有工程意义的研究对象，按照几乎相同的实验和数据分析路径即可复制出相近深度的研究成果。因此CT方向进入了由黄俊宇老师带领我组成的“尖兵部队”到可以以面铺开尝试建立科研流水线的阶段。</p>
<p>对我个人而言，一份相当扎实的博士研究生的工作成型了，虽然时间还没有到，但我已经拿到了我的博士学位。时至今日即便我已经在 <em>Acta Mater.</em> 上发表文章，往后也许还会有更高水平的成果，但这篇可能在他人看来不那么出色的 <em>Int. J. Plast.</em> 始终是我心中最引以为豪的成果。它真正是我曾用尽浑身解数从荒芜中建立的一个个实验与数据分析方法学能力凝结成的礼物。</p>
<p>然而，团队对我多年的冷落早已让我失望，此时的我考虑转向寻觅人生的下一站。如千百个竞赛选手的命运，散落在世界各地搞一些所谓的科研，做出一些成绩，拿到博士学位，最后回流到金融行业。在2020年时，我的奖项还勉强能蹭上量化金融准入门槛通货膨胀的末班车，因此我也抱有相同的打算。</p>
<p>但也在此时罗老师授意黄俊宇老师劝说我留在团队工作。在第一次黄俊宇老师语重心长的向我传达团队的意见时，我便如实表明了我的打算。四年来我作为牺牲品趟出来了完整的CT方向，已经远远超过了团队对一个常规博士生即便是科大过来的博士生应有的预期。何况我和罗书璇的恋人关系，和罗老师的间接裙带关系，在不明真相的外人看来我所取得的成就不过是领导给到我的而已，在这种困境中我如何自处。相比张抑扬、陈森等做热门方向拿着PRL的人，孤身一人的我必须在科研上做到更加无可挑剔，因为被怀疑，所以必须更卓越的悲凉感从未离我而去，也注定伴我终身，所以我没有打算留下。我会和罗书璇去上海工作，要不了几年我们即可定居。</p>
<p>往后每过一两个月，黄俊宇老师便就此事劝说我一回，但我始终没有什么表示，几次之后黄老师就不再提起了。</p>
<h2 id="沉沦"><a href="#沉沦" class="headerlink" title="沉沦"></a>沉沦</h2><p>2021年6月，罗老师忽然叫我到办公室谈话。一开场，罗老师在那时巨大无比的空旷办公室里以不容置疑的威压对我说：</p>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：我代表罗书璇的父母说这个话，今天，你要么决定留下来工作，要么立刻和罗书璇分手。</font><br/></p>
</blockquote>
<p>我完全被他的气势震慑住了。即便我已26岁，但读书多年我鲜少和人就真实的博弈问题打交道，何况是这样的突发场面。时至今日回头看，罗老师不过是在虚张声势而已。我的大脑飞速转动，许久没有说话。我基于如下三点做出了最终的决定：</p>
<p>1.感性的角度，CT方向是我一手缔造的方向，在2021年时，CT是我亲手挖掘出的礼物和宝藏，在一片混沌时它就像虚拟伙伴一般与孤身一人的我同行多年，我爱它。理性的角度，CT方向此时即已成熟，可以作为我继续深度开展研究工作的基石。相比之下，感性略高于理性。</p>
<p>2.我与罗书璇爱恨六年之久，所谓爱情早已在最初的半年里被愤怒冲刷殆尽，而此时此刻确已经是几乎互相填满了对方整个青年时代。我出于义气也好，责任感也好，世俗的社会道德压力也罢，都绝无可能接受此时抛弃罗书璇。</p>
<p>3.什么样的人，会在明知道严重伤害我个人利益的情况下，要求我留下呢？那时我无法想象世上会有人做出这种不付出任何筹码来侵害他人的决策。再想到，罗老师和第二任妻子生的小儿子刚刚诞生不久，等到他长大成人时，罗老师早已花甲影响力褪去，恐怕这里需要一个有能力又值得信赖的人来做承上启下的角色。我，恐怕是最合适的人选了吧，那时我如此判断。</p>
<p>基于如上三点，大约1占40%，2占30%，3占30%的心理权重，我答应罗老师留下。因为第3点是我的推测，所以考虑概率问题，占比略低，如若确定，3的占比将会更高。</p>
<p>我做出了人生中的最重大的战略决策错误。如若2015年我刚来成都时选择和罗书璇成为恋人关系是我年少无知，但这次决定确是我在经过理性思考后做出的决策。我在完全不了解罗老师及其家人的为人的情况下，将自己的人生赌注押注在他人的善意上，这几乎等同于将人生的遥控器拱手让人，而我最终除了掀翻整个赌桌以外，再没有任何节制对方侵犯的方法。事实上，后面的故事也如此发展。</p>
<p>2021年12月，我按计划如期毕业并立即和中物院成都科学技术发展中心签约兼职特聘研究员，并在西南交通大学材料科学与工程学院正式办理入职。也在此时，团队划拨了我实质指导的第一位学生，赖国栋，加入CT方向。国栋本科来自南京信息工程大学，现在西南交大物理学院就读研究生二年级，并计划当年转博。我初接触下来就是认真努力的角色，但通过一些简单的任务试了试后，大概因为教育经历不一致导致一些基础技能和理论知识有所欠缺。不过这都可以通过实践来弥补，后来他个人的博士生涯发展也印证了最初的判断。</p>
<img src="https://s41.ax1x.com/2025/12/17/pZlZxVe.jpg" width="100%" alt="" align=center />

<p>2022年5月，我与罗书璇正式登记结婚。这似乎是噩梦的真正起点。稍早些时候，他们便因为罗老师的大儿子生活无法自理需要人照料，安排罗书璇的妈妈来到成都，并与我们夫妻同住，我无权反对，最初也相安无事。往后的生活，发生了两个显著的变化。第一、罗老师似乎经常和罗书璇谈论起我的工作情况，反而不与我本人交流。并且时至今日我不清楚发生了什么，婚后罗书璇在小家庭中都很明显地转向唯罗老师马首是瞻，而对我连基本的礼貌都愈发减少。第二、由于罗书璇妈妈以家长的身份在场，我大部分时候听之任之，但偶有拌嘴的事情发生。起先，罗书璇妈妈还能帮我说说公平的话，但往后不久便完全变成了对我一个人的攻击与倾轧。</p>
<p>我本不是什么大男子主义者，但基本的尊严与家庭中的男性失权发生时，对我这样自信的人来说，已经是十分痛苦的局面了。</p>
<p>5月领证后不久，罗书璇妈妈和罗书璇本人开始积极筹划备孕，势必要在今年内怀孕生子。我十分抗拒，那时我刚刚参加工作，尚不稳定，还有大量的基础工作和积累需要完成才能站住脚跟。我多次强调等到我站稳脚跟之后我们再考虑小孩的问题。但持续半年的时间，我的家庭几乎整天就此问题鸡飞狗跳，一定要立即怀孕生小孩。并在外扬言说如果不能尽快生子担心我的父母瞧不起他，这种污蔑的说辞简直无厘头到我几近崩溃。我逃避了近半年之久，但最终在2023年1月春节前夕软磨硬泡之下终于沦陷。</p>
<p>2023年初春节过后，罗书璇检测到怀孕迹象。我所谓的家里终于恢复了平静的气息。在过了接近半个月后医院的正式检查结果确认怀孕后，罗书璇一家当即召来罗书璇的爸爸来到成都与我们一同生活，所谓照顾家庭。仍然是起先相安无事。</p>
<p>2023年5月，罗氏家族以罗老师的大儿子情况更加严重为由，想要我的母亲来到成都照顾孕期的罗书璇，而罗书璇的父母离开家中去照顾罗老师的大儿子。我的妈妈想都没想，准备了5万元的礼金，立即辞去了工作赶来成都。</p>
<p>很快，因为我的母亲坐上了罗书璇和我的床、洗衣服没有拧干就挂起来导致滴水到地上、做饭做的不够辣等等等等不可胜数，几乎每天都有数不尽的指责和怪罪。直到我真正离婚后，我的母亲才告诉我，他们甚至还和我的母亲说过「你也不想你的儿子工作受影响吧」这样标志性的反派发言，我的母亲不得不低头。</p>
<p>也是在此时，罗书璇的母亲要求我将我的全部收入交出给罗书璇管理。我没有同意。</p>
<p>那时我不懂事，轻易掉入了早已挖好的陷阱。今日回想起来，从没有明明岳母可以照顾的情况下一定要婆婆来照顾孕妇的道理，这近乎是一场为家庭地位争夺战早已埋下的陷阱。以罗书璇的暴戾脾性，孕期和我妈妈相处的矛盾近乎是可以预判、必然发生的事情，饶是如此，她的爸妈仍然放我的母亲一个人和她相处了很长一段时间，直到矛盾爆发到生活无以为继，罗书璇妈妈才再次住进家里。但对我的母亲的人格的倾轧更进一步，没有丝毫衰退。罗书璇就如同原始的、打开囚笼的无知野兽，被利用着疯狂人格攻击我的妈妈。而此时罗书璇正在孕期，根本没有可能说让我的母亲回去。更甚的是，罗老师也开始拉偏架，对我的工作开始挑剔指责。</p>
<p>2023年10月，我的女儿诞生，我十分激动欣喜，为我的女儿取名「柴洛一」。我向来崇尚至简，起先我想为她取名「柴一」，但我的女儿出生时已不允许取两个字的名字，所以在中间加「洛」通「罗」。</p>
<p>但地狱也在此刻降临。最开始的一天，医院的豪华套间都已住满，我们不得已只能在普通的病房里度过，罗书璇的妈妈和我在医院留守。第一天夜里我在医院四处奔走终于抢到第二天可以入住的豪华套间并且订了医院里最好的专职陪护人员协助我们处理产妇和宝宝的护理工作。第二天我们转移到了像酒店房间一样的套房里，我的妈妈和我留守。我已经近四十多个小时没有合眼，不得已在第三天的凌晨三点我在套房的椅子上还是睡着了。再次迷迷糊糊醒来是大约4点多，我还没睁开眼，已经听到罗书璇响彻云霄对我母亲的谩骂侮辱，我已记不清具体因为什么，大约是因为给我盖被子？或是给宝宝翻身没有翻好？我马上醒来开始制止，并处理事情。但我笨手笨脚的母亲似乎哪怕是呼吸在罗书璇眼里都是罪恶，只要出现在她的视线里就避免不了谩骂。第三天天亮后，罗书璇妈妈来到医院，我让我的妈妈回去家里准备其他事项。</p>
<p>如此这般度过了在医院住院的时间，回到家中坐月子前，我订了天鹅到家上最贵一档的唯一一位月嫂全程陪护照料。我的母亲在家中却被罗书璇和她的妈妈百般刁难嫌弃，终于某天下午，我的妈妈给我通过微信发来消息，「儿子，让我回去吧。」。恰巧我的手机正放在桌子上，罗书璇第一个看见了这条消息，几乎是开水沸腾了一般，家里彻底爆炸了。推搡着让我的妈妈赶快滚。期间我努力尝试沟通缓和矛盾，我的妈妈又留了一天，但最终还是被罗书璇一家要求离开，我母亲的包裹当着我的面被丢出门外。我送我的妈妈到成都东站并买票回家。</p>
<p>也在此时，为我的女儿登记姓名在即。罗书璇的爸爸站了出来，说「你当爸爸太不称职了，小孩不能姓柴，要姓罗。」我大发雷霆，说你要姓罗那现在就离婚好了。事后我又说了一些好话，才终于顺利把我女儿的姓名登记上。</p>
<p>罗书璇一家在孕期仗着自己是孕妇，挥舞着道德大棒，对我的母亲的百般羞辱打压以激怒我，回过头来看，不过是为了在罗老师面前打压我的形象，争夺罗老师团队及正在经营的公司的决策主动权，也即转化为家庭地位。还有另一层原因，是罗书璇一家认为我出身普通家庭，现在不过是罗老师手下讨饭吃的一个员工而已，翻不起什么风浪。农村出身的他两的思想犹如原始的野兽，不懂得长期的投入与回报和共赢，只能看见眼前的利益将周遭疯狂啃噬殆尽，直至将周遭倾轧枯萎，仿佛自己在这片小天地里取得了胜利。</p>
<p>我决心离婚，这场婚姻是我人生犯下的巨大错误。我所有的工作重心转向人工智能方向以及为我尚未毕业的学生们争取足够他们毕业的素材。</p>
<p>2023年11月，我开始放浪形骸，在bilibili直播平台上看不露脸的电台直播和女主播聊天，倾诉我的苦难与不屈，开始给女主播打赏礼物，加微信聊天，等等等等以稍舒缓我的心情。说来有些可笑吧，是电台聊天女主播拯救了那时破碎的我。</p>
<p>2024年5月，我在看直播并和女主播聊天的事情终于败露，被罗书璇看到了我全部的聊天记录。这真正不是故意为之，而是一次意外。我原本想的是至少等到李思文和苗玉飞这两个毕业可能会遇到困难的学生达到毕业条件后再择机离开，王威铮和吴辉两个最小的学生能力出众，他们哪怕是凭自己也一定能行，不用担心。</p>
<p>立即，家里炸开了锅，罗书璇召集她的家人朋友，并在我的家族大肆宣扬我精神出轨，扬言要到西南交大告发我，并公开我和女主播聊一些生活与情感困苦的聊天记录。还联系上我主要看的两位兼职电台聊天主播，威吓他们要到她们的学校或工作单位告发她们。我早已心灰意冷，既然事情到了这一步，那离婚已经是不二选择。</p>
<p>第二天清早，罗书璇一家带着我第一时间来到银行，势要我将全部的存款转到罗书璇名下，这本就在我早已计划的决定之中。这些钱，我一定赚的回来，相比之下，我的人格健全要更重要。当天下午，罗书璇又不知从哪变出来的财产公证证明，约定我过去所有的钱都属于罗书璇的个人资产，我以后赚的钱都属于夫妻共同财产，她以后赚的钱都属于她的个人资产，又好像早已约好财产公证处，轻车熟路地带着我办理完了手续。因为已经决心离婚，这对我而言已无意义，只不过是在早已失衡的天平上再压上的一块砝码而已。</p>
<p>当天晚上回到家，家里又多了一份离婚协议书，约定现有财产全部归女方，将来我的收入20%作为抚养费支付给他们。我早已心灰意冷，现在的全部我都不想要了，但抚养费的条款我不能接受，我最多接受到5000元&#x2F;月，我还将重新开始生活。</p>
<p>多年来我的礼貌和体谅，在罗书璇一家三个原始人眼中似乎解读成了软弱和退让。我最终尝试做最后的挽留，分别与他们谈了话，但得到了三份不同的回应：</p>
<blockquote>
<p><font color="#B5B5B5"> 罗书璇：你现在之所以还在挽留，不过是因为加上你给我的，我现在算上房子手上的资产你要奋斗十年才能赚的回来。</font><br/></p>
</blockquote>
<p>罗书璇向来不是什么有追求或独立人格的人，她的人格仿佛一个初级元胞自动机，仿佛游荡在这个世界上的吞金机器，但与我相伴多年，所以过去我向来包容她的贪婪和狂妄。她说出这样的话，最终刺伤了我，但也还算在意料之中。</p>
<p>罗书璇的妈妈并未与我直接谈话，而是和罗书璇说她手上还私藏了多少多少钱，一定支持罗书璇离婚，来给我一个教训。我最后向罗书璇的爸爸发问并做最后的挽留。</p>
<blockquote>
<p><font color="#B5B5B5"> 罗书璇爸爸戏谑地说道：柴海伟，你这一辈子是竹篮打水一场空啊。</font><br/></p>
</blockquote>
<p>有些话太重了，落在我刚好脆弱无助的致命弱点上，砸断了所有的情分。我的心在这一刻死去，仅剩游荡在世上的残躯。谎言，骗局，一场精心策划的用罗老师的威压零成本招赘的计谋，从一开始这就是计划好的陷阱。</p>
<p>我当即离开了我所谓的家，我走前他们说给我一个机会用两年的时间把罗书璇追回来。天大的笑话。</p>
<p>当天晚上，我在公园的长椅上度过，我稍微哭了一场。由于西南交大当时正在组织硕士毕业生答辩，而我不幸被抽中做答辩秘书，答辩会议就在第二天，当天我需要去往学校准备一些毕业生的资料，所以我必须重新打起精神来。第二天天亮后，我来到中物院成科中心的办公室拿上电脑和一些必要的材料准备出发去往西南交大。我神容枯槁，面色憔悴，十分狼狈。临出门时，我叫出赖国栋：</p>
<blockquote>
<p><font color="#B5B5B5"> 我说：国栋，这是我们最后一次见面，我马上会从团队离开。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 国栋：啊？那你很吃亏啊。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：不要紧，不用担心我，我这样的人在哪都饿不死。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 国栋：「无言」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：我知道你现在在犹豫工作的问题。CT是我一手孕育的方向，我不希望她死掉。站在CT的立场上，我希望你留下来替我守住火种。站在你个人的立场上，我希望你走。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 国栋：「无言」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：你继续把手头上这份工作做完，博士毕业条件即已完成，所以不要太过焦虑。我走之后，其他师弟师妹那边还需要你多帮一帮忙。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我继续说：以后不管我在哪，我和你至少是黄俊宇老师和我的关系。</font><br/></p>
</blockquote>
<p>说完这些话后，我又拜托王招萍帮我办理成科中心员工周转房。随即我离开去往西南交大。</p>
<p>到达西南交大已是下午，当天我什么事情都没有做，只准备了这几位毕业生必要的一些资料。当天晚上我住在了西南交大北门外的酒店。第二天天亮后如期到达会场，强撑着我的残躯和大家组织这场硕士答辩会议。会议分上午、下午两场，待到下午场时，罗老师似乎察觉到我来了西南交大，因为过去我经常为他跑项目的原因所以我很少来到学校。他在会议期间给我发消息让我过去找他谈话来聊一聊接下来的工作安排：</p>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你怎么会做这么恶心的事情？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：你说再多我也觉得我没错。别说精神出轨了，这种处境下就是真的去出轨我也觉得我没问题。今天的局面…</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 没有等我说完，罗老师直接打断我：你就是理由多。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：我卡上的60万现金已经全部转给罗书璇了，学校账上还没发给我的15万绩效奖励我全都不要了，全部给罗书璇。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你不要以为你给的钱有多少。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我说：再怎么样这都是我的全部了。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：现在开始CT方向归卢磊管理，你就继续做你以前的事情吧。</font><br/></p>
</blockquote>
<p>我没什么好说的，草草结束了这次会话，随即回到了硕士答辩的会场，继续组织会议。会后合影环节散场后，一位刚通过答辩的学生周子豪找到我开玩笑的说，「必须和柴院士来合个影！」我强装镇定挤着笑容和他合照。我的人生轨迹注定转向，那个瞬间我又是什么心情呢。</p>
<p>当天晚上散会后，我再次带上电脑回到酒店，我还不能崩溃，因为那时我正在承担「Python在科研中的应用」课程的授课任务，这学期还剩最后四周的四堂课，而下一堂课就在第二天。崩溃边缘，我想向冯庆国老师求助，请他替我上最后这四堂课，但第二天就要上课却在今天才去请别人似乎太过冒犯了，于是作罢。我强撑着残躯准备起后续的课程内容，我原本精心准备的授课计划业已打乱，我已无心顾及，只草草准备了一份关于如何使用 Python 环境进行科研论文绘图的课程，十分简略。我仍然记得最后四堂课我只准备了两堂课的画图方法，一堂课很简略的聚类分析算法讲解，等到最后一堂课临近时，我已几近崩塌边缘，再无心授课备课，只得上了一堂课程作业讲解的现场 freestyle。</p>
<p>最后一堂课上，来的人并不多，大约只有平时的三分之二。所有布置习题讲完后，离下课还有一点时间。于是我说：</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：对各位同学来说这可能只是一堂普通的选修课吧，但对我来说的感受却有些不一样。这门课程设置原本是我所在的材料科学与工程学院的院内选修课，由我们学院的一位做第一性原理数值仿真模拟的资深老教授冯庆国老师去年发起。但我们学院的学生对编程课程的兴趣似乎不高，只有零星几个人选了课，由于人数没有达标去年没能开设成功。所以今年冯庆国老师申请将我们这门课程改为全年级全校范围的选修课，今年终于把这门课开起来了。冯教授因为授课和科研任务过重了，一个人很难承担全年的课程授课，于是和我约定每年上半年由我来授课，下半年冯教授亲自来为大家授课。原本我们是这么预想的。</font><br/></p>
</blockquote>
<p>我停顿了一会儿。</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：这是我作为大学老师第一次站上讲台，对于我的人生体验来说也很奇妙。但是因为我的一些私人原因我明年就会离开西南交大去美国工作了。这很可能也是我最后一次站在讲台上了。也许有一天我还会回到中国的大学再次任职，但大概一定不会是我们西南交大了吧。所以至少这肯定是我第一次也是最后一次站在我们学校的讲台上了。这门课程讲到现在对我来说，我现在的感觉也很奇妙。</font><br/></p>
</blockquote>
<p>我稍有些落寞，于是马上转过头去在黑板上装模作样的开始画起DNA的双螺旋结构，防止被学生们察觉我的失落。既然都画出来了，我又讲了讲先前提到过的独热编码、霍夫曼编码以及与人工智能大模型技术结合对生命遗传密码的词元化方法。讲完之后我随即宣布下课，「再见，同学们。」</p>
<p>下课之后，我在收拾东西时，几位同学竟没有离开，凑到讲台边上来，有自报家门并向我请教一些研究问题的，也有要加我微信保持联系的。课上没有一个同学我能叫得出他们的名字，但大概记得一些长相。随后又一个同学在我离开教室前对我说：</p>
<blockquote>
<p><font color="#B5B5B5"> 佚名同学：柴老师，我和我的朋友都很喜欢上你的课。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我马上得意忘形：哈哈哈，为什么？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 佚名同学：因为你上课经常说大家是能考到我们西南交大来的同学，智商能力各方面肯定都很优秀的，肯定学的懂。我们上的其他课老师很多都只会说你们现在的学生是一年不如一年了。</font><br/></p>
</blockquote>
<p>不是因为我的专业素养而是因为这些不咸不淡的口头禅着实让我感觉有些无厘头，不过想来我也有过这样的时刻。在我尚未经事，还很稚嫩的年代，也会有因为一些琐碎事情而不自信的时刻。2016年4月在我大四时，我曾经在 Argonne 国家实验室的APS光源和时任2-BM线站的线站工程师 Pavel D. Shevchenko 一起动手组装一台用于拉压试验目标的电器设备的底座并做设备电气安全检查。这是我第一次踏足美国，我的英语也不好，没有稍事休息第二天清早就开启了这项工作。实验室的其他师兄和同学都在光源令半边的32-ID线站从事冲击波物理方面相关的实验，只有负责CT任务的我一人在专用于CT成像的2-BM线站这边开展工作。不自信今天回想起来也是难免的吧，真是难为那时候的我了。弄了一段时间后，肖教授走过来用中文问我是否需要协助，Pavel 对他说了些什么，我听的不是很真切，似乎是质疑我的专业素养。肖教授随后中气十足大声地说：</p>
<blockquote>
<p><font color="#B5B5B5"> Xiao: Don’t worry. He has been trained enough. </font><br/></p>
</blockquote>
<p>这句话我听的真真切切，曾经赋予稚嫩的我无穷的力量。在我黑暗的博士生涯，除肖教授外，从没有人鼓励过我支撑我走下去，如同深渊井底照下来的一丝微光，从此我相信语言的力量。也许是从那时埋在的种子吧，也可能是我天生性格如此，在我后来带师弟师妹们和学生们后，很多时候都习惯性地鼓励他们，希望他们也能从语言中得到力量。</p>
<p>我和最后尚未离开的同学道别，并离开。回到我的住所后，我彻底崩溃了。</p>
<h2 id="曲终人散"><a href="#曲终人散" class="headerlink" title="曲终人散"></a>曲终人散</h2><p>2024年5月，我和罗书璇正式登记离婚，并进入离婚的1个月冷静期。我陷入巨大悲痛之中，我所谓的家庭、多年的噬人爱人、我刚刚诞生的女儿、我热爱的研究方向和我的学生、我的事业和我所有的积蓄，社会意义上我的一切全部都被剥夺或失去了，我仅存的只有我的生命和残存的信念而已。</p>
<p>大约有两三个月的时间，我很苛待自己，夜不眠，餐不食，不见人，终日不言不语。饶是如此，却依然没能救赎我支离破碎的心。我在心如死灰的年岁蹉跎时光，至于那段过往我开始记忆错乱，连时间都记不清了，稍清醒些的时候，我又觉得仿佛一直沉浸在一场旷日持久的巨大噩梦之中刚刚惊醒。</p>
<p>带我走好吗？就像时光倒流，回到中学年代的某个夜晚，如同从一场旷日持久的巨大噩梦中惊醒，回到那个冷的可以哈出雾气的清晨扬州。如果不是命运馈赠给我本不属于普通人的礼物，会不会命运就不会找上我？我不要这么要强的性格，我不要这么追名逐利的信念，我不要这颗不屈的心脏，我全都不要了，带我走好吗？</p>
<p>在车流呼啸的马路边，在落叶梭梭的林中长椅，香火缭绕的寺院佛像，风声咧咧的青城山顶，四处是我挣扎彷徨的灵魂，滚进尘泥里发出细碎的唔咽。人生走向穷途末路，似乎连呼吸都是一场罪孽。从来就只有我自己一个人用残存的信念拖着这副早已枯萎的躯壳，东一脚踩在荆棘上，西一步陷进泥潭里，就这般深一脚浅一脚的从噩梦和地狱之中徘徊。</p>
<p>那一段时间，我万分悔恨当年留下来工作的决定，更让我崩溃的是，此时我才得知，罗书璇当年就在四处宣扬「如果柴海伟不留下来工作，我马上就会和他分手。」这么多年来所有人都瞒下了我这句话，我多年来一度以为当年我要带她走她一定会和我一起走。如若是这样，如若我早知道真相，那我当年定不会有半分犹豫。</p>
<p>在那段天旋地转的时光里，我唯一残存的念头是，我要活下去！我要去哪里谋生！那时我初步的考虑是：</p>
<p>1.申请位于美国纽约的布鲁克海文国家实验室NSLS-II国家同步辐射光源的博士后，继续前沿X射线诊断技术和如实验固体力学等的交叉学科应用研究。自从2019年以来，能源部下任职的华人学者似乎都不好过，肖教授也不例外，不久之后肖教授就从 Argonne 国家实验室转去了布鲁克海文国家实验室。自从中美摩擦以来已多年不见，我却落难时来投，肖教授一定会很困扰吧，但他定不会拒绝我。</p>
<p>2.去往欧洲的几家医学影像中心研究团队，继续前沿的CT与MRI的三维重建方法学研究。这是我一直以来崇尚的方向，因为它极难，相应的不可替代，是我所在的研究方向从难度角度来评估的最高峰。</p>
<p>3.或是直接去往沿海地区寻觅高薪工作。但相应的这样的工作上升空间有限，想象空间不足。</p>
<p>由于我还需每月支付5000元的抚养费，所以理性决策我必须依靠汇率来对冲高额抚养费对我的影响。出海，已经是我的唯一选择。也许我们中国科大物理学院出身的灵魂终有一天会踏上这条船吧，是执念，是信仰，是诅咒。我只是比旁人晚了十年出发而已，但也算不上太晚。我还年轻。</p>
<p>正是在我做出决定后，一些朋友也得知了我已离婚的消息。大熊猫夫妇首先得知我离婚的消息，他们推测，以我的秉性离婚后一定会从西南交大离开，他们两商量，如若我来找他们求助，就带我离开，如若不然，就放任我不管。海内外的一些朋友得知我已离婚并将离开中国，有些给了我一些建议和前沿的信息，有些表示可以支援我10-20万不等的钱让我度过难关，有些直接从其他地方飞来成都陪我喝的烂醉，不过其实根本没喝多少啦，是我酒量极差。</p>
<p>不久后离婚冷静期的期限已到，我正式和罗书璇在离婚登记处签字并领到离婚证。</p>
<p>但我如同一滩烂掉的枯木一般不声不响的在世界上沉寂了很久，大熊猫先生见我迟迟不联系他们，于是在不久后主动联系上我。我首先向他请教以我现在的条件如需申请美国布鲁克海文国家实验室的博士后需要准备的一些材料及注意事项，大熊猫先生没有理会我，却说：</p>
<blockquote>
<p><font color="#B5B5B5"> 大熊猫先生：我给你两条路选。第一，你立刻动身前往我以前的导师团队任 Research Assistant Professor 职务，后面的研究工作我可以支持你。第二，去往某某某单位同样任 Research Assistant Professor 职务，我再给你一个博士生名额，但还需要一些时间。</font><br/></p>
</blockquote>
<p>选项二中的某某某单位是我此生哪怕是在梦中也无法想象能够触及的地方，我毫不犹豫接下我命运的挑战。大熊猫夫人随后又说，「罗书璇居然真的签字了？罗书璇一家是蠢蛋吗？居然就为了10万美元把你给放出来了。」让我很是无语。</p>
<p>恰恰就是在大熊猫先生和我谈话后的第二天，罗老师叫我到成科中心的办公室谈话，刚一见面：</p>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：想不到你们还是走到了这一步，你们是始于颜值，败于现实，对你们的事情，我只能说很遗憾。现在你不是我的女婿了，但还是我的学生，是我的员工，也是我孙女的爸爸。所以我们不是敌人，我希望你好。CT方向归卢磊管理，以后你留在团队工作，每年我还可以给你一个学生，你就继续做你以前擅长的一些事情。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：「无言，我站的笔直，在静静的听。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师以一种我从未听他发出过的奇怪语气发问，稍斜着着头端倪着我：那交大那边以后就交给卢磊管了哦？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：好。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：当年怎么就找了你这么牛逼的人。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：「无言，听到这里，我终于确定这场婚姻就是一场彻头彻尾的骗局和陷阱。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你不要以为你给的钱有多少。你给的钱可以全都还给你，但是你要把小孩的姓给改姓罗。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：我不可能接受。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：过去的事情我已经仁至义尽了。在我们团队里，CT是什么？这几年您重视CT的原因是什么？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：CT是一种很有用的方法啊。它能够无损地看到目标内部的三维结构，之前我一直跟你说，要把有限元仿真搞起来，这样可以用CT拿到目标的初始结构就可以做后续的很多种实验的仿真模拟。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 我想得到的答案是我离开前对我的盖棺定论，我不愿再听这些，于是打断道：那我的CT方向弄的怎么样？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：我虽然搞不清楚你弄的那个粒子追踪算法是怎么回事，但你不过是把许峰他们做的那些事情在团队里复现了而已。</font><br/></p>
</blockquote>
<p>我得到了他心中的真实答案，心灰意冷，得偿所愿，没再说话。可能这就是时机与命运的捉弄吧，同样的摸黑探路，许峰教授今天已是优青，而我在这条路上恐怕永远籍籍无名，连黄、罗两位导师都跟我不一个方向，如同沧海一粟在学术圈里挣扎。罗老师又和我说了说他和团队的一些往事，他离婚的原因啊，张抑扬出走的原因啊，陈森多年来十分嫉妒我所以找了中心某个官员的侄女谈恋爱啊等等等等，我静静听完没再说话，随后离开。</p>
<p>临走之前，罗老师又向我推荐了一款安眠药，说这是经过他尝试多种药物后确认副作用最小的一款药，只有这一款吃完后第二天上午还能保持清醒继续工作。</p>
<p>2024年6月，我仍然沉浸在巨大的痛苦中挣扎，但我仅存的信念驱使着我的残躯一定要做些什么。也是在这一段时间，我和随后陪伴我度过煎熬时刻的景然小姐结识。景然小姐今天已得偿所愿进入某所顶级名校就读，但初相识时仍是清华的本科生。我们是在某款学习英语的软件上结识的，最初是在互相练习口语。练口语时说到她最近在清华的圆顶大礼堂里看了希区柯克的经典惊悚电影，恰巧我曾经唯一一次进去那个礼堂也是在大三时和当时的女朋友看的希区柯克的纪念影片，没想到十年过去了，礼堂的节目还是老花样（开玩笑，毕竟是经典嘛），今日我却已离婚，一时失神，勾起许多我的回忆。</p>
<p>那时我还有写信的习惯。因当年的女朋友陈小姐在清华的中文系念书，时常会有布置读些名著或小说的课后作业，所以偶尔会要求我一起看些她正在看的书并被要求书信往来交流。有些时候我玩游戏贪玩实在懒得写了就骗她说八成是邮差寄丢了吧，她大概从没信过，却从未戳破。时至今日分别多年我连她的样貌都稍有模糊了，但偶尔买些闲书来看看的习惯却早已融入我的血液，成为我生命的一部分。</p>
<p>景然小姐竟自顾自地扮演起陈小姐的角色，在我挣扎的这段时光里，她首先推荐我看「另一种选择」，她说：</p>
<blockquote>
<p><font color="#B5B5B5"> 这是一本很小众的书，是Facebook 第一夫人所写。说来我为什么会看到，也挺有趣。我在一年前看过她赫赫有名的「向前一步」，其中的坚强和自信在当时引起了不小的轰动。然后了解作者生平得知在她出版「向前一步」之后丈夫去世，生活经历重大变故。很多人想知道她是否能像书中一样坚强，于是有了新书「另一种选择」，我如同千万人一般去围观她的自证，为之震撼。也许你也会觉得聆听伟人思想的脉搏是件有趣的事。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 提起这本书，之所以想请你看看，是因为其中有一句话，很期待你读到这句话时，会是什么感受。现在没有书在，但我仍然能记得那句话，不送给你太可惜了。“如果必须坠落，就让我坠落。我将会成为的那个人，一定会接住我。”相信我们思维默契，会让你读懂我的感受。</font><br/></p>
</blockquote>
<p>如此种种，一个多月的时间我看了很多闲书，也恰恰是这些闲书赋予了我重新振作的力量。</p>
<p>2024年7月，我稍振作了些，偶尔重新回到办公室开始做一些正式离职前的筹划，并安排一些我过去的学生们的后续事情，确保我离开后有足够他们毕业的素材。有一天卢磊见我来了成科中心的办公室，便进来找到我说「罗老师让你安心好好做现在的事情，明年去申请博士生导师资格。」我没说什么，只说「好。」大概罗老师也知道他什么有用的都没有给我这个他所谓的学生吧，但时至今日还有什么意义呢，我已经绝无可能接受了。随后我和罗老师上次谈话时决不要的绩效奖励还是通过各种渠道发到了我的手上。此后竟还成为罗书璇和我的谈资，说那些绩效不还是发给你了吗？仿佛本属于我的劳动报酬成了他们的恩典一般。</p>
<p>2024年8月，海南大学的某位副院长对我正在做的人工智能和基因组结合的事情很感兴趣，来成都和我请教一些具体问题，我向他讲授了一些粗浅的数据准备环节的算法技巧。得知我已离婚并计划从西南交大离开，他邀请我加入海南大学，并声称可以帮我争取解决副教授问题。我对这一点抱有怀疑，另一方面大学老师的收入根本不足以支撑我支付抚养费，所以作罢。</p>
<p>2024年11月，我完全振作了起来，正式开始筹划公司组建事宜，开始接触中国和北美的投资机构。最初，我计划用即将成立的中国公司的30%原始股份融资人民币300万元，首先将中国公司落地以较低成本的方式缓速平稳启动研发运作。最初我将中国公司命名为「海源人工智能科技有限公司」，因为我十分喜欢「华严经」中的一句诗文：</p>
<blockquote class="blockquote-center">
<p>如以精进力 能尽海源底 </p>

</blockquote>

<p>但很遗憾「海源」在中国境内属于驰名商标无法注册，我们只得正式注册时更名为「源策人工智能科技有限公司」。</p>
<p>2025年1月，有两组主要的投资伙伴A、B对我正要做的事情很感兴趣，希望出资。投资伙伴A组的出资金额是B组的近两倍，而要求却不相同。A组仅出资金，除要求我签署保密条款外再无其它要求。B组要求由他本人担任公司CEO执行公司管理工作，并要求增设一名由他指定的管理人员参与公司管理，增设董事会计票制共五票，并由他本人出任董事长占两票。在双方交换了想法过后，A组的领导潘总说「如果不由柴博士管理公司，这笔钱我们就不投了！」潘总是长虹电器的副总，现在经营一家独立投资机构，今天已经是我最早也最重要的支柱。这句话被我默默收藏在了心底，此生铭记。也在这个瞬间，我意识到我离婚时自杀式的决绝举动似乎让我拥有了轻易获取他人信任的能力，我好像收获了相当了不得的东西。</p>
<p>选择已显而易见。但投资伙伴B组也确是愿意资助我们的重要伙伴，因此不能怠慢了别人。我向北美投资咨询机构 Sequoia Capital 请教这种情况应该如何处理，随后不久，Sequoia Capital 建议我：与投资伙伴A组组建公司A，由我本人出任CEO管理公司启动研发；与投资伙伴B组组建公司B，所有管理职权全部让渡给B，我不参与公司管理，只提供必要的技术支持。</p>
<p>临近春节，框架性的事宜终于敲定，我向大家如此提议后，由潘总领导的A组确认投资，没有要求竞业，没有要求对赌，没有要求回购，一笔无条件的资金，感动不知所言。而投资伙伴B组担心我的工作重心将会倾斜向A公司，而怠慢了B公司，因此决定暂时撤退再观望一段时间，等待下一轮融资。</p>
<p>2025年春节的大年初三，我正在扬州过春节，忽然接到他们的电话，说有急事找我，希望我赶快到成都来，我赶忙买了些扬州特产作伴手礼大年初四时飞往成都。结果到地方之后，却没什么事情，我很是纳闷。而一个合作伙伴带来了他妻子的妹妹过来，和我年龄相仿，说着说着好像有些许相亲的气氛出现了，我赶忙趁机以去厨房帮忙为由逃走。事后，我和其中一些人郑重地说，「在我动身离开去美国前，我还要给罗书璇最后一次考验，在这之前我不打算考虑男女问题。」</p>
<p>不久后，我正在筹划的北美公司的意向性投资商却有不同的看法，他们找到我说，「其他人都可以，如果你带着罗书璇在身边，我们将不能信任你。」并且声称我和罗书璇存在再次离婚的风险，他们不允许任何可能将罗书璇混进股东会的情况发生。此外，他们希望我驻扎在 Cambridge, MA 管理北美公司期间申请在附近某所名校再攻读一个计算机&#x2F;人工智能方向的博士学位，这样对公司经营有利。从这里开始，我的人生轨迹再次发生了战略性的偏移。</p>
<h2 id="终"><a href="#终" class="headerlink" title="终"></a>终</h2><p>2025年春节过后，我给罗老师发消息说我即将在西南交大办理离职，需要团队领导签字，想今天下午去找他签字。下午到达西南交大的研究所，我先是在曾经的办公室里坐了坐，上次过来还是半年前的硕士答辩会议，以前的琐碎杂物居然都还完好的保留着，一眼扫过去，每个东西所关联的事情立刻历历在目尽在眼前，然而今后都将不再与我有关，失落是难免的事情。我向来念旧，无论是与我有所关联的人或是一件物品，都总是能牵动我的心绪，我十分清楚这是我的巨大弱点，过去极力避免在人前暴露出来，但独自一人时的神伤又该如何控制呢。坐了大约一刻钟，我起身准备去找罗老师签字然后离开。一走出办公室恰巧遇见了赖国栋，我便改变主意先叫赖国栋到我的办公室聊一聊，问问他和其他同学们的近况。</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：你最近怎么样。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 赖国栋：挺好的。</font><br/></p>
</blockquote>
<p>赖国栋还是像以前一样对人爱答不理的样子，总是让我没法把话聊下去。过去我就想好好就这一点和他说道说道，但又担心别人说我像黄俊宇老师一样爱啰嗦在一些奇奇怪怪的点上教育人。何况以前让赖国栋做一些事情，哪怕是光源现场通宵实验，他也只是表面上难看的样子，但都能扎扎实实的落到实处。所以我从没在这个点上和他聊过。但这实在不是个好习惯，往后难免要得罪小人。</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：你的成果已经达到了博士毕业硬性条件，所以不要太过焦虑。接下来一段时间把工作量补齐，来填充你的博士论文。写博士论文的时候如果需要人看一看就来找我，就算我不在西南交大了你也可以来找我。和其他同学说一下对他们也一样。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 赖国栋：好。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：组里其他的同学们怎么样？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 赖国栋：我不是很清楚。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 国栋似乎这会儿是真的不想理我，于是我一个人一个人的问：苗玉飞怎么样？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 赖国栋：他在双流那边，还在弄CT，应该还可以吧。</font><br/></p>
</blockquote>
<p>苗玉飞是我的第一个来自科大的学生，是物理学院的直系师弟，但成绩几乎是贴地飞行刚刚飘过不允许保研的线，后用增补名额进入团队，能力确实在团队内科大学生中最垫底。更要命的是，苗玉飞的行为竟有几分轻度自闭症的症状，我最开始就察觉到了，所以2023年我信念崩塌前还在团队时对苗玉飞格外关注，这似乎引来一些非议。因为苗玉飞父母在中物院本部任职，但只是普通员工，后来团队里一些闲言碎语竟变成苗玉飞家里是单位里的大官，因此我才对他百般爱护。这让我感觉十分无厘头。</p>
<p>他2022年来到团队，在2023年时，苗玉飞面临转博的选择，我严厉地对他说「你如果选择读硕士，我可以包你平安，但对你来说把博士读下来，路会很难。」苗玉飞丝毫没有为我的劝告所动摇，坚持要走这条路。我十分清楚，我们物理学院出身的灵魂不可能允许自己不是Ph.D，我为他的坚决撼动，不再阻拦。苗玉飞注定是我的学生中最可能面临毕业困难的一位。我一直希望他来完成我曾经的愿望「全流程全自动CT数据分析方法学」的研发建设，再与一个具体的问题如聚氨酯泡沫发泡等等结合远远足够他博士毕业，但始终进展缓慢。再后来的故事，我就已经被排除出局外了。</p>
<p>比他更小一届的两位同样是我直系师弟的学生，王威铮、吴辉，他两能力出众，不比当年的我们要差，英语能力更好，以及开源大模型的加持，要比我们更容易做出成果，我相信他们凭自己也一定能杀出来的。他俩2023年初通过增补名额来到团队，大约是在2023年夏天确定成为我的学生。那时超算项目接近尾声，罗老师又有了另一个人工智能相关商务方面的想法让我去执行，同时划拨王威铮和吴辉进入我组。因此最初我对王威铮和吴辉的计划是同我一起学习人工智能技术，边干边学，掌握一定技能之后如能在人工智能方向立足最好不过，如不能，则考虑回归X射线诊断技术与人工智能结合的交叉应用来做一些新方法。</p>
<p>王威铮是我所有的学生中最像我的，因此成了我内心深处最喜欢的一位。早上爱睡懒觉，严重的精神内耗，刚正不阿，对新鲜和困难事物强烈的好奇心（这不是基于利益驱动的好奇心），性格却又傻乎乎的，别人让他做什么都傻乎乎地跑去给别人帮忙做嫁衣。如同成了我自己六年前的老师一般，命运赠予我的一场自我救赎。如果他不是刚刚好在这个时间点加入团队，如果再早一些呢，如果再晚一些呢，也许一切都不一样。我自知即将离开，赖国栋恐怕也不会留在团队，因此王威铮从能力各方面角度都是最适合接替我来继续支撑CT技术的人选。</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：李思文呢？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 赖国栋：李思文现在转去了冲击波那边了，具体不清楚。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：他们那边路径成熟，出文章快，对她来说是好事。</font><br/></p>
</blockquote>
<p>李思文是西南交大物理学院的博士。2021年她和另一位现已毕业的硕士魏晋芳一起来到团队，分别来自江苏第二师范学院和泸州医学院，团队让她们在我和史进春老师之间自由选择。起先我看李思文要更聪慧一些想选择她，但让她们自由选择的结果是魏晋芳选了我这里，而李思文却去了史进春组，既已做出选择我就没再干预。再次见到她已经是2022年下半年，此时史进春老师即将离开团队，李思文再次被安排成为了我的学生。但此时她竟然已经转成博士，过去却没有被安排任何题目，如此被荒废了近一年多的时间。我观察下来，李思文的智力水平不比赖国栋要差，只要花心思就能一定程度的解决新问题。因此我安排她承担显微CT成像实验室的建设工作，框定「显微CT装置硬件建设、实验方法」-「显微CT实验室的三维重建算法」-「某项具体研究对象的应用研究」一套完整的装置建设、算法建设及具体科学问题研究的博士论文思路。</p>
<p>2022年下半年，刘老师和我正在与成都某烟草生产公司接洽一项对卷烟滤棒制造工艺-三维结构-渗流及过滤性能研究的项目。卷烟滤棒的空间结构（开孔泡沫）与尺度（百微米级）是近乎完美的实验室显微CT装置的研究对象，因此我决定让李思文来开展该项工作，补齐她完整的博士工作中具体研究对象的部分。项目的商务接洽进行多轮迭代后，事情几乎已经敲定，对方都已经将大袋小袋的大量试样给我邮寄过来，至今塞满了显微CT实验室外干燥柜的一层。项目的最后一关是专家评审会，对方告诉我们评审会就是走个过场，不会不通过的。但事与愿违，我们的项目恰恰就在这个最终的过场会议上被毙掉了，我十分惊讶，连对方的人也搞不清楚是怎么回事。后来刘老师多方打听后才得知，评审组专家有多名川大物理学院的教授，而我们罗团队当年刚刚建所时最初是在川大建设的，后来不知因为什么原因搬来了西南交大，在这里罗老师得罪了一些人，埋下了种子。就这样，这个近乎完美的研究对象彻底泡汤了。</p>
<p>时间来到2023年，我安排李思文继续做装置建设，而我也在伺机寻觅与显微CT装置相适配的研究对象，但显微CT装置的研究对象实在不容易遇到，太大（指微观特征结构），小小，太硬（指原子序数），太软都不合适。苦寻无果后，我开始联系3D打印机构直接生产与CT装置相适配的样品来做，但始终效果不好。2023年春节后，西南交大的超算项目上马，罗团队原超算团队，刘、张、徐等老师或告病或其他原因全部脱离团队，原来具备这种程度解决问题能力的陈森、张抑扬、黄佳伟三人也全部离去，只剩我一人，项目毫无悬念的压在我的头上。近半年我绝大部分的时间都压在超算项目不得脱身，随后又卷入了家庭战争的泥潭里。李思文从没经历过硬件装置建设的事情，可以想见注定进展缓慢。</p>
<p>2023年3月，我的某位硕士研究生F找到我，那时她研究生二年级，十分委屈，和我说「柴老师，我，我怀孕了。」我先是一惊，首先向她询问「发生什么事了？你有遇到什么不好的事情吗？」她告诉我没有任何事情，是和她的男友意外怀孕了。我再次向她询问「那你打算怎么办？小孩要生下来吗？」她给了我确定的答案，并告知我她打算5月和男友举行婚礼。我懂了她的意思，告诉她「好，你不要担心，你的事情我来帮你处理，今天等我通知。」我让她离开后，马上给罗老师打去电话，说「罗老师，F怀孕了。」罗老师也是一惊，向我确认是不是什么犯罪事件，我说「不是，是正常的男女朋友关系，她打算马上结婚。」我接着说「她是西南交大物理学院的硕士，明年毕业，我不打算让她休学，让她如期毕业没问题。」罗老师支持我的提案，并说「在她怀孕期间不要安排她任何事情，以防意外事件对团队的连带责任。」</p>
<p>我随后做出安排上的调整，将赖国栋正在进行的固体火箭推进剂HEPE结构性能关系研究的一份完整工作按数据挖掘深度拆分为较基础的结构表征及定量化部分和深度的追踪、仿真及力学建模部分，由赖国栋带领F以最快速度完成第一部分的绘图及写作，我校正修改后投稿在正在向我邀稿的一份中文期刊上，首先确保F达到她的毕业指标。赖国栋原研究工作不变按照既定路线推进。此时苗玉飞距离毕业还有三年半，李思文距离毕业还有两年半，分别正在探索「全流程全自动CT数据分析算法」和「显微CT实验室装置建设、算法、应用」，无论是从取得成果的可能性还是时间的紧凑性上，李思文这边的情况都更紧迫。于是我要求F将她正在进行的一种铝基复合材料结构性能关系研究的工作打包转交给李思文，由李思文继续推进完成，以防她的既定路线无法完成，可以用这个成果支撑她毕业。随后，我对F提出两点要求，第一，立即离开团队回家静养，待到生产完恢复后需完善毕业论文时再回到团队；第二，不得向正在罗团队就读的学生透露她怀孕生子的消息，这是因为她一人怀孕生子我尚可以接受，但如果由她起坏了规矩常有人效仿，那团队的规范化管理将无从谈起。</p>
<p>这件事赖国栋牺牲很多，曾经一度我能清晰地感受到赖国栋的敌意，我完全理解，但这已经是我能做出的最好选择。今天回忆起此事再分析，这是一场彻头彻尾的由规则缺位引起的人治危机，女性学生就读期间意外怀孕是一种小概率但在统计尺度上必然会大面积广泛发生的事件。一旦发生，那么必然在怀孕学生和管理团队间倾轧一方或双方权益，一场本应由规则约束的事件处理办法却由于规则缺位，导致人治的局面。在严重伤害F和赖国栋与我稍幸苦一些之间，我毫无疑问选择后者。最终怨恨集中在我的头上，我理性地接受，这是必然发生的结局。</p>
<p>2024年5月，我所谓的家庭已如同地狱酷刑将我折磨的体无完肤，我本打算至少坚持到苗玉飞和李思文这两位必然有困难的学生成果凑齐时再离开，但事与愿违，我在bilibili平台看电台直播的事情败露，东窗事发，我连最后一丝尊严与体面都被践踏在地，再无法同行。离婚后，我勒令苗玉飞尽快处理我交给他的一整套聚氨酯泡沫发泡实验数据，也赶忙找来一种3D打印镁合金轻量化功能复合材料在同步辐射光源上按照打印朝向和热处理工艺两种变量采集到一整套实验数据要求李思文尽快处理。随后厚着脸皮硬挤在我已被踢出局的CT组的组会里，希望能给他们最后再带一带路。这样至少赖国栋、苗玉飞、李思文能在我的眼皮底下把这几个题目处理到中段，我离开后，不至于有人无故从他们手上挪走这些数据交由他人。</p>
<p>但事与愿违，我不在身边苗玉飞的糊涂脑袋更是无从抓起，再得到李思文的消息却已离开CT组。最终，我还是没能带他们走出那片沼泽，在我离职的余波中，那个充满敌意的环境里，他们成了我试图守护却最终失败的最后一块拼图，成为我长久不能释怀的一块巨石压在我的心底。</p>
<blockquote>
<p><font color="#B5B5B5"> 我接着说：王招萍和李俊廷的指标都达到了，我知道，跟她们讲她们写毕业论文的时候如果没人帮忙也可以找我。</font><br/></p>
</blockquote>
<p>李俊廷和王招萍在2022年9月成为我的学生，分别是西南交大物理学院和材料学院的硕士，分别来自西南石油大学和莆田学院，稍不一样的是，李俊廷在入学之前还有过一年左右的工作经历，因此比其他同学们更稳重和内敛一些。大概我都配不上自称她两的老师吧。</p>
<p>赖国栋走后，我在办公室又坐了一会儿平复情绪，但想起这些事情我的悲伤更进一步。回忆起过去作为大学老师的经历，我相当大部分时间都在给罗老师处理商务事项，原本我想这至少是一种置换，但等到我完全被踢出局，暮然回首，学术却已松懈许久。更糟糕的是，我的学生太多了，如此捉襟见肘的情形下，我的每个学生所分到的我的关注，不及寻常老师寻常学生之间的十分之一。大家大概恨透我了吧，我几乎把一切都搞砸了。</p>
<p>随后，我径直去到罗老师的办公室找他签字。罗老师少见的正襟危坐稍佝偻着盯着一台似乎新安装的台式机电脑屏幕。我进去后，他先开口：</p>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：我一直在等你。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：罗老师，这是我辞职必要的材料，需要签字。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：现在网上 DeepSeek 这么火，他们的技术到底怎么样啊？是真的突破还是假的突破啊？</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟，罗老师：「我最近在关注一些法律方面相关的东西，根本没有在关注这些，因此只能用网上的一些说辞和罗老师随意地谈一谈。对人工智能行业发展的推测，我们随意东聊聊西扯扯至少有15分钟。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师话锋一转：我听人说你在外面讲黄俊宇是你的老师，我不是你的老师啊。当年连黄俊宇都是我派过去带你的，不然当年你连博士都毕不了业。</font><br/></p>
</blockquote>
<p>时至今日我早已不再会对这种轻蔑有所反应，以我的能力都会遇到如此巨大困境的情境，我完全确信换旁人来，只会跌落的比我更甚。我想说相比我这个要走的人怎么想你，什么人会在你耳边拿这种捏造的事来嚼舌根才是你更应该关注的点，会是谁呢，想一想也不难猜到。但转念一想那又怎么样呢。我说：</p>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：黄俊宇老师完整的指导了我硕博士时期，他毫无疑问当然是我的老师。但我也在PIMS这么多年，你当然也是我的老师。这不冲突。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你这么说还差不多。你之前说我在边缘化你，我不是在边缘化你而是在培养你。我到今天还能找到一年前的聊天记录，我问你要不要学人工智能，你说你要学，我才让你去学的。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：「我没有说话，到底是怎么回事，看团队安排的细节已经给出了答案。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师再次重复了以前说的话：你的事情我只能说很遗憾。你和罗书璇是始于颜值，终于现实。今天你不是我的女婿了，但还是我的学生，还是我孙女的爸爸，所以我希望你好。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：「无言」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：我很多次劝他们说把钱还给你，但是你要把小孩的姓改姓罗。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 这就如同用我的东西来换我的另一样东西一样可笑：我不接受。这样我还会好受一些。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你不要太动肝火，长期生闷气对身体不好，我之前就是。现在你才30岁，感觉身体还好，等到你到40岁就会感觉身体机能下降，力不从心了。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：「无言，我在静静地听」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：「罗老师开始没完没了的说起团队的事情，说我离开之后他把CT方向模块化拆解成几部分，谁谁谁在做哪一部分，做的不错云云。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：有一天我还会把CT捡起来的，我最开始学人工智能很重要一点就是为了融合提高CT技术能力。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：那是啊，你弄了那么多年，基础理论都在，捡起来也容易。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：「罗老师又开始说起他现在已经不那么骂人了，对学生都是以培养为主，说些什么难听的话也是为了引导。又说给哪个哪个贫困生发了多少多少钱啊，诸如此类。」</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：我知道你在担心什么，你放心，我不会找你的麻烦。一方面，我确实是在PIMS成长起来的。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：是的，你当年刚来的时候就跟流氓一样，你现在也当大学老师，没有一个老师会喜欢你当年那个样子的。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师稍迟疑了一会儿，不知是在和我说还是在呢喃自语：PIMS确实锻炼人。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 柴海伟：另一方面，我现在唯一值钱的不过是我的人格而已，我不会为了找你的麻烦把我的人格丢了。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 罗老师：你找我的麻烦我也不怕，大不了我就回美国去。忠于我的学生也很多，会有我的学生给我报仇的。</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5"> 一阵沉默后，罗老师又端倪起我来，说：你比张抑扬男人多了。</font><br/></p>
</blockquote>
<p>2020年，张抑扬同我一样经历过一次硕士毕业，在他的硕士毕业答辩会议上，我坐在角落旁听，罗老师当着各单位评委专家和同学们的面对张抑扬盛赞道「这是我最聪明的学生！」那时的我连带CT方向已经被冷落多年，我曾经十分艳羡。再后来我一度渴望也有这样的评价，但我唯一一次听到这样的点评却是在罗书璇老家办婚礼酒席时。我在一众叔伯辈的宴席上敬酒时，罗老师似乎有些勉强地向大家介绍道「这是我最聪明的学生。」不是在工作场合而是在这种场景蹦出的这句话，简直让我哭笑不得，连这句话的魅力都褪色了几分。</p>
<p>时至今日，罗老师也许终于能意识到刨去裙带关系这层面纱我也不差吧。多年来我永远逼迫自己做到无可挑剔，因为裙带关系而被怀疑，所以必须更卓越。连做人我也决不要再有瑕疵。也许终于觉得我也不差了吧。悲凉感油然而生，我终于无法支撑一直强装的气势，漏出落寞的眼神。为了眼泪不被察觉，我赶忙转身准备离开。</p>
<p>刚打开门正要迈出一只脚出去，我回过头去看他最后一眼，他竟勉强挺直了身躯，但没有站起来，朝我竖起了大拇指，看起来却有几分老态。竟然连他也会老去吗？我一时恍神，想起大四的春节后我刚刚回到PIMS开始博士生涯时，黄佳伟师兄某天晚上交给我一份文献，要我读完第二天组会上给罗老师汇报。我早已忘记那是一篇什么文章，只记得是一种非主流的X射线诊断技术。我完全没有看懂，随后在交大办公室三角区汇报时讲的稀烂，刚从北京出差回来的罗老师大发雷霆，把我在三角区的讲台上骂了至少有20分钟。似乎我的大脑自我保护机制发挥了作用，嗡嗡作响，让我完全屏蔽了他的声音。我很清楚他是在数月之后才得知我和罗书璇的恋人关系，因此那时是对一个初来乍到的本科生的纯粹恶意而已。那时他如同一头健硕的雄狮，似能吞噬一切。以某位博士后为代表的佞臣们和张抑扬、黄佳伟等诤臣们统统围绕在他身边摇尾祈怜。后来佞臣们都拿到了自己想要的东西潇洒离他而去，诤臣们都在恰当的时机被雄狮的利爪和咆哮喝退，惨淡收场。而只有我，在本该被喝退时，被他的爪牙团团围住，最后被撕的粉碎时方才脱身。想不到这头健硕的雄狮有一天也会老去吗？</p>
<h2 id="最后附上-Sheryl-Sandberg-与丈夫的结婚誓言："><a href="#最后附上-Sheryl-Sandberg-与丈夫的结婚誓言：" class="headerlink" title="最后附上 Sheryl Sandberg 与丈夫的结婚誓言："></a>最后附上 Sheryl Sandberg 与丈夫的结婚誓言：</h2><blockquote>
<p><font color="#B5B5B5">I take you to be mine in love. I promise to love you deliberately each day, to feel your joy and your sorrow as my own. Together, we will build a home filled with honor and honesty, comfort and compassion, learning and love. I take you to be mine in friendship. I vow to celebrate all that you are, to help you become the person you aspire to be. From this day forward, your dreams are my dreams and I dedicate myself to helping you fulfill the promise of your life. I take you to be mine in faith. I believe that our commitment to each other will last a lifetime, that with you, my soul is complete. Knowing who I am and who I want to be, on this day of our marriage, I give you my heart to be forever united with yours.</font><br/></p>
</blockquote>
<blockquote>
<p><font color="#B5B5B5">我将你视为我的挚爱。誓言每天都有意识地爱你，把你的喜怒哀乐视作自己的喜怒哀乐。我们将共同建立一个充满荣誉和诚实、舒适和同情、学习与爱的家庭。我将你视为我的朋友，誓言赞美你的一切，帮助你成为你渴望成为的人。从今天起，你的梦想就是我的梦想，我致力于帮助你实现你的人生承诺。我确信你是我的。我确信我们对彼此的承诺将持续一生，有了你，我的灵魂才是完整的。此刻我知道我是谁，也知道我想成为谁，在我们结婚的这一天，我把我的心交给你，愿我的心永远与你相结合。</font><br/></p>
</blockquote>
<p>言语将尽，又怎诉一声叹惋，隐隐作痛，不过是回声依稀。在我的青年时代，我曾尤其钟爱「哪吒乐队」的一张专辑「他在时间门外」，他们的歌像针一样刺向年轻人悲伤的心脏，象征着不屈，象征着反抗，象征着永远挣扎彷徨着奋不顾身横冲直撞。我如同哪吒剔骨还父，割肉还母，自刎谢罪一般，演绎了一场社会意义的自杀，割舍了我所谓的家庭、多年的噬人爱人、我刚刚诞生的女儿、我热爱的研究方向和我的学生、我过去的事业和我所有的积蓄，一度我仅存的只有我的身躯和残存的信念而已。我期望以这场社会意义的自杀洗刷我过去的罪孽，以这场鲜血淋漓的轻盈救赎我破碎的灵魂。</p>
<p>即便黑暗吞噬了生活，但能观测世界本质的我，从未死去。今天，人类基因组计划启动已逾20年，从人类第一次解读个人基因组信息，到为特殊病人进行个性化全基因组测序，再到大规模高通量测序的实现，可谓翻天覆地。高通量基因组测序已将二十年前人类基因组计划耗资30亿美元完成的事情降至数千人民币「数据」，大规模GPU超算阵列的普及「算力」，后Transformer时代日新月异的算法革新「算法」，今天，黎明前的拼图似乎日趋完备。通过基因组编辑等新的技术手段，人类将实现延缓衰老，甚至让老化的细胞年轻化；作物的选种育种效率将得到数十倍的加速；大多数困扰人类的疾病，从心脏病到神经退行性疾病，都将减少甚至消失。这些前沿科学话题也是当下人们所描绘的一个愿景，但它的到来似乎真的已为时不远。即便我不能在此有所突破，仅存的信念也一定要我凑到最近前，亲眼目睹那黎明破晓的时刻。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 03：科学计算环境 NumPy</title>
    <url>/PythonLes04/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Numpy是Python中科学计算的核心库。它提供了一个多维数组对象，以及用于高并发处理这些数组的向量化计算工具集。NumPy允许用户在Python环境中进行向量和矩阵计算，并且由于许多底层函数实际上是用C编写的，因此你可以体验在原生Python中永远无法体验到的速度。NumPy绝对是Python在科学计算领域成功的关键之一，如果你想要进入Python中的数据科学或机器学习，你就要必须学习它。Have a good day!</p>
<span id="more"></span>

<h2 id="创建数组"><a href="#创建数组" class="headerlink" title="创建数组"></a>创建数组</h2><p>NumPy数组是一个值网格，所有类型都相同，并由非负整数元组索引。创建数组通常有5种常规机制：</p>
<ul>
<li>从其他Python结构（例如，列表，元组，array_like）转换</li>
<li>numpy原生数组的创建（例如，arange、ones、zeros等）</li>
<li>从磁盘读取数组，无论是标准格式还是自定义格式</li>
<li>通过使用字符串或缓冲区从原始字节创建数组</li>
<li>使用特殊库函数（例如，random）</li>
</ul>
<h3 id="直接创建"><a href="#直接创建" class="headerlink" title="直接创建"></a>直接创建</h3><p>通常，在Python中排列成array-like结构的数值数据可以通过使用array()函数转换为数组。最明显的例子是列表和元组。np.array() 直接创建：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<img src="https://pic1.zhimg.com/v2-90de7812f9fc3169cffb7e39d4c3cfd8_r.jpg" width="45%" alt="np.array()创建数组" align=center />

<p>对于一维数组，我们在写数组的时候是横着写的，而其实数组是列向量。</p>
<h3 id="内置函数创建"><a href="#内置函数创建" class="headerlink" title="内置函数创建"></a>内置函数创建</h3><p>Numpy内置了从头开始创建数组的函数，<code>zeros()</code>将创建一个用指定形状用0填充的数组。默认的<code>dtype</code>是<code>float64</code>。使用 np.ones()、np.zeros()、np.random.random() 等方法：</p>
<img src="https://pic4.zhimg.com/v2-6e73db4bcf9e406d110da4f2827200ab_r.jpg" width="100%" alt="np.ones(), np.zeros(), np.random.random()创建数组" align=center />

<p>NumPy同样可以创建多维数组。数组的形状（shape）是一个整数元组，给出了每个维度的数组大小。我们可以从嵌套的Python列表初始化NumPy数组，并使用方括号访问元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])   <span class="comment"># Create a rank 1 array</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a))            <span class="comment"># Prints &quot;&lt;class &#x27;numpy.ndarray&#x27;&gt;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(a.shape)            <span class="comment"># Prints &quot;(3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>], a[<span class="number">1</span>], a[<span class="number">2</span>])   <span class="comment"># Prints &quot;1 2 3&quot;</span></span><br><span class="line">a[<span class="number">0</span>] = <span class="number">5</span>                  <span class="comment"># Change an element of the array</span></span><br><span class="line"><span class="built_in">print</span>(a)                  <span class="comment"># Prints &quot;[5, 2, 3]&quot;</span></span><br><span class="line"></span><br><span class="line">b = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])    <span class="comment"># Create a rank 2 array</span></span><br><span class="line"><span class="built_in">print</span>(b.shape)                     <span class="comment"># Prints &quot;(2, 3)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>, <span class="number">0</span>], b[<span class="number">0</span>, <span class="number">1</span>], b[<span class="number">1</span>, <span class="number">0</span>])   <span class="comment"># Prints &quot;1 2 4&quot;</span></span><br></pre></td></tr></table></figure>

<p>我们再来看一些例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">b = np.array((<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">c = np.arange(<span class="number">5</span>)</span><br><span class="line">d = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(b)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(c)     <span class="comment"># &gt;&gt;&gt;[0 1 2 3 4]</span></span><br><span class="line"><span class="built_in">print</span>(d)     <span class="comment"># &gt;&gt;&gt;[ 0.  1.57079633  3.14159265  4.71238898  6.28318531]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">3</span>])  <span class="comment"># &gt;&gt;&gt;3</span></span><br></pre></td></tr></table></figure>

<p>上面的代码显示了创建数组的4种不同方法。最基本的方法是将序列传递给NumPy的<code>array()</code>函数; 你可以传递任何序列（类数组），而不仅仅是常见的列表（list）数据类型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3.0</span>)</span><br><span class="line">array([ <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">array([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">&gt;&gt;&gt;np.arange(<span class="number">3</span>,<span class="number">7</span>,<span class="number">2</span>)</span><br><span class="line">array([<span class="number">3</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p><code>np.arange()</code>函数对于整数参数，该函数大致相当于Python内置的<code>range()</code>。当使用非整数步长（例如0.1）时，通常使用<a href="https://github.com/numpy/numpy/blob/v1.26.0/numpy/core/function_base.py#L24-L182">numpy.linspace</a>更好。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.linspace(start, stop, num=<span class="number">50</span>, endpoint=<span class="literal">True</span>, retstep=<span class="literal">False</span>, dtype=<span class="literal">None</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>start: array_like 序列的起始值；</li>
<li>stop: array_like 序列的结束值，除非endpoint被设置为False。在这种情况下，序列由除num+1个均匀间隔样本的最后一个之外的所有样本组成，因此stop值被排除在外。注意，当endpoint为False时，步长会发生变化。</li>
<li>num: int 可选项，要生成的样本数量，默认值是50，必须为非负整数；</li>
<li>endpoint: bool 可选项，如果为True，则最后一个元素为stop值，否则不包含。默认为True；</li>
<li>retstep: bool 可选项，如果True，返回(samples, step)，其中step是采样之间的间隔。</li>
<li>dtype: dtype 可选项，输出数组的数据类型。如果不指定dtype，则从start和stop推断数据类型。推断的dtype永远不会是整型；即使参数将产生一个整数数组，也选择float。</li>
<li>axis: int 可选项，1.9.0新版功能。Axis在结果中存储样品。只有当start或stop是数组类型时才相关。默认情况下(0)，样本将沿着在开始时插入的新轴。用-1得到最后的轴。</li>
</ul>
<p>这个创建函数的优点是可以保证元素的数量以及开始和结束点，对于任意的开始，停止和步骤值，<code>arange()</code>通常不会这样做。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>)</span><br><span class="line">array([<span class="number">2.</span>  , <span class="number">2.25</span>, <span class="number">2.5</span> , <span class="number">2.75</span>, <span class="number">3.</span>  ])</span><br><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>, endpoint=<span class="literal">False</span>)</span><br><span class="line">array([<span class="number">2.</span> ,  <span class="number">2.2</span>,  <span class="number">2.4</span>,  <span class="number">2.6</span>,  <span class="number">2.8</span>])</span><br><span class="line">&gt;&gt;&gt;np.linspace(<span class="number">2.0</span>, <span class="number">3.0</span>, num=<span class="number">5</span>, retstep=<span class="literal">True</span>)</span><br><span class="line">(array([<span class="number">2.</span>  ,  <span class="number">2.25</span>,  <span class="number">2.5</span> ,  <span class="number">2.75</span>,  <span class="number">3.</span>  ]), <span class="number">0.25</span>)</span><br></pre></td></tr></table></figure>

<p>同样类似的函数还有<code>geomspace()</code>以及<code>logspace()</code>，功能与<code>linspace()</code>函数类似，分别对应生成指数级数与对数级数数组，在此不做过多介绍。</p>
<h3 id="创建多维数组"><a href="#创建多维数组" class="headerlink" title="创建多维数组"></a>创建多维数组</h3><p>上面的数组示例是如何使用NumPy表示向量的，接下来我们将看看如何使用多维数组表示矩阵和更多的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">2</span>,<span class="number">4</span>]) <span class="comment"># &gt;&gt;&gt;25</span></span><br></pre></td></tr></table></figure>

<p>为了创建一个二维数组，我们传递一个列表的列表（或者是一个序列的序列）给<code>array()</code>函数。如果我们想要一个3D（三维）数组，我们就要传递一个列表的列表的列表，如果是一个4D（四维）数组，那就是列表的列表的列表的列表，以此类推。请注意2D（二维）数组是如何按行和列排列的。要索引2D（二维）数组，我们只需引用行数和列数即可。</p>
<p>我们再来看看一些二维情况下创建数组的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.zeros((<span class="number">2</span>,<span class="number">2</span>))   <span class="comment"># Create an array of all zeros</span></span><br><span class="line"><span class="built_in">print</span>(a)              <span class="comment"># Prints &quot;[[ 0.  0.]</span></span><br><span class="line">                      <span class="comment">#          [ 0.  0.]]&quot;</span></span><br><span class="line"></span><br><span class="line">b = np.ones((<span class="number">1</span>,<span class="number">2</span>))    <span class="comment"># Create an array of all ones</span></span><br><span class="line"><span class="built_in">print</span>(b)              <span class="comment"># Prints &quot;[[ 1.  1.]]&quot;</span></span><br><span class="line"></span><br><span class="line">c = np.full((<span class="number">2</span>,<span class="number">2</span>), <span class="number">7</span>)  <span class="comment"># Create a constant array</span></span><br><span class="line"><span class="built_in">print</span>(c)               <span class="comment"># Prints &quot;[[ 7.  7.]</span></span><br><span class="line">                       <span class="comment">#          [ 7.  7.]]&quot;</span></span><br><span class="line"></span><br><span class="line">d = np.eye(<span class="number">2</span>)         <span class="comment"># Create a 2x2 identity matrix</span></span><br><span class="line"><span class="built_in">print</span>(d)              <span class="comment"># Prints &quot;[[ 1.  0.]</span></span><br><span class="line">                      <span class="comment">#          [ 0.  1.]]&quot;</span></span><br><span class="line"></span><br><span class="line">e = np.random.random((<span class="number">2</span>,<span class="number">2</span>))  <span class="comment"># Create an array filled with random values</span></span><br><span class="line"><span class="built_in">print</span>(e)                     <span class="comment"># Might print &quot;[[ 0.91940167  0.08143941]</span></span><br><span class="line">                             <span class="comment">#               [ 0.68744134  0.87236687]]&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="数组属性"><a href="#数组属性" class="headerlink" title="数组属性"></a>数组属性</h3><p>在使用NumPy时，你会想知道数组的某些信息。很幸运，NumPy包里边包含了很多便捷的方法，可以给你想要的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Array properties</span></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a)) <span class="comment"># &gt;&gt;&gt;&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(a.dtype) <span class="comment"># &gt;&gt;&gt;int64</span></span><br><span class="line"><span class="built_in">print</span>(a.size) <span class="comment"># &gt;&gt;&gt;25</span></span><br><span class="line"><span class="built_in">print</span>(a.shape) <span class="comment"># &gt;&gt;&gt;(5, 5)</span></span><br><span class="line"><span class="built_in">print</span>(a.itemsize) <span class="comment"># &gt;&gt;&gt;8</span></span><br><span class="line"><span class="built_in">print</span>(a.ndim) <span class="comment"># &gt;&gt;&gt;2</span></span><br><span class="line"><span class="built_in">print</span>(a.nbytes) <span class="comment"># &gt;&gt;&gt;200</span></span><br></pre></td></tr></table></figure>

<p>正如你在上面的代码中看到的，NumPy数组实际上被称为<code>&#39;numpy.ndarray&#39;</code>。</p>
<ul>
<li><p><code>shape</code>属性是数组有多少行和列，上面的数组有5行和5列，所以它的shape是(5, 5)。</p>
</li>
<li><p><code>itemsize</code>属性是每个项占用的字节（Byte）数。这个数组的数据类型是<code>int64</code>，一个<code>int64</code>中有64 bit，1 byte &#x3D; 8 bit，即为8 byte。</p>
</li>
<li><p><code>ndim</code>属性是数组的维数，在本例中为2。</p>
</li>
<li><p><code>nbytes</code>属性是数组中的所有数据消耗掉的字节数。这并不计算数组信息定义开销，因此数组占用的实际内存空间将稍微大一点。</p>
</li>
</ul>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>每个NumPy数组都是相同类型元素的网格。NumPy提供了一组可用于构造数组的大量数值数据类型。NumPy在创建数组时尝试猜测数据类型，但构造数组的函数通常还包含一个可选参数来显式指定数据类型。这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>])   <span class="comment"># Let numpy choose the datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)         <span class="comment"># Prints &quot;int64&quot;</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1.0</span>, <span class="number">2.0</span>])   <span class="comment"># Let numpy choose the datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)             <span class="comment"># Prints &quot;float64&quot;</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>], dtype=np.int64)   <span class="comment"># Force a particular datatype</span></span><br><span class="line"><span class="built_in">print</span>(x.dtype)                         <span class="comment"># Prints &quot;int64&quot;</span></span><br></pre></td></tr></table></figure>

<p>NumPy支持比Python更多种类的数字类型。本节显示了哪些可用，以及如何修改数组的数据类型。支持的原始类型与 C 中的原始类型紧密相关：</p>
<img src="https://s21.ax1x.com/2024/03/25/pF5SVln.png" width="85%" alt="NumPy数据类型1" align=center />

<p>由于其中许多都具有依赖于平台的定义，因此提供了一组固定大小的别名：</p>
<img src="https://s21.ax1x.com/2024/03/25/pF5SZyq.png" width="85%" alt="NumPy数据类型2" align=center />

<p>NumPy数值类型是<code>dtype</code>（数据类型）对象的实例，每个对象都具有独特的特征。导入NumPy后使用，在<code>dtypes</code>可作为<code>np.bool_</code>，<code>np.float32</code>等等。</p>
<p>上表中未列出的高级类型将在后续的课程中教授结构化数组时进行探讨。</p>
<p>有5种基本数字类型表示布尔值（bool），整数（int），无符号整数（uint）浮点（float）和复数（complex）。名称中带有数字的那些表示该类型的位大小（即，在内存中表示单个值需要多少位）。某些类型（例如<code>int</code>和<code>intp</code>）具有不同的位，取决于平台（例如，32位与64位计算机）。在与寻址原始内存的低层代码（例如C或Fortran）连接时，应考虑这一点。</p>
<p>数据类型可以用作将Python数转换为数组标量的函数，将Python数字序列转换为该类型的数组，或作为许多NumPy函数或方法接受的<code>dtype</code>关键字的参数。一些例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.float32(<span class="number">1.0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line"><span class="number">1.0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = np.int_([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z = np.arange(<span class="number">3</span>, dtype=np.uint8)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>z</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=uint8)</span><br></pre></td></tr></table></figure>

<p>数组类型也可以通过字符代码引用，主要是为了保持与较旧的包（如Numeric）的向后兼容性。有些文档可能仍然引用这些，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=<span class="string">&#x27;f&#x27;</span>)</span><br><span class="line">array([ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>], dtype=float32)</span><br></pre></td></tr></table></figure>

<p>但我们仍然建议使用<code>dtype</code>对象。</p>
<p>要转换数组的类型，请使用 <code>.astype()</code> 方法（首选）或类型本身作为函数。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.astype(<span class="built_in">float</span>)                 </span><br><span class="line">array([  <span class="number">0.</span>,  <span class="number">1.</span>,  <span class="number">2.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.int8(z)</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], dtype=int8)</span><br></pre></td></tr></table></figure>

<p>注意，在上面，我们使用 Python 的<code>float</code>对象作为<code>dtype</code>。NumPy中<code>int</code>是指<code>np.int_</code>，<code>bool</code>意味着<code>np.bool_</code>，<code>float</code>是<code>np.float_</code>，<code>complex</code>是<code>np.complex_</code>。其他数据类型没有Python等价物。</p>
<p>要确定数组的类型，请查看<code>dtype</code>属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>z.dtype</span><br><span class="line">dtype(<span class="string">&#x27;uint8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>dtype</code>对象还包含有关类型的信息，例如其位宽和字节顺序。数据类型也可以间接用于查询类型的属性，例如它是否为整数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = np.dtype(<span class="built_in">int</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d</span><br><span class="line">dtype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.issubdtype(d, np.integer)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.issubdtype(d, np.floating)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h3 id="数组标量"><a href="#数组标量" class="headerlink" title="数组标量"></a>数组标量</h3><p>NumPy通常将数组元素作为数组标量返回（带有关联<code>dtype</code>的标量）。数组标量与Python标量不同，但在大多数情况下它们可以互换使用（主要的例外是早于v2.x的Python版本，其中整数数组标量不能作为列表和元组的索引）。有一些例外，例如当代码需要标量的非常特定的属性或者它特定地检查值是否是Python标量时。通常，存在的问题很容易被显式转换数组标量到Python标量，采用相应的Python类型的功能（例如，固定的<code>int</code>，<code>float</code>，<code>complex</code>，<code>str</code>，<code>unicode</code>）。</p>
<p>使用数组标量的主要优点是它们保留了数组类型（Python可能没有匹配的标量类型，例如int16）。因此，使用数组标量可确保数组和标量之间的相同行为，无论值是否在数组内。NumPy标量也有许多与数组相同的方法。</p>
<h3 id="溢出错误"><a href="#溢出错误" class="headerlink" title="溢出错误"></a>溢出错误</h3><p>当值需要比数据类型中的可用内存更多的内存时，NumPy数值类型的固定大小可能会导致溢出错误。例如，<code>numpy.power</code>对于int64可以正确计算 100 * 10 * 8，但对于int32给出1874919424（不正确）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">8</span>, dtype=np.int64)</span><br><span class="line"><span class="number">10000000000000000</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">8</span>, dtype=np.int32)</span><br><span class="line"><span class="number">1874919424</span></span><br></pre></td></tr></table></figure>

<p>NumPy和Python整数类型的行为在整数溢出方面存在显着差异，并且可能会使用户期望NumPy整数的行为类似于Python中的<code>int</code>。与 NumPy 不同，Python本体的<code>int</code>是灵活的。这意味着Python整数可以扩展以容纳任何整数并且不会溢出。</p>
<p>NumPy分别提供<code>numpy.iinfo</code>和<code>numpy.finfo</code>验证NumPy整数和浮点值的最小值或最大值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.<span class="built_in">int</span>) <span class="comment"># Bounds of the default integer on this system.</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">9223372036854775808</span>, <span class="built_in">max</span>=<span class="number">9223372036854775807</span>, dtype=int64)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.int32) <span class="comment"># Bounds of a 32-bit integer</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">2147483648</span>, <span class="built_in">max</span>=<span class="number">2147483647</span>, dtype=int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.iinfo(np.int64) <span class="comment"># Bounds of a 64-bit integer</span></span><br><span class="line">iinfo(<span class="built_in">min</span>=-<span class="number">9223372036854775808</span>, <span class="built_in">max</span>=<span class="number">9223372036854775807</span>, dtype=int64)</span><br></pre></td></tr></table></figure>

<p>如果int64仍然太小，则结果可能会转换为浮点数。浮点数提供了更大但不精确的可能值范围。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">100</span>, dtype=np.int64) <span class="comment"># Incorrect even with 64-bit int</span></span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.power(<span class="number">100</span>, <span class="number">100</span>, dtype=np.float64)</span><br><span class="line"><span class="number">1e+200</span></span><br></pre></td></tr></table></figure>

<h3 id="扩展精度"><a href="#扩展精度" class="headerlink" title="扩展精度"></a>扩展精度</h3><p>Python 的浮点数通常是64位浮点数，几乎等同于<code>np.float64</code>。在某些不寻常的情况下，使用更精确的浮点数可能会很有用。这在numpy中是否可行取决于硬件和开发环境：具体地说，x86机器提供80位精度的硬件浮点，虽然大多数C编译器提供这一点作为它们的<code>long double</code>类型，MSVC（Windows构建的标准）使<code>long double</code>等同于<code>double</code>（64位）。NumPy使编译器的<code>long double</code>作为<code>np.longdouble</code>可用（而<code>np.clongdouble</code>用于复数)。</p>
<p>NumPy不提供比C的<code>long double</code>更高精度的dtype；特别是128位IEEE四精度数据类型（FORTRAN的 <code>REAL*16</code> ）不可用。</p>
<p>为了有效地进行内存的校准，<code>np.longdouble</code>通常以零位进行填充，即96或者128位，哪个更有效率取决于硬件和开发环境；通常在32位系统上它们被填充到96位，而在64位系统上它们通常被填充到128位。<code>np.longdouble</code>被填充到系统默认值；为需要特定填充的用户提供了<code>np.float96</code>和<code>np.float128</code>。尽管它们的名称是这样叫的, 但是<code>np.float96</code>和<code>np.float128</code>只提供与<code>np.longdouble</code>一样的精度, 即大多数x86机器上的80位和标准Windows版本中的64位。</p>
<p>请注意，即使<code>np.longdouble</code>提供比Python中<code>float</code>更多的精度，也很容易失去额外的精度，因为Python通常强制值通过<code>float</code>传递值。</p>
<h2 id="数组索引"><a href="#数组索引" class="headerlink" title="数组索引"></a>数组索引</h2><p>NumPy提供了几种索引数组的方法。</p>
<h3 id="单元素索引"><a href="#单元素索引" class="headerlink" title="单元素索引"></a>单元素索引</h3><p>人们期望的是1-D数组的单元素索引。它的工作方式与其他标准Python序列完全相同。它从0开始计数，并接受从数组末尾开始索引的负索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">2</span>]</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>

<p>与列表和元组不同，NumPy数组支持多维数组的多维索引。这意味着没有必要将每个维度的索引分成它自己的一组方括号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.shape = (<span class="number">2</span>,<span class="number">5</span>) <span class="comment"># now x is 2-dimensional</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>,<span class="number">3</span>]</span><br><span class="line"><span class="number">8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>,-<span class="number">1</span>]</span><br><span class="line"><span class="number">9</span></span><br></pre></td></tr></table></figure>

<p>请注意，如果索引索引比维度少的多维数组，则会获得一个子维数组。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>]</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>

<p>也就是说，指定的每个索引选择与所选维度的其余部分对应的数组。在上面的示例中，选择0表示长度为5的剩余维度未指定，返回的是该维度和大小的数组。必须注意的是，返回的数组不是原始数据的副本，而是指向内存中与原始数组相同的值。在这种情况下，返回第一个位置（0）的1-D数组。因此，在返回的数组上使用单个索引会导致返回单个元素。那是：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>请注意，尽管第二种情况效率较低，因为在第一个索引之后创建了一个新的临时数组，该索引随后被索引为2：<code>x[0,2] = x[0][2]</code></p>
<h3 id="切片索引（Slicing）"><a href="#切片索引（Slicing）" class="headerlink" title="切片索引（Slicing）"></a>切片索引（Slicing）</h3><p>与Python列表类似，可以对NumPy数组进行切片。由于数组可能是多维的，因此必须为数组的每个维指定一个切片：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],     <span class="comment"># Create the following rank 2 array with shape (3, 4)</span></span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">b = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]    <span class="comment"># Use slicing to pull out the subarray consisting of the first 2 rows and columns 1 and 2; </span></span><br><span class="line"><span class="built_in">print</span>(b)          <span class="comment"># b is the following array of shape (2, 2):</span></span><br><span class="line">                  <span class="comment"># [[2 3]</span></span><br><span class="line">                  <span class="comment">#  [6 7]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A slice of an array is a view into the same data, so modifying it</span></span><br><span class="line"><span class="comment"># will modify the original array.</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;2&quot;</span></span><br><span class="line">b[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">77</span>     <span class="comment"># b[0, 0] is the same piece of data as a[0, 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;77&quot;</span></span><br></pre></td></tr></table></figure>

<p>你还可以将整数索引与切片索引混合使用。 但是，这样做会产生比原始数组更低级别的数组。 请注意，这与MATLAB处理数组切片的方式完全不同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], </span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two ways of accessing the data in the middle row of the array.</span></span><br><span class="line"><span class="comment"># Mixing integer indexing with slices yields an array of lower rank,</span></span><br><span class="line"><span class="comment"># while using only slices yields an array of the same rank as the</span></span><br><span class="line"><span class="comment"># original array:</span></span><br><span class="line">row_r1 = a[<span class="number">1</span>, :]    <span class="comment"># Rank 1 view of the second row of a</span></span><br><span class="line">row_r2 = a[<span class="number">1</span>:<span class="number">2</span>, :]  <span class="comment"># Rank 2 view of the second row of a</span></span><br><span class="line"><span class="built_in">print</span>(row_r1, row_r1.shape)  <span class="comment"># Prints &quot;[5 6 7 8] (4,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(row_r2, row_r2.shape)  <span class="comment"># Prints &quot;[[5 6 7 8]] (1, 4)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can make the same distinction when accessing columns of an array:</span></span><br><span class="line">col_r1 = a[:, <span class="number">1</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1, col_r1.shape)  <span class="comment"># Prints &quot;[ 2  6 10] (3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(col_r2, col_r2.shape)  <span class="comment"># Prints &quot;[[ 2]</span></span><br><span class="line">                             <span class="comment">#          [ 6]</span></span><br><span class="line">                             <span class="comment">#          [10]] (3, 1)&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="整数数组索引"><a href="#整数数组索引" class="headerlink" title="整数数组索引"></a>整数数组索引</h3><p>使用切片索引到NumPy数组时，生成的数组视图将始终是原始数组的子数组。 相反，整数数组索引允许你使用另一个数组中的数据构造任意数组。 这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># An example of integer array indexing.</span></span><br><span class="line"><span class="comment"># The returned array will have shape (3,) and</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The above example of integer array indexing is equivalent to this:</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">0</span>], a[<span class="number">1</span>, <span class="number">1</span>], a[<span class="number">2</span>, <span class="number">0</span>]]))  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When using integer array indexing, you can reuse the same</span></span><br><span class="line"><span class="comment"># element from the source array:</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Equivalent to the previous integer array indexing example</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">1</span>], a[<span class="number">0</span>, <span class="number">1</span>]]))  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br></pre></td></tr></table></figure>

<p>整数数组索引的一个有用技巧是从矩阵的每一行中选择或改变一个元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a new array from which we will select elements</span></span><br><span class="line">a = np.array([[ <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">              [ <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], </span><br><span class="line">              [ <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], </span><br><span class="line">              [<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an array of indices</span></span><br><span class="line">b = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select one element from each row of a using the indices in b</span></span><br><span class="line"><span class="built_in">print</span>(a[np.arange(<span class="number">4</span>), b])  <span class="comment"># Prints &quot;[ 1  6  7 11]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mutate one element from each row of a using the indices in b</span></span><br><span class="line">a[np.arange(<span class="number">4</span>), b] += <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)  <span class="comment"># prints &quot;array([[11,  2,  3],</span></span><br><span class="line">          <span class="comment">#                [ 4,  5, 16],</span></span><br><span class="line">          <span class="comment">#                [17,  8,  9],</span></span><br><span class="line">          <span class="comment">#                [10, 21, 12]])</span></span><br></pre></td></tr></table></figure>

<h3 id="布尔数组索引"><a href="#布尔数组索引" class="headerlink" title="布尔数组索引"></a>布尔数组索引</h3><p>布尔数组索引允许你选择数组的任意元素。通常，这种类型的索引用于选择满足某些条件的数组元素。下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line">bool_idx = (a &gt; <span class="number">2</span>)   <span class="comment"># Find the elements of a that are bigger than 2;</span></span><br><span class="line">                     <span class="comment"># this returns a numpy array of Booleans of the same</span></span><br><span class="line">                     <span class="comment"># shape as a, where each slot of bool_idx tells</span></span><br><span class="line">                     <span class="comment"># whether that element of a is &gt; 2.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bool_idx)      <span class="comment"># Prints &quot;[[False False]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We use boolean array indexing to construct a rank 1 array</span></span><br><span class="line"><span class="comment"># consisting of the elements of a corresponding to the True values</span></span><br><span class="line"><span class="comment"># of bool_idx</span></span><br><span class="line"><span class="built_in">print</span>(a[bool_idx])  <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can do all of the above in a single concise statement:</span></span><br><span class="line"><span class="built_in">print</span>(a[a &gt; <span class="number">2</span>])     <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="广播-Broadcasting"><a href="#广播-Broadcasting" class="headerlink" title="广播(Broadcasting)"></a>广播(Broadcasting)</h2><p>广播是一种强大的机制，它允许NumPy在执行算术运算时使用不同形状的数组。通常，我们有一个较小的数组和一个较大的数组，我们希望多次使用较小的数组来对较大的数组执行一些操作。</p>
<p>例如，假设我们要向矩阵的每一行添加一个常数向量。我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y = np.empty_like(x)   <span class="comment"># Create an empty matrix with the same shape as x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the vector v to each row of the matrix x with an explicit loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    y[i, :] = x[i, :] + v</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now y is the following</span></span><br><span class="line"><span class="comment"># [[ 2  2  4]</span></span><br><span class="line"><span class="comment">#  [ 5  5  7]</span></span><br><span class="line"><span class="comment">#  [ 8  8 10]</span></span><br><span class="line"><span class="comment">#  [11 11 13]]</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<p>这会凑效; 但是当矩阵 x 非常大时，在Python中计算显式循环可能会很慢。注意，向矩阵 x 的每一行添加向量 v 等同于通过垂直堆叠多个 v 副本来形成矩阵 vv，然后执行元素的求和x 和 vv。 我们可以像如下这样实现这种方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">vv = np.tile(v, (<span class="number">4</span>, <span class="number">1</span>))   <span class="comment"># Stack 4 copies of v on top of each other</span></span><br><span class="line"><span class="built_in">print</span>(vv)                 <span class="comment"># Prints &quot;[[1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]]&quot;</span></span><br><span class="line">y = x + vv  <span class="comment"># Add x and vv elementwise</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>NumPy广播允许我们在不实际创建v的多个副本的情况下执行此计算。考虑这个需求，使用广播如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">y = x + v  <span class="comment"># Add v to each row of x using broadcasting</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4]</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>y&#x3D;x+v行即使x具有形状(4，3)和v具有形状(3,)，但由于广播的关系，该行的工作方式就好像v实际上具有形状(4，3)，其中每一行都是v的副本，并且求和是按元素执行的。</p>
<p>将两个数组一起广播遵循以下规则：</p>
<ul>
<li>如果数组不具有相同的rank，则将较低等级数组的形状添加1，直到两个形状具有相同的长度。</li>
<li>如果两个数组在维度上具有相同的大小，或者如果其中一个数组在该维度中的大小为1，则称这两个数组在维度上是兼容的。</li>
<li>如果数组在所有维度上兼容，则可以一起广播。</li>
<li>广播之后，每个数组的行为就好像它的形状等于两个输入数组的形状的元素最大值。</li>
<li>在一个数组的大小为1且另一个数组的大小大于1的任何维度中，第一个数组的行为就像沿着该维度复制一样</li>
</ul>
<p>支持广播的功能称为通用功能。</p>
<p>以下是广播的一些应用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute outer product of vectors</span></span><br><span class="line">v = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])  <span class="comment"># v has shape (3,)</span></span><br><span class="line">w = np.array([<span class="number">4</span>,<span class="number">5</span>])    <span class="comment"># w has shape (2,)</span></span><br><span class="line"><span class="comment"># To compute an outer product, we first reshape v to be a column</span></span><br><span class="line"><span class="comment"># vector of shape (3, 1); we can then broadcast it against w to yield</span></span><br><span class="line"><span class="comment"># an output of shape (3, 2), which is the outer product of v and w:</span></span><br><span class="line"><span class="comment"># [[ 4  5]</span></span><br><span class="line"><span class="comment">#  [ 8 10]</span></span><br><span class="line"><span class="comment">#  [12 15]]</span></span><br><span class="line"><span class="built_in">print</span>(np.reshape(v, (<span class="number">3</span>, <span class="number">1</span>)) * w)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a vector to each row of a matrix</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),</span></span><br><span class="line"><span class="comment"># giving the following matrix:</span></span><br><span class="line"><span class="comment"># [[2 4 6]</span></span><br><span class="line"><span class="comment">#  [5 7 9]]</span></span><br><span class="line"><span class="built_in">print</span>(x + v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a vector to each column of a matrix</span></span><br><span class="line"><span class="comment"># x has shape (2, 3) and w has shape (2,).</span></span><br><span class="line"><span class="comment"># If we transpose x then it has shape (3, 2) and can be broadcast</span></span><br><span class="line"><span class="comment"># against w to yield a result of shape (3, 2); transposing this result</span></span><br><span class="line"><span class="comment"># yields the final result of shape (2, 3) which is the matrix x with</span></span><br><span class="line"><span class="comment"># the vector w added to each column. Gives the following matrix:</span></span><br><span class="line"><span class="comment"># [[ 5  6  7]</span></span><br><span class="line"><span class="comment">#  [ 9 10 11]]</span></span><br><span class="line"><span class="built_in">print</span>((x.T + w).T)</span><br><span class="line"><span class="comment"># Another solution is to reshape w to be a column vector of shape (2, 1);</span></span><br><span class="line"><span class="comment"># we can then broadcast it directly against x to produce the same</span></span><br><span class="line"><span class="comment"># output.</span></span><br><span class="line"><span class="built_in">print</span>(x + np.reshape(w, (<span class="number">2</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiply a matrix by a constant:</span></span><br><span class="line"><span class="comment"># x has shape (2, 3). Numpy treats scalars as arrays of shape ();</span></span><br><span class="line"><span class="comment"># these can be broadcast together to shape (2, 3), producing the</span></span><br><span class="line"><span class="comment"># following array:</span></span><br><span class="line"><span class="comment"># [[ 2  4  6]</span></span><br><span class="line"><span class="comment">#  [ 8 10 12]]</span></span><br><span class="line"><span class="built_in">print</span>(x * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>广播通常会使你的代码更简洁，效率更高，因此你应该尽可能地使用它。</p>
<h2 id="数组中的基本数学"><a href="#数组中的基本数学" class="headerlink" title="数组中的基本数学"></a>数组中的基本数学</h2><p>基本数学函数在数组上以元素方式运行，既可以作为运算符重载，也可以作为NumPy模块中的函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise sum; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 6.0  8.0]</span></span><br><span class="line"><span class="comment">#  [10.0 12.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"><span class="built_in">print</span>(np.add(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise difference; both produce the array</span></span><br><span class="line"><span class="comment"># [[-4.0 -4.0]</span></span><br><span class="line"><span class="comment">#  [-4.0 -4.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x - y)</span><br><span class="line"><span class="built_in">print</span>(np.subtract(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise product; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 5.0 12.0]</span></span><br><span class="line"><span class="comment">#  [21.0 32.0]]</span></span><br><span class="line"><span class="built_in">print</span>(x * y)</span><br><span class="line"><span class="built_in">print</span>(np.multiply(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise division; both produce the array</span></span><br><span class="line"><span class="comment"># [[ 0.2         0.33333333]</span></span><br><span class="line"><span class="comment">#  [ 0.42857143  0.5       ]]</span></span><br><span class="line"><span class="built_in">print</span>(x / y)</span><br><span class="line"><span class="built_in">print</span>(np.divide(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Elementwise square root; produces the array</span></span><br><span class="line"><span class="comment"># [[ 1.          1.41421356]</span></span><br><span class="line"><span class="comment">#  [ 1.73205081  2.        ]]</span></span><br><span class="line"><span class="built_in">print</span>(np.sqrt(x))</span><br></pre></td></tr></table></figure>

<p>请注意，与MATLAB不同，<code>*</code>是元素乘法，而不是矩阵乘法。 我们使用<code>dot</code>函数来计算向量的内积，将向量乘以矩阵。 <code>dot</code>既可以作为NumPy模块中的函数，也可以作为数组对象的实例方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line">y = np.array([[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line">v = np.array([<span class="number">9</span>,<span class="number">10</span>])</span><br><span class="line">w = np.array([<span class="number">11</span>, <span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inner product of vectors; both produce 219</span></span><br><span class="line"><span class="built_in">print</span>(v.dot(w))</span><br><span class="line"><span class="built_in">print</span>(np.dot(v, w))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix / vector product; both produce the rank 1 array [29 67]</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(v))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x, v))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix / matrix product; both produce the rank 2 array</span></span><br><span class="line"><span class="comment"># [[19 22]</span></span><br><span class="line"><span class="comment">#  [43 50]]</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(y))</span><br><span class="line"><span class="built_in">print</span>(np.dot(x, y))</span><br></pre></td></tr></table></figure>

<p>NumPy为在数组上执行计算提供了许多有用的函数；其中最常用的函数之一是求和函数<code>sum</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x))  <span class="comment"># Compute sum of all elements; prints &quot;10&quot;</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">0</span>))  <span class="comment"># Compute sum of each column; prints &quot;[4 6]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">1</span>))  <span class="comment"># Compute sum of each row; prints &quot;[3 7]&quot;</span></span><br></pre></td></tr></table></figure>


<p>除了使用数组计算数学函数外，我们经常需要对数组中的数据进行整形或其他操作。这种操作的最简单的例子是转置一个矩阵；要转置一个矩阵，只需使用一个数组对象的T属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x)    <span class="comment"># Prints &quot;[[1 2]</span></span><br><span class="line">            <span class="comment">#          [3 4]]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(x.T)  <span class="comment"># Prints &quot;[[1 3]</span></span><br><span class="line">            <span class="comment">#          [2 4]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that taking the transpose of a rank 1 array does nothing:</span></span><br><span class="line">v = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(v)    <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(v.T)  <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="点积运算原理"><a href="#点积运算原理" class="headerlink" title="点积运算原理"></a>点积运算原理</h3><h4 id="数组特殊运算符"><a href="#数组特殊运算符" class="headerlink" title="数组特殊运算符"></a>数组特殊运算符</h4><p>NumPy还提供了一些别的用于处理数组的好用的运算符。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># dot, sum, min, max, cumsum</span></span><br><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">sum</span>()) <span class="comment"># &gt;&gt;&gt;45</span></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">min</span>()) <span class="comment"># &gt;&gt;&gt;0</span></span><br><span class="line"><span class="built_in">print</span>(a.<span class="built_in">max</span>()) <span class="comment"># &gt;&gt;&gt;9</span></span><br><span class="line"><span class="built_in">print</span>(a.cumsum()) <span class="comment"># &gt;&gt;&gt;[ 0  1  3  6 10 15 21 28 36 45]</span></span><br></pre></td></tr></table></figure>

<p>sum()、min()和max()函数的作用非常明显。将所有元素相加，找出最小和最大元素。</p>
<p>然而，cumsum()函数就不那么明显了。它将像sum()这样的每个元素相加，但是它首先将第一个元素和第二个元素相加，并将计算结果存储在一个列表中，然后将该结果添加到第三个元素中，然后再将该结果存储在一个列表中。这将对数组中的所有元素执行此操作，并返回作为列表的数组之和的运行总数。</p>
<h4 id="Where-函数"><a href="#Where-函数" class="headerlink" title="Where 函数"></a>Where 函数</h4><p>where() 函数是一个根据条件返回数组中的值的有效方法。只需要把条件传递给它，它就会返回一个使得条件为真的元素的列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Where</span></span><br><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">b = np.where(a &lt; <span class="number">50</span>) </span><br><span class="line">c = np.where(a &gt;= <span class="number">50</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(b) <span class="comment"># &gt;&gt;&gt;(array([0, 1, 2, 3, 4]),)</span></span><br><span class="line"><span class="built_in">print</span>(c) <span class="comment"># &gt;&gt;&gt;[5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>


<h2 id="字节交换"><a href="#字节交换" class="headerlink" title="字节交换"></a>字节交换</h2><h3 id="字节排序和ndarrays简介"><a href="#字节排序和ndarrays简介" class="headerlink" title="字节排序和ndarrays简介"></a>字节排序和ndarrays简介</h3><p>ndarray是一个为内存中的数据提供python数组接口的对象。经常发生的情况是，要用数组查看的内存与运行Python的计算机的字节顺序不同。</p>
<p>例如，我可能正在使用带有 little-endian CPU 的计算机 - 例如Intel Pentium，但是我已经从一个由 big-endian计算机 编写的文件中加载了一些数据。假设我已经从Sun（big-endian）计算机写入的文件中加载了4个字节。我知道这4个字节代表两个16位整数。在 big-endian 机器上，首先以最高有效字节（MSB）存储双字节整数，然后存储最低有效字节（LSB）。因此字节按内存顺序排列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MSB整数<span class="number">1</span></span><br><span class="line">LSB整数<span class="number">1</span></span><br><span class="line">MSB整数<span class="number">2</span></span><br><span class="line">LSB整数<span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>假设两个整数实际上是1和770.因为770 &#x3D; 256 * 3 + 2，内存中的4个字节将分别包含：0,1,3,2。我从文件加载的字节将包含这些内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_buffer = <span class="built_in">bytearray</span>([<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_buffer</span><br><span class="line"><span class="built_in">bytearray</span>(<span class="string">b&#x27;\x00\x01\x03\x02&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>我们可能需要使用 ndarray 来访问这些整数。在这种情况下，我们可以围绕这个内存创建一个数组，并告诉numpy有两个整数，并且它们是16位和Big-endian：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr = np.ndarray(shape=(<span class="number">2</span>,),dtype=<span class="string">&#x27;&gt;i2&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">1</span>]</span><br><span class="line"><span class="number">770</span></span><br></pre></td></tr></table></figure>

<p>注意上面的数组<code>dtype &gt; i2</code>。<code>&gt;</code> 表示 big-endian( <code>&lt;</code> 是 Little-endian )，i2 表示‘有符号的2字节整数’。例如，如果我们的数据表示单个无符号4字节小端整数，则dtype字符串将为 <code>&lt;u4</code>。</p>
<p>事实上，为什么我们不尝试呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>little_end_u4 = np.ndarray(shape=(<span class="number">1</span>,),dtype=<span class="string">&#x27;&lt;u4&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>little_end_u4[<span class="number">0</span>] == <span class="number">1</span> * <span class="number">256</span>**<span class="number">1</span> + <span class="number">3</span> * <span class="number">256</span>**<span class="number">2</span> + <span class="number">2</span> * <span class="number">256</span>**<span class="number">3</span></span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<p>回到我们的 big_end_arr - 在这种情况下我们的基础数据是big-endian（数据字节序），我们设置dtype匹配（dtype也是big-endian）。但是，有时你需要翻转它们。</p>
<p>标量当前不包含字节顺序信息，因此从数组中提取标量将返回本机字节顺序的整数。因此：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>big_end_arr[<span class="number">0</span>].dtype.byteorder == little_end_u4[<span class="number">0</span>].dtype.byteorder</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<h3 id="更改字节顺序"><a href="#更改字节顺序" class="headerlink" title="更改字节顺序"></a>更改字节顺序</h3><p>从介绍中可以想象，有两种方法可以影响数组的字节顺序与它所查看的底层内存之间的关系：</p>
<ul>
<li><p>更改数组dtype中的字节顺序信息，以便将基础数据解释为不同的字节顺序。这是作用 <code>arr.newbyteorder()</code></p>
</li>
<li><p>更改基础数据的字节顺序，保留<code>dtype</code>解释。这是做什么的 <code>arr.byteswap()</code>。</p>
</li>
</ul>
<p>需要更改字节顺序的常见情况是：</p>
<ul>
<li>数据和dtype字节顺序不匹配，并且希望更改dtype以使其与数据匹配。</li>
<li>数据和dtype字节顺序不匹配，并且希望交换数据以使它们与dtype匹配</li>
<li>数据和dtype字节顺序匹配，但希望交换数据和dtype来反映这一点</li>
</ul>
<h4 id="数据和dtype字节顺序不匹配，更改dtype以匹配数据"><a href="#数据和dtype字节顺序不匹配，更改dtype以匹配数据" class="headerlink" title="数据和dtype字节顺序不匹配，更改dtype以匹配数据"></a>数据和dtype字节顺序不匹配，更改dtype以匹配数据</h4><p>我们制作一些他们不匹配的东西：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>wrong_end_dtype_arr = np.ndarray(shape=(<span class="number">2</span>,),dtype=<span class="string">&#x27;&lt;i2&#x27;</span>, buffer=big_end_buffer)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>wrong_end_dtype_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">256</span></span><br></pre></td></tr></table></figure>

<p>这种情况的明显解决方法是更改dtype，以便它给出正确的字节顺序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr = wrong_end_dtype_arr.newbyteorder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>请注意，内存中的数组未更改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_dtype_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<h4 id="数据和类型字节顺序不匹配，更改数据以匹配dtype"><a href="#数据和类型字节顺序不匹配，更改数据以匹配dtype" class="headerlink" title="数据和类型字节顺序不匹配，更改数据以匹配dtype"></a>数据和类型字节顺序不匹配，更改数据以匹配dtype</h4><p>如果需要内存中的数据是某种顺序，可能希望这样做。例如，可能正在将内存写入需要特定字节排序的文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr = wrong_end_dtype_arr.byteswap()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>现在数组 已 在内存中更改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fixed_end_mem_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h4 id="数据和dtype字节序匹配，交换数据和dtype"><a href="#数据和dtype字节序匹配，交换数据和dtype" class="headerlink" title="数据和dtype字节序匹配，交换数据和dtype"></a>数据和dtype字节序匹配，交换数据和dtype</h4><p>可能有一个正确指定的数组dtype，但是需要数组在内存中具有相反的字节顺序，并且希望dtype匹配以便数组值有意义。在这种情况下，只需执行上述两个操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr = big_end_arr.byteswap().newbyteorder()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p>使用ndarray astype方法可以更简单地将数据转换为特定的dtype和字节顺序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr = big_end_arr.astype(<span class="string">&#x27;&lt;i2&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr[<span class="number">0</span>]</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>swapped_end_arr.tobytes() == big_end_buffer</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>


<h2 id="结构化数组"><a href="#结构化数组" class="headerlink" title="结构化数组"></a>结构化数组</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>结构化数组是ndarray，其数据类型是由一系列命名字段组织的简单数据类型组成。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">9</span>, <span class="number">81.0</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.0</span>)],</span><br><span class="line"><span class="meta">... </span>             dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">9</span>, <span class="number">81.</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>x 是一个长度为2的一维数组，其数据类型是一个包含三个字段的结构：</p>
<ul>
<li>长度为10或更少的字符串，名为“name”。</li>
<li>一个32位整数，名为“age”。</li>
<li>一个32位的名为’weight’的float类型。</li>
</ul>
<p>如果x在位置1处索引，则会得到一个结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>]</span><br><span class="line">(<span class="string">&#x27;Fido&#x27;</span>, <span class="number">3</span>, <span class="number">27.0</span>)</span><br></pre></td></tr></table></figure>

<p>可以通过使用字段名称建立索引来访问和修改结构化数组的各个字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;age&#x27;</span>]</span><br><span class="line">array([<span class="number">9</span>, <span class="number">3</span>], dtype=int32)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;age&#x27;</span>] = <span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="string">&#x27;Rex&#x27;</span>, <span class="number">5</span>, <span class="number">81.</span>), (<span class="string">&#x27;Fido&#x27;</span>, <span class="number">5</span>, <span class="number">27.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;U10&#x27;</span>), (<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;weight&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>结构化数据类型旨在能够模仿C语言中的“结构”，并共享类似的内存布局。它们用于连接C代码和低级操作结构化缓冲区，例如用于解释二进制blob。出于这些目的，它们支持诸如子数组，嵌套数据类型和联合之类的专用功能，并允许控制结构的内存布局。</p>
<p>希望操纵表格数据的用户（例如存储在csv文件中）可能会发现其他更适合的pydata项目，例如xarray，pandas或DataArray。这些为表格数据分析提供了高级接口，并且针对该用途进行了更好的优化。例如，numpy中结构化数组的类似C-struct的内存布局可能导致较差的缓存行为。</p>
<h3 id="结构化数据类型创建"><a href="#结构化数据类型创建" class="headerlink" title="结构化数据类型创建"></a>结构化数据类型创建</h3><p>结构化数据类型可以被认为是一定长度的字节序列（结构的项目大小），它被解释为字段集合。每个字段在结构中都有一个名称，一个数据类型和一个字节偏移量。字段的数据类型可以是包括其他结构化数据类型的任何numpy数据类型，也可以是子行数据类型，其行为类似于指定形状的ndarray。字段的偏移是任意的，字段甚至可以重叠。这些偏移量通常由numpy自动确定，但也可以指定。</p>
<p>可以使用该函数创建结构化数据类型numpy.dtype。有4种不同的规范形式， 其灵活性和简洁性各不相同。这些在 “数据类型对象” 参考页面中进一步记录，总结如下：</p>
<h4 id="元组列表，每个字段一个元组"><a href="#元组列表，每个字段一个元组" class="headerlink" title="元组列表，每个字段一个元组"></a>元组列表，每个字段一个元组</h4><p>每个元组都具有以下形式（字段名称、数据类型、形状），其中Shape是可选的。 fieldname 是字符串（如果使用标题，则为元组，请参见下面的字段标题）， datatype 可以是任何可转换为数据类型的对象，而 shape 是指定子数组形状的整数元组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, np.float32), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>, (<span class="number">2</span>, <span class="number">2</span>))])</span><br><span class="line">dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>, (<span class="number">2</span>, <span class="number">2</span>))])</span><br></pre></td></tr></table></figure>

<p>如果 fieldname 是空字符串 ‘’ ，则将为字段指定格式为 f# 的默认名称， 其中 # 是字段的整数索引，从左侧开始从0开始计数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>)])</span><br><span class="line">dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>自动确定结构内字段的字节偏移量和总结构项大小。</p>
<h4 id="逗号分隔的数据类型规范字符串"><a href="#逗号分隔的数据类型规范字符串" class="headerlink" title="逗号分隔的数据类型规范字符串"></a>逗号分隔的数据类型规范字符串</h4><p>在这个速记符号中，任何 字符串dtype规范 都可以在字符串中使用， 并用逗号分隔。 字段的项目大小和字节偏移是自动确定的，并且字段名称被赋予默认名称 f0、f1等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(<span class="string">&#x27;i8, f4, S3&#x27;</span>)</span><br><span class="line">dtype([(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(<span class="string">&#x27;3int8, float32, (2, 3)float64&#x27;</span>)</span><br><span class="line">dtype([(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;i1&#x27;</span>, (<span class="number">3</span>,)), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>, (<span class="number">2</span>, <span class="number">3</span>))])</span><br></pre></td></tr></table></figure>

<h4 id="字段参数组字典"><a href="#字段参数组字典" class="headerlink" title="字段参数组字典"></a>字段参数组字典</h4><p>这是最灵活的规范形式，因为它允许控制字段的字节偏移和结构的项目大小。</p>
<p>字典有两个必需键 “names” 和 “format”，以及四个可选键 “offsets”、“itemsize”、“Aligned” 和 “title”。 名称和格式的值应该分别是相同长度的字段名列表和dtype规范列表。 可选的 “offsets” 值应该是整数字节偏移量的列表，结构中的每个字段都有一个偏移量。 如果未给出 “Offsets” ，则自动确定偏移量。可选的 “itemsize” 值应该是一个整数， 描述dtype的总大小（以字节为单位），它必须足够大以包含所有字段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;names&#x27;</span>: [<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>], <span class="string">&#x27;formats&#x27;</span>: [<span class="string">&#x27;i4&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>]&#125;)</span><br><span class="line">dtype([(<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;col2&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;names&#x27;</span>: [<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;col2&#x27;</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;formats&#x27;</span>: [<span class="string">&#x27;i4&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;offsets&#x27;</span>: [<span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line"><span class="meta">... </span>          <span class="string">&#x27;itemsize&#x27;</span>: <span class="number">12</span>&#125;)</span><br><span class="line">dtype(&#123;<span class="string">&#x27;names&#x27;</span>:[<span class="string">&#x27;col1&#x27;</span>,<span class="string">&#x27;col2&#x27;</span>], <span class="string">&#x27;formats&#x27;</span>:[<span class="string">&#x27;&lt;i4&#x27;</span>,<span class="string">&#x27;&lt;f4&#x27;</span>], <span class="string">&#x27;offsets&#x27;</span>:[<span class="number">0</span>,<span class="number">4</span>], <span class="string">&#x27;itemsize&#x27;</span>:<span class="number">12</span>&#125;)</span><br></pre></td></tr></table></figure>

<p>可以选择偏移量，使得字段重叠，尽管这将意味着分配给一个字段可能会破坏任何重叠字段的数据。 作为一个例外，numpy.object类型的字段不能与其他字段重叠，因为存在破坏内部对象指针然后取消引用它的风险。</p>
<p>可选的“Aligned”值可以设置为True，以使自动偏移计算使用对齐的偏移量（请参阅自动字节偏移量和对齐）， 就好像numpy.dtype的“Align”关键字参数已设置为True一样。</p>
<p>可选的 ‘titles’ 值应该是长度与 ‘names’ 相同的标题列表，请参阅下面的字段标题。</p>
<h4 id="字段名称字典"><a href="#字段名称字典" class="headerlink" title="字段名称字典"></a>字段名称字典</h4><p>不鼓励使用这种形式的规范。 字典的关键字是字段名称，值是指定类型和偏移量的元组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;col1&#x27;</span>: (<span class="string">&#x27;i1&#x27;</span>, <span class="number">0</span>), <span class="string">&#x27;col2&#x27;</span>: (<span class="string">&#x27;f4&#x27;</span>, <span class="number">1</span>)&#125;)</span><br><span class="line">dtype([(<span class="string">&#x27;col1&#x27;</span>, <span class="string">&#x27;i1&#x27;</span>), (<span class="string">&#x27;col2&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>不鼓励使用这种形式，因为Python字典在Python 3.6之前的Python版本中不保留顺序， 并且结构化dtype中字段的顺序有意义。字段标题可以通过使用3元组来指定，见下文。</p>
<h3 id="操作和显示结构化数据类型"><a href="#操作和显示结构化数据类型" class="headerlink" title="操作和显示结构化数据类型"></a>操作和显示结构化数据类型</h3><p>可以names 在dtype对象的属性中找到结构化数据类型的字段名称列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = np.dtype([(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d.names</span><br><span class="line">(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以通过names使用相同长度的字符串序列分配属性来修改字段名称。</p>
<p>dtype对象还具有类似字典的属性，fields其键是字段名称（和字段标题，见下文）， 其值是包含每个字段的dtype和字节偏移量的元组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>d.fields</span><br><span class="line">mappingproxy(&#123;<span class="string">&#x27;x&#x27;</span>: (dtype(<span class="string">&#x27;int64&#x27;</span>), <span class="number">0</span>), <span class="string">&#x27;y&#x27;</span>: (dtype(<span class="string">&#x27;float32&#x27;</span>), <span class="number">8</span>)&#125;)</span><br></pre></td></tr></table></figure>

<p>对于非结构化数组，names和fields属性都相同None。 测试 dtype 是否结构化的推荐方法是， 如果dt.names不是None 而不是 dt.names ，则考虑具有0字段的dtypes。</p>
<p>如果可能，结构化数据类型的字符串表示形式显示在“元组列表”表单中，否则numpy将回退到使用更通用的字典表单。</p>
<h3 id="自动字节偏移和对齐"><a href="#自动字节偏移和对齐" class="headerlink" title="自动字节偏移和对齐"></a>自动字节偏移和对齐</h3><p>NumPy使用两种方法之一自动确定字段字节偏移量和结构化数据类型的总项目大小，具体取决于是否 align&#x3D;True指定为关键字参数numpy.dtype。</p>
<p>默认情况下（align&#x3D;False），numpy将字段打包在一起，使得每个字段从前一个字段结束的字节偏移开始，并且字段在内存中是连续的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">print_offsets</span>(<span class="params">d</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;offsets:&quot;</span>, [d.fields[name][<span class="number">1</span>] <span class="keyword">for</span> name <span class="keyword">in</span> d.names])</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(<span class="string">&quot;itemsize:&quot;</span>, d.itemsize)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print_offsets(np.dtype(<span class="string">&#x27;u1, u1, i4, u1, i8, u2&#x27;</span>))</span><br><span class="line">offsets: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">15</span>]</span><br><span class="line">itemsize: <span class="number">17</span></span><br></pre></td></tr></table></figure>

<p>如果align&#x3D;True设置了，NumPy将以与许多C编译器填充C结构相同的方式填充结构。在某些情况下，对齐结构可以提高性能，但代价是增加了数据类型的大小。在字段之间插入填充字节，使得每个字段的字节偏移量将是该字段对齐的倍数，对于简单数据类型，通常等于字段的字节大小，请参阅PyArray_Descr.alignment。该结构还将添加尾随填充，以使其itemsize是最大字段对齐的倍数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print_offsets(np.dtype(<span class="string">&#x27;u1, u1, i4, u1, i8, u2&#x27;</span>, align=<span class="literal">True</span>))</span><br><span class="line">offsets: [<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">24</span>]</span><br><span class="line">itemsize: <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>请注意，尽管默认情况下几乎所有现代C编译器都以这种方式填充，但C结构中的填充依赖于C实现，因此不能保证此内存布局与C程序中相应结构的内容完全匹配。为了获得确切的对应关系，可能需要在numpy侧或C侧进行一些工作。</p>
<p>如果使用offsets基于字典的dtype规范中的可选键指定了偏移量，则设置align&#x3D;True将检查每个字段的偏移量是其大小的倍数，并且itemsize是最大字段大小的倍数，如果不是，则引发异常。</p>
<p>如果结构化数组的字段和项目大小的偏移满足对齐条件，则数组将具有该ALIGNED flag集合。</p>
<p>便捷函数<code>numpy.lib.recfunctions.repack_fields</code>将对齐的dtype或数组转换为打包的dtype或数组，反之亦然。它需要一个dtype或结构化的ndarray作为参数，并返回一个带有字段重新打包的副本，带或不带填充字节。</p>
<h3 id="字段标题"><a href="#字段标题" class="headerlink" title="字段标题"></a>字段标题</h3><p>除了字段名称之外，字段还可以具有关联的标题，备用名称，有时用作字段的附加说明或别名。标题可用于索引数组，就像字段名一样。</p>
<p>要在使用dtype规范的list-of-tuples形式时添加标题，可以将字段名称指定为两个字符串的元组而不是单个字符串，它们分别是字段的标题和字段名称。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line">dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>当使用第一种形式的基于字典的规范时，标题可以’titles’作为如上所述的额外密钥提供。当使用第二个（不鼓励的）基于字典的规范时，可以通过提供3元素元组而不是通常的2元素元组来提供标题：(datatype, offset, title)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.dtype(&#123;<span class="string">&#x27;name&#x27;</span>: (<span class="string">&#x27;i4&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;my title&#x27;</span>)&#125;)</span><br><span class="line">dtype([((<span class="string">&#x27;my title&#x27;</span>, <span class="string">&#x27;name&#x27;</span>), <span class="string">&#x27;&lt;i4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>该dtype.fields字典将包含标题作为键，如果使用任何头衔。这有效地表示具有标题的字段将在字典字典中表示两次。这些字段的元组值还将具有第三个元素，即字段标题。因此，并且因为names属性保留了字段顺序而fields 属性可能没有，所以建议使用dtype的names属性迭代dtype的字段，该属性不会列出标题，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> name <span class="keyword">in</span> d.names:</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(d.fields[name][:<span class="number">2</span>])</span><br><span class="line">(dtype(<span class="string">&#x27;int64&#x27;</span>), <span class="number">0</span>)</span><br><span class="line">(dtype(<span class="string">&#x27;float32&#x27;</span>), <span class="number">8</span>)</span><br></pre></td></tr></table></figure>

<h3 id="联合类型"><a href="#联合类型" class="headerlink" title="联合类型"></a>联合类型</h3><p>默认情况下，结构化数据类型在numpy中实现为基本类型 numpy.void， 但是可以使用 数据类型对象中 中描述的dtype规范的 (base_dtype, dtype) 形式将其他 numpy 类型解释为结构化类型。 这里，base_dtype 是所需的底层 dtype，字段和标志将从dtype复制。此 dtype 类似于 C 中的“Union”。</p>
<h3 id="将数据分配给结构化数组"><a href="#将数据分配给结构化数组" class="headerlink" title="将数据分配给结构化数组"></a>将数据分配给结构化数组</h3><p>有许多方法可以为结构化数组赋值：使用python元组，使用标量值或使用其他结构化数组。</p>
<h4 id="从Python本机类型（元组）分配"><a href="#从Python本机类型（元组）分配" class="headerlink" title="从Python本机类型（元组）分配"></a>从Python本机类型（元组）分配</h4><p>为结构化数组赋值的最简单方法是使用python元组。每个赋值应该是一个长度等于数组中字段数的元组，而不是列表或数组，因为它们将触发numpy的广播规则。元组的元素从左到右分配给数组的连续字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), (<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)], dtype=<span class="string">&#x27;i8, f4, f8&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">1</span>] = (<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">1</span>, <span class="number">2.</span>, <span class="number">3.</span>), (<span class="number">7</span>, <span class="number">8.</span>, <span class="number">9.</span>)],</span><br><span class="line">     dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;&lt;f8&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<h4 id="Scalars的赋值"><a href="#Scalars的赋值" class="headerlink" title="Scalars的赋值"></a>Scalars的赋值</h4><p>分配给结构化元素的标量将分配给所有字段。将标量分配给结构化数组时，或者将非结构化数组分配给结构化数组时，会发生这种情况：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.zeros(<span class="number">2</span>, dtype=<span class="string">&#x27;i8, f4, ?, S1&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:] = <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">3</span>, <span class="number">3.</span>, <span class="literal">True</span>, <span class="string">b&#x27;3&#x27;</span>), (<span class="number">3</span>, <span class="number">3.</span>, <span class="literal">True</span>, <span class="string">b&#x27;3&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;?&#x27;</span>), (<span class="string">&#x27;f3&#x27;</span>, <span class="string">&#x27;S1&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[:] = np.arange(<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">0</span>, <span class="number">0.</span>, <span class="literal">False</span>, <span class="string">b&#x27;0&#x27;</span>), (<span class="number">1</span>, <span class="number">1.</span>, <span class="literal">True</span>, <span class="string">b&#x27;1&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;f0&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;f1&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;f2&#x27;</span>, <span class="string">&#x27;?&#x27;</span>), (<span class="string">&#x27;f3&#x27;</span>, <span class="string">&#x27;S1&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>结构化数组也可以分配给非结构化数组，但前提是结构化数据类型只有一个字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>twofield = np.zeros(<span class="number">2</span>, dtype=[(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>onefield = np.zeros(<span class="number">2</span>, dtype=[(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nostruct = np.zeros(<span class="number">2</span>, dtype=<span class="string">&#x27;i4&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>nostruct[:] = twofield</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">...</span><br><span class="line">TypeError: Cannot cast scalar <span class="keyword">from</span> dtype([(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>), (<span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;&lt;i4&#x27;</span>)]) to dtype(<span class="string">&#x27;int32&#x27;</span>) according to the rule <span class="string">&#x27;unsafe&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="来自其他结构化数组的赋值"><a href="#来自其他结构化数组的赋值" class="headerlink" title="来自其他结构化数组的赋值"></a>来自其他结构化数组的赋值</h4><p>两个结构化数组之间的分配就像源元素已转换为元组然后分配给目标元素一样。也就是说，源数组的第一个字段分配给目标数组的第一个字段，第二个字段同样分配，依此类推，而不管字段名称如何。具有不同数量的字段的结构化数组不能彼此分配。未包含在任何字段中的目标结构的字节不受影响。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = np.zeros(<span class="number">3</span>, dtype=[(<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.ones(<span class="number">3</span>, dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;O&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b[:] = a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">array([(<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>), (<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>), (<span class="number">0.</span>, <span class="string">b&#x27;0.0&#x27;</span>, <span class="string">b&#x27;&#x27;</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;S3&#x27;</span>), (<span class="string">&#x27;z&#x27;</span>, <span class="string">&#x27;O&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<h4 id="涉及子数组的分配"><a href="#涉及子数组的分配" class="headerlink" title="涉及子数组的分配"></a>涉及子数组的分配</h4><p>分配给子数组的字段时，首先将指定的值广播到子数组的形状。</p>
<h3 id="索引结构化数组"><a href="#索引结构化数组" class="headerlink" title="索引结构化数组"></a>索引结构化数组</h3><h4 id="访问单个字段"><a href="#访问单个字段" class="headerlink" title="访问单个字段"></a>访问单个字段</h4><p>可以通过使用字段名称索引数组来访问和修改结构化数组的各个字段。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.array([(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">3</span>, <span class="number">4</span>)], dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;f4&#x27;</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line">array([<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;foo&#x27;</span>] = <span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">10</span>, <span class="number">2.</span>), (<span class="number">10</span>, <span class="number">4.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>生成的数组是原始数组的视图。它共享相同的内存位置，写入视图将修改原始数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = x[<span class="string">&#x27;bar&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[:] = <span class="number">11</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">array([(<span class="number">10</span>, <span class="number">11.</span>), (<span class="number">10</span>, <span class="number">11.</span>)],</span><br><span class="line">      dtype=[(<span class="string">&#x27;foo&#x27;</span>, <span class="string">&#x27;&lt;i8&#x27;</span>), (<span class="string">&#x27;bar&#x27;</span>, <span class="string">&#x27;&lt;f4&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>此视图与索引字段具有相同的dtype和itemsize，因此它通常是非结构化数组，但嵌套结构除外。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.dtype, y.shape, y.strides</span><br><span class="line">(dtype(<span class="string">&#x27;float32&#x27;</span>), (<span class="number">2</span>,), (<span class="number">12</span>,))</span><br></pre></td></tr></table></figure>

<p>如果访问的字段是子数组，则子数组的维度将附加到结果的形状：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.zeros((<span class="number">2</span>, <span class="number">2</span>), dtype=[(<span class="string">&#x27;a&#x27;</span>, np.int32), (<span class="string">&#x27;b&#x27;</span>, np.float64, (<span class="number">3</span>, <span class="number">3</span>))])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;a&#x27;</span>].shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="string">&#x27;b&#x27;</span>].shape</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>序</title>
    <url>/Exp001-hello-world/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUtC1H.jpg"></p>
<blockquote class="blockquote-center">
<p>“在学校开课的时节，我便专心教书，等到学校放寒暑假，我才从事写作。”  —— 老舍</p>

</blockquote>

<p>第一次接触Hexo|NexT主题博客，是在某位多晶相变专家的个人主页。当时不仅为他的学识所折服，更惊叹于如此优雅的知识分享方式。那时就曾想，以后一定要搭建自己的博客，来记录自己的经历和成长，今日终如愿。</p>
<span id="more"></span>

<h2 id="为什么记录生活"><a href="#为什么记录生活" class="headerlink" title="为什么记录生活"></a>为什么记录生活</h2><p>决定攻读博士学位那刻起，人生的很多种可能已再无法实现。身上的责任越来越重，太多事情需要去做，每天每天周而复始。于自身有益的、无益的信息，都未经过滤从各种渠道钻进大脑里占据一部分空间。记录生活，可以把自己从喧闹的现实生活中释放出来，放空自己，使内心重归平静。我越来越难以回忆起，去年的这个时候我在做些什么，在想些什么，对未来的人生有着什么样的想法，然后思考自己过去这一年，做了些什么有意义的事，完成了什么重要的任务，并进一步思考，未来的路应该怎么走，而不是被现实的压力驱赶着，一直低头赶路。所以需要通过文字，让过去不止是淹没在时间长河中再也打捞不起来的过去，而是一条清晰的锁链，我拽着锁链的这头，就能与过去的自己对话，了解自己的人生观是如何悄然变化。</p>
<h2 id="为什么记录技术笔记"><a href="#为什么记录技术笔记" class="headerlink" title="为什么记录技术笔记"></a>为什么记录技术笔记</h2><p>这就有很多原因了。一方面作为科研人员，没有整理技术笔记的习惯让人难以置信。技术笔记可以帮助自己理清解决问题的思路，归纳知识体系。在工作中遇到了技术难题，一味的摸索、尝试，直到柳暗花明突然解决问题，但没有停下手头的工作来思考并记录始末，则是错失了一大笔财富，或许一年后再遇到同样的问题，依然要花费大量时间重新探索。每过一段时间的技术积淀，都要停下脚步来重新思考，梳理一下零散的知识体系，或是记录一些关键问题的探索方案，延续已付出的智慧与努力的价值。这里有两点很重要，第一，亲自实践，第二，重新思考。即使是走在前人的老路上而没有做出创新性的贡献，自己重新归纳总结也有助于梳理流程，深化理解。</p>
<p>制作个人博客的另一层目的是为博士学位论文累积素材。因为一些特殊原因，今年我需要走一遍硕士毕业的流程，开了一星期夜车硬是折腾完了整篇硕士学位论文和答辩报告，写完后也实在是没有兴趣再去校对修改了。结果当然是存在大量行文逻辑不严谨的地方，虽然是形式主义，但毕竟也署着我的名字。评委发回的意见里甚至直接写上 “此处XX用词不当”，这让我始终很后悔。我很期望能写出系统、深刻的博士学位论文，于我而言，无论结果如何，这都将是我此生视若珍宝的东西之一，因此目前的准备工作必不可少。</p>
<h2 id="为什么使用Hexo并在网络上公开"><a href="#为什么使用Hexo并在网络上公开" class="headerlink" title="为什么使用Hexo并在网络上公开"></a>为什么使用Hexo并在网络上公开</h2><p>使用Hexo|NexT的初衷是觉得这非常优雅，我尤其钟爱这类极简的艺术，搭建并调整Hexo|NexT的过程也着实让我沉浸其中。</p>
<p>至于在网络上公开的原因，一方面，我越来越觉得，要把知识、经验、感悟分享出来，给他人带来价值，或经受批判后成长。</p>
<p>另一方面，离开母校后人际关系愈加复杂，喧嚣的社交早已不再适合谈及生活与理想，只有在此延续另一种形态的社交。</p>
]]></content>
      <categories>
        <category>Notes on Life and Letter</category>
      </categories>
      <tags>
        <tag>Life</tag>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 04：NumPy 数据分析基础</title>
    <url>/PythonLes05/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程仅作为学习NumPy的参考，并让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="导入NumPy作为np，并查看版本"><a href="#导入NumPy作为np，并查看版本" class="headerlink" title="导入NumPy作为np，并查看版本"></a>导入NumPy作为np，并查看版本</h2><p>将NumPy导入为 np 并打印版本号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.__version__)</span><br><span class="line"><span class="comment"># &gt; 1.13.3</span></span><br></pre></td></tr></table></figure>

<p>你必须将NumPy导入np作为简称，才能使本节课程中的其余代码正常工作。要安装NumPy，建议安装Anaconda，里面已经包含了NumPy。</p>
<h2 id="如何创建一维数组"><a href="#如何创建一维数组" class="headerlink" title="如何创建一维数组"></a>如何创建一维数组</h2><p>创建从0到9的一维数字数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"></span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure>

<h2 id="创建一个布尔数组"><a href="#创建一个布尔数组" class="headerlink" title="创建一个布尔数组"></a>创建一个布尔数组</h2><p>创建一个NumPy数组元素值全为True的数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.full((<span class="number">3</span>, <span class="number">3</span>), <span class="literal">True</span>, dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="comment"># array([[ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True]], dtype=bool)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Alternate method:</span></span><br><span class="line">np.ones((<span class="number">3</span>,<span class="number">3</span>), dtype=<span class="built_in">bool</span>)</span><br><span class="line"><span class="comment"># array([[ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True],</span></span><br><span class="line"><span class="comment">#        [ True,  True,  True]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从一维数组中提取满足指定条件的元素"><a href="#从一维数组中提取满足指定条件的元素" class="headerlink" title="从一维数组中提取满足指定条件的元素"></a>从一维数组中提取满足指定条件的元素</h2><p>从 arr 中提取所有的奇数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(arr % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt; array([False, True, False, True, False, True, False, True, False, True])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr[arr % <span class="number">2</span> == <span class="number">1</span>])</span><br><span class="line"><span class="comment"># &gt; array([1, 3, 5, 7, 9])</span></span><br></pre></td></tr></table></figure>

<h2 id="将数组中的另一个值替换满足条件的元素项"><a href="#将数组中的另一个值替换满足条件的元素项" class="headerlink" title="将数组中的另一个值替换满足条件的元素项"></a>将数组中的另一个值替换满足条件的元素项</h2><p>将arr中的所有奇数替换为-1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr[arr % <span class="number">2</span> == <span class="number">1</span>] = -<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># &gt; array([ 0, -1,  2, -1,  4, -1,  6, -1,  8, -1])</span></span><br></pre></td></tr></table></figure>

<h2 id="在不影响原始数组的情况下替换满足条件的元素项"><a href="#在不影响原始数组的情况下替换满足条件的元素项" class="headerlink" title="在不影响原始数组的情况下替换满足条件的元素项"></a>在不影响原始数组的情况下替换满足条件的元素项</h2><p>将arr中的所有奇数替换为-1，而不改变arr。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">out = np.where(arr % <span class="number">2</span> == <span class="number">1</span>, -<span class="number">1</span>, arr)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr)</span><br><span class="line"><span class="comment"># &gt; array([0,  1,  2,  3,  4,  5,  6,  7,  8,  9])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment">#&gt; array([ 0, -1,  2, -1,  4, -1,  6, -1,  8, -1])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.where(condition, x, y)</span><br></pre></td></tr></table></figure>

<ul>
<li>condition: array_like, bool如果为True，则返回x，否则返回y。</li>
<li>x, y: array_like, 可选择的值。 x, y和condition适配广播规则。</li>
<li>returns: ndarray数组，当condition为True，元素值取自x, 否则元素值取自y。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">np.where(a &lt; <span class="number">5</span>, a, <span class="number">10</span>*a)</span><br><span class="line">array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>,  <span class="number">4</span>, <span class="number">50</span>, <span class="number">60</span>, <span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># This can be used on multidimensional arrays too:</span></span><br><span class="line">np.where([[<span class="literal">True</span>, <span class="literal">False</span>], [<span class="literal">True</span>, <span class="literal">True</span>]],</span><br><span class="line">         [[<span class="number">1</span>   , <span class="number">2</span>    ], [<span class="number">3</span>   , <span class="number">4</span>   ]],</span><br><span class="line">         [[<span class="number">9</span>   , <span class="number">8</span>    ], [<span class="number">7</span>   , <span class="number">6</span>   ]])</span><br><span class="line"><span class="comment"># &gt;array([[1   , 8    ], [3   , 4   ]])</span></span><br></pre></td></tr></table></figure>


<h2 id="改变数组的形状"><a href="#改变数组的形状" class="headerlink" title="改变数组的形状"></a>改变数组的形状</h2><p>问题：如何将一维数组转换为2行的2维数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">arr.reshape(<span class="number">2</span>, -<span class="number">1</span>)  <span class="comment"># Setting to -1 automatically decides the number of cols</span></span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9]])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.reshape(a, newshape, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Gives a new shape to an array without changing its data.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>a: array_like, 待改变形状的数组；</li>
<li>newshape: int 或 int 元组, 新形状应与原形状兼容。如果是整数，则结果将是该长度的1-D数组。一个形状维度可以是-1。在这种情况下，该值是从数组的长度和剩余维度推断出来的。</li>
<li>order: {‘C’, ‘F’, ‘A’} 可选项，使用此索引顺序读取a的元素，并使用此索引顺序将元素放入重塑的数组中。’C’ 意味着使用类似C的索引顺序读写元素，最后一个轴索引变化最快，回到第一个轴索引变化最慢。 ‘F’表示使用类似fortran的索引顺序读写元素，第一个索引变化最快，最后一个索引变化最慢。请注意，’C’和’F’选项不考虑底层数组的内存布局，而只参考索引的顺序。’A’表示如果A在内存中是Fortran连续的，则以类似Fortran的索引顺序读取&#x2F;写入元素，否则以类似C的顺序读取。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">6</span>).reshape((<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">a</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.reshape(a, (<span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># C-like index ordering</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line">np.reshape(a, (<span class="number">2</span>, <span class="number">3</span>), order=<span class="string">&#x27;F&#x27;</span>) <span class="comment"># Fortran-like index ordering</span></span><br><span class="line">array([[<span class="number">0</span>, <span class="number">4</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">1</span>, <span class="number">5</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="垂直叠加两个数组"><a href="#垂直叠加两个数组" class="headerlink" title="垂直叠加两个数组"></a>垂直叠加两个数组</h2><p>问题：垂直堆叠数组a和数组b</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.vstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.r_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>


<h2 id="水平叠加两个数组"><a href="#水平叠加两个数组" class="headerlink" title="水平叠加两个数组"></a>水平叠加两个数组</h2><p>问题：将数组a和数组b水平堆叠。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Answers</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.hstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.c_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>

<h2 id="获取两个NumPy数组之间的公共项"><a href="#获取两个NumPy数组之间的公共项" class="headerlink" title="获取两个NumPy数组之间的公共项"></a>获取两个NumPy数组之间的公共项</h2><p>问题：获取数组a和数组b之间的公共项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">b = np.array([<span class="number">7</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line">np.intersect1d(a,b)</span><br><span class="line"><span class="comment"># &gt; array([2, 4])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[intersect1d, comm1, comm2] = numpy.intersect1d(ar1, ar2, assume_unique=<span class="literal">False</span>, return_indices=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Find the intersection of two arrays.</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>ar1, ar2: array_like, 输入数组。即使不是一维，也会被一维化。</p>
</li>
<li><p>assume_unique: bool, 如果为True，则假定输入数组都是唯一的，这可以加快计算速度。如果为True，但ar1或ar2不是唯一的，则可能导致不正确的结果和越界索引。默认为False。</p>
</li>
<li><p>return_indices: bool, 如果为True，则返回两个数组的交点对应的索引。如果有多个值，则使用值的第一个实例。默认为False。</p>
</li>
<li><p>intersect1d: ndarray, 对共有元素和唯一元素的1D数组进行排序。</p>
</li>
<li><p>comm1: ar1中第一次出现的公共值的索引。仅当<code>return_indices</code>为<code>True</code>时提供。</p>
</li>
<li><p>comm2: ar2中第一次出现的公共值的索引。仅当<code>return_indices</code>为<code>True</code>时提供。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>])</span><br><span class="line">xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=<span class="literal">True</span>)</span><br><span class="line">x_ind, y_ind</span><br><span class="line"><span class="comment"># &gt;(array([0, 2, 4]), array([1, 0, 2]))</span></span><br><span class="line">xy, x[x_ind], y[y_ind]</span><br><span class="line"><span class="comment"># &gt;(array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))</span></span><br></pre></td></tr></table></figure>

<h2 id="从一个数组中删除存在于另一个数组中的项"><a href="#从一个数组中删除存在于另一个数组中的项" class="headerlink" title="从一个数组中删除存在于另一个数组中的项"></a>从一个数组中删除存在于另一个数组中的项</h2><p>问题：从数组a中删除数组b中的所有项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># From &#x27;a&#x27; remove all of &#x27;b&#x27;</span></span><br><span class="line">np.setdiff1d(a,b)</span><br><span class="line"><span class="comment"># &gt; array([1, 2, 3, 4])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">setdiff1d = numpy.setdiff1d(ar1, ar2, assume_unique=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># Find the set difference of two arrays.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>ar1: array_like, 输入数组；</li>
<li>ar2: array_like, 输入比较数组；</li>
<li>assume_unique: bool, 如果为True，则假定输入数组都是唯一的，这可以加快计算速度。默认为False。</li>
<li>setdiff1d: ar1中不属于ar2的值的一维数组。当assume_unique&#x3D;False时对结果进行排序，否则只在输入已排序时才对结果进行排序。</li>
</ul>
<h2 id="得到两个数组元素匹配的位置"><a href="#得到两个数组元素匹配的位置" class="headerlink" title="得到两个数组元素匹配的位置"></a>得到两个数组元素匹配的位置</h2><p>问题：获取a和b元素匹配的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>])</span><br><span class="line">b = np.array([<span class="number">7</span>,<span class="number">2</span>,<span class="number">10</span>,<span class="number">2</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line">np.where(a == b)</span><br><span class="line"><span class="comment"># &gt; (array([1, 3, 5, 7]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="从NumPy数组中提取给定范围内的所有数字"><a href="#从NumPy数组中提取给定范围内的所有数字" class="headerlink" title="从NumPy数组中提取给定范围内的所有数字"></a>从NumPy数组中提取给定范围内的所有数字</h2><p>问题：获取5到10之间的所有项目。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">index = np.where((a &gt;= <span class="number">5</span>) &amp; (a &lt;= <span class="number">10</span>))</span><br><span class="line">a[index]</span><br><span class="line"><span class="comment"># &gt; (array([6, 9, 10]),)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">index = np.where(np.logical_and(a&gt;=<span class="number">5</span>, a&lt;=<span class="number">10</span>))</span><br><span class="line">a[index]</span><br><span class="line"><span class="comment"># &gt; (array([6, 9, 10]),)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3: (thanks loganzk!)</span></span><br><span class="line">a[(a &gt;= <span class="number">5</span>) &amp; (a &lt;= <span class="number">10</span>)]</span><br></pre></td></tr></table></figure>

<h2 id="创建一个Python函数来处理标量运算并在NumPy数组上工作"><a href="#创建一个Python函数来处理标量运算并在NumPy数组上工作" class="headerlink" title="创建一个Python函数来处理标量运算并在NumPy数组上工作"></a>创建一个Python函数来处理标量运算并在NumPy数组上工作</h2><p>问题：转换适用于两个标量的函数maxx，以处理两个数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 给定：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maxx</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the maximum of two items&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> x &gt;= y:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">maxx(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"><span class="comment"># &gt; 5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望的输出：</span></span><br><span class="line">a = np.array([<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>])</span><br><span class="line">pair_max(a, b)</span><br><span class="line"><span class="comment"># &gt; array([ 6.,  7.,  9.,  8.,  9.,  7.,  5.])</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">maxx</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get the maximum of two items&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> x &gt;= y:</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">pair_max = np.vectorize(maxx, otypes=[<span class="built_in">float</span>])</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">6</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">pair_max(a, b)</span><br><span class="line"><span class="comment"># &gt; array([ 6.,  7.,  9.,  8.,  9.,  7.,  5.])</span></span><br></pre></td></tr></table></figure>


<h2 id="交换二维numpy数组中的两列"><a href="#交换二维numpy数组中的两列" class="headerlink" title="交换二维numpy数组中的两列"></a>交换二维numpy数组中的两列</h2><p>问题：在数组arr中交换列1和2。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, [<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="comment"># &gt; array([[1, 0, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [4, 3, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [7, 6, 8]])</span></span><br></pre></td></tr></table></figure>

<h2 id="交换二维numpy数组中的两行"><a href="#交换二维numpy数组中的两行" class="headerlink" title="交换二维numpy数组中的两行"></a>交换二维numpy数组中的两行</h2><p>问题：交换数组arr中的第1和第2行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[[<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>], :]</span><br><span class="line"><span class="comment"># &gt; array([[3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br></pre></td></tr></table></figure>

<h2 id="反转二维数组的行"><a href="#反转二维数组的行" class="headerlink" title="反转二维数组的行"></a>反转二维数组的行</h2><p>问题：反转二维数组arr的行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[::-<span class="number">1</span>]</span><br><span class="line">array([[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="反转二维数组的列"><a href="#反转二维数组的列" class="headerlink" title="反转二维数组的列"></a>反转二维数组的列</h2><p>问题：反转二维数组arr的列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, ::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; array([[2, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 4, 3],</span></span><br><span class="line"><span class="comment"># &gt;        [8, 7, 6]])</span></span><br></pre></td></tr></table></figure>

<h2 id="创建包含5到10之间随机浮动的二维数组"><a href="#创建包含5到10之间随机浮动的二维数组" class="headerlink" title="创建包含5到10之间随机浮动的二维数组"></a>创建包含5到10之间随机浮动的二维数组</h2><p>问题：创建一个形状为5x3的二维数组，以包含5到10之间的随机十进制数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution Method 1:</span></span><br><span class="line">rand_arr = np.random.randint(low=<span class="number">5</span>, high=<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>)) + np.random.random((<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># print(rand_arr)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution Method 2:</span></span><br><span class="line">rand_arr = np.random.uniform(<span class="number">5</span>,<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(rand_arr)</span><br><span class="line"><span class="comment"># &gt; [[ 8.50061025  9.10531502  6.85867783]</span></span><br><span class="line"><span class="comment"># &gt;  [ 9.76262069  9.87717411  7.13466701]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.48966403  8.33409158  6.16808631]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.75010551  9.94535696  5.27373226]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8.0850361   5.56165518  7.31244004]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中只打印小数点后三位"><a href="#在NumPy数组中只打印小数点后三位" class="headerlink" title="在NumPy数组中只打印小数点后三位"></a>在NumPy数组中只打印小数点后三位</h2><p>问题：只打印或显示numpy数组rand_arr的小数点后3位。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create the random array</span></span><br><span class="line">rand_arr = np.random.random([<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Limit to 3 decimal places</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">3</span>)</span><br><span class="line">rand_arr[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 0.443,  0.109,  0.97 ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.388,  0.447,  0.191],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.891,  0.474,  0.212],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.609,  0.518,  0.403]])</span></span><br></pre></td></tr></table></figure>

<h2 id="通过e式科学记数法（如1e10）来打印一个NumPy数组"><a href="#通过e式科学记数法（如1e10）来打印一个NumPy数组" class="headerlink" title="通过e式科学记数法（如1e10）来打印一个NumPy数组"></a>通过e式科学记数法（如1e10）来打印一个NumPy数组</h2><p>问题：通过e式科学记数法来打印rand_arr（如1e10）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reset printoptions to default</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the random array</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">rand_arr = np.random.random([<span class="number">3</span>,<span class="number">3</span>])/<span class="number">1e3</span></span><br><span class="line">rand_arr</span><br><span class="line"><span class="comment"># &gt; array([[  5.434049e-04,   2.783694e-04,   4.245176e-04],</span></span><br><span class="line"><span class="comment"># &gt;        [  8.447761e-04,   4.718856e-06,   1.215691e-04],</span></span><br><span class="line"><span class="comment"># &gt;        [  6.707491e-04,   8.258528e-04,   1.367066e-04]])</span></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>, precision=<span class="number">6</span>)  <span class="comment"># precision is optional</span></span><br><span class="line">rand_arr</span><br><span class="line"><span class="comment"># &gt; array([[ 0.000543,  0.000278,  0.000425],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.000845,  0.000005,  0.000122],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.000671,  0.000826,  0.000137]])</span></span><br></pre></td></tr></table></figure>

<h2 id="限制numpy数组输出中打印的项目数"><a href="#限制numpy数组输出中打印的项目数" class="headerlink" title="限制numpy数组输出中打印的项目数"></a>限制numpy数组输出中打印的项目数</h2><p>问题：将numpy数组a中打印的项数限制为最多6个元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.set_printoptions(threshold=<span class="number">6</span>)</span><br><span class="line">a = np.arange(<span class="number">15</span>)</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2, ..., 12, 13, 14])</span></span><br></pre></td></tr></table></figure>

<h2 id="打印完整的numpy数组而不截断"><a href="#打印完整的numpy数组而不截断" class="headerlink" title="打印完整的numpy数组而不截断"></a>打印完整的numpy数组而不截断</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(threshold=<span class="number">6</span>)</span><br><span class="line">a = np.arange(<span class="number">15</span>\</span><br><span class="line">	&#125;<span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.set_printoptions(threshold=np.nan)</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])</span></span><br></pre></td></tr></table></figure>


<h2 id="导入数字和文本的数据集保持文本在numpy数组中完好无损"><a href="#导入数字和文本的数据集保持文本在numpy数组中完好无损" class="headerlink" title="导入数字和文本的数据集保持文本在numpy数组中完好无损"></a>导入数字和文本的数据集保持文本在numpy数组中完好无损</h2><p>问题：导入鸢尾属植物数据集，保持文本不变。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first 3 rows</span></span><br><span class="line">iris[:<span class="number">3</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="从1维元组数组中提取特定列"><a href="#从1维元组数组中提取特定列" class="headerlink" title="从1维元组数组中提取特定列"></a>从1维元组数组中提取特定列</h2><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="将1维元组数组转换为2维NumPy数组"><a href="#将1维元组数组转换为2维NumPy数组" class="headerlink" title="将1维元组数组转换为2维NumPy数组"></a>将1维元组数组转换为2维NumPy数组</h2><p>问题：通过省略鸢尾属植物数据集种类的文本字段，将一维鸢尾属植物数据集转换为二维数组iris_2d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="comment"># Method 1: Convert each row to a list and get the first 4 items</span></span><br><span class="line">iris_2d = np.array([row.tolist()[:<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Alt Method 2: Import only the first 4 columns from source url</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算numpy数组的均值，中位数，标准差"><a href="#计算numpy数组的均值，中位数，标准差" class="headerlink" title="计算numpy数组的均值，中位数，标准差"></a>计算numpy数组的均值，中位数，标准差</h2><p>问题：求出鸢尾属植物萼片长度的平均值、中位数和标准差(第1列)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">mu, med, sd = np.mean(sepallength), np.median(sepallength), np.std(sepallength)</span><br><span class="line"><span class="built_in">print</span>(mu, med, sd)</span><br><span class="line"><span class="comment"># &gt; 5.84333333333 5.8 0.825301291785</span></span><br></pre></td></tr></table></figure>

<h2 id="规范化数组，使数组的值正好介于0和1之间"><a href="#规范化数组，使数组的值正好介于0和1之间" class="headerlink" title="规范化数组，使数组的值正好介于0和1之间"></a>规范化数组，使数组的值正好介于0和1之间</h2><p>问题：创建一种标准化形式的鸢尾属植物间隔长度，其值正好介于0和1之间，这样最小值为0，最大值为1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">Smax, Smin = sepallength.<span class="built_in">max</span>(), sepallength.<span class="built_in">min</span>()</span><br><span class="line">S = (sepallength - Smin)/(Smax - Smin)</span><br><span class="line"><span class="comment"># or </span></span><br><span class="line">S = (sepallength - Smin)/sepallength.ptp()  <span class="comment"># Thanks, David Ojeda!</span></span><br><span class="line"><span class="built_in">print</span>(S)</span><br><span class="line"><span class="comment"># &gt; [ 0.222  0.167  0.111  0.083  0.194  0.306  0.083  0.194  0.028  0.167</span></span><br><span class="line"><span class="comment"># &gt;   0.306  0.139  0.139  0.     0.417  0.389  0.306  0.222  0.389  0.222</span></span><br><span class="line"><span class="comment"># &gt;   0.306  0.222  0.083  0.222  0.139  0.194  0.194  0.25   0.25   0.111</span></span><br><span class="line"><span class="comment"># &gt;   0.139  0.306  0.25   0.333  0.167  0.194  0.333  0.167  0.028  0.222</span></span><br><span class="line"><span class="comment"># &gt;   0.194  0.056  0.028  0.194  0.222  0.139  0.222  0.083  0.278  0.194</span></span><br><span class="line"><span class="comment"># &gt;   0.75   0.583  0.722  0.333  0.611  0.389  0.556  0.167  0.639  0.25</span></span><br><span class="line"><span class="comment"># &gt;   0.194  0.444  0.472  0.5    0.361  0.667  0.361  0.417  0.528  0.361</span></span><br><span class="line"><span class="comment"># &gt;   0.444  0.5    0.556  0.5    0.583  0.639  0.694  0.667  0.472  0.389</span></span><br><span class="line"><span class="comment"># &gt;   0.333  0.333  0.417  0.472  0.306  0.472  0.667  0.556  0.361  0.333</span></span><br><span class="line"><span class="comment"># &gt;   0.333  0.5    0.417  0.194  0.361  0.389  0.389  0.528  0.222  0.389</span></span><br><span class="line"><span class="comment"># &gt;   0.556  0.417  0.778  0.556  0.611  0.917  0.167  0.833  0.667  0.806</span></span><br><span class="line"><span class="comment"># &gt;   0.611  0.583  0.694  0.389  0.417  0.583  0.611  0.944  0.944  0.472</span></span><br><span class="line"><span class="comment"># &gt;   0.722  0.361  0.944  0.556  0.667  0.806  0.528  0.5    0.583  0.806</span></span><br><span class="line"><span class="comment"># &gt;   0.861  1.     0.583  0.556  0.5    0.944  0.556  0.583  0.472  0.722</span></span><br><span class="line"><span class="comment"># &gt;   0.667  0.722  0.417  0.694  0.667  0.667  0.556  0.611  0.528  0.444]</span></span><br></pre></td></tr></table></figure>

<h2 id="找到numpy数组的百分位数"><a href="#找到numpy数组的百分位数" class="headerlink" title="找到numpy数组的百分位数"></a>找到numpy数组的百分位数</h2><p>问题：找到鸢尾属植物数据集的第5和第95百分位数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">sepallength = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.percentile(sepallength, q=[<span class="number">5</span>, <span class="number">95</span>])</span><br><span class="line"><span class="comment"># &gt; array([ 4.6  ,  7.255])</span></span><br></pre></td></tr></table></figure>

<h2 id="在数组中的随机位置插入值"><a href="#在数组中的随机位置插入值" class="headerlink" title="在数组中的随机位置插入值"></a>在数组中的随机位置插入值</h2><p>问题：在iris_2d数据集中的20个随机位置插入np.nan值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到缺失值的位置"><a href="#在NumPy数组中找到缺失值的位置" class="headerlink" title="在NumPy数组中找到缺失值的位置"></a>在NumPy数组中找到缺失值的位置</h2><p>问题：在iris_2d的sepallength中查找缺失值的数量和位置（第1列）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Number of missing values: \n&quot;</span>, np.isnan(iris_2d[:, <span class="number">0</span>]).<span class="built_in">sum</span>())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Position of missing values: \n&quot;</span>, np.where(np.isnan(iris_2d[:, <span class="number">0</span>])))</span><br><span class="line"><span class="comment"># &gt; Number of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  5</span></span><br><span class="line"><span class="comment"># &gt; Position of missing values: </span></span><br><span class="line"><span class="comment"># &gt;  (array([ 39,  88,  99, 130, 147]),)</span></span><br></pre></td></tr></table></figure>

<h2 id="根据两个或多个条件过滤numpy数组"><a href="#根据两个或多个条件过滤numpy数组" class="headerlink" title="根据两个或多个条件过滤numpy数组"></a>根据两个或多个条件过滤numpy数组</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">答案：</span><br><span class="line"></span><br><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">condition = (iris_2d[:, <span class="number">2</span>] &gt; <span class="number">1.5</span>) &amp; (iris_2d[:, <span class="number">0</span>] &lt; <span class="number">5.0</span>)</span><br><span class="line">iris_2d[condition]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.8,  3.4,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.4,  1.9,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.8,  3.1,  1.6,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.4,  3.3,  1. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  2.5,  4.5,  1.7]])</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组中删除包含缺失值的行"><a href="#从numpy数组中删除包含缺失值的行" class="headerlink" title="从numpy数组中删除包含缺失值的行"></a>从numpy数组中删除包含缺失值的行</h2><p>问题：选择没有任何nan值的iris_2d行。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct numpy function for this.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">any_nan_in_row = np.array([~np.<span class="built_in">any</span>(np.isnan(row)) <span class="keyword">for</span> row <span class="keyword">in</span> iris_2d])</span><br><span class="line">iris_2d[any_nan_in_row][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2: (By Rong)</span></span><br><span class="line">iris_2d[np.<span class="built_in">sum</span>(np.isnan(iris_2d), axis = <span class="number">1</span>) == <span class="number">0</span>][:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5. ,  3.6,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5.4,  3.9,  1.7,  0.4]])</span></span><br></pre></td></tr></table></figure>

<h2 id="找到numpy数组的两列之间的相关性"><a href="#找到numpy数组的两列之间的相关性" class="headerlink" title="找到numpy数组的两列之间的相关性"></a>找到numpy数组的两列之间的相关性</h2><p>问题：在iris_2d中找出SepalLength（第1列）和PetalLength（第3列）之间的相关性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.corrcoef(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])[<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats.stats <span class="keyword">import</span> pearsonr  </span><br><span class="line">corr, p_value = pearsonr(iris[:, <span class="number">0</span>], iris[:, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(corr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Correlation coef indicates the degree of linear relationship between two numeric variables.</span></span><br><span class="line"><span class="comment"># It can range between -1 to +1.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The p-value roughly indicates the probability of an uncorrelated system producing </span></span><br><span class="line"><span class="comment"># datasets that have a correlation at least as extreme as the one computed.</span></span><br><span class="line"><span class="comment"># The lower the p-value (&lt;0.01), stronger is the significance of the relationship.</span></span><br><span class="line"><span class="comment"># It is not an indicator of the strength.</span></span><br><span class="line"><span class="comment"># &gt; 0.871754157305</span></span><br></pre></td></tr></table></figure>

<h2 id="查找给定数组是否具有任何空值"><a href="#查找给定数组是否具有任何空值" class="headerlink" title="查找给定数组是否具有任何空值"></a>查找给定数组是否具有任何空值</h2><p>问题：找出iris_2d是否有任何缺失值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">np.isnan(iris_2d).<span class="built_in">any</span>()</span><br><span class="line"><span class="comment"># &gt; False</span></span><br></pre></td></tr></table></figure>

<h2 id="在numpy数组中用0替换所有缺失值"><a href="#在numpy数组中用0替换所有缺失值" class="headerlink" title="在numpy数组中用0替换所有缺失值"></a>在numpy数组中用0替换所有缺失值</h2><p>问题：在numpy数组中将所有出现的nan替换为0</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;float&#x27;</span>, usecols=[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">iris_2d[np.isnan(iris_2d)] = <span class="number">0</span></span><br><span class="line">iris_2d[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[ 5.1,  3.5,  1.4,  0. ],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.9,  3. ,  1.4,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.7,  3.2,  1.3,  0.2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 4.6,  3.1,  1.5,  0.2]])</span></span><br></pre></td></tr></table></figure>

<h2 id="在numpy数组中查找唯一值的计数"><a href="#在numpy数组中查找唯一值的计数" class="headerlink" title="在numpy数组中查找唯一值的计数"></a>在numpy数组中查找唯一值的计数</h2><p>问题：找出鸢尾属植物物种中的独特值和独特值的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Extract the species column as an array</span></span><br><span class="line">species = np.array([row.tolist()[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the unique values and the counts</span></span><br><span class="line">np.unique(species, return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;        dtype=&#x27;|S15&#x27;), array([50, 50, 50]))</span></span><br></pre></td></tr></table></figure>

<h2 id="将数字转换为分类（文本）数组"><a href="#将数字转换为分类（文本）数组" class="headerlink" title="将数字转换为分类（文本）数组"></a>将数字转换为分类（文本）数组</h2><p>问题：将iris_2d的花瓣长度（第3列）加入以形成文本数组，这样如果花瓣长度为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;= 3 --&gt; &#x27;small&#x27;</span><br><span class="line"> 3-5 --&gt; &#x27;medium&#x27;</span><br><span class="line">&#x27;&gt;=5 --&gt; &#x27;large&#x27;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bin petallength </span></span><br><span class="line">petal_length_bin = np.digitize(iris[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>), [<span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Map it to respective category</span></span><br><span class="line">label_map = &#123;<span class="number">1</span>: <span class="string">&#x27;small&#x27;</span>, <span class="number">2</span>: <span class="string">&#x27;medium&#x27;</span>, <span class="number">3</span>: <span class="string">&#x27;large&#x27;</span>, <span class="number">4</span>: np.nan&#125;</span><br><span class="line">petal_length_cat = [label_map[x] <span class="keyword">for</span> x <span class="keyword">in</span> petal_length_bin]</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">petal_length_cat[:<span class="number">4</span>]</span><br><span class="line">&lt;<span class="comment"># &gt; [&#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;, &#x27;small&#x27;]</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组的现有列创建新列"><a href="#从numpy数组的现有列创建新列" class="headerlink" title="从numpy数组的现有列创建新列"></a>从numpy数组的现有列创建新列</h2><p>问题：在iris_2d中为卷创建一个新列，其中volume是（pi x petallength x sepal_length ^ 2）&#x2F; 3</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Compute volume</span></span><br><span class="line">sepallength = iris_2d[:, <span class="number">0</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">petallength = iris_2d[:, <span class="number">2</span>].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line">volume = (np.pi * petallength * (sepallength**<span class="number">2</span>))/<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Introduce new dimension to match iris_2d&#x27;s</span></span><br><span class="line">volume = volume[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the new column</span></span><br><span class="line">out = np.hstack([iris_2d, volume])</span><br><span class="line"></span><br><span class="line"><span class="comment"># View</span></span><br><span class="line">out[:<span class="number">4</span>]</span><br><span class="line"><span class="comment"># &gt; array([[b&#x27;5.1&#x27;, b&#x27;3.5&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 38.13265162927291],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.9&#x27;, b&#x27;3.0&#x27;, b&#x27;1.4&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 35.200498485922445],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.7&#x27;, b&#x27;3.2&#x27;, b&#x27;1.3&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 30.0723720777127],</span></span><br><span class="line"><span class="comment"># &gt;        [b&#x27;4.6&#x27;, b&#x27;3.1&#x27;, b&#x27;1.5&#x27;, b&#x27;0.2&#x27;, b&#x27;Iris-setosa&#x27;, 33.238050274980004]], dtype=object)</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy中进行概率抽样"><a href="#在NumPy中进行概率抽样" class="headerlink" title="在NumPy中进行概率抽样"></a>在NumPy中进行概率抽样</h2><p>问题：随机抽鸢尾属植物的种类，使得刚毛的数量是云芝和维吉尼亚的两倍</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species column</span></span><br><span class="line">species = iris[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 1: Generate Probablistically</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.array([<span class="string">&#x27;Iris-setosa&#x27;</span>, <span class="string">&#x27;Iris-versicolor&#x27;</span>, <span class="string">&#x27;Iris-virginica&#x27;</span>])</span><br><span class="line">species_out = np.random.choice(a, <span class="number">150</span>, p=[<span class="number">0.5</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Approach 2: Probablistic Sampling (preferred)</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">probs = np.r_[np.linspace(<span class="number">0</span>, <span class="number">0.500</span>, num=<span class="number">50</span>), np.linspace(<span class="number">0.501</span>, <span class="number">.750</span>, num=<span class="number">50</span>), np.linspace(<span class="number">.751</span>, <span class="number">1.0</span>, num=<span class="number">50</span>)]</span><br><span class="line">index = np.searchsorted(probs, np.random.random(<span class="number">150</span>))</span><br><span class="line">species_out = species[index]</span><br><span class="line"><span class="built_in">print</span>(np.unique(species_out, return_counts=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; (array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-versicolor&#x27;, b&#x27;Iris-virginica&#x27;], dtype=object), array([77, 37, 36]))</span></span><br></pre></td></tr></table></figure>

<p>方法2是首选方法，因为它创建了一个索引变量，该变量可用于取样2维表格数据。</p>
<h2 id="在按另一个数组分组时获取数组的第二大值"><a href="#在按另一个数组分组时获取数组的第二大值" class="headerlink" title="在按另一个数组分组时获取数组的第二大值"></a>在按另一个数组分组时获取数组的第二大值</h2><p>问题：第二长的物种setosa的价值是多少</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import iris keeping the text column intact</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Get the species and petal length columns</span></span><br><span class="line">petal_len_setosa = iris[iris[:, <span class="number">4</span>] == <span class="string">b&#x27;Iris-setosa&#x27;</span>, [<span class="number">2</span>]].astype(<span class="string">&#x27;float&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the second last value</span></span><br><span class="line">np.unique(np.sort(petal_len_setosa))[-<span class="number">2</span>]</span><br><span class="line"><span class="comment"># &gt; 1.7</span></span><br></pre></td></tr></table></figure>

<h2 id="按列对2D数组进行排序"><a href="#按列对2D数组进行排序" class="headerlink" title="按列对2D数组进行排序"></a>按列对2D数组进行排序</h2><p>问题：根据sepallength列对虹膜数据集进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sort by column position 0: SepalLength</span></span><br><span class="line"><span class="built_in">print</span>(iris[iris[:,<span class="number">0</span>].argsort()][:<span class="number">20</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;4.3&#x27; b&#x27;3.0&#x27; b&#x27;1.1&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;3.0&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; b&#x27;2.9&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.5&#x27; b&#x27;2.3&#x27; b&#x27;1.3&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.6&#x27; b&#x27;1.0&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.2&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.9&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.4&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.8&#x27; b&#x27;3.1&#x27; b&#x27;1.6&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.4&#x27; b&#x27;3.3&#x27; b&#x27;1.0&#x27; b&#x27;Iris-versicolor&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;2.5&#x27; b&#x27;4.5&#x27; b&#x27;1.7&#x27; b&#x27;Iris-virginica&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>

<h2 id="在NumPy数组中找到最常见的值"><a href="#在NumPy数组中找到最常见的值" class="headerlink" title="在NumPy数组中找到最常见的值"></a>在NumPy数组中找到最常见的值</h2><p>问题：在鸢尾属植物数据集中找到最常见的花瓣长度值（第3列）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">vals, counts = np.unique(iris[:, <span class="number">2</span>], return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vals[np.argmax(counts)])</span><br><span class="line"><span class="comment"># &gt; b&#x27;1.5&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="找到第一次出现的值大于给定值的位置"><a href="#找到第一次出现的值大于给定值的位置" class="headerlink" title="找到第一次出现的值大于给定值的位置"></a>找到第一次出现的值大于给定值的位置</h2><p>问题：在虹膜数据集的petalwidth第4列中查找第一次出现的值大于1.0的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: (edit: changed argmax to argwhere. Thanks Rong!)</span></span><br><span class="line">np.argwhere(iris[:, <span class="number">3</span>].astype(<span class="built_in">float</span>) &gt; <span class="number">1.0</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># &gt; 50</span></span><br></pre></td></tr></table></figure>

<h2 id="将大于给定值的所有值替换为给定的截止值"><a href="#将大于给定值的所有值替换为给定的截止值" class="headerlink" title="将大于给定值的所有值替换为给定的截止值"></a>将大于给定值的所有值替换为给定的截止值</h2><p>问题：从数组a中，替换所有大于30到30和小于10到10的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.set_printoptions(precision=<span class="number">2</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1: Using np.clip</span></span><br><span class="line">np.clip(a, a_min=<span class="number">10</span>, a_max=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2: Using np.where</span></span><br><span class="line"><span class="built_in">print</span>(np.where(a &lt; <span class="number">10</span>, <span class="number">10</span>, np.where(a &gt; <span class="number">30</span>, <span class="number">30</span>, a)))</span><br><span class="line"><span class="comment"># &gt; [ 27.63  14.64  21.8   30.    10.    10.    30.    30.    10.    29.18  30.</span></span><br><span class="line"><span class="comment"># &gt;   11.25  10.08  10.    11.77  30.    30.    10.    30.    14.43]</span></span><br></pre></td></tr></table></figure>

<h2 id="从numpy数组中获取最大n值的位置"><a href="#从numpy数组中获取最大n值的位置" class="headerlink" title="从numpy数组中获取最大n值的位置"></a>从numpy数组中获取最大n值的位置</h2><p>问题：获取给定数组a中前5个最大值的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.uniform(<span class="number">1</span>,<span class="number">50</span>,<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="built_in">print</span>(a.argsort())</span><br><span class="line"><span class="comment"># &gt; [18 7 3 10 15]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">np.argpartition(-a, <span class="number">5</span>)[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; [15 10  3  7 18]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Below methods will get you the values.</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">a[a.argsort()][-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.sort(a)[-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.partition(a, kth=-<span class="number">5</span>)[-<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 4:</span></span><br><span class="line">a[np.argpartition(-a, <span class="number">5</span>)][:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<p>计算数组中所有可能值的行数</p>
<p>问题：按行计算唯一值的计数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">arr = np.random.randint(<span class="number">1</span>,<span class="number">11</span>,size=(<span class="number">6</span>, <span class="number">10</span>))</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[ 9,  9,  4,  8,  8,  1,  5,  3,  6,  3],</span></span><br><span class="line"><span class="comment"># &gt;        [ 3,  3,  2,  1,  9,  5,  1, 10,  7,  3],</span></span><br><span class="line"><span class="comment"># &gt;        [ 5,  2,  6,  4,  5,  5,  4,  8,  2,  2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 8,  8,  1,  3, 10, 10,  4,  3,  6,  9],</span></span><br><span class="line"><span class="comment"># &gt;        [ 2,  1,  8,  7,  3,  1,  9,  3,  6,  2],</span></span><br><span class="line"><span class="comment"># &gt;        [ 9,  2,  6,  5,  3,  9,  4,  6,  1, 10]])</span></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">counts_of_all_values_rowwise</span>(<span class="params">arr2d</span>):</span><br><span class="line">    <span class="comment"># Unique values and its counts row wise</span></span><br><span class="line">    num_counts_array = [np.unique(row, return_counts=<span class="literal">True</span>) <span class="keyword">for</span> row <span class="keyword">in</span> arr2d]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Counts of all values row wise</span></span><br><span class="line">    <span class="keyword">return</span>([[<span class="built_in">int</span>(b[a==i]) <span class="keyword">if</span> i <span class="keyword">in</span> a <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> np.unique(arr2d)] <span class="keyword">for</span> a, b <span class="keyword">in</span> num_counts_array])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print</span></span><br><span class="line"><span class="built_in">print</span>(np.arange(<span class="number">1</span>,<span class="number">11</span>))</span><br><span class="line">counts_of_all_values_rowwise(arr)</span><br><span class="line"><span class="comment"># &gt; [ 1  2  3  4  5  6  7  8  9 10]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; [[1, 0, 2, 1, 1, 1, 0, 2, 2, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [2, 1, 3, 0, 1, 0, 1, 0, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 3, 0, 2, 3, 1, 0, 1, 0, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [1, 0, 2, 1, 0, 1, 0, 2, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;  [2, 2, 2, 0, 0, 1, 1, 1, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [1, 1, 1, 1, 1, 2, 0, 0, 2, 1]]</span></span><br><span class="line"><span class="comment"># 输出包含10列，表示从1到10的数字。这些值是各行中数字的计数。 例如，cell(0，2)的值为2，这意味着数字3在第一行中恰好出现了2次。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Example 2:</span></span><br><span class="line">arr = np.array([np.array(<span class="built_in">list</span>(<span class="string">&#x27;bill clinton&#x27;</span>)), np.array(<span class="built_in">list</span>(<span class="string">&#x27;narendramodi&#x27;</span>)), np.array(<span class="built_in">list</span>(<span class="string">&#x27;jjayalalitha&#x27;</span>))])</span><br><span class="line"><span class="built_in">print</span>(np.unique(arr))</span><br><span class="line">counts_of_all_values_rowwise(arr)</span><br><span class="line"><span class="comment"># &gt; [&#x27; &#x27; &#x27;a&#x27; &#x27;b&#x27; &#x27;c&#x27; &#x27;d&#x27; &#x27;e&#x27; &#x27;h&#x27; &#x27;i&#x27; &#x27;j&#x27; &#x27;l&#x27; &#x27;m&#x27; &#x27;n&#x27; &#x27;o&#x27; &#x27;r&#x27; &#x27;t&#x27; &#x27;y&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; [[1, 0, 1, 1, 0, 0, 0, 2, 0, 3, 0, 2, 1, 0, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 0, 0],</span></span><br><span class="line"><span class="comment"># &gt;  [0, 4, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 1, 1]]</span></span><br></pre></td></tr></table></figure>

<h2 id="将数组转换为平面一维数组"><a href="#将数组转换为平面一维数组" class="headerlink" title="将数组转换为平面一维数组"></a>将数组转换为平面一维数组</h2><p>问题：将array_of_arrays转换为扁平线性1d数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = np.arange(<span class="number">3</span>)</span><br><span class="line">arr2 = np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">arr3 = np.arange(<span class="number">7</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">array_of_arrays = np.array([arr1, arr2, arr3])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array_of_arrays: &#x27;</span>, array_of_arrays)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">arr_2d = np.array([a <span class="keyword">for</span> arr <span class="keyword">in</span> array_of_arrays <span class="keyword">for</span> a <span class="keyword">in</span> arr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">arr_2d = np.concatenate(array_of_arrays)</span><br><span class="line"><span class="built_in">print</span>(arr_2d)</span><br><span class="line"><span class="comment"># &gt; array_of_arrays:  [array([0, 1, 2]) array([3, 4, 5, 6]) array([7, 8, 9])]</span></span><br><span class="line"><span class="comment"># &gt; [0 1 2 3 4 5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 06：NumPy 数据分析进阶</title>
    <url>/PythonLes07/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>NumPy，是“Numerical Python”的简称，是Python编程语言中的一个核心数学库，专注于高效处理多维数组和矩阵数据。在数据分析领域，NumPy发挥着举足轻重的作用，它提供了丰富的功能和工具，可以执行复杂的数学运算、线性代数操作以及统计分析。NumPy的高性能数组处理能力，使得用户可以轻松地处理大规模数据集，无论是进行数值计算、数据转换还是数据清洗，NumPy都能提供强大的支持。其简洁而直观的API设计，使得数据分析和科学计算变得更为简单高效。在数据科学、机器学习、科学计算等领域，NumPy都是不可或缺的基础工具，助力研究人员和工程师们快速实现复杂的数据处理和分析任务。</p>
<p>本节课程是第六周课程的延续，让你脱离基础性的NumPy使用，通过一些具体问题的形式学习NumPy的进阶使用方法。</p>
<span id="more"></span>

<h2 id="将数组转换为平面一维数组"><a href="#将数组转换为平面一维数组" class="headerlink" title="将数组转换为平面一维数组"></a>将数组转换为平面一维数组</h2><p>问题：将array_of_arrays转换为扁平线性1d数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr1 = np.arange(<span class="number">3</span>)</span><br><span class="line">arr2 = np.arange(<span class="number">3</span>,<span class="number">7</span>)</span><br><span class="line">arr3 = np.arange(<span class="number">7</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">array_of_arrays = np.array([arr1, arr2, arr3])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array_of_arrays: &#x27;</span>, array_of_arrays)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">arr_2d = np.array([a <span class="keyword">for</span> arr <span class="keyword">in</span> array_of_arrays <span class="keyword">for</span> a <span class="keyword">in</span> arr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2:</span></span><br><span class="line">arr_2d = np.concatenate(array_of_arrays)</span><br><span class="line"><span class="built_in">print</span>(arr_2d)</span><br><span class="line"><span class="comment"># &gt; array_of_arrays:  [array([0, 1, 2]) array([3, 4, 5, 6]) array([7, 8, 9])]</span></span><br><span class="line"><span class="comment"># &gt; [0 1 2 3 4 5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.concatenate()</code>函数，沿现有轴连接数组序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.concatenate((a1, a2, ...), axis=<span class="number">0</span>, out=<span class="literal">None</span>, dtype=<span class="literal">None</span>, casting=<span class="string">&quot;same_kind&quot;</span>)</span><br><span class="line"><span class="comment"># Join a sequence of arrays along an existing axis.</span></span><br></pre></td></tr></table></figure>

<p>参数:</p>
<ul>
<li>a1, a2,…: array_like数组序列，必须具有相同的形状，除了待拼接轴对应的维度（默认是第一个维度）。</li>
<li>axis: int, 可选项，数组将沿其连接的轴。如果axis为None，则数组在使用前被平面化。默认为0。</li>
<li>out: ndarray, 可选项，如果提供，则为输出存储的位置。形状必须是正确的，与未指定out参数时concatenate返回的形状相匹配。如果提供，目标数组将具有此</li>
<li>dtype: str or dtype, 可选项，不能和out一起提供。</li>
<li>cast: {‘no’,’equiv’,’safe’,’same_kind’,’unsafe’}, 可选项，控制可能发生的数据强制转换类型。默认为’same_kind’。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = np.array([[<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b), axis=<span class="number">0</span>)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b.T), axis=<span class="number">1</span>)</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>]])</span><br><span class="line">np.concatenate((a, b), axis=<span class="literal">None</span>)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure>


<h2 id="如何在NumPy中为数组生成单热编码？"><a href="#如何在NumPy中为数组生成单热编码？" class="headerlink" title="如何在NumPy中为数组生成单热编码？"></a>如何在NumPy中为数组生成单热编码？</h2><p>在机器学习算法中，我们经常会遇到分类特征，例如：人的性别有男女，祖国有中国，美国，法国等。这些特征值并不是连续的，而是离散的，无序的。通常我们需要对其进行特征数字化。One-Hot编码，又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。</p>
<p>为什么使用单热编码：在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。</p>
<p>计算一次性编码（数组中每个唯一值的虚拟二进制变量）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">np.random.seed(<span class="number">101</span>) </span><br><span class="line">arr = np.random.randint(<span class="number">1</span>,<span class="number">4</span>, size=<span class="number">6</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([2, 3, 2, 2, 2, 1])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输出：</span></span><br><span class="line"><span class="comment"># &gt; array([[ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 1.,  0.,  0.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encodings</span>(<span class="params">arr</span>):</span><br><span class="line">    uniqs = np.unique(arr)</span><br><span class="line">    out = np.zeros((arr.shape[<span class="number">0</span>], uniqs.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(arr):</span><br><span class="line">        out[i, k-<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">one_hot_encodings(arr)</span><br><span class="line"><span class="comment"># &gt; array([[ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  0.,  1.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 0.,  1.,  0.],</span></span><br><span class="line"><span class="comment"># &gt;        [ 1.,  0.,  0.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">(arr[:, <span class="literal">None</span>] == np.unique(arr)).view(np.int8)</span><br></pre></td></tr></table></figure>

<h2 id="如何创建按分类变量分组的序号？"><a href="#如何创建按分类变量分组的序号？" class="headerlink" title="如何创建按分类变量分组的序号？"></a>如何创建按分类变量分组的序号？</h2><p>创建按分类变量分组的序号。使用以下来自鸢尾属植物物种的样本作为输入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">species = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;str&#x27;</span>, usecols=<span class="number">4</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">species_small = np.sort(np.random.choice(species, size=<span class="number">20</span>))</span><br><span class="line">species_small</span><br><span class="line"><span class="comment"># &gt; array([&#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-setosa&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;&lt;U15&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>([i <span class="keyword">for</span> val <span class="keyword">in</span> np.unique(species_small) <span class="keyword">for</span> i, grp <span class="keyword">in</span> <span class="built_in">enumerate</span>(species_small[species_small==val])])</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br></pre></td></tr></table></figure>

<h2 id="如何根据给定的分类变量创建组ID？"><a href="#如何根据给定的分类变量创建组ID？" class="headerlink" title="如何根据给定的分类变量创建组ID？"></a>如何根据给定的分类变量创建组ID？</h2><p>根据给定的分类变量创建组ID。使用以下来自鸢尾属植物物种的样本作为输入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">species = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;str&#x27;</span>, usecols=<span class="number">4</span>)</span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">species_small = np.sort(np.random.choice(species, size=<span class="number">20</span>))</span><br><span class="line">species_small</span><br><span class="line"><span class="comment"># &gt; array([&#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;, &#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-setosa&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;, &#x27;Iris-versicolor&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-versicolor&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;, &#x27;Iris-virginica&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;Iris-virginica&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;&lt;U15&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">output = [np.argwhere(np.unique(species_small) == s).tolist()[<span class="number">0</span>][<span class="number">0</span>] <span class="keyword">for</span> val <span class="keyword">in</span> np.unique(species_small) <span class="keyword">for</span> s <span class="keyword">in</span> species_small[species_small==val]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution: For Loop version</span></span><br><span class="line">output = []</span><br><span class="line">uniqs = np.unique(species_small)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> val <span class="keyword">in</span> uniqs:  <span class="comment"># uniq values in group</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> species_small[species_small==val]:  <span class="comment"># each element in group</span></span><br><span class="line">        groupid = np.argwhere(uniqs == s).tolist()[<span class="number">0</span>][<span class="number">0</span>]  <span class="comment"># groupid</span></span><br><span class="line">        output.append(groupid)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># &gt; [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2]</span></span><br></pre></td></tr></table></figure>

<h2 id="使用NumPy获取数组中各项排名？"><a href="#使用NumPy获取数组中各项排名？" class="headerlink" title="使用NumPy获取数组中各项排名？"></a>使用NumPy获取数组中各项排名？</h2><p>为给定的数组a创建排名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">a = np.random.randint(<span class="number">20</span>, size=<span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([ 9,  4, 15,  0, 17, 16, 17,  8,  9,  0])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">a.argsort()</span><br><span class="line"><span class="comment"># array([3, 9, 1, 7, 0, 8, 2, 5, 4, 6], dtype=int64)</span></span><br><span class="line"></span><br><span class="line">a.argsort().argsort()</span><br><span class="line"><span class="comment"># array([4, 2, 6, 0, 8, 7, 9, 3, 5, 1], dtype=int64)</span></span><br></pre></td></tr></table></figure>

<h2 id="如何使用NumPy对多维数组中的项进行排名？"><a href="#如何使用NumPy对多维数组中的项进行排名？" class="headerlink" title="如何使用NumPy对多维数组中的项进行排名？"></a>如何使用NumPy对多维数组中的项进行排名？</h2><p>创建与给定数字数组a相同形状的排名数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：**</span></span><br><span class="line">np.random.seed(<span class="number">10</span>)</span><br><span class="line">a = np.random.randint(<span class="number">20</span>, size=[<span class="number">2</span>,<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># &gt; [[ 9  4 15  0 17]</span></span><br><span class="line"><span class="comment"># &gt;  [16 17  8  9  0]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(a.ravel().argsort().argsort().reshape(a.shape))</span><br><span class="line"><span class="comment"># &gt; [[4 2 6 0 8]</span></span><br><span class="line"><span class="comment"># &gt;  [7 9 3 5 1]]</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.ravel()</code>返回一个连续的扁平数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.ravel(a, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Return a contiguous flattened array. A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.</span></span><br></pre></td></tr></table></figure>

<h2 id="如何在二维NumPy数组的每一行中找到最大值？"><a href="#如何在二维NumPy数组的每一行中找到最大值？" class="headerlink" title="如何在二维NumPy数组的每一行中找到最大值？"></a>如何在二维NumPy数组的每一行中找到最大值？</h2><p>问题：计算给定数组中每行的最大值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">10</span>, [<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([[9, 9, 4],</span></span><br><span class="line"><span class="comment">#        [8, 8, 1],</span></span><br><span class="line"><span class="comment">#        [5, 3, 6],</span></span><br><span class="line"><span class="comment">#        [3, 3, 3],</span></span><br><span class="line"><span class="comment">#        [2, 1, 9]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1</span></span><br><span class="line">np.amax(a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># np.amax 函数就是 np.max 函数，历史遗留问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2</span></span><br><span class="line">np.apply_along_axis(np.<span class="built_in">max</span>, arr=a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># &gt; array([9, 8, 6, 3, 9])</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.apply_along_axis()</code>表示沿给定轴向对一维切片应用函数 func1d。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numpy.apply_along_axis</span></span><br><span class="line">numpy.apply_along_axis(func1d, axis, arr, *args, **kwargs)</span><br><span class="line"><span class="comment"># Apply a function to 1-D slices along the given axis.</span></span><br></pre></td></tr></table></figure>


<h2 id="如何计算二维NumPy数组每行的最小值与最大值的比值？"><a href="#如何计算二维NumPy数组每行的最小值与最大值的比值？" class="headerlink" title="如何计算二维NumPy数组每行的最小值与最大值的比值？"></a>如何计算二维NumPy数组每行的最小值与最大值的比值？</h2><p>为给定的二维NumPy数组计算每行的最小值与最大值的比值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">1</span>,<span class="number">10</span>, [<span class="number">5</span>,<span class="number">3</span>])</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([[9, 9, 4],</span></span><br><span class="line"><span class="comment">#        [8, 8, 1],</span></span><br><span class="line"><span class="comment">#        [5, 3, 6],</span></span><br><span class="line"><span class="comment">#        [3, 3, 3],</span></span><br><span class="line"><span class="comment">#        [2, 1, 9]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">np.apply_along_axis(<span class="keyword">lambda</span> x: np.<span class="built_in">min</span>(x)/np.<span class="built_in">max</span>(x), arr=a, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([0.44444444, 0.125     , 0.5       , 1.        , 0.11111111])</span></span><br><span class="line"></span><br><span class="line">np.apply_along_axis(<span class="keyword">lambda</span> x: np.<span class="built_in">min</span>(x)/np.<span class="built_in">max</span>(x), arr=a, axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># array([0.22222222, 0.11111111, 0.11111111])</span></span><br></pre></td></tr></table></figure>

<h2 id="如何在NumPy数组中找到重复的记录？"><a href="#如何在NumPy数组中找到重复的记录？" class="headerlink" title="如何在NumPy数组中找到重复的记录？"></a>如何在NumPy数组中找到重复的记录？</h2><p>在给定的NumPy数组中找到重复的条目(第二次出现以后)，并将它们标记为True。第一次出现应该是False的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">a = np.random.randint(<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">a</span><br><span class="line"><span class="comment"># array([0, 0, 3, 0, 2, 4, 2, 2, 2, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Solution</span></span><br><span class="line"><span class="comment"># There is no direct function to do this as of 1.13.3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an all True array</span></span><br><span class="line">out = np.full(a.shape[<span class="number">0</span>], <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the index positions of unique elements</span></span><br><span class="line">unique_positions = np.unique(a, return_index=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Mark those positions as False</span></span><br><span class="line">out[unique_positions] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="comment"># &gt; [False  True False  True False False  True  True  True  True]</span></span><br></pre></td></tr></table></figure>

<h2 id="如何找出数字的分组均值？"><a href="#如何找出数字的分组均值？" class="headerlink" title="如何找出数字的分组均值？"></a>如何找出数字的分组均值？</h2><p>在二维数字数组中查找按分类列分组的数值列的平均值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line">names = (<span class="string">&#x27;sepallength&#x27;</span>, <span class="string">&#x27;sepalwidth&#x27;</span>, <span class="string">&#x27;petallength&#x27;</span>, <span class="string">&#x27;petalwidth&#x27;</span>, <span class="string">&#x27;species&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 理想的输出：</span></span><br><span class="line"><span class="comment"># &gt; [[b&#x27;Iris-setosa&#x27;, 3.418],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-versicolor&#x27;, 2.770],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-virginica&#x27;, 2.974]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># No direct way to implement this. Just a version of a workaround.</span></span><br><span class="line">numeric_column = iris[:,<span class="number">1</span>].astype(<span class="string">&#x27;float&#x27;</span>)  <span class="comment"># sepalwidth</span></span><br><span class="line">grouping_column = iris[:,<span class="number">4</span>]  <span class="comment"># species</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List comprehension version</span></span><br><span class="line">[[group_val, numeric_column[grouping_column==group_val].mean()] <span class="keyword">for</span> group_val <span class="keyword">in</span> np.unique(grouping_column)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># For Loop version</span></span><br><span class="line">output = []</span><br><span class="line"><span class="keyword">for</span> group_val <span class="keyword">in</span> np.unique(grouping_column):</span><br><span class="line">    output.append([group_val, numeric_column[grouping_column==group_val].mean()])</span><br><span class="line"></span><br><span class="line">output</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;Iris-setosa&#x27;, 3.418],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-versicolor&#x27;, 2.770],</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;Iris-virginica&#x27;, 2.974]]</span></span><br></pre></td></tr></table></figure>

<h2 id="如何将PIL图像转换为NumPy数组？"><a href="#如何将PIL图像转换为NumPy数组？" class="headerlink" title="如何将PIL图像转换为NumPy数组？"></a>如何将PIL图像转换为NumPy数组？</h2><p>从以下URL导入图像并将其转换为numpy数组。<br>URL &#x3D; ‘<a href="https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg">https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg</a>‘</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> PIL, requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import image from URL</span></span><br><span class="line">URL = <span class="string">&#x27;https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg&#x27;</span></span><br><span class="line">response = requests.get(URL)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read it as Image</span></span><br><span class="line">I = Image.<span class="built_in">open</span>(BytesIO(response.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionally resize</span></span><br><span class="line">I = I.resize([<span class="number">150</span>,<span class="number">150</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to numpy array</span></span><br><span class="line">arr = np.asarray(I)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionaly Convert it back to an image and show</span></span><br><span class="line">im = PIL.Image.fromarray(np.uint8(arr))</span><br><span class="line">Image.Image.show(im)</span><br></pre></td></tr></table></figure>

<h2 id="删除NumPy数组中所有NaN值"><a href="#删除NumPy数组中所有NaN值" class="headerlink" title="删除NumPy数组中所有NaN值"></a>删除NumPy数组中所有NaN值</h2><p>从一维NumPy数组中删除所有NaN值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,np.nan,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,np.nan])</span><br><span class="line">a[~np.isnan(a)]</span><br><span class="line"><span class="comment"># &gt; array([ 1.,  2.,  3.,  5.,  6.,  7.])</span></span><br></pre></td></tr></table></figure>

<h2 id="计算两个数组之间的欧氏距离"><a href="#计算两个数组之间的欧氏距离" class="headerlink" title="计算两个数组之间的欧氏距离"></a>计算两个数组之间的欧氏距离</h2><p>计算两个数组a和数组b之间的欧氏距离。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">b = np.array([<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">dist = np.linalg.norm(a-b)</span><br><span class="line">dist</span><br><span class="line"><span class="comment"># &gt; 6.7082039324993694</span></span><br></pre></td></tr></table></figure>

<h2 id="在一维数组中找到所有的局部极大值-或峰值-？"><a href="#在一维数组中找到所有的局部极大值-或峰值-？" class="headerlink" title="在一维数组中找到所有的局部极大值(或峰值)？"></a>在一维数组中找到所有的局部极大值(或峰值)？</h2><p>找到一个一维数字数组a中的所有峰值。峰顶是两边被较小数值包围的点。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">doublediff = np.diff(np.sign(np.diff(a)))</span><br><span class="line">peak_locations = np.where(doublediff == -<span class="number">2</span>)[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">peak_locations</span><br><span class="line"><span class="comment"># &gt; array([2, 5])</span></span><br></pre></td></tr></table></figure>

<p><code>numpy.diff()</code>函数计算计算沿给定轴的n-th离散差分。</p>
<p>The <code>numpy.sign</code> function returns -1 if x &lt; 0, 0 if x&#x3D;&#x3D;0, 1 if x &gt; 0.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numpy.diff(a, n=<span class="number">1</span>, axis=-<span class="number">1</span>, prepend=&lt;no value&gt;, append=&lt;no value&gt;)[source]</span><br><span class="line"><span class="comment"># Calculate the n-th discrete difference along the given axis.</span></span><br></pre></td></tr></table></figure>

<p>参数说明:</p>
<ul>
<li>a: array_like, 输入数组；</li>
<li>n: int, 可选项，值差的次数。默认值为1，如果为零，则按原样返回输入。</li>
<li>axis: int, 可选项，计算差值的轴，默认是最后一个轴。</li>
<li>diff: ndarray, n-th差值。输出的形状与a相同，除了沿轴的尺寸小n。输出的类型与a的任意两个元素之间的差的类型相同。在大多数情况下，这与a的类型相同。一个值得注意的例外是datetime64，它产生一个timedelta64输出数组。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">0</span>])</span><br><span class="line">np.diff(x)</span><br><span class="line">array([ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, -<span class="number">7</span>])</span><br><span class="line">np.diff(x, n=<span class="number">2</span>)</span><br><span class="line">array([  <span class="number">1</span>,   <span class="number">1</span>, -<span class="number">10</span>])</span><br><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">10</span>], [<span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>]])</span><br><span class="line">np.diff(x)</span><br><span class="line">array([[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line">np.diff(x, axis=<span class="number">0</span>)</span><br><span class="line">array([[-<span class="number">1</span>,  <span class="number">2</span>,  <span class="number">0</span>, -<span class="number">2</span>]])</span><br></pre></td></tr></table></figure>

<h2 id="从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去"><a href="#从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去" class="headerlink" title="从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去"></a>从二维数组中减去一维数组，其中一维数组的每一项从各自的行中减去</h2><p>从2d数组a_2d中减去一维数组b_1D，使得b_1D的每一项从a_2d的相应行中减去。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">a_2d = np.array([[<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>],[<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>]])</span><br><span class="line">b_1d = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="built_in">print</span>(a_2d - b_1d[:,<span class="literal">None</span>])</span><br><span class="line"><span class="comment"># &gt; [[2 2 2]</span></span><br><span class="line"><span class="comment"># &gt;  [2 2 2]</span></span><br><span class="line"><span class="comment"># &gt;  [2 2 2]]</span></span><br></pre></td></tr></table></figure>

<h2 id="查找数组中项的第n次重复索引"><a href="#查找数组中项的第n次重复索引" class="headerlink" title="查找数组中项的第n次重复索引"></a>查找数组中项的第n次重复索引</h2><p>找出x中数字1的第5次重复的索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">n = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 1: List comprehension</span></span><br><span class="line">[i <span class="keyword">for</span> i, v <span class="keyword">in</span> <span class="built_in">enumerate</span>(x) <span class="keyword">if</span> v == <span class="number">1</span>][n-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution 2: Numpy version</span></span><br><span class="line">np.where(x == <span class="number">1</span>)[<span class="number">0</span>][n-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; 8</span></span><br></pre></td></tr></table></figure>

<h1 id="将NumPy的datetime-64对象转换为datetime的datetime对象？"><a href="#将NumPy的datetime-64对象转换为datetime的datetime对象？" class="headerlink" title="将NumPy的datetime 64对象转换为datetime的datetime对象？"></a>将NumPy的datetime 64对象转换为datetime的datetime对象？</h1><p>问题：将NumPy的datetime64对象转换为datetime的datetime对象</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># **给定：** a numpy datetime64 object</span></span><br><span class="line">dt64 = np.datetime64(<span class="string">&#x27;2018-02-25 22:10:10&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">dt64.tolist()</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">dt64.astype(datetime)</span><br><span class="line"><span class="comment"># &gt; datetime.datetime(2018, 2, 25, 22, 10, 10)</span></span><br></pre></td></tr></table></figure>

<h2 id="计算NumPy数组的移动平均值"><a href="#计算NumPy数组的移动平均值" class="headerlink" title="计算NumPy数组的移动平均值"></a>计算NumPy数组的移动平均值</h2><p>对于给定的一维数组，计算窗口大小为3的移动平均值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">Z = np.random.randint(<span class="number">10</span>, size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line"><span class="comment"># Source: https://stackoverflow.com/questions/14313510/how-to-calculate-moving-average-using-numpy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moving_average</span>(<span class="params">a, n=<span class="number">3</span></span>) :</span><br><span class="line">    ret = np.cumsum(a, dtype=<span class="built_in">float</span>)</span><br><span class="line">    ret[n:] = ret[n:] - ret[:-n]</span><br><span class="line">    <span class="keyword">return</span> ret[n - <span class="number">1</span>:] / n</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;array: &#x27;</span>, Z)</span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">moving_average(Z, n=<span class="number">3</span>).<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:  # Thanks AlanLRH!</span></span><br><span class="line"><span class="comment"># np.ones(3)/3 gives equal weights. Use np.ones(4)/4 for window size 4.</span></span><br><span class="line">np.convolve(Z, np.ones(<span class="number">3</span>)/<span class="number">3</span>, mode=<span class="string">&#x27;valid&#x27;</span>) . </span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; array:  [8 8 3 7 7 0 4 2 5 2]</span></span><br><span class="line"><span class="comment"># &gt; moving average:  [ 6.33  6.    5.67  4.67  3.67  2.    3.67  3.  ]</span></span><br></pre></td></tr></table></figure>

<h2 id="在给定起始点、长度和步骤的情况下创建一个NumPy数组序列"><a href="#在给定起始点、长度和步骤的情况下创建一个NumPy数组序列" class="headerlink" title="在给定起始点、长度和步骤的情况下创建一个NumPy数组序列"></a>在给定起始点、长度和步骤的情况下创建一个NumPy数组序列</h2><p>创建长度为10的NumPy数组，从5开始，在连续的数字之间的步长为3。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">length = <span class="number">10</span></span><br><span class="line">start = <span class="number">5</span></span><br><span class="line">step = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">seq</span>(<span class="params">start, length, step</span>):</span><br><span class="line">    end = start + (step*length)</span><br><span class="line">    <span class="keyword">return</span> np.arange(start, end, step)</span><br><span class="line"></span><br><span class="line">seq(start, length, step)</span><br><span class="line"><span class="comment"># &gt; array([ 5,  8, 11, 14, 17, 20, 23, 26, 29, 32])</span></span><br></pre></td></tr></table></figure>

<h2 id="填写不规则系列的NumPy日期中的缺失日期"><a href="#填写不规则系列的NumPy日期中的缺失日期" class="headerlink" title="填写不规则系列的NumPy日期中的缺失日期"></a>填写不规则系列的NumPy日期中的缺失日期</h2><p>给定一系列不连续的日期序列。填写缺失的日期，使其成为连续的日期序列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">dates = np.arange(np.datetime64(<span class="string">&#x27;2018-02-01&#x27;</span>), np.datetime64(<span class="string">&#x27;2018-02-25&#x27;</span>), <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(dates)</span><br><span class="line"><span class="comment"># &gt; [&#x27;2018-02-01&#x27; &#x27;2018-02-03&#x27; &#x27;2018-02-05&#x27; &#x27;2018-02-07&#x27; &#x27;2018-02-09&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-11&#x27; &#x27;2018-02-13&#x27; &#x27;2018-02-15&#x27; &#x27;2018-02-17&#x27; &#x27;2018-02-19&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-21&#x27; &#x27;2018-02-23&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution ---------------</span></span><br><span class="line">filled_in = np.array([np.arange(date, (date+d)) <span class="keyword">for</span> date, d <span class="keyword">in</span> <span class="built_in">zip</span>(dates, np.diff(dates))]).reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the last day</span></span><br><span class="line">output = np.hstack([filled_in, dates[-<span class="number">1</span>]])</span><br><span class="line">output</span><br><span class="line"></span><br><span class="line"><span class="comment"># For loop version -------</span></span><br><span class="line">out = []</span><br><span class="line"><span class="keyword">for</span> date, d <span class="keyword">in</span> <span class="built_in">zip</span>(dates, np.diff(dates)):</span><br><span class="line">    out.append(np.arange(date, (date+d)))</span><br><span class="line"></span><br><span class="line">filled_in = np.array(out).reshape(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># add the last day</span></span><br><span class="line">output = np.hstack([filled_in, dates[-<span class="number">1</span>]])</span><br><span class="line">output</span><br><span class="line"><span class="comment"># &gt; [&#x27;2018-02-01&#x27; &#x27;2018-02-03&#x27; &#x27;2018-02-05&#x27; &#x27;2018-02-07&#x27; &#x27;2018-02-09&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-11&#x27; &#x27;2018-02-13&#x27; &#x27;2018-02-15&#x27; &#x27;2018-02-17&#x27; &#x27;2018-02-19&#x27;</span></span><br><span class="line"><span class="comment"># &gt;  &#x27;2018-02-21&#x27; &#x27;2018-02-23&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt; array([&#x27;2018-02-01&#x27;, &#x27;2018-02-02&#x27;, &#x27;2018-02-03&#x27;, &#x27;2018-02-04&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-05&#x27;, &#x27;2018-02-06&#x27;, &#x27;2018-02-07&#x27;, &#x27;2018-02-08&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-09&#x27;, &#x27;2018-02-10&#x27;, &#x27;2018-02-11&#x27;, &#x27;2018-02-12&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-13&#x27;, &#x27;2018-02-14&#x27;, &#x27;2018-02-15&#x27;, &#x27;2018-02-16&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-17&#x27;, &#x27;2018-02-18&#x27;, &#x27;2018-02-19&#x27;, &#x27;2018-02-20&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        &#x27;2018-02-21&#x27;, &#x27;2018-02-22&#x27;, &#x27;2018-02-23&#x27;], dtype=&#x27;datetime64[D]&#x27;)</span></span><br></pre></td></tr></table></figure>

<h2 id="从给定的一维数组创建步长"><a href="#从给定的一维数组创建步长" class="headerlink" title="从给定的一维数组创建步长"></a>从给定的一维数组创建步长</h2><p>从给定的一维数组arr中，利用步进生成一个二维矩阵，窗口长度为4，步距为2，类似于 [[0,1,2,3], [2,3,4,5], [4,5,6,7]..]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">15</span>) </span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gen_strides</span>(<span class="params">a, stride_len=<span class="number">5</span>, window_len=<span class="number">5</span></span>):</span><br><span class="line">    n_strides = ((a.size-window_len)//stride_len) + <span class="number">1</span></span><br><span class="line">    <span class="comment"># return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])</span></span><br><span class="line">    <span class="keyword">return</span> np.array([a[s:(s+window_len)] <span class="keyword">for</span> s <span class="keyword">in</span> np.arange(<span class="number">0</span>, n_strides*stride_len, stride_len)])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(gen_strides(np.arange(<span class="number">15</span>), stride_len=<span class="number">2</span>, window_len=<span class="number">4</span>))</span><br><span class="line"><span class="comment"># &gt; [[ 0  1  2  3]</span></span><br><span class="line"><span class="comment"># &gt;  [ 2  3  4  5]</span></span><br><span class="line"><span class="comment"># &gt;  [ 4  5  6  7]</span></span><br><span class="line"><span class="comment"># &gt;  [ 6  7  8  9]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8  9 10 11]</span></span><br><span class="line"><span class="comment"># &gt;  [10 11 12 13]]</span></span><br></pre></td></tr></table></figure>





















<h2 id="本章总结"><a href="#本章总结" class="headerlink" title="本章总结"></a>本章总结</h2><h3 id="数组属性"><a href="#数组属性" class="headerlink" title="数组属性"></a>数组属性</h3><p>在使用NumPy时，你会想知道数组的某些信息。很幸运，NumPy包里边包含了很多便捷的方法，可以给你想要的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Array properties</span></span><br><span class="line">a = np.array([[<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>],</span><br><span class="line">              [<span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>],</span><br><span class="line">              [<span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>, <span class="number">25</span>],</span><br><span class="line">              [<span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span> ,<span class="number">29</span>, <span class="number">30</span>],</span><br><span class="line">              [<span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a)) <span class="comment"># &gt;&gt;&gt;&lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br><span class="line"><span class="built_in">print</span>(a.dtype) <span class="comment"># &gt;&gt;&gt;int64</span></span><br><span class="line"><span class="built_in">print</span>(a.size) <span class="comment"># &gt;&gt;&gt;25</span></span><br><span class="line"><span class="built_in">print</span>(a.shape) <span class="comment"># &gt;&gt;&gt;(5, 5)</span></span><br><span class="line"><span class="built_in">print</span>(a.itemsize) <span class="comment"># &gt;&gt;&gt;8</span></span><br><span class="line"><span class="built_in">print</span>(a.ndim) <span class="comment"># &gt;&gt;&gt;2</span></span><br><span class="line"><span class="built_in">print</span>(a.nbytes) <span class="comment"># &gt;&gt;&gt;200</span></span><br></pre></td></tr></table></figure>

<p>正如你在上面的代码中看到的，NumPy数组实际上被称为<code>&#39;numpy.ndarray&#39;</code>。</p>
<ul>
<li><p><code>shape</code>属性是数组有多少行和列，上面的数组有5行和5列，所以它的shape是(5, 5)。</p>
</li>
<li><p><code>itemsize</code>属性是每个项占用的字节（Byte）数。这个数组的数据类型是<code>int64</code>，一个<code>int64</code>中有64 bit，1 byte &#x3D; 8 bit，即为8 byte。</p>
</li>
<li><p><code>ndim</code>属性是数组的维数，在本例中为2。</p>
</li>
<li><p><code>nbytes</code>属性是数组中的所有数据消耗掉的字节数。这并不计算数组信息定义开销，因此数组占用的实际内存空间将稍微大一点。</p>
</li>
</ul>
<h3 id="数组索引"><a href="#数组索引" class="headerlink" title="数组索引"></a>数组索引</h3><p>NumPy提供了几种索引数组的方法，包括单元素索引，切片索引，整数数组索引，布尔数组索引等等。</p>
<h4 id="单元素索引"><a href="#单元素索引" class="headerlink" title="单元素索引"></a>单元素索引</h4><p>人们期望的是1-D数组的单元素索引。它的工作方式与其他标准Python序列完全相同。它从0开始计数，并接受从数组末尾开始索引的负索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">2</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[-<span class="number">2</span>]</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>

<h4 id="切片索引（Slicing）"><a href="#切片索引（Slicing）" class="headerlink" title="切片索引（Slicing）"></a>切片索引（Slicing）</h4><p>与Python列表类似，可以对NumPy数组进行切片。由于数组可能是多维的，因此必须为数组的每个维指定一个切片：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],     <span class="comment"># Create the following rank 2 array with shape (3, 4)</span></span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line">b = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]    <span class="comment"># Use slicing to pull out the subarray consisting of the first 2 rows and columns 1 and 2; </span></span><br><span class="line"><span class="built_in">print</span>(b)          <span class="comment"># b is the following array of shape (2, 2):</span></span><br><span class="line">                  <span class="comment"># [[2 3]</span></span><br><span class="line">                  <span class="comment">#  [6 7]]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A slice of an array is a view into the same data, so modifying it</span></span><br><span class="line"><span class="comment"># will modify the original array.</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;2&quot;</span></span><br><span class="line">b[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">77</span>     <span class="comment"># b[0, 0] is the same piece of data as a[0, 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">1</span>])   <span class="comment"># Prints &quot;77&quot;</span></span><br></pre></td></tr></table></figure>

<p>你还可以将整数索引与切片索引混合使用。 但是，这样做会产生比原始数组更低级别的数组。 请注意，这与MATLAB处理数组切片的方式完全不同：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], </span><br><span class="line">              [<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Two ways of accessing the data in the middle row of the array.</span></span><br><span class="line"><span class="comment"># Mixing integer indexing with slices yields an array of lower rank,</span></span><br><span class="line"><span class="comment"># while using only slices yields an array of the same rank as the</span></span><br><span class="line"><span class="comment"># original array:</span></span><br><span class="line">row_r1 = a[<span class="number">1</span>, :]    <span class="comment"># Rank 1 view of the second row of a</span></span><br><span class="line">row_r2 = a[<span class="number">1</span>:<span class="number">2</span>, :]  <span class="comment"># Rank 2 view of the second row of a</span></span><br><span class="line"><span class="built_in">print</span>(row_r1, row_r1.shape)  <span class="comment"># Prints &quot;[5 6 7 8] (4,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(row_r2, row_r2.shape)  <span class="comment"># Prints &quot;[[5 6 7 8]] (1, 4)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can make the same distinction when accessing columns of an array:</span></span><br><span class="line">col_r1 = a[:, <span class="number">1</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1, col_r1.shape)  <span class="comment"># Prints &quot;[ 2  6 10] (3,)&quot;</span></span><br><span class="line"><span class="built_in">print</span>(col_r2, col_r2.shape)  <span class="comment"># Prints &quot;[[ 2]</span></span><br><span class="line">                             <span class="comment">#          [ 6]</span></span><br><span class="line">                             <span class="comment">#          [10]] (3, 1)&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="整数数组索引"><a href="#整数数组索引" class="headerlink" title="整数数组索引"></a>整数数组索引</h4><p>使用切片索引到NumPy数组时，生成的数组视图将始终是原始数组的子数组。 相反，整数数组索引允许你使用另一个数组中的数据构造任意数组。 这是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              [<span class="number">3</span>, <span class="number">4</span>], </span><br><span class="line">              [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># An example of integer array indexing.</span></span><br><span class="line"><span class="comment"># The returned array will have shape (3,) and</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The above example of integer array indexing is equivalent to this:</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">0</span>], a[<span class="number">1</span>, <span class="number">1</span>], a[<span class="number">2</span>, <span class="number">0</span>]]))  <span class="comment"># Prints &quot;[1 4 5]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># When using integer array indexing, you can reuse the same</span></span><br><span class="line"><span class="comment"># element from the source array:</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Equivalent to the previous integer array indexing example</span></span><br><span class="line"><span class="built_in">print</span>(np.array([a[<span class="number">0</span>, <span class="number">1</span>], a[<span class="number">0</span>, <span class="number">1</span>]]))  <span class="comment"># Prints &quot;[2 2]&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="布尔数组索引"><a href="#布尔数组索引" class="headerlink" title="布尔数组索引"></a>布尔数组索引</h4><p>布尔数组索引允许你选择数组的任意元素。通常，这种类型的索引用于选择满足某些条件的数组元素。下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line">bool_idx = (a &gt; <span class="number">2</span>)   <span class="comment"># Find the elements of a that are bigger than 2;</span></span><br><span class="line">                     <span class="comment"># this returns a numpy array of Booleans of the same</span></span><br><span class="line">                     <span class="comment"># shape as a, where each slot of bool_idx tells</span></span><br><span class="line">                     <span class="comment"># whether that element of a is &gt; 2.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(bool_idx)      <span class="comment"># Prints &quot;[[False False]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]</span></span><br><span class="line">                     <span class="comment">#          [ True  True]]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We use boolean array indexing to construct a rank 1 array</span></span><br><span class="line"><span class="comment"># consisting of the elements of a corresponding to the True values</span></span><br><span class="line"><span class="comment"># of bool_idx</span></span><br><span class="line"><span class="built_in">print</span>(a[bool_idx])  <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># We can do all of the above in a single concise statement:</span></span><br><span class="line"><span class="built_in">print</span>(a[a &gt; <span class="number">2</span>])     <span class="comment"># Prints &quot;[3 4 5 6]&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="Where-函数"><a href="#Where-函数" class="headerlink" title="Where 函数"></a>Where 函数</h4><p><code>where()</code>函数是一个根据条件返回数组中的值的有效方法。只需要把条件传递给它，它就会返回一个使得条件为真的元素的列表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Where</span></span><br><span class="line">a = np.arange(<span class="number">0</span>, <span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">b = np.where(a &lt; <span class="number">50</span>) </span><br><span class="line">c = np.where(a &gt;= <span class="number">50</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(b) <span class="comment"># &gt;&gt;&gt;(array([0, 1, 2, 3, 4]),)</span></span><br><span class="line"><span class="built_in">print</span>(c) <span class="comment"># &gt;&gt;&gt;[5 6 7 8 9]</span></span><br></pre></td></tr></table></figure>

<h4 id="反转二维数组的列"><a href="#反转二维数组的列" class="headerlink" title="反转二维数组的列"></a>反转二维数组的列</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, ::-<span class="number">1</span>]</span><br><span class="line"><span class="comment"># &gt; array([[2, 1, 0],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 4, 3],</span></span><br><span class="line"><span class="comment"># &gt;        [8, 7, 6]])</span></span><br></pre></td></tr></table></figure>

<h4 id="交换二维-numpy-数组中的两列"><a href="#交换二维-numpy-数组中的两列" class="headerlink" title="交换二维 numpy 数组中的两列"></a>交换二维 numpy 数组中的两列</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Input</span></span><br><span class="line">arr = np.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">arr</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [3, 4, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [6, 7, 8]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution</span></span><br><span class="line">arr[:, [<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="comment"># &gt; array([[1, 0, 2],</span></span><br><span class="line"><span class="comment"># &gt;        [4, 3, 5],</span></span><br><span class="line"><span class="comment"># &gt;        [7, 6, 8]])</span></span><br></pre></td></tr></table></figure>


<h4 id="从-1-维元组数组中提取特定列"><a href="#从-1-维元组数组中提取特定列" class="headerlink" title="从 1 维元组数组中提取特定列"></a>从 1 维元组数组中提取特定列</h4><p>问题：从前面问题中导入的一维鸢尾属植物数据集中提取文本列的物种。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_1d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(iris_1d.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">species = np.array([row[<span class="number">4</span>] <span class="keyword">for</span> row <span class="keyword">in</span> iris_1d])</span><br><span class="line">species[:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># &gt; array([b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;, b&#x27;Iris-setosa&#x27;,</span></span><br><span class="line"><span class="comment"># &gt;        b&#x27;Iris-setosa&#x27;],</span></span><br><span class="line"><span class="comment"># &gt;       dtype=&#x27;|S15&#x27;)</span></span><br></pre></td></tr></table></figure>


<h3 id="广播-Broadcasting"><a href="#广播-Broadcasting" class="headerlink" title="广播(Broadcasting)"></a>广播(Broadcasting)</h3><p>广播是一种强大的机制，它允许NumPy在执行算术运算时使用不同形状的数组。通常，我们有一个较小的数组和一个较大的数组，我们希望多次使用较小的数组来对较大的数组执行一些操作。</p>
<p>例如，假设我们要向矩阵的每一行添加一个常数向量。我们可以这样做：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># We will add the vector v to each row of the matrix x,</span></span><br><span class="line"><span class="comment"># storing the result in the matrix y</span></span><br><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">vv = np.tile(v, (<span class="number">4</span>, <span class="number">1</span>))   <span class="comment"># Stack 4 copies of v on top of each other</span></span><br><span class="line"><span class="built_in">print</span>(vv)                 <span class="comment"># Prints &quot;[[1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]]&quot;</span></span><br><span class="line">y = x + vv  <span class="comment"># Add x and vv elementwise</span></span><br><span class="line"><span class="built_in">print</span>(y)  <span class="comment"># Prints &quot;[[ 2  2  4</span></span><br><span class="line">          <span class="comment">#          [ 5  5  7]</span></span><br><span class="line">          <span class="comment">#          [ 8  8 10]</span></span><br><span class="line">          <span class="comment">#          [11 11 13]]&quot;</span></span><br></pre></td></tr></table></figure>

<p>广播通常会使你的代码更简洁，效率更高，因此你应该尽可能地使用它。</p>
<h3 id="改变数组的形状"><a href="#改变数组的形状" class="headerlink" title="改变数组的形状"></a>改变数组的形状</h3><p>问题：如何将一维数组转换为 2 行的 2 维数组</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">10</span>)</span><br><span class="line">arr.reshape(<span class="number">2</span>, -<span class="number">1</span>)  <span class="comment"># Setting to -1 automatically decides the number of cols</span></span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">numpy.reshape(a, newshape, order=<span class="string">&#x27;C&#x27;</span>)</span><br><span class="line"><span class="comment"># Gives a new shape to an array without changing its data.</span></span><br></pre></td></tr></table></figure>

<h3 id="数组拼接"><a href="#数组拼接" class="headerlink" title="数组拼接"></a>数组拼接</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment">#        [5, 6, 7, 8, 9]])</span></span><br><span class="line"></span><br><span class="line">b = np.repeat(<span class="number">1</span>, <span class="number">10</span>).reshape(<span class="number">2</span>,-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># array([[1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment">#        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 垂直叠加两个数组</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.vstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.r_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [1, 1, 1, 1, 1]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 水平叠加两个数组</span></span><br><span class="line"><span class="comment"># Method 1:</span></span><br><span class="line">np.concatenate([a, b], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2:</span></span><br><span class="line">np.hstack([a, b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3:</span></span><br><span class="line">np.c_[a, b]</span><br><span class="line"><span class="comment"># &gt; array([[0, 1, 2, 3, 4, 1, 1, 1, 1, 1],</span></span><br><span class="line"><span class="comment"># &gt;        [5, 6, 7, 8, 9, 1, 1, 1, 1, 1]])</span></span><br></pre></td></tr></table></figure>

<h3 id="随机数产生器"><a href="#随机数产生器" class="headerlink" title="随机数产生器"></a>随机数产生器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Solution Method 1:</span></span><br><span class="line">rand_arr = np.random.randint(low=<span class="number">5</span>, high=<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>)) + np.random.random((<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment"># print(rand_arr)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Solution Method 2:</span></span><br><span class="line">rand_arr = np.random.uniform(<span class="number">5</span>,<span class="number">10</span>, size=(<span class="number">5</span>,<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(rand_arr)</span><br><span class="line"><span class="comment"># &gt; [[ 8.50061025  9.10531502  6.85867783]</span></span><br><span class="line"><span class="comment"># &gt;  [ 9.76262069  9.87717411  7.13466701]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.48966403  8.33409158  6.16808631]</span></span><br><span class="line"><span class="comment"># &gt;  [ 7.75010551  9.94535696  5.27373226]</span></span><br><span class="line"><span class="comment"># &gt;  [ 8.0850361   5.56165518  7.31244004]]</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 问题：在 iris_2d 数据集中的 20 个随机位置插入 np.nan 值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input</span></span><br><span class="line">url = <span class="string">&#x27;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#x27;</span></span><br><span class="line">iris_2d = np.genfromtxt(url, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="string">&#x27;object&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 1</span></span><br><span class="line">i, j = np.where(iris_2d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># i, j contain the row numbers and column numbers of 600 elements of iris_x</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.choice((i), <span class="number">20</span>), np.random.choice((j), <span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 2</span></span><br><span class="line">np.random.seed(<span class="number">100</span>)</span><br><span class="line">iris_2d[np.random.randint(<span class="number">150</span>, size=<span class="number">20</span>), np.random.randint(<span class="number">4</span>, size=<span class="number">20</span>)] = np.nan</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print first 10 rows</span></span><br><span class="line"><span class="built_in">print</span>(iris_2d[:<span class="number">10</span>])</span><br><span class="line"><span class="comment"># &gt; [[b&#x27;5.1&#x27; b&#x27;3.5&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.0&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.7&#x27; b&#x27;3.2&#x27; b&#x27;1.3&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.6&#x27; b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.4&#x27; b&#x27;3.9&#x27; b&#x27;1.7&#x27; b&#x27;0.4&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.6&#x27; b&#x27;3.4&#x27; b&#x27;1.4&#x27; b&#x27;0.3&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;5.0&#x27; b&#x27;3.4&#x27; b&#x27;1.5&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.4&#x27; nan b&#x27;1.4&#x27; b&#x27;0.2&#x27; b&#x27;Iris-setosa&#x27;]</span></span><br><span class="line"><span class="comment"># &gt;  [b&#x27;4.9&#x27; b&#x27;3.1&#x27; b&#x27;1.5&#x27; b&#x27;0.1&#x27; b&#x27;Iris-setosa&#x27;]]</span></span><br></pre></td></tr></table></figure>


<h2 id="随堂练习"><a href="#随堂练习" class="headerlink" title="随堂练习"></a>随堂练习</h2><blockquote class="blockquote-center">
<ol>
<li>生成一个尺寸为[10,20]的随机数数组a，数值在[-10,10)之间均匀随机分布;</li>
<li>在数组a中的20个随机位置插入NaN;</li>
<li>检索数组a中的NaN值，并替换为在[-20,20)之间均匀随机分布的随机数；</li>
<li>将数组a中大于5的值替换为5，小于-5的值替换为-5.</li>
</ol>

</blockquote>

<h2 id="随堂练习答案"><a href="#随堂练习答案" class="headerlink" title="随堂练习答案"></a>随堂练习答案</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.random.uniform(-<span class="number">10</span>,<span class="number">10</span>,(<span class="number">10</span>,<span class="number">20</span>))</span><br><span class="line">a[np.random.choice((i),<span class="number">20</span>),np.random.choice((j),<span class="number">20</span>)] = np.nan</span><br><span class="line">a[np.isnan(a)] = np.random.uniform(-<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">a = np.clip(a,-<span class="number">5</span>,<span class="number">5</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python在科研中的应用 07：Python 环境下的数字图像分析方法</title>
    <url>/PythonLes08/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Python的图像分析方法是一种强大的数据处理技术，它利用多种算法和工具来提取、处理和分析图像数据。通过Python，我们可以方便地调用各种图像处理库，如OpenCV、PIL(Pillow)、SciPy等，进行图像的预处理、特征提取、图像分割、边缘检测等操作。此外，利用Python的机器学习库，如scikit-learn、TensorFlow等，我们还可以对图像进行更高级的分析，如目标检测、图像识别、图像分类等。SciPy是构建在Python的NumPy扩展上的数学算法和便利函数的集合。它通过向用户提供用于操作和可视化数据的高级命令和类，为交互式Python会话添加了强大的功能。有了SciPy，交互式Python会话将成为可与MATLAB、IDL、Octave、R-Lab和SciLab等系统相媲美的数据处理和系统原型环境。</p>
<p>Python的数字图像分析方法章节将持续3-4周的课程，包括数字图像的基础操作，图像降噪，图像分割，边缘检测，目标检测等等。本节课程我们将学习Python在数字图像分析领域的一些基础方法。</p>
<span id="more"></span>

<h2 id="Pillow-与-PIL-库"><a href="#Pillow-与-PIL-库" class="headerlink" title="Pillow 与 PIL 库"></a>Pillow 与 PIL 库</h2><p>PIL (Python Imaging Library) 是Python平台上图像处理的标准库，功能丰富，API简单易用，不过只支持到Python 2.7。</p>
<p>PIL官方网站：<a href="http://www.pythonware.com/products/pil/">http://www.pythonware.com/products/pil/</a></p>
<p>Pillow是PIL的一个派生分支，但如今已经发展成为比PIL本身更具活力的图像处理库。</p>
<p>Pillow的Github主页：<a href="https://github.com/python-pillow/Pillow">https://github.com/python-pillow/Pillow</a><br>Pillow的文档(对应版本v3.0.0)：<a href="https://pillow.readthedocs.org/en/latest/handbook/index.html">https://pillow.readthedocs.org/en/latest/handbook/index.html</a></p>
<p>给Python安装Pillow非常简单，使用pip或easy_install只要一行代码即可。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">在命令行使用PIP安装：</span></span><br><span class="line">pip install Pillow</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">或在命令行使用easy_install安装：</span></span><br><span class="line">easy_install Pillow</span><br></pre></td></tr></table></figure>

<p>安装完成后，使用from PIL import Image就引用使用库了。如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>)</span><br><span class="line">im.rotate(<span class="number">45</span>).show()</span><br></pre></td></tr></table></figure>

<h2 id="使用-Image-类"><a href="#使用-Image-类" class="headerlink" title="使用 Image 类"></a>使用 Image 类</h2><p>PIL最重要的类是 <code>Image</code> class, 你可以通过多种方法创建这个类的实例；你可以从文件加载图像，或者处理其他图像, 或者从 scratch 创建。</p>
<p>要从文件加载图像，使用 <code>open()</code> 函数， 在 <code>Image</code> 模块:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>加载成功将返回一个 <code>Image</code> 对象。 你现在可以使用示例属性检查文件内容:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="built_in">print</span>(im.<span class="built_in">format</span>, im.size, im.mode)</span><br><span class="line"><span class="comment"># PNG (512, 512) RGB</span></span><br></pre></td></tr></table></figure>

<p><code>format</code> 这个属性标识了图像来源。如果图像不是从文件读取它的值就是None。<code>size</code>属性是一个二元tuple，包含width和height（宽度和高度，单位都是px）。 <code>mode</code> 属性定义了图像通道的数量和名称，以及像素类型和深度。常见的modes 有 “L” (luminance) 表示灰度图像, “RGB” 表示真彩色图像, 以及 “CMYK” 表示出版图像。</p>
<p>如果文件打开错误，返回 <code>IOError</code> 错误。</p>
<p>只要你有了 <code>Image</code> 类的实例，你就可以通过类的方法处理图像。比如，下列方法可以显示图像:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im.show()</span><br></pre></td></tr></table></figure>

<p>标准的 <code>im.show()</code> 效率并不高，它需要保存图像到临时文件然后通过 xv 显示图像。你需要先安装 xv ，显示图像有助于调试和测试。</p>
<h2 id="读写图像"><a href="#读写图像" class="headerlink" title="读写图像"></a>读写图像</h2><p>PIL 模块支持大量图片格式。使用在 <code>Image</code> 模块的 <code>open()</code> 函数从磁盘读取文件。你不需要知道文件格式就能打开它，这个库能够根据文件内容自动确定文件格式。</p>
<h3 id="从文件读取"><a href="#从文件读取" class="headerlink" title="从文件读取"></a>从文件读取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fp = <span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">im = Image.<span class="built_in">open</span>(fp)</span><br></pre></td></tr></table></figure>

<h3 id="从指定路径读取"><a href="#从指定路径读取" class="headerlink" title="从指定路径读取"></a>从指定路径读取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(os.path.join(os.getcwd(),<span class="string">&quot;im.png&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>要保存文件，使用 <code>Image</code> 类的 <code>save()</code> 方法。保存文件的时候文件名变得重要了。除非你指定格式，否则这个库将会以文件名的扩展名作为格式保存。</p>
<h3 id="转换文件格式到JPEG"><a href="#转换文件格式到JPEG" class="headerlink" title="转换文件格式到JPEG"></a>转换文件格式到JPEG</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    f, e = os.path.splitext(infile)</span><br><span class="line">    outfile = f + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            Image.<span class="built_in">open</span>(infile).convert(<span class="string">&#x27;RGB&#x27;</span>).save(outfile)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cannot convert&quot;</span>, infile)</span><br></pre></td></tr></table></figure>

<p><code>argv</code>是sys模块的一个全局变量，也称sys模块的一个属性！<code>argv</code>本身为一个list类型的对象，该对象持有的第1个元素是命令行中传入的模块名、从第2个元素开始（含），均为命令行中传入的参数！</p>
<p>注意：argv持有的每个元素的类型均为str（字符串）</p>
<p><code>save()</code> 方法的第二个参数可以指定文件格式，如果你使用非标准的扩展名你必须这样做：</p>
<h3 id="创建-JPEG-缩略图"><a href="#创建-JPEG-缩略图" class="headerlink" title="创建 JPEG 缩略图"></a>创建 JPEG 缩略图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">size = (<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    outfile = os.path.splitext(infile)[<span class="number">0</span>] + <span class="string">&quot;.jpg&quot;</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            im = Image.<span class="built_in">open</span>(infile)</span><br><span class="line">            im.thumbnail(size)</span><br><span class="line">            im.convert(<span class="string">&quot;RGB&quot;</span>).save(outfile, <span class="string">&quot;JPEG&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;cannot create thumbnail for&quot;</span>, infile)</span><br></pre></td></tr></table></figure>

<p>很重要的一点是这个库不会直接解码或者加载图像栅格数据。当你打开一个文件，只会读取文件头信息用来确定格式，颜色模式，大小等等，文件的剩余部分不会主动处理。这意味着打开一个图像文件的操作十分快速，跟图片大小和压缩方式无关。下面是一个简单的脚本用来快速验证大量图片。</p>
<h3 id="验证图像文件"><a href="#验证图像文件" class="headerlink" title="验证图像文件"></a>验证图像文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(infile) <span class="keyword">as</span> im:</span><br><span class="line">            <span class="built_in">print</span>(infile, im.<span class="built_in">format</span>, <span class="string">&quot;%dx%d&quot;</span> % im.size, im.mode)</span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h2 id="图像剪切，粘贴，合并，几何变换等"><a href="#图像剪切，粘贴，合并，几何变换等" class="headerlink" title="图像剪切，粘贴，合并，几何变换等"></a>图像剪切，粘贴，合并，几何变换等</h2><p><code>Image</code> 类包含的方法允许你操作图像部分选区。使用:py:meth:~PIL.Image.Image.crop 方法获取图像的一个子矩形选区。</p>
<h3 id="从图像中复制出一个矩形选区"><a href="#从图像中复制出一个矩形选区" class="headerlink" title="从图像中复制出一个矩形选区"></a>从图像中复制出一个矩形选区</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">box = (<span class="number">100</span>, <span class="number">100</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">region = im.crop(box)</span><br></pre></td></tr></table></figure>

<p>矩形选区有一个4元元组定义，分别表示左、上、右、下的坐标。这个库以左上角为坐标原点，单位是px，所以上诉代码复制了一个 300x300 pixels 的矩形选区。这个选区现在可以被处理并且粘贴到原图。</p>
<h3 id="处理复制的矩形选区并粘贴到原图"><a href="#处理复制的矩形选区并粘贴到原图" class="headerlink" title="处理复制的矩形选区并粘贴到原图"></a>处理复制的矩形选区并粘贴到原图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">region = region.transpose(Image.ROTATE_180)</span><br><span class="line">im.paste(region, box)</span><br></pre></td></tr></table></figure>

<p>当你粘贴矩形选区的时候必须保证尺寸一致。此外，矩形选区不能在图像外。然而你不必保证矩形选区和原图的颜色模式一致，因为矩形选区会被自动转换颜色（参看下面的 颜色变换 部分），下面是一个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Rolling an image</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">roll</span>(<span class="params">image, delta</span>):</span><br><span class="line">    <span class="string">&quot;Roll an image sideways&quot;</span></span><br><span class="line"></span><br><span class="line">    xsize, ysize = image.size</span><br><span class="line"></span><br><span class="line">    delta = delta % xsize</span><br><span class="line">    <span class="keyword">if</span> delta == <span class="number">0</span>: <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">    part1 = image.crop((<span class="number">0</span>, <span class="number">0</span>, delta, ysize))</span><br><span class="line">    part2 = image.crop((delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line">    image.paste(part2, (<span class="number">0</span>, <span class="number">0</span>, xsize-delta, ysize))</span><br><span class="line">    image.paste(part1, (xsize-delta, <span class="number">0</span>, xsize, ysize))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>

<h3 id="分离和合并颜色通道"><a href="#分离和合并颜色通道" class="headerlink" title="分离和合并颜色通道"></a>分离和合并颜色通道</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">r, g, b = im.split()</span><br><span class="line">im = Image.merge(<span class="string">&quot;RGB&quot;</span>, (b, g, r))</span><br></pre></td></tr></table></figure>

<p>注意，对于单通道图像，<code>split()</code>返回图像本身。</p>
<h3 id="几何变换"><a href="#几何变换" class="headerlink" title="几何变换"></a>几何变换</h3><p><code>PIL.Image.Image</code>类包含了<code>resize()</code>和<code>rotate()</code>方法。前者接受一个元组，给出新的大小，后者接受以逆时针为单位的角度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = im.resize((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">out = im.rotate(<span class="number">45</span>) <span class="comment"># degrees counter-clockwise</span></span><br><span class="line">im1 = im1.rotate(<span class="number">90</span>, PIL.Image.NEAREST, expand = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>要以90度的步骤旋转图像，您可以使用<code>rotate()</code>方法或<code>transpose()</code>方法。后者也可用于围绕其水平或垂直轴翻转图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = im.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">out = im.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">out = im.transpose(Image.ROTATE_90)</span><br><span class="line">out = im.transpose(Image.ROTATE_180)</span><br><span class="line">out = im.transpose(Image.ROTATE_270)</span><br></pre></td></tr></table></figure>

<p><code>transpose()</code>方法和相应的<code>rotate()</code>方法在性能和结果上没有区别。</p>
<h3 id="颜色变换"><a href="#颜色变换" class="headerlink" title="颜色变换"></a>颜色变换</h3><p>Python成像库允许您使用<code>convert()</code>方法在不同色彩表示之间转换图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;im.png&quot;</span>).convert(<span class="string">&quot;L&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>该库支持每种受支持的模式与“L”和“RGB”模式之间的转换。要在其他模式之间进行转换，可能必须使用中间图像(通常是“RGB”图像)。</p>
<h3 id="随堂练习"><a href="#随堂练习" class="headerlink" title="随堂练习"></a>随堂练习</h3><blockquote class="blockquote-center">
<p>构建一张PNG格式图像，读取该图片，左右翻转后，侧向平移50个像素，沿顺时针方向旋转70度后保留完整的画幅尺寸，输出为JPEG格式。</p>

</blockquote>


<h2 id="如何将PIL图像转换为NumPy数组？"><a href="#如何将PIL图像转换为NumPy数组？" class="headerlink" title="如何将PIL图像转换为NumPy数组？"></a>如何将PIL图像转换为NumPy数组？</h2><p>从以下URL导入图像并将其转换为numpy数组。<br>URL &#x3D; ‘<a href="https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg">https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg</a>‘</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> PIL, requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import image from URL</span></span><br><span class="line">URL = <span class="string">&#x27;https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg&#x27;</span></span><br><span class="line">response = requests.get(URL)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read it as Image</span></span><br><span class="line">I = Image.<span class="built_in">open</span>(BytesIO(response.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionally resize</span></span><br><span class="line">I = I.resize([<span class="number">150</span>,<span class="number">150</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert to numpy array</span></span><br><span class="line">arr = np.asarray(I)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optionaly Convert it back to an image and show</span></span><br><span class="line">im = PIL.Image.fromarray(np.uint8(arr))</span><br></pre></td></tr></table></figure>




<h2 id="插值-scipy-interpolate"><a href="#插值-scipy-interpolate" class="headerlink" title="插值 (scipy.interpolate)"></a>插值 (scipy.interpolate)</h2><h3 id="一维插值-interp1d"><a href="#一维插值-interp1d" class="headerlink" title="一维插值 (interp1d)"></a>一维插值 (interp1d)</h3><p>这个 <code>interp1d</code> 中的类 <code>scipy.interpolate</code> 是一种基于固定数据点创建函数的便捷方法，可以使用线性插值在给定数据定义的域内的任何位置计算该函数。通过传递组成数据的一维向量来创建此类的实例。此类的实例定义了一个 <code>__call__</code> 方法，因此可以将其视为在已知数据值之间进行插值以获得未知值的函数(它还具有用于帮助的文档字符串)。边界处的行为可以在实例化时指定。下面的示例演示了它在线性样条插值和三次样条插值中的用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f = interp1d(x, y)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">41</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>, xnew, f(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;cubic&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-1.png" width="75%" alt="" align=center />



<p>插值 <code>interp1d</code> 的方法常见的可以有nearest, previous以及next，其中它们返回沿x轴最近的点、上一个点或下一个点。最近的和次要的可以被认为是因果插值过滤的特例。下面的示例使用与上一个示例中相同的数据演示它们的用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f1 = interp1d(x, y, kind=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;previous&#x27;</span>)</span><br><span class="line">f3 = interp1d(x, y, kind=<span class="string">&#x27;next&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">1001</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(xnew, f1(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>, xnew, f3(xnew), <span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;nearest&#x27;</span>, <span class="string">&#x27;previous&#x27;</span>, <span class="string">&#x27;next&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-2.png" width="80%" alt="" align=center />

<h3 id="多变量数据插值-griddata"><a href="#多变量数据插值-griddata" class="headerlink" title="多变量数据插值 (griddata)"></a>多变量数据插值 (griddata)</h3><p>例如，假设您具有基础函数的多维数据 $F(x,y)$，你只知道若干个点上的值 $[(x[i],y[i])]$，它们不会形成规则的网格。</p>
<p>假设我们要对二维函数 $F(x,y)$ 进行插值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x*(<span class="number">1</span>-x)*np.cos(<span class="number">4</span>*np.pi*x) * np.sin(<span class="number">4</span>*np.pi*y**<span class="number">2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">grid_x, grid_y = np.mgrid[<span class="number">0</span>:<span class="number">1</span>:<span class="number">100j</span>, <span class="number">0</span>:<span class="number">1</span>:<span class="number">200j</span>]</span><br></pre></td></tr></table></figure>

<p>但我们只知道它在1000个数据点的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.random.random((<span class="number">1000</span>, <span class="number">2</span>))</span><br><span class="line">values = func(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>这可以通过以下方式完成 <code>griddata</code> –下面我们将尝试所有的插值方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> griddata</span><br><span class="line"></span><br><span class="line">grid_z0 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">grid_z1 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">grid_z2 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;cubic&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到，所有方法都在一定程度上重现了准确的结果，但对于此光滑函数，三次样条插值提供了最好的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.imshow(func(grid_x, grid_y).T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>,cmap = <span class="string">&#x27;hsv&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;k.&#x27;</span>, ms=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.imshow(grid_z0.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Nearest&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.imshow(grid_z1.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Linear&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.imshow(grid_z2.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic&#x27;</span>)</span><br><span class="line">plt.gcf().set_size_inches(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-3.png" width="80%" alt="" align=center />

<h3 id="样条插值"><a href="#样条插值" class="headerlink" title="样条插值"></a>样条插值</h3><h4 id="一维中的样条插值：程序化"><a href="#一维中的样条插值：程序化" class="headerlink" title="一维中的样条插值：程序化"></a>一维中的样条插值：程序化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三次样条</span></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">2</span>*np.pi+np.pi/<span class="number">4</span>, np.pi/<span class="number">4</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 求一条一维曲线的b-spline样条表示。给定一组数据点(x[i],y[i])，在有限区间上确定光滑样条近似。</span></span><br><span class="line"><span class="comment"># 详细信息请参照：https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splrep.html</span></span><br><span class="line"></span><br><span class="line">xnew = np.arange(<span class="number">0</span>, <span class="number">2</span>*np.pi, np.pi/<span class="number">50</span>)</span><br><span class="line">ynew = interpolate.splev(xnew, tck, der=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 求b-spline样条曲线或它的导数。给定b样条表示的结点和系数，计算平滑多项式及其导数的值。这是对FITPACK的FORTRAN例程splev和splder的包装。</span></span><br><span class="line"><span class="comment"># der 要计算的样条导数的阶数(必须小于或等于k，即样条的阶数)。</span></span><br><span class="line"><span class="comment"># 详细信息请参照：https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splev.html</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;x&#x27;</span>, xnew, ynew, xnew, np.sin(xnew), x, y, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Linear&#x27;</span>, <span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic-spline interpolation&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_00_00.png" width="80%" alt="" align=center />


<h4 id="样条的导数"><a href="#样条的导数" class="headerlink" title="样条的导数"></a>样条的导数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yder = interpolate.splev(xnew, tck, der=<span class="number">1</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(xnew, yder, xnew, np.cos(xnew),<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Derivative estimation from spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_01_00.png" width="80%" alt="" align=center />



<h4 id="样条的所有导数"><a href="#样条的所有导数" class="headerlink" title="样条的所有导数"></a>样条的所有导数</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">yders = interpolate.spalde(xnew, tck)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(yders[<span class="number">0</span>])):</span><br><span class="line">   plt.plot(xnew, [d[i] <span class="keyword">for</span> d <span class="keyword">in</span> yders], <span class="string">&#x27;--&#x27;</span>, label=<span class="string">f&quot;<span class="subst">&#123;i&#125;</span> derivative&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;All derivatives of a B-spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_02_00.png" width="80%" alt="" align=center />

<h4 id="样条的积分"><a href="#样条的积分" class="headerlink" title="样条的积分"></a>样条的积分</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">integ</span>(<span class="params">x, tck, constant=-<span class="number">1</span></span>):</span><br><span class="line">    x = np.atleast_1d(x)</span><br><span class="line">    out = np.zeros(x.shape, dtype=x.dtype)</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(out)):</span><br><span class="line">        out[n] = interpolate.splint(<span class="number">0</span>, x[n], tck)</span><br><span class="line">    out += constant</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line">yint = integ(xnew, tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(xnew, yint, xnew, -np.cos(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">0.05</span>, <span class="number">6.33</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Integral estimation from spline&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_03_00.png" width="80%" alt="" align=center />

<p>样条的根</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">interpolate.sproot(tck)</span><br><span class="line">array([<span class="number">3.1416</span>])</span><br></pre></td></tr></table></figure>

<p>请注意， <code>sproot</code> 在近似区间的边缘找不到明显的解。如果我们在稍微大一点的间隔上定义样条，我们可以恢复两个根：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(-np.pi/<span class="number">4</span>, <span class="number">2.</span>*np.pi + np.pi/<span class="number">4</span>, <span class="number">21</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line">interpolate.sproot(tck)</span><br><span class="line">array([<span class="number">0.</span>, <span class="number">3.1416</span>])</span><br></pre></td></tr></table></figure>

<p>参数样条</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">.1</span>)</span><br><span class="line">x = np.sin(<span class="number">2</span>*np.pi*t)</span><br><span class="line">y = np.cos(<span class="number">2</span>*np.pi*t)</span><br><span class="line">tck, u = interpolate.splprep([x, y], s=<span class="number">0</span>)</span><br><span class="line">unew = np.arange(<span class="number">0</span>, <span class="number">1.01</span>, <span class="number">0.01</span>)</span><br><span class="line">out = interpolate.splev(unew, tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;x&#x27;</span>, out[<span class="number">0</span>], out[<span class="number">1</span>], np.sin(<span class="number">2</span>*np.pi*unew), np.cos(<span class="number">2</span>*np.pi*unew), x, y, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;Linear&#x27;</span>, <span class="string">&#x27;Cubic Spline&#x27;</span>, <span class="string">&#x27;True&#x27;</span>])</span><br><span class="line">plt.axis([-<span class="number">1.05</span>, <span class="number">1.05</span>, -<span class="number">1.05</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.title(<span class="string">&#x27;Spline of parametrically-defined curve&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-4_04_00.png" width="80%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在稀疏的20x20网格上定义函数</span></span><br><span class="line">x_edges, y_edges = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">21j</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">21j</span>]</span><br><span class="line">x = x_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(x_edges[:<span class="number">2</span>, <span class="number">0</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">y = y_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(y_edges[<span class="number">0</span>, :<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">z = (x+y) * np.exp(-<span class="number">6.0</span>*(x*x+y*y))</span><br><span class="line">plt.figure()</span><br><span class="line">lims = <span class="built_in">dict</span>(cmap=<span class="string">&#x27;RdBu_r&#x27;</span>, vmin=-<span class="number">0.25</span>, vmax=<span class="number">0.25</span>)</span><br><span class="line">plt.pcolormesh(x_edges, y_edges, z, shading=<span class="string">&#x27;flat&#x27;</span>, **lims)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.title(<span class="string">&quot;Sparsely sampled function.&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-6_00_00.png" width="80%" alt="" align=center />


<p>新的70x70网格上的插值函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xnew_edges, ynew_edges = np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">71j</span>, -<span class="number">1</span>:<span class="number">1</span>:<span class="number">71j</span>]</span><br><span class="line">xnew = xnew_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(xnew_edges[:<span class="number">2</span>, <span class="number">0</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">ynew = ynew_edges[:-<span class="number">1</span>, :-<span class="number">1</span>] + np.diff(ynew_edges[<span class="number">0</span>, :<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">tck = interpolate.bisplrep(x, y, z, s=<span class="number">0</span>)</span><br><span class="line">znew = interpolate.bisplev(xnew[:,<span class="number">0</span>], ynew[<span class="number">0</span>,:], tck)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.pcolormesh(xnew_edges, ynew_edges, znew, shading=<span class="string">&#x27;flat&#x27;</span>, **lims)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.title(<span class="string">&quot;Interpolated function.&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-6_01_00.png" width="80%" alt="" align=center />


<h3 id="随堂练习-1"><a href="#随堂练习-1" class="headerlink" title="随堂练习"></a>随堂练习</h3><blockquote class="blockquote-center">
<p>定义一个三次二元函数，在[-10,10] x [-10,10]定义域范围内随机生成1000个点，并计算函数值。通过插值方法获取每[0.01 x 0.01]间隔的网格点处的函数值。</p>

</blockquote>


<h2 id="空间数据结构和算法-scipy-spatial"><a href="#空间数据结构和算法-scipy-spatial" class="headerlink" title="空间数据结构和算法 (scipy.spatial)"></a>空间数据结构和算法 (scipy.spatial)</h2><p>SciPy通过利用Qhull类库，spatial可以计算三角剖分、Voronoi图和凸包等等。此外，它还包含 KDTree 最近邻点查询的实现，以及各种度量中距离计算的实用程序。</p>
<h3 id="Delaunay三角测量"><a href="#Delaunay三角测量" class="headerlink" title="Delaunay三角测量"></a>Delaunay三角测量</h3><p>Delaunay三角剖分是将一组点细分为一组不重叠的三角形，这样任何三角形的外接圆内都没有点。在实践中，这样的三角剖分往往会避免带有小角度的三角形。</p>
<p>可以使用以下方法计算Delaunay三角剖分 scipy.spatial 具体如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> Delaunay</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1.1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">tri = Delaunay(points)</span><br></pre></td></tr></table></figure>

<p>我们可以把它形象化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.triplot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], tri.simplices)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(points):</span><br><span class="line">    plt.text(p[<span class="number">0</span>]-<span class="number">0.03</span>, p[<span class="number">1</span>]+<span class="number">0.03</span>, j, ha=<span class="string">&#x27;right&#x27;</span>) <span class="comment"># label the points</span></span><br><span class="line"><span class="keyword">for</span> j, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(tri.simplices):</span><br><span class="line">    p = points[s].mean(axis=<span class="number">0</span>)</span><br><span class="line">    plt.text(p[<span class="number">0</span>], p[<span class="number">1</span>], <span class="string">&#x27;#%d&#x27;</span> % j, ha=<span class="string">&#x27;center&#x27;</span>) <span class="comment"># label triangles</span></span><br><span class="line">plt.xlim(-<span class="number">0.5</span>, <span class="number">1.5</span>); plt.ylim(-<span class="number">0.5</span>, <span class="number">1.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-1.png" width="60%" alt="" align=center />


<p>三角剖分的结构按以下方式编码： simplices 属性包含 points 组成三角形的数组。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line">tri.simplices[i,:]</span><br><span class="line"><span class="comment"># array([3, 1, 0], dtype=int32)</span></span><br><span class="line"></span><br><span class="line">points[tri.simplices[i,:]]</span><br><span class="line"><span class="comment"># array([[ 1. ,  1. ],</span></span><br><span class="line"><span class="comment">#        [ 0. ,  1.1],</span></span><br><span class="line"><span class="comment">#        [ 0. ,  0. ]])</span></span><br></pre></td></tr></table></figure>

<p>此外，还可以找到相邻三角形：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tri.neighbors[i]</span><br><span class="line"># array([-1,  0, -1], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这告诉我们这个三角形有#0号三角形作为邻居，但没有其他邻居。此外，它还告诉我们邻居0与三角形的顶点1相对：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points[tri.simplices[i, <span class="number">1</span>]]</span><br><span class="line"><span class="comment"># array([ 0. ,  1.1])</span></span><br></pre></td></tr></table></figure>

<p>事实上，从数字上，我们可以看到情况是这样的。</p>
<p>Qhull还可以对高维点集执行细分以简化(例如，在3-D中细分为四面体)。</p>
<p>共面点</p>
<p>重要的是要注意到，不是 all 由于形成三角剖分的数值精度问题，点必然显示为三角剖分的顶点。请考虑具有重复点的上述内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">tri = Delaunay(points)</span><br><span class="line">np.unique(tri.simplices.ravel())</span><br><span class="line">array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>请注意，重复的点#4不会作为三角剖分的顶点出现。这件事已被记录在案：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tri.coplanar</span><br><span class="line">array([[<span class="number">4</span>, <span class="number">0</span>, <span class="number">3</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这意味着点4位于三角形0和顶点3附近，但不包括在三角剖分中。</p>
<p>请注意，这种退化不仅可能是因为重复的点，也可能是由于更复杂的几何原因，即使在乍看起来表现良好的点集中也是如此。</p>
<p>但是，Qhull具有“qj”选项，该选项指示它随机扰乱输入数据，直到解决退化问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tri = Delaunay(points, qhull_options=<span class="string">&quot;QJ Pp&quot;</span>)</span><br><span class="line">points[tri.simplices]</span><br><span class="line">array([[[<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>]]])</span><br></pre></td></tr></table></figure>

<p>出现了两个新的三角形。然而，我们看到它们是退化的，面积为零。</p>
<h3 id="凸包"><a href="#凸包" class="headerlink" title="凸包"></a>凸包</h3><p>凸包是包含给定点集中所有点的最小凸对象。</p>
<p>这些值可以通过中的qhull包装器进行计算。 scipy.spatial 具体如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> ConvexHull</span><br><span class="line">rng = np.random.default_rng()</span><br><span class="line">points = rng.random((<span class="number">30</span>, <span class="number">2</span>))   <span class="comment"># 30 random points in 2-D</span></span><br><span class="line">hull = ConvexHull(points)</span><br></pre></td></tr></table></figure>

<p>凸包被表示为一组N个1-D简化，在2-D中表示线段。存储方案与上面讨论的Delaunay三角剖分中的简化完全相同。</p>
<p>我们可以举例说明上述结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> simplex <span class="keyword">in</span> hull.simplices:</span><br><span class="line">    plt.plot(points[simplex,<span class="number">0</span>], points[simplex,<span class="number">1</span>], <span class="string">&#x27;k-&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-2.png" width="60%" alt="" align=center />

<p>同样的情况也可以通过以下方式实现 <code>scipy.spatial.convex_hull_plot_2d</code>。</p>
<h3 id="Voronoi图"><a href="#Voronoi图" class="headerlink" title="Voronoi图"></a>Voronoi图</h3><p>Voronoi图是将空间细分为一组给定点的最近邻域。</p>
<p>使用以下两种方法可以接近此对象scipy.spatial 。首先，可以使用 KDTree 要回答“哪个点最接近这个点”的问题，并这样定义区域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> KDTree</span><br><span class="line">points = np.array([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                   [<span class="number">2</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">tree = KDTree(points)</span><br><span class="line">tree.query([<span class="number">0.1</span>, <span class="number">0.1</span>])</span><br><span class="line">(<span class="number">0.14142135623730953</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>所以重点是 (0.1, 0.1) 属于区域 0 。在颜色方面：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(-<span class="number">0.5</span>, <span class="number">2.5</span>, <span class="number">31</span>)</span><br><span class="line">y = np.linspace(-<span class="number">0.5</span>, <span class="number">2.5</span>, <span class="number">33</span>)</span><br><span class="line">xx, yy = np.meshgrid(x, y)</span><br><span class="line">xy = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">dx_half, dy_half = np.diff(x[:<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span>, np.diff(y[:<span class="number">2</span>])[<span class="number">0</span>] / <span class="number">2.</span></span><br><span class="line">x_edges = np.concatenate((x - dx_half, [x[-<span class="number">1</span>] + dx_half]))</span><br><span class="line">y_edges = np.concatenate((y - dy_half, [y[-<span class="number">1</span>] + dy_half]))</span><br><span class="line">plt.pcolormesh(x_edges, y_edges, tree.query(xy)[<span class="number">1</span>].reshape(<span class="number">33</span>, <span class="number">31</span>), shading=<span class="string">&#x27;flat&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;ko&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-3_00_00.png" width="60%" alt="" align=center />

<p>然而，这并没有给出作为几何对象的Voronoi图。</p>
<p>线和点的表示可以通过中的qhull包装器再次获得 scipy.spatial：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> Voronoi</span><br><span class="line">vor = Voronoi(points)</span><br><span class="line">vor.vertices</span><br><span class="line">array([[<span class="number">0.5</span>, <span class="number">0.5</span>],</span><br><span class="line">       [<span class="number">0.5</span>, <span class="number">1.5</span>],</span><br><span class="line">       [<span class="number">1.5</span>, <span class="number">0.5</span>],</span><br><span class="line">       [<span class="number">1.5</span>, <span class="number">1.5</span>]])</span><br></pre></td></tr></table></figure>

<p>Voronoi顶点表示形成Voronoi区域的多边形边的点集。在本例中，有9个不同的区域：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.regions</span><br><span class="line">[[], [-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">0</span>], [<span class="number">3</span>, -<span class="number">1</span>, <span class="number">2</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>], [<span class="number">2</span>, -<span class="number">1</span>, <span class="number">0</span>], [<span class="number">3</span>, -<span class="number">1</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>

<p>负值 -1 再次表示无穷远处的一个点。事实上，只有一个地区， [0, 1, 3, 2]，是有界的。请注意，由于与上面的Delaunay三角剖分中类似的数值精度问题，Voronoi区域可能比输入点少。</p>
<p>将分隔区域的脊（二维中的线）描述为与凸面壳片类似的简化集合：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.ridge_vertices</span><br><span class="line">[[-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">1</span>], [-<span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">3</span>], [-<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">0</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure>

<p>这些数字表示组成线段的Voronoi顶点的索引。 -1 又是一个无穷远的点-12条直线中只有4条是有界线段，而其他的延伸到无穷远。</p>
<p>Voronoi山脊垂直于输入点之间绘制的线。还记录了每个脊对应的两个点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vor.ridge_points</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">4</span>],</span><br><span class="line">       [<span class="number">8</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">       [<span class="number">4</span>, <span class="number">3</span>]], dtype=int32)</span><br></pre></td></tr></table></figure>

<p>这些信息加在一起，足以构成完整的图表。</p>
<p>我们可以把它画成如下图。首先，点和Voronoi顶点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.plot(points[:, <span class="number">0</span>], points[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(vor.vertices[:, <span class="number">0</span>], vor.vertices[:, <span class="number">1</span>], <span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">plt.xlim(-<span class="number">1</span>, <span class="number">3</span>); plt.ylim(-<span class="number">1</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>绘制有限线段与绘制凸壳一样，但现在我们必须注意无限边：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> simplex <span class="keyword">in</span> vor.ridge_vertices:</span><br><span class="line">    simplex = np.asarray(simplex)</span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">all</span>(simplex &gt;= <span class="number">0</span>):</span><br><span class="line">        plt.plot(vor.vertices[simplex, <span class="number">0</span>], vor.vertices[simplex, <span class="number">1</span>], <span class="string">&#x27;k-&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>延伸到无穷远的山脊需要稍微小心一点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">center = points.mean(axis=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> pointidx, simplex <span class="keyword">in</span> <span class="built_in">zip</span>(vor.ridge_points, vor.ridge_vertices):</span><br><span class="line">    simplex = np.asarray(simplex)</span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">any</span>(simplex &lt; <span class="number">0</span>):</span><br><span class="line">        i = simplex[simplex &gt;= <span class="number">0</span>][<span class="number">0</span>] <span class="comment"># finite end Voronoi vertex</span></span><br><span class="line">        t = points[pointidx[<span class="number">1</span>]] - points[pointidx[<span class="number">0</span>]]  <span class="comment"># tangent</span></span><br><span class="line">        t = t / np.linalg.norm(t)</span><br><span class="line">        n = np.array([-t[<span class="number">1</span>], t[<span class="number">0</span>]]) <span class="comment"># normal</span></span><br><span class="line">        midpoint = points[pointidx].mean(axis=<span class="number">0</span>)</span><br><span class="line">        far_point = vor.vertices[i] + np.sign(np.dot(midpoint - center, n)) * n * <span class="number">100</span></span><br><span class="line">        plt.plot([vor.vertices[i,<span class="number">0</span>], far_point[<span class="number">0</span>]],</span><br><span class="line">                 [vor.vertices[i,<span class="number">1</span>], far_point[<span class="number">1</span>]], <span class="string">&#x27;k--&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-3_01_00.png" width="60%" alt="" align=center />

<p>也可以使用以下命令创建此图 <code>scipy.spatial.voronoi_plot_2d</code> 。</p>
<p>Vornoi图可以用来创作有趣的创作艺术。尝试使用此设置 mandala 函数来创建您自己的！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> spatial</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mandala</span>(<span class="params">n_iter, n_points, radius</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates a mandala figure using Voronoi tesselations.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    n_iter : int</span></span><br><span class="line"><span class="string">        Number of iterations, i.e. how many times the equidistant points will</span></span><br><span class="line"><span class="string">        be generated.</span></span><br><span class="line"><span class="string">    n_points : int</span></span><br><span class="line"><span class="string">        Number of points to draw per iteration.</span></span><br><span class="line"><span class="string">    radius : scalar</span></span><br><span class="line"><span class="string">        The radial expansion factor.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    fig : matplotlib.Figure instance</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Notes</span></span><br><span class="line"><span class="string">    -----</span></span><br><span class="line"><span class="string">    This code is adapted from the work of Audrey Roy Greenfeld [1]_ and Carlos</span></span><br><span class="line"><span class="string">    Focil-Espinosa [2]_, who created beautiful mandalas with Python code.  That</span></span><br><span class="line"><span class="string">    code in turn was based on Antonio Sánchez Chinchón&#x27;s R code [3]_.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    References</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    .. [1] https://www.codemakesmehappy.com/2019/09/voronoi-mandalas.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. [2] https://github.com/CarlosFocil/mandalapy</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    .. [3] https://github.com/aschinchon/mandalas</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    ax.set_axis_off()</span><br><span class="line">    ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>, adjustable=<span class="string">&#x27;box&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    angles = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi * (<span class="number">1</span> - <span class="number">1</span>/n_points), num=n_points) + np.pi/<span class="number">2</span></span><br><span class="line">    <span class="comment"># Starting from a single center point, add points iteratively</span></span><br><span class="line">    xy = np.array([[<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_iter):</span><br><span class="line">        t1 = np.array([])</span><br><span class="line">        t2 = np.array([])</span><br><span class="line">        <span class="comment"># Add `n_points` new points around each existing point in this iteration</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(xy.shape[<span class="number">0</span>]):</span><br><span class="line">            t1 = np.append(t1, xy[i, <span class="number">0</span>] + radius**k * np.cos(angles))</span><br><span class="line">            t2 = np.append(t2, xy[i, <span class="number">1</span>] + radius**k * np.sin(angles))</span><br><span class="line"></span><br><span class="line">        xy = np.column_stack((t1, t2))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the Mandala figure via a Voronoi plot</span></span><br><span class="line">    spatial.voronoi_plot_2d(spatial.Voronoi(xy), ax=ax)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"><span class="comment"># Modify the following parameters in order to get different figures</span></span><br><span class="line">n_iter = <span class="number">3</span></span><br><span class="line">n_points = <span class="number">6</span></span><br><span class="line">radius = <span class="number">4</span></span><br><span class="line">fig = mandala(n_iter, n_points, radius)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/spatial-4.png" width="60%" alt="" align=center />]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>NumPy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 08：Python 环境下的数字图像降噪</title>
    <url>/PythonLes09/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>Antoni Buades 提出指标 method noise 对数字图像降噪方法的性能进行了评价和比较。他首先针对几个被广泛使用的降噪算法计算并分析了降噪性能。同时，基于图像中所有像素的非局部平均，提出了全新的数字图像降噪算法 Non Local means Algorithm，并通过实验比较了新算法与常用的平滑滤波方法的性能。</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h2 id="课程作业-01，占总成绩30"><a href="#课程作业-01，占总成绩30" class="headerlink" title="课程作业 01，占总成绩30%"></a>课程作业 01，占总成绩30%</h2><blockquote class="blockquote-center">
<p>在二维平面中构建随机 Vornoi 结构，将交界处壁厚设置为随机数，生成Vornoi结构图像。要求：三维平面的像素画幅、Vornoi的初始种子的数密度、交界处壁厚的随机分布范围可设置，作为输入参数集放置在程序的最开始。输出：二维结构图像，并输出各个交界节点、棱边的结构信息至.txt文件。 </p>

</blockquote>

<h3 id="数字图像噪声"><a href="#数字图像噪声" class="headerlink" title="数字图像噪声"></a>数字图像噪声</h3><p>&emsp;&emsp;数字图像的两个主要限制是模糊及噪声（blur &amp; noise）。模糊是图像采集系统的固有性质，同时数字图像对连续信号离散采样的形式必须遵循 Shannon-Nyquist 采样定律。另一种主要的干扰形式是噪声。数字图像中每个像素点的值 $u(i)$ 都是对局部光强测量的结果，通常通过 CCD 及光学聚焦元件实现。CCD 中每个方形探测单元（captor）都将记录曝光时间内探测区域的入射光子数。在光源强度恒定的情况下，每个探测单元每个曝光周期内采集的光子数的概率分布将遵循中心极限定理，在光强均值周围震荡。另外，如果 CCD 没有经过充分冷却就会接收热光子（heat spurious photons），由此产生的扰动通常称为 obscurity noise。</p>
<p>&emsp;&emsp;数字图像降噪方法的目标是从观测到的噪声图像中还原出原始信号，</p>
<p>$$ v(i)&#x3D;u(i)+n(i), \tag{1}\label{1} $$</p>
<p>其中 $v(i)$ 为实测图像，$u(i)$ 为原始信号，$n(i)$ 则是噪声信号。评估图像中噪声水平通常采用信噪比（signal noise ratio, SNR）：</p>
<p>$$ SNR &#x3D; \sigma(u)&#x2F;\sigma(n), \tag{2}\label{2} $$</p>
<p>其中，$\sigma(n)$为噪声信号标准差，$\sigma(u)$表示真实信号的经验标准差，</p>
<p>$$ \sigma(u) &#x3D; \sqrt{\frac{1}{|I|}\sum_i(u(i)- \overline{u} )^2}, \tag{3}\label{3} $$</p>
<p>$$ \overline{u}&#x3D;\frac{1}{|I|}\sum_{i\in I} u(i) \tag{4}\label{4}$$ 为图像的平均灰度值，$|I|$指全图像素数。当噪声模型和参数已知时，噪声的标准差也可以用经验测量法或形式化方法得到。</p>
<p>&emsp;&emsp;迄今为止，图像处理领域已经提出了诸多抑制噪声、还原真实信号的算法。即便它们通常拥有截然不同的数学形式，但都拥有一个共性：平均。这种平均可以在局部进行：高斯滤波器(<a href="https://freddy.cs.technion.ac.il/wp-content/uploads/2018/01/on-gabors-contribution-to-image-enhancement.pdf">Gabor 1994</a>)，各向异性滤波(<a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona-Malik 1990</a>, <a href="https://accedacris.ulpgc.es/bitstream/10553/52821/1/image_selective_smoothing_edge.pdf">Alvarez et al. 1992</a>)，邻域滤波器(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.5808&rep=rep1&type=pdf">Smith et al. 1997</a>)；也可以通过计算variations实现：TV滤波(<a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin-Osher-Fatemi 1992</a>)；或是在频域进行：经验维纳滤波(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>)，小波阈值方法(<a href="https://pdfs.semanticscholar.org/78a5/90a8ac92f02fb48e4e488b6eb00dc7b931eb.pdf">Coiffman-Donoho 1995</a>)。</p>
<h3 id="Method-noise"><a href="#Method-noise" class="headerlink" title="Method noise"></a>Method noise</h3><p>&emsp;&emsp;不妨令 $u$ 表示实测图像，$D_hu$ 表示降噪方法的输出结果，$h$ 为滤波参数。Antoni Buades 定义 method noise 为降噪前后图像之差：</p>
<p>$$ u-D_hu. \tag{5}\label{5} $$</p>
<p>&emsp;&emsp;完美的降噪算法在应用中不应该改变无噪声图像。因此，当图像具有某种规律性时，method noise 理应很小。对理想的降噪算法，Method noise 必须看起来与随机噪声无异，几乎不包含原始信号的结构。因为即便是质量非常高的实测图像，噪声也是不可避免的，计算 method noise 对评估任何降噪算法都是有意义的，而非传统的“添加噪声，再去除噪声”的把戏。</p>
<h2 id="局部平均算法"><a href="#局部平均算法" class="headerlink" title="局部平均算法"></a>局部平均算法</h2><h3 id="高斯滤波-Gaussian-Filtering"><a href="#高斯滤波-Gaussian-Filtering" class="headerlink" title="高斯滤波 (Gaussian Filtering)"></a>高斯滤波 (Gaussian Filtering)</h3><p>&emsp;&emsp;对数字图像进行各向同性过滤，本质上可以归结为图像与各向同性核的卷积。采用数值呈现出高斯分布的卷积核，既是高斯滤波，是图像处理中最常用的操作之一。通俗的讲，高斯滤波就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到（所有的局部平滑滤波方法都是如此）。高斯卷积核：</p>
<p>$$ G_h(x)&#x3D;\frac{1}{4\pi h^2}e^{-\frac{|x|^2}{4h^2}}. \tag{6}\label{6} $$</p>
<p><strong>Theorem 1 (Babor 1960):</strong> 当高斯卷积核的特征尺寸 $h$ 极小时，高斯滤波的 method noise 为：</p>
<p>$$ u-G_h* u&#x3D;-h^2\Delta u+o(h^2). \tag{7}\label{7} $$</p>
<p>&emsp;&emsp;高斯滤波的 method noise 在图像谐波部分几乎为零，而在边缘、纹理区域非常大。因此，高斯滤波在图像的平坦区域相对表现优秀，但在边缘、纹理区域较为模糊（blurred）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img_medianBlur=cv2.medianBlur(img01,<span class="number">5</span>)</span><br><span class="line">font=cv2.FONT_HERSHEY_SIMPLEX</span><br><span class="line"></span><br><span class="line"><span class="comment">#均值滤波</span></span><br><span class="line">img_Blur=cv2.blur(img01,(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#高斯滤波</span></span><br><span class="line">img_GaussianBlur=cv2.GaussianBlur(img01,(<span class="number">7</span>,<span class="number">7</span>),<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#高斯双边滤波</span></span><br><span class="line">img_bilateralFilter=cv2.bilateralFilter(img01,<span class="number">40</span>,<span class="number">75</span>,<span class="number">75</span>)</span><br></pre></td></tr></table></figure>

<h3 id="各向异性滤波（Anisotropic-Filtering-AF）"><a href="#各向异性滤波（Anisotropic-Filtering-AF）" class="headerlink" title="各向异性滤波（Anisotropic Filtering, AF）"></a>各向异性滤波（Anisotropic Filtering, AF）</h3><p>&emsp;&emsp;各向异性滤波提出之初旨在解决高斯滤波在边缘及纹理区域的模糊问题。该算法通过只在 $Du(\vec x)$ 正交方向上计算图像 $u$ 在 $\vec x$ 处的卷积。这种想法可以追溯到 <a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona &amp; Malik</a>。各向异性滤波算法的定义为：</p>
<p>$$ AF_hu(\vec x)&#x3D;\int G_h(t)u(\vec x+t\frac{Du(\vec x)^\perp}{|Du(\vec x)|})dt, \tag{8}\label{8} $$</p>
<p>在 $\vec x$ 处，当 $Du(\vec x)\neq0$ 时成立。$(x,y)^\perp&#x3D;(-y,x)$，且 $G_h$ 代指方差 $h^2$ 的一维高斯函数。假设原始图像 $u$ 在 $\vec x$ 处二次连续可微（twice continuously differentiable ($C^2$)）,将上式二次泰勒展开（second order Taylor expansion）可以推导出：</p>
<p><strong>Theorem 2:</strong> 当 $Du(\vec x)\neq0$ 时，各向异性滤波 $AF_h$ 的 method noise 为：</p>
<p>$$ u(\vec x)-AF_hu(\vec x)&#x3D;-\frac{1}{2}h^2|Du|curv(u)(\vec x)+o(h^2), \tag{9}\label{9} $$</p>
<p>$curv(u)(\vec x)$ 指局部曲率，即经过 $\vec x$ 点的水平直线上曲率半径的逆（signed inverse）。在图像 $u$ 中局部几乎为一条直线的区域，method noise 几乎为零，而在弯曲的边缘或纹理区域较大。因而，各向异性滤波对直边区域得以保持，而平坦、纹理区域图像精度有所退化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">anisodiff</span>(<span class="params">img,niter=<span class="number">1</span>,kappa=<span class="number">50</span>,gamma=<span class="number">0.1</span>,step=(<span class="params"><span class="number">1.</span>,<span class="number">1.</span></span>),option=<span class="number">1</span>,ploton=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Anisotropic diffusion.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">    imgout = anisodiff(im, niter, kappa, gamma, option)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">            img    - input image</span></span><br><span class="line"><span class="string">            niter  - number of iterations</span></span><br><span class="line"><span class="string">            kappa  - conduction coefficient 20-100 ?</span></span><br><span class="line"><span class="string">            gamma  - max value of .25 for stability</span></span><br><span class="line"><span class="string">            step   - tuple, the distance between adjacent pixels in (y,x)</span></span><br><span class="line"><span class="string">            option - 1 Perona Malik diffusion equation No 1</span></span><br><span class="line"><span class="string">                     2 Perona Malik diffusion equation No 2</span></span><br><span class="line"><span class="string">            ploton - if True, the image will be plotted on every iteration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">            imgout   - diffused image.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    kappa controls conduction as a function of gradient.  If kappa is low</span></span><br><span class="line"><span class="string">    small intensity gradients are able to block conduction and hence diffusion</span></span><br><span class="line"><span class="string">    across step edges.  A large value reduces the influence of intensity</span></span><br><span class="line"><span class="string">    gradients on conduction.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma controls speed of diffusion (you usually want it at a maximum of</span></span><br><span class="line"><span class="string">    0.25)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    step is used to scale the gradients in case the spacing between adjacent</span></span><br><span class="line"><span class="string">    pixels differs in the x and y axes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Diffusion equation 1 favours high contrast edges over low contrast ones.</span></span><br><span class="line"><span class="string">    Diffusion equation 2 favours wide regions over smaller ones.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">    P. Perona and J. Malik.</span></span><br><span class="line"><span class="string">    Scale-space and edge detection using ansotropic diffusion.</span></span><br><span class="line"><span class="string">    IEEE Transactions on Pattern Analysis and Machine Intelligence,</span></span><br><span class="line"><span class="string">    12(7):629-639, July 1990.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Original MATLAB code by Peter Kovesi</span></span><br><span class="line"><span class="string">    School of Computer Science &amp; Software Engineering</span></span><br><span class="line"><span class="string">    The University of Western Australia</span></span><br><span class="line"><span class="string">    pk @ csse uwa edu au</span></span><br><span class="line"><span class="string">    &lt;http://www.csse.uwa.edu.au&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Translated to Python and optimised by Alistair Muldal</span></span><br><span class="line"><span class="string">    Department of Pharmacology</span></span><br><span class="line"><span class="string">    University of Oxford</span></span><br><span class="line"><span class="string">    &lt;alistair.muldal@pharm.ox.ac.uk&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    June 2000  original version.</span></span><br><span class="line"><span class="string">    March 2002 corrected diffusion eqn No 2.</span></span><br><span class="line"><span class="string">    July 2012 translated to Python</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    April 2019 - Corrected for Python 3.7 - AvW </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...you could always diffuse each color channel independently if you</span></span><br><span class="line">    <span class="comment"># really want</span></span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">3</span>:</span><br><span class="line">        warnings.warn(<span class="string">&quot;Only grayscale images allowed, converting to 2D matrix&quot;</span>)</span><br><span class="line">        img = img.mean(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output array</span></span><br><span class="line">    img = img.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    imgout = img.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize some internal variables</span></span><br><span class="line">    deltaS = np.zeros_like(imgout)</span><br><span class="line">    deltaE = deltaS.copy()</span><br><span class="line">    NS = deltaS.copy()</span><br><span class="line">    EW = deltaS.copy()</span><br><span class="line">    gS = np.ones_like(imgout)</span><br><span class="line">    gE = gS.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create the plot figure, if requested</span></span><br><span class="line">    <span class="keyword">if</span> ploton:</span><br><span class="line">        <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line">        <span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">        fig = pl.figure(figsize=(<span class="number">20</span>,<span class="number">5.5</span>),num=<span class="string">&quot;Anisotropic diffusion&quot;</span>)</span><br><span class="line">        ax1,ax2 = fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        ax1.imshow(img,interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        ih = ax2.imshow(imgout,interpolation=<span class="string">&#x27;nearest&#x27;</span>,animated=<span class="literal">True</span>)</span><br><span class="line">        ax1.set_title(<span class="string">&quot;Original image&quot;</span>)</span><br><span class="line">        ax2.set_title(<span class="string">&quot;Iteration 0&quot;</span>)</span><br><span class="line"></span><br><span class="line">        fig.canvas.draw()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the diffs</span></span><br><span class="line">        deltaS[:-<span class="number">1</span>,: ] = np.diff(imgout,axis=<span class="number">0</span>)</span><br><span class="line">        deltaE[: ,:-<span class="number">1</span>] = np.diff(imgout,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conduction gradients (only need to compute one per dim!)</span></span><br><span class="line">        <span class="keyword">if</span> option == <span class="number">1</span>:</span><br><span class="line">            gS = np.exp(-(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gE = np.exp(-(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">elif</span> option == <span class="number">2</span>:</span><br><span class="line">            gS = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gE = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update matrices</span></span><br><span class="line">        E = gE*deltaE</span><br><span class="line">        S = gS*deltaS</span><br><span class="line"></span><br><span class="line">        <span class="comment"># subtract a copy that has been shifted &#x27;North/West&#x27; by one</span></span><br><span class="line">        <span class="comment"># pixel. don&#x27;t as questions. just do it. trust me.</span></span><br><span class="line">        NS[:] = S</span><br><span class="line">        EW[:] = E</span><br><span class="line">        NS[<span class="number">1</span>:,:] -= S[:-<span class="number">1</span>,:]</span><br><span class="line">        EW[:,<span class="number">1</span>:] -= E[:,:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update the image</span></span><br><span class="line">        imgout += gamma*(NS+EW)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ploton:</span><br><span class="line">            iterstring = <span class="string">&quot;Iteration %i&quot;</span> %(ii+<span class="number">1</span>)</span><br><span class="line">            ih.set_data(imgout)</span><br><span class="line">            ax2.set_title(iterstring)</span><br><span class="line">            fig.canvas.draw()</span><br><span class="line">            <span class="comment"># sleep(0.01)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> imgout</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">anisodiff3</span>(<span class="params">stack,niter=<span class="number">1</span>,kappa=<span class="number">50</span>,gamma=<span class="number">0.1</span>,step=(<span class="params"><span class="number">1.</span>,<span class="number">1.</span>,<span class="number">1.</span></span>),option=<span class="number">1</span>,ploton=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    3D Anisotropic diffusion.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">    stackout = anisodiff(stack, niter, kappa, gamma, option)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">            stack  - input stack</span></span><br><span class="line"><span class="string">            niter  - number of iterations</span></span><br><span class="line"><span class="string">            kappa  - conduction coefficient 20-100 ?</span></span><br><span class="line"><span class="string">            gamma  - max value of .25 for stability</span></span><br><span class="line"><span class="string">            step   - tuple, the distance between adjacent pixels in (z,y,x)</span></span><br><span class="line"><span class="string">            option - 1 Perona Malik diffusion equation No 1</span></span><br><span class="line"><span class="string">                     2 Perona Malik diffusion equation No 2</span></span><br><span class="line"><span class="string">            ploton - if True, the middle z-plane will be plotted on every</span></span><br><span class="line"><span class="string">                 iteration</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">            stackout   - diffused stack.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    kappa controls conduction as a function of gradient.  If kappa is low</span></span><br><span class="line"><span class="string">    small intensity gradients are able to block conduction and hence diffusion</span></span><br><span class="line"><span class="string">    across step edges.  A large value reduces the influence of intensity</span></span><br><span class="line"><span class="string">    gradients on conduction.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    gamma controls speed of diffusion (you usually want it at a maximum of</span></span><br><span class="line"><span class="string">    0.25)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    step is used to scale the gradients in case the spacing between adjacent</span></span><br><span class="line"><span class="string">    pixels differs in the x,y and/or z axes</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Diffusion equation 1 favours high contrast edges over low contrast ones.</span></span><br><span class="line"><span class="string">    Diffusion equation 2 favours wide regions over smaller ones.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Reference:</span></span><br><span class="line"><span class="string">    P. Perona and J. Malik.</span></span><br><span class="line"><span class="string">    Scale-space and edge detection using ansotropic diffusion.</span></span><br><span class="line"><span class="string">    IEEE Transactions on Pattern Analysis and Machine Intelligence,</span></span><br><span class="line"><span class="string">    12(7):629-639, July 1990.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Original MATLAB code by Peter Kovesi</span></span><br><span class="line"><span class="string">    School of Computer Science &amp; Software Engineering</span></span><br><span class="line"><span class="string">    The University of Western Australia</span></span><br><span class="line"><span class="string">    pk @ csse uwa edu au</span></span><br><span class="line"><span class="string">    &lt;http://www.csse.uwa.edu.au&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Translated to Python and optimised by Alistair Muldal</span></span><br><span class="line"><span class="string">    Department of Pharmacology</span></span><br><span class="line"><span class="string">    University of Oxford</span></span><br><span class="line"><span class="string">    &lt;alistair.muldal@pharm.ox.ac.uk&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    June 2000  original version.</span></span><br><span class="line"><span class="string">    March 2002 corrected diffusion eqn No 2.</span></span><br><span class="line"><span class="string">    July 2012 translated to Python</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ...you could always diffuse each color channel independently if you</span></span><br><span class="line">    <span class="comment"># really want</span></span><br><span class="line">    <span class="keyword">if</span> stack.ndim == <span class="number">4</span>:</span><br><span class="line">        warnings.warn(<span class="string">&quot;Only grayscale stacks allowed, converting to 3D matrix&quot;</span>)</span><br><span class="line">        stack = stack.mean(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize output array</span></span><br><span class="line">    stack = stack.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    stackout = stack.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize some internal variables</span></span><br><span class="line">    deltaS = np.zeros_like(stackout)</span><br><span class="line">    deltaE = deltaS.copy()</span><br><span class="line">    deltaD = deltaS.copy()</span><br><span class="line">    NS = deltaS.copy()</span><br><span class="line">    EW = deltaS.copy()</span><br><span class="line">    UD = deltaS.copy()</span><br><span class="line">    gS = np.ones_like(stackout)</span><br><span class="line">    gE = gS.copy()</span><br><span class="line">    gD = gS.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create the plot figure, if requested</span></span><br><span class="line">    <span class="keyword">if</span> ploton:</span><br><span class="line">        <span class="keyword">import</span> pylab <span class="keyword">as</span> pl</span><br><span class="line">        <span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">        showplane = stack.shape[<span class="number">0</span>]//<span class="number">2</span></span><br><span class="line"></span><br><span class="line">        fig = pl.figure(figsize=(<span class="number">20</span>,<span class="number">5.5</span>),num=<span class="string">&quot;Anisotropic diffusion&quot;</span>)</span><br><span class="line">        ax1,ax2 = fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>),fig.add_subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        ax1.imshow(stack[showplane,...].squeeze(),interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        ih = ax2.imshow(stackout[showplane,...].squeeze(),interpolation=<span class="string">&#x27;nearest&#x27;</span>,animated=<span class="literal">True</span>)</span><br><span class="line">        ax1.set_title(<span class="string">&quot;Original stack (Z = %i)&quot;</span> %showplane)</span><br><span class="line">        ax2.set_title(<span class="string">&quot;Iteration 0&quot;</span>)</span><br><span class="line"></span><br><span class="line">        fig.canvas.draw()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ii <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate the diffs</span></span><br><span class="line">        deltaD[:-<span class="number">1</span>,: ,:  ] = np.diff(stackout,axis=<span class="number">0</span>)</span><br><span class="line">        deltaS[:  ,:-<span class="number">1</span>,: ] = np.diff(stackout,axis=<span class="number">1</span>)</span><br><span class="line">        deltaE[:  ,: ,:-<span class="number">1</span>] = np.diff(stackout,axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># conduction gradients (only need to compute one per dim!)</span></span><br><span class="line">        <span class="keyword">if</span> option == <span class="number">1</span>:</span><br><span class="line">            gD = np.exp(-(deltaD/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gS = np.exp(-(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">            gE = np.exp(-(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> option == <span class="number">2</span>:</span><br><span class="line">            gD = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaD/kappa)**<span class="number">2.</span>)/step[<span class="number">0</span>]</span><br><span class="line">            gS = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaS/kappa)**<span class="number">2.</span>)/step[<span class="number">1</span>]</span><br><span class="line">            gE = <span class="number">1.</span>/(<span class="number">1.</span>+(deltaE/kappa)**<span class="number">2.</span>)/step[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update matrices</span></span><br><span class="line">        D = gD*deltaD</span><br><span class="line">        E = gE*deltaE</span><br><span class="line">        S = gS*deltaS</span><br><span class="line"></span><br><span class="line">        <span class="comment"># subtract a copy that has been shifted &#x27;Up/North/West&#x27; by one</span></span><br><span class="line">        <span class="comment"># pixel. don&#x27;t as questions. just do it. trust me.</span></span><br><span class="line">        UD[:] = D</span><br><span class="line">        NS[:] = S</span><br><span class="line">        EW[:] = E</span><br><span class="line">        UD[<span class="number">1</span>:,: ,: ] -= D[:-<span class="number">1</span>,:  ,:  ]</span><br><span class="line">        NS[: ,<span class="number">1</span>:,: ] -= S[:  ,:-<span class="number">1</span>,:  ]</span><br><span class="line">        EW[: ,: ,<span class="number">1</span>:] -= E[:  ,:  ,:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># update the image</span></span><br><span class="line">        stackout += gamma*(UD+NS+EW)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ploton:</span><br><span class="line">            iterstring = <span class="string">&quot;Iteration %i&quot;</span> %(ii+<span class="number">1</span>)</span><br><span class="line">            ih.set_data(stackout[showplane,...].squeeze())</span><br><span class="line">            ax2.set_title(iterstring)</span><br><span class="line">            fig.canvas.draw()</span><br><span class="line">            <span class="comment"># sleep(0.01)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> stackout</span><br></pre></td></tr></table></figure>

<h3 id="TV滤波（Total-Variation-Minimization）"><a href="#TV滤波（Total-Variation-Minimization）" class="headerlink" title="TV滤波（Total Variation Minimization）"></a>TV滤波（Total Variation Minimization）</h3><p>&emsp;&emsp;全变分图像去噪算法最早由 <a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin, Osher and Fatemi</a>提出。给定一幅实测图像 $v(\vec x)$，该算法将恢复原始信号 $u(\vec x)$ 的问题转化为下式的最小化问题：</p>
<p>$$ TVF_\lambda(v)&#x3D;{\rm arg},\underset{u}{\rm \mathop {min}},TV(u)+\lambda\int|v(\vec x)-u(\vec x)|^2d\vec x, \tag{10}\label{10} $$</p>
<p>其中 $TV(u)$ 为图像 $u$ 的全变分，$\lambda$ 为给定的拉格朗日乘子（Lagrange multiplier）。上述最小化问题的最小值存在且唯一。参数 $\lambda$ 与噪声的统计信息相关，并控制了滤波程度。</p>
<p><strong>Theorem 3:</strong> TV滤波的 method noise 为：</p>
<p>$$ u(\vec x)-TVF_\lambda(u)(\vec x)&#x3D;-\frac{1}{2\lambda}curv(TVF_\lambda(u))(\vec x). \tag{11}\label{11} $$</p>
<p>&emsp;&emsp;在各向异性的情况下，直边由于曲率小而得以保持。但 $\lambda$ 过小时细节及纹理会被过度平滑。</p>
<h3 id="邻域滤波（Neighborhood-Filtering）"><a href="#邻域滤波（Neighborhood-Filtering）" class="headerlink" title="邻域滤波（Neighborhood Filtering）"></a>邻域滤波（Neighborhood Filtering）</h3><p>&emsp;&emsp;我们称邻域滤波为将临近区域内具有相似灰度值的像素取平均以期恢复原始信号的滤波器。<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky(1985)</a>首次提出的方法通过计算空间邻域 $B_\rho(\vec x)$ 内具有相似灰度值像素的平均来恢复信号：</p>
<p>$$ YNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{B_\rho (\vec x)} u(\vec y)e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{12}\label{12} $$</p>
<p>其中，$\vec x\in\Omega$，$C(\vec x)&#x3D;\int_{B_\rho(\vec x)} e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$h$ 为滤波参数。</p>
<p>&emsp;&emsp;较晚提出的邻域滤波算法相较 Yaroslavsky 滤波要更广为人知一些，既 SUSAN 滤波（1995）及双边滤波（1998）。这些滤波算法都引入到参考像素 $\vec x$ 的距离作为权重因子，而非单纯的考虑一个固定范围的邻域，</p>
<p>$$ SNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{\Omega} u(\vec y)e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{13}\label{13} $$</p>
<p>这里 $C(\vec x)&#x3D;\int_{\Omega}e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$\rho$ 为空间滤波参数（spatial filtering parameter）。事实上，$YNF_{h,\rho}$ 与 $SNF_{h,\rho}$ 之间并没有本质区别。如果两个区域的灰度值差异大于 $h$，这些算法都将计算来自于同一区域的像素灰度平均值来恢复参考点的原始信号。因而该算法不会模糊边界区域，这是正是该类算法最核心的用途。</p>
<p>&emsp;&emsp;然而这类算法的问题是，只将单个像素作为参考点，而如若该参考像素恰好被噪声干扰严重，滤波效果将不够鲁棒（robust）。同时，邻域滤波器也会制造人为干扰（artificial shocks），这将会在它的 method noise 中展示出来。</p>
<h2 id="非局部平均算法（Non-Local-Means-Algorithm）"><a href="#非局部平均算法（Non-Local-Means-Algorithm）" class="headerlink" title="非局部平均算法（Non Local Means Algorithm）"></a>非局部平均算法（Non Local Means Algorithm）</h2><p>&emsp;&emsp;Antoni Buades 于 2005 年提出非局部平均数字图像降噪算法（Non Local Algorithm）。给定一幅实测图像 $v&#x3D;\lbrace v(i)|i\in I\rbrace $，像素 $i$ 处的估计值 $NL[v](i)$ 是该图像上所有像素点的加权平均值，</p>
<p>$$ NL(i)&#x3D;\sum_{j\in I}\omega(i,j)v(j), \tag{14}\label{14} $$</p>
<p>这里的权重系数 $\lbrace\omega (i,j)\rbrace_j$ 取决于像素 $i$ 与 $j$ 之间的相似程度，且始终满足如下标准： $0\leq\omega(i,j)\leq 1$ 且 $\sum_{j} \omega(i,j)&#x3D;1$（等价于上文介绍的滤波算法中归一化常量）。</p>
<p>&emsp;&emsp;俩个像素 $(i,j)$ 之间的相似程度取决于邻域灰度矩阵 $v(N_i)$ 及 $v(N_j)$（intensity gray level vectors），这里 $N_k$ 指以像素 $k$ 为中心，给定尺寸的方形邻域。这种相似性被定义为加权欧式距离的递减函数，$\parallel v(N_i)-v(N_j)\parallel_{2,a}^2$，其中 $a&gt;0$ 是高斯卷积核的标准差。欧式距离对噪声邻域的应用引入了如下等式：</p>
<p>$$ E\parallel v(N_i)-v(N_j)\parallel_{2,a}^2 &#x3D; \parallel u(N_i)-u(N_j) \parallel_{2,a}^2+2\sigma^2. \tag{15}\label{15} $$</p>
<p>&emsp;&emsp;这个等式证明了该算法的鲁棒性（robustness）。因为含噪声的实测图像 $v$ 的欧式距离期望恰恰遵循真正的原始信号之间的相似性。</p>
<p>&emsp;&emsp;与 $v(N_i)$ 具有相似灰度邻域的像素在计算平均时的权重因子更大，</p>
<p>$$ \omega(i,j)&#x3D;\frac{1}{Z(i)}e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{16}\label{16} $$</p>
<p>这里，$Z(i)$ 为归一化常量，</p>
<p>$$ Z(i) &#x3D; \sum_j e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{17}\label{17} $$</p>
<p>参数 $h$ 控制滤波程度，它直接影响了指数函数的衰减趋势，进而控制欧式距离对权重因子衰减速度的影响。</p>
<p>&emsp;&emsp;NL-means 算法不仅仅考虑单个像素的灰度值，而是考虑该像素整个邻域的几何构型，这正是 NL-means 算法比邻域滤波更鲁棒的原因。图$(1)$ 也说明了这个问题，像素 $q3$ 与 $p$ 具有完全一致的灰度值，而邻域的几何构型完全不同，导致 NL-means 中的权重因子 $\omega(p,q3)$ 几乎为零。</p>
<img src="https://s21.ax1x.com/2024/05/07/pkEWDxI.jpg" width="45%" alt="" align=center title="图1.  NL-means 算法方案。相似的像素邻域将提供更大的权重，如 $\omega(p,q1), \omega(p,q2)$，而不相似的邻域提供的权重几乎为零，如 $\omega(p,q3)$。"/>

<p>&nbsp;<br>&emsp;&emsp;NL-means 算法最终的数学形式：</p>
<p>$$ NL(x)&#x3D;\frac{1}{C(x)} \int_{\Omega} e^{-\cfrac{(G_a * |v(x+.)-v(y+.)|^2)(0)}{h^2}}v(y)dy, \tag{18}\label{18} $$</p>
<p>$x\in\Omega$，$C(x)&#x3D;\int_{\Omega} {\rm exp}\lbrack -\frac{(G_a* |u(x+.)-u(z+.)|^2)(0)}{h^2}\rbrack dz$ 为归一化常量，$G_a$ 为高斯核，$h$ 控制过滤程度。</p>
<p>&emsp;&emsp;NL-means 算法的中心思想是：像素 $x$ 处的信息恢复，是由整幅图像内所有邻域与像素 $x$ 邻域相似的点取平均得到的。与局部滤波算法或频域滤波算法相比，NL-means 算法的主要区别在于可以系统地运用整幅图像中所有可能自预测局部结构的信息。</p>
<h2 id="Non-local-means-方法代码实现"><a href="#Non-local-means-方法代码实现" class="headerlink" title="Non-local means 方法代码实现"></a>Non-local means 方法代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_nl_means, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">astro = img_as_float(data.astronaut())</span><br><span class="line">astro = astro[<span class="number">30</span>:<span class="number">180</span>, <span class="number">150</span>:<span class="number">300</span>]</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.08</span></span><br><span class="line">noisy = random_noise(astro, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># estimate the noise standard deviation from the noisy image</span></span><br><span class="line">sigma_est = np.mean(estimate_sigma(noisy, channel_axis=-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;estimated noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">patch_kw = <span class="built_in">dict</span>(patch_size=<span class="number">5</span>,      <span class="comment"># 5x5 patches</span></span><br><span class="line">                patch_distance=<span class="number">6</span>,  <span class="comment"># 13x13 search area</span></span><br><span class="line">                channel_axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm</span></span><br><span class="line">denoise = denoise_nl_means(noisy, h=<span class="number">1.15</span> * sigma_est, fast_mode=<span class="literal">False</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm, sigma provided</span></span><br><span class="line">denoise2 = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">False</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm</span></span><br><span class="line">denoise_fast = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, fast_mode=<span class="literal">True</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm, sigma provided</span></span><br><span class="line">denoise2_fast = denoise_nl_means(noisy, h=<span class="number">0.6</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">True</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>),sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;noisy&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(denoise)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(slow)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(denoise2)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(slow, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(astro)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;original\n(noise free)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(denoise_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(fast)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(denoise2_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(fast, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print PSNR metric for each case</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(astro, noisy)</span><br><span class="line">psnr = peak_signal_noise_ratio(astro, denoise)</span><br><span class="line">psnr2 = peak_signal_noise_ratio(astro, denoise2)</span><br><span class="line">psnr_fast = peak_signal_noise_ratio(astro, denoise_fast)</span><br><span class="line">psnr2_fast = peak_signal_noise_ratio(astro, denoise2_fast)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (noisy) = <span class="subst">&#123;psnr_noisy:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow) = <span class="subst">&#123;psnr:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow, using sigma) = <span class="subst">&#123;psnr2:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast) = <span class="subst">&#123;psnr_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast, using sigma) = <span class="subst">&#123;psnr2_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h2 id="实验及讨论"><a href="#实验及讨论" class="headerlink" title="实验及讨论"></a>实验及讨论</h2><p>&emsp;&emsp;本节将针对以下三点比较 Non Local Means 算法与局部平滑滤波的性能： method noise，视觉效果，均方差（mean square error）。这里均方差指修复图像与真实图像的欧几里得差异（Euclidean difference）。</p>
<p>&emsp;&emsp;在实现 NL-means 算法时，我们将相似邻域的搜索范围约束在一个较大的 $S\times S$ pixels 区域内。在所有的实验中均固定该搜索范围为 $21\times 21$ pixels，并指定邻域 $N_i$ 范围为 $7\times 7$ pixels。不妨设输入图像的像素数为 $N^2$，那么该算法的时间复杂度约为 $21^2\times 7^2 \times N^2$。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWwPH.jpg">https://s21.ax1x.com/2024/05/07/pkEWwPH.jpg</a>“ width&#x3D;”70%” alt&#x3D;”” align&#x3D;center &#x2F; title&#x3D;”图2.  NL-means 权重分布。每组中左图中心像素为参考像素点 $x$，每组中右图为权重因子分布，由黑至白对应从0到1。”&#x2F;&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;$7\times 7$ pixels 的邻域范围已经足够大，能够确保算法对噪声是鲁棒的；也足够小，让细节及纹理得以保持。滤波参数 $h$ 被设置为 $10\sigma$，这里 $\sigma$ 为人工添加高斯白噪声的标准差。由于指数权重的快速衰减，距离中心较远像素的权重几乎为零，这发挥了自动剔除远处像素的作用。Non Local means 算法的权重分布见图$(2)$。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEW0Gd.jpg">https://s21.ax1x.com/2024/05/07/pkEW0Gd.jpg</a>“ width &#x3D; 80% div align&#x3D;center &#x2F; title&#x3D;”图3.  对自然图像的降噪实验。从左至右：含噪声的实测图像（噪声标准差 35），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;在前面的段落中，我们明确的计算了各种局部平滑滤波方法的 method noise 理论值。图$(4)$ 的可视化实验证明了前文中公式的正确性。图$(4)$ 对比了数种降噪方法对含噪声lena图像运算的 method noise，噪声为高斯白噪声，标准差 2.5，滤波参数 $h$ 均相同。Method noise 能更好的协助判断降噪算法的性能及局限，因为被移除或改变的纹理、细节将被 method noise 醒目的展示出来。对比图$(4)$ 中数种降噪算法，NL-means 算法的 method noise 几乎无法察觉任何几何纹理。图$(2)$ 可以解释这一现象，因为 NL-means 算法选取的权重因子完全适应图像局部及非局部的几何结构。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWysP.jpg">https://s21.ax1x.com/2024/05/07/pkEWysP.jpg</a>“ width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图4.  降噪算法的method noise。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。视觉实验验证了第二节的计算公式。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;由于算法本身的性质，纹理及周期性结构是 NL-means 算法最适用的情况。因为对任意像素 $i$，纹理图像或周期性图像中将可以找到大量与该像素具有相似邻域的点，如图$(2.e)$。图$(3)$ 展示了局部平滑滤波器及 NL-means 算法对自然纹理的平滑效果。</p>
<p>&emsp;&emsp;自然图像同样含有足够的信息冗余会被 NL-means 恢复。平坦区域内部将呈现出大量相似的几何结构，见图$(2.a)$。直边界、或弯曲边界将被筛选出一条结构相似的像素线，见图$(2. b)，(2.c)$。并且，NL-means 将会在很远的位置寻找到与参考点相似的结构，如图$(2.f)$。图$(5)$ 展示了一次对自然图像的可视化实验，这组结果与图$(4)$ 是相对应的。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWBRA.jpg">https://s21.ax1x.com/2024/05/07/pkEWBRA.jpg</a>“ width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图5.  对自然图像的降噪实验。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;最后，表$(1)$ 展示了本文介绍的降噪方法的均方差。这种数值测量方法是最客观的，因为它不依赖于任何肉眼视觉上的解释。然而，这个误差在实际问题中是不可计算的（原始信号是未知的），小的均方误差并不能保证高的视觉质量。因此，以上讨论的标准似乎是比较算法性能的必要条件。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/07/pkEWsMt.jpg">https://s21.ax1x.com/2024/05/07/pkEWsMt.jpg</a>“ width &#x3D; 35% div align&#x3D;center &#x2F; title&#x3D;”表1.  均方误差表。均方误差越小，降噪后越接近原始图像。”&gt;</p>
<p>&nbsp;<br><img src="https://s21.ax1x.com/2024/05/07/pkEWgZ8.jpg" width = "60%" title="图6.  多种滤波方法对周期性图像应用结果。从左到右、从上到下：含噪声图像（标准差 35）；高斯滤波；TV滤波；邻域滤波；维纳滤波（ideal filter）；Hard TIWT；DCT 经验维纳滤波；NL-means 算法。" align=center /></p>
<p>&nbsp;<br><img src="https://s21.ax1x.com/2024/05/07/pkEW6qf.jpg" width = "40%" title = "图7.  多种滤波方法对自然图像应用结果。从左到右、从上至下：含噪声图像（标准差 25）；DCT 经验维纳滤波；Hard TIWT；NL-means 算法。"  align=center /></p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>&emsp;&emsp;Non-local means 方法 C 语言实现：<a href="http://www.ipol.im/pub/art/2011/bcm_nlm/">http://www.ipol.im/pub/art/2011/bcm_nlm&#x2F;</a></p>
<h2 id="其他滤波器"><a href="#其他滤波器" class="headerlink" title="其他滤波器"></a>其他滤波器</h2><h3 id="Top-hat-filter"><a href="#Top-hat-filter" class="headerlink" title="Top-hat filter"></a>Top-hat filter</h3><p>使用Top-hat滤波器去除灰度图像中的小目标：这个例子展示了如何从灰度图像中移除小物体。顶帽变换是一种从给定图像中提取小元素和细节的操作。这里我们使用白色顶帽变换，它被定义为输入图像与其(数学形态学)开口之间的差异。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> color, morphology</span><br><span class="line"></span><br><span class="line">image = color.rgb2gray(data.hubble_deep_field())[:<span class="number">500</span>, :<span class="number">500</span>]</span><br><span class="line"></span><br><span class="line">footprint = morphology.disk(<span class="number">1</span>)</span><br><span class="line">res = morphology.white_tophat(image, footprint)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(ncols=<span class="number">3</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>].imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&#x27;White tophat&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(res, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">&#x27;Complementary&#x27;</span>)</span><br><span class="line">ax[<span class="number">2</span>].imshow(image - res, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h3 id="小波傅里叶变换"><a href="#小波傅里叶变换" class="headerlink" title="小波傅里叶变换"></a>小波傅里叶变换</h3><p>小波去噪依赖于图像的小波表示。高斯噪声倾向于用小波域中的小值来表示，并且可以通过将低于给定阈值的系数设置为零(硬阈值)或将所有系数缩小到给定数量的零(软阈值)来去除。<br>在这个例子中，我们展示了两种不同的小波系数阈值选择方法:BayesShrink和VisuShrink。</p>
<img src="https://scikit-image.org/docs/stable/_images/sphx_glr_plot_denoise_wavelet_001.png" width="80%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_wavelet, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">original = img_as_float(data.chelsea()[<span class="number">100</span>:<span class="number">250</span>, <span class="number">50</span>:<span class="number">300</span>])</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.12</span></span><br><span class="line">noisy = random_noise(original, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">5</span>), sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.gray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Estimate the average noise standard deviation across color channels.</span></span><br><span class="line">sigma_est = estimate_sigma(noisy, channel_axis=-<span class="number">1</span>, average_sigmas=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># Due to clipping in random_noise, the estimate will be a bit smaller than the</span></span><br><span class="line"><span class="comment"># specified sigma.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Estimated Gaussian noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">im_bayes = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;BayesShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">im_visushrink = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># VisuShrink is designed to eliminate noise with high probability, but this</span></span><br><span class="line"><span class="comment"># results in a visually over-smooth appearance.  Repeat, specifying a reduction</span></span><br><span class="line"><span class="comment"># in the threshold by factors of 2 and 4.</span></span><br><span class="line">im_visushrink2 = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est / <span class="number">2</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">im_visushrink4 = denoise_wavelet(</span><br><span class="line">    noisy,</span><br><span class="line">    channel_axis=-<span class="number">1</span>,</span><br><span class="line">    convert2ycbcr=<span class="literal">True</span>,</span><br><span class="line">    method=<span class="string">&#x27;VisuShrink&#x27;</span>,</span><br><span class="line">    mode=<span class="string">&#x27;soft&#x27;</span>,</span><br><span class="line">    sigma=sigma_est / <span class="number">4</span>,</span><br><span class="line">    rescale_sigma=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute PSNR as an indication of image quality</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(original, noisy)</span><br><span class="line">psnr_bayes = peak_signal_noise_ratio(original, im_bayes)</span><br><span class="line">psnr_visushrink = peak_signal_noise_ratio(original, im_visushrink)</span><br><span class="line">psnr_visushrink2 = peak_signal_noise_ratio(original, im_visushrink2)</span><br><span class="line">psnr_visushrink4 = peak_signal_noise_ratio(original, im_visushrink4)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">f&#x27;Noisy\nPSNR=<span class="subst">&#123;psnr_noisy:<span class="number">0.4</span>g&#125;</span>&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(im_bayes)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">f&#x27;Wavelet denoising\n(BayesShrink)\nPSNR=<span class="subst">&#123;psnr_bayes:<span class="number">0.4</span>g&#125;</span>&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(im_visushrink)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink</span><br><span class="line">)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(original)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(im_visushrink2)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;/2$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink2</span><br><span class="line">)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(im_visushrink4)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(</span><br><span class="line">    <span class="string">&#x27;Wavelet denoising\n(VisuShrink, $\\sigma=\\sigma_&#123;est&#125;/4$)\n&#x27;</span></span><br><span class="line">    <span class="string">&#x27;PSNR=%0.4g&#x27;</span> % psnr_visushrink4</span><br><span class="line">)</span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>denoise</tag>
        <tag>Non Local Means</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 09：Python 环境下的数字图像分割</title>
    <url>/PythonLes10/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>数字图像分割是计算机视觉中的一项基础且关键的任务，其目的是将图像划分成若干个互不相交的区域，使得这些区域内部的像素在某种特性上表现出一致性或相似性，而区域间的像素则表现出明显的差异。</p>
<span id="more"></span>

<h1 id="图像直方图"><a href="#图像直方图" class="headerlink" title="图像直方图"></a>图像直方图</h1><h2 id="计算图像的灰度直方图"><a href="#计算图像的灰度直方图" class="headerlink" title="计算图像的灰度直方图"></a>计算图像的灰度直方图</h2><p>在Python中，统计灰度图像的灰度直方图并绘制，通常可以使用matplotlib库来绘制直方图，以及使用numpy库来处理图像数据。此外，PIL（Python Imaging Library）或其分支Pillow库可以用来读取图像文件。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmBI4s.jpg">https://s21.ax1x.com/2024/05/14/pkmBI4s.jpg</a>“ width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”直方图均衡化演示图像，请将此图存储为’your_image_path.jpg’。”&gt;</p>
<p>以下是一个完整的示例，展示如何使用这些库来统计灰度图像的直方图并绘制：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;L&#x27;</span>)  <span class="comment"># 确保图像是灰度格式</span></span><br><span class="line">gray_array = np.array(image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计灰度直方图</span></span><br><span class="line">histogram = np.histogram(gray_array, bins=<span class="number">256</span>, <span class="built_in">range</span>=(<span class="number">0</span>, <span class="number">255</span>))[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;Grayscale Histogram&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Pixel Intensity&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Frequency&#x27;</span>)</span><br><span class="line">plt.plot(histogram, color=<span class="string">&#x27;blue&#x27;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>, <span class="number">255</span>])  <span class="comment"># 设置x轴的范围</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>Pillow</code>的<code>Image.open()</code>函数打开图像文件，并使用<code>convert(&#39;L&#39;)</code>确保图像是灰度格式。</li>
<li>使用<code>numpy</code>的<code>array()</code>函数将图像转换为一个二维数组，数组中的每个元素代表一个像素的灰度值。</li>
<li>使用<code>numpy</code>的<code>histogram()</code>函数来计算图像的灰度直方图。bins&#x3D;256表示将灰度范围（0到255）分成256个等大小的箱子，range&#x3D;(0, 255)定义了直方图的范围。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>plot()</code>函数绘制直方图，并通过<code>figure()</code>设置图形的大小，<code>xlim()</code>设置x轴的范围。</li>
</ul>
<h2 id="图像直方图均衡化"><a href="#图像直方图均衡化" class="headerlink" title="图像直方图均衡化"></a>图像直方图均衡化</h2><p>直方图均衡化是图像处理领域中利用图像直方图对对比度进行调整的方法。这种方法通常用来增加许多图像的全局对比度，尤其是当图像的有用数据的对比度相当接近的时候。通过这种方法，亮度可以更好地在直方图上分布。这样就可以用于增强局部的对比度而不影响整体的对比度，直方图均衡化通过有效地扩展常用的亮度来实现这种功能。这种方法对于背景和前景都太亮或者太暗的图像非常有用，这种方法尤其是可以带来X光图像中更好的骨骼结构显示以及曝光过度或者曝光不足照片中更好的细节。这种方法的一个主要优势是它是一个相当直观的技术并且是可逆操作，如果已知均衡化函数，那么就可以恢复原始的直方图，并且计算量也不大。这种方法的一个缺点是它对处理的数据不加选择，它可能会增加背景噪声的对比度并且降低有用信号的对比度。</p>
<p>考虑一个离散的灰度图像${x}$，让 $n_i$ 表示灰度 $i$ 出现的次数，这样图像中灰度为 $i$ 的像素的出现概率是:<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/2085ca8d9ae45213103bff0b9c786ca717e55bba">https://wikimedia.org/api/rest_v1/media/math/render/svg/2085ca8d9ae45213103bff0b9c786ca717e55bba</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>$L$是图像中所有的灰度数（通常为256），$n$是图像中所有的像素数，$p_x(i)$实际上是像素值为$i$的图像的直方图，归一化到$[0,1]$。把对应于 $p_x$ 的累积分布函数，定义为：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/4a4c8dccf53825085974fc78c1612f30b8410bf9">https://wikimedia.org/api/rest_v1/media/math/render/svg/4a4c8dccf53825085974fc78c1612f30b8410bf9</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>是图像的累计归一化直方图。</p>
<p>我们创建一个形式为 $y &#x3D; T(x)$ 的变换，对于原始图像中的每个值它就产生一个$y$，这样$y$的累计概率函数就可以在所有值范围内进行线性化，转换公式定义为：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/1786f939592d82e19d416f548c1e3e23ea5302c8">https://wikimedia.org/api/rest_v1/media/math/render/svg/1786f939592d82e19d416f548c1e3e23ea5302c8</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>对于常数K。CDF的性质允许我们做这样的变换（参见逆分布函数）；定义为<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/9322f34cc135a86f8f58fc0d563be67aa11d685f">https://wikimedia.org/api/rest_v1/media/math/render/svg/9322f34cc135a86f8f58fc0d563be67aa11d685f</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>其中 k 属于区间 [0,L)。注意 T 将不同的等级映射到$0..1$域，为了将这些值映射回它们最初的域，需要在结果上应用下面的简单变换：<br>&lt;img src&#x3D;”<a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/19d4b57f5ee70a919eeafad1c8b8019d89ce77ab">https://wikimedia.org/api/rest_v1/media/math/render/svg/19d4b57f5ee70a919eeafad1c8b8019d89ce77ab</a>“ div align&#x3D;center &#x2F; &gt;</p>
<p>上面描述了灰度图像上使用直方图均衡化的方法，但是通过将这种方法分别用于图像RGB颜色值的红色、绿色和蓝色分量，从而也可以对彩色图像进行处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 直方图均衡化</span></span><br><span class="line">    equ_image = cv2.equalizeHist(image)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和均衡化后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Equalized Image&#x27;</span>)</span><br><span class="line">    plt.imshow(equ_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。如果图像未正确加载，将打印错误消息。</li>
<li>使用<code>cv2.equalizeHist()</code>函数对图像进行直方图均衡化处理。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和均衡化后的图像。</li>
<li>请确保将<code>image_path</code>变量的值替换为你的灰度图像文件的路径。</li>
</ul>
<p>如果你还没有安装OpenCV库，可以使用pip进行安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>

<p>直方图均衡化对于改善低对比度图像的质量非常有效，它通过拉伸直方图分布到整个范围，从而增加图像的全局对比度。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/13/pkm3Pw6.jpg">https://s21.ax1x.com/2024/05/13/pkm3Pw6.jpg</a>“ width &#x3D; 75% div align&#x3D;center &#x2F; title&#x3D;”直方图均衡化的效果示例。”&gt;</p>
<h1 id="图像分割（Image-Segementation）"><a href="#图像分割（Image-Segementation）" class="headerlink" title="图像分割（Image Segementation）"></a>图像分割（Image Segementation）</h1><h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>边缘检测是图像处理中的一项关键技术，用于识别图像中亮度变化最显著的区域，这些区域通常对应于物体的边界。边缘是图像的重要特征，可以用于后续的图像分割、对象识别和图像理解等多种应用。</p>
<p>以下是一些经典的边缘检测算法：</p>
<ol>
<li><p>Sobel算子：通过计算图像中每个像素点的上下和左右邻居的灰度值差异来得出边缘强度。Sobel算子包括两组3x3的卷积核，分别用于检测水平和垂直边缘。</p>
</li>
<li><p>Prewitt算子：类似于Sobel算子，但是卷积核的系数都是1，这使得Prewitt算子对边缘的响应更加“柔和”。</p>
</li>
<li><p>Roberts算子：是一种简单的2x2卷积核，用于检测边缘。Roberts算子通过检测对角线方向的灰度变化来识别边缘。</p>
</li>
<li><p>Canny边缘检测：这是一个多阶段算法，包括噪声降低、梯度计算、非极大值抑制和滞后阈值。Canny算法被认为是最可靠的边缘检测技术之一。</p>
</li>
<li><p>Laplacian算子：是一个二阶导数算子，用于增强图像的边缘。它对图像进行卷积，以突出图像灰度变化的局部极大值和极小值点。</p>
</li>
<li><p>Marr-Hildreth算子或Gaussian of Difference of Gaussians (DoG)：这些算子使用高斯函数和它们的差分来检测边缘。</p>
</li>
</ol>
<h3 id="Sobel算子"><a href="#Sobel算子" class="headerlink" title="Sobel算子"></a>Sobel算子</h3><p>obel算子是一种用于边缘检测的离散微分算子，它结合了高斯平滑和微分求导。该算子用于计算图像明暗程度近似值，根据图像边缘旁边明暗程度把该区域内超过某个数的特定点记为边缘。Sobel算子在Prewitt算子的基础上增加了权重的概念，认为相邻点的距离远近对当前像素点的影响是不同的，距离越近的像素点对应当前像素的影响越大，从而实现图像锐化并突出边缘轮廓。</p>
<p>Sobel算子的边缘定位更准确，常用于噪声较多、灰度渐变的图像。其算法模板如下式所示，其中$G_x$表示水平方向，$G_y$表示垂直方向。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRnjs.jpg">https://s21.ax1x.com/2024/05/14/pkmRnjs.jpg</a>“ width &#x3D; 40% div align&#x3D;center &#x2F; &gt;</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRmcj.jpg">https://s21.ax1x.com/2024/05/14/pkmRmcj.jpg</a>“ width &#x3D; 20% div align&#x3D;center &#x2F; &gt;</p>
<p>在Python中，可以使用OpenCV库中的<code>cv2.Sobel</code>函数来应用Sobel算子。</p>
<h3 id="Canny-边缘检测"><a href="#Canny-边缘检测" class="headerlink" title="Canny 边缘检测"></a>Canny 边缘检测</h3><p>Canny算法是一种著名的边缘检测技术，由John F. Canny在1986年提出。它是一个多阶段算法，旨在从图像中准确地检测出边缘，同时保持边缘的精确定位。Canny算法的基本步骤包括：首先使用高斯滤波器对图像进行平滑以减少噪声；然后计算图像的梯度幅度和方向；接着应用非极大值抑制步骤来细化边缘，只保留局部最大值；最后，通过滞后阈值方法确定和连接边缘像素，这通常涉及两个阈值：高阈值用于检测强边缘，低阈值用于连接这些强边缘以形成完整的边缘。Canny算法因其出色的性能和对边缘的精确识别而广泛应用于计算机视觉和图像处理领域。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmRr4O.jpg">https://s21.ax1x.com/2024/05/14/pkmRr4O.jpg</a>“ width &#x3D; 40% div align&#x3D;center &#x2F; title&#x3D;”边缘检测、图像分割演示图像，请将此图存储为’your_iamge_path_02.jpg’。”&gt;</p>
<p>下面是一个使用OpenCV实现Canny边缘检测的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 使用Canny算法进行边缘检测</span></span><br><span class="line">    edges = cv2.Canny(image, <span class="number">100</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和边缘检测后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Edge Detected Image&#x27;</span>)</span><br><span class="line">    plt.imshow(edges, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。</li>
<li>使用<code>cv2.Canny()</code>函数进行Canny边缘检测。这个函数接受三个参数：输入图像和两个阈值，分别用于连接边缘和检测强边缘。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和边缘检测后的图像。</li>
</ul>
<h2 id="阈值分割"><a href="#阈值分割" class="headerlink" title="阈值分割"></a>阈值分割</h2><p>阈值分割是一种基于像素值的图像处理技术，用于将图像的前景和背景分离。该方法通过设定一个或多个阈值，将像素根据其灰度值分配到不同的类别中。单阈值分割使用一个固定值将图像分为两部分，而多阈值分割则可以用于更细致地将图像分为多个区域。阈值分割简单、快速，适用于目标和背景在灰度上具有明显差异的场景。</p>
<p>以下是使用Python和OpenCV库进行简单阈值分割的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用阈值分割</span></span><br><span class="line">    _, threshold_image = cv2.threshold(image, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和阈值分割后的图像</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Thresholded Image&#x27;</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.imread()</code>函数以灰度模式读取图像文件。</li>
<li>使用<code>cv2.threshold()</code>函数进行阈值分割，其中<code>threshold_value</code>是设定的阈值，<code>max_value</code>是二值化图像中前景的灰度值（通常设置为255表示白色）。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像和阈值分割后的图像。</li>
</ul>
<h2 id="Top-hat-变换"><a href="#Top-hat-变换" class="headerlink" title="Top-hat 变换"></a>Top-hat 变换</h2><p>Top-hat 变换是一种形态学图像处理技术，用于突出图像中相对于背景的较小目标或细节。Top-hat变换的结果是一个图像，其中包含了原始图像与背景（通过开运算处理的图像）之间的差异。这种变换通常用于分离图像中的小物体或特征，这些物体或特征在背景中可能不那么明显。</p>
<p>以下是使用Python和OpenCV库进行Top-hat分割以提取小目标的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">100</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">131</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">132</span>)</span><br><span class="line">    plt.imshow(tophat, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">133</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Segementation&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>定义用于形态学操作的卷积核。</li>
<li>使用<code>cv2.morphologyEx()</code>函数进行Top-hat变换，其中<code>cv2.MORPH_TOPHAT</code>指定了Top-hat操作。</li>
<li>使用<code>matplotlib.pyplot的subplot()</code>和<code>imshow()</code>函数显示原始图像和Top-hat变换结果。</li>
</ul>
<h2 id="膨胀与腐蚀"><a href="#膨胀与腐蚀" class="headerlink" title="膨胀与腐蚀"></a>膨胀与腐蚀</h2><p>图像膨胀与腐蚀是两种基本的形态学图像处理技术，用于修改图像中物体的轮廓和结构。膨胀操作通过增加物体边界像素来“膨胀”或增厚图像中的前景对象，而腐蚀操作则通过移除物体边界像素来“腐蚀”或减薄前景对象。这两种技术可以用于分离相邻对象、平滑轮廓、填充小孔以及从背景中分离出前景对象。</p>
<p>以下是使用Python和OpenCV库进行膨胀与腐蚀操作的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用膨胀操作</span></span><br><span class="line">    dilation = cv2.dilate(threshold_image, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用腐蚀操作</span></span><br><span class="line">    erosion = cv2.erode(threshold_image, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">141</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">142</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">143</span>)</span><br><span class="line">    plt.imshow(dilation, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;dilation image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">144</span>)</span><br><span class="line">    plt.imshow(erosion, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;erosion image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>函数定义一个卷积核，用于膨胀和腐蚀操作。</li>
<li>使用<code>cv2.dilate()</code>函数对图像进行膨胀操作，<code>iterations</code>&#x3D;1表示膨胀操作应用的次数。</li>
<li>使用<code>cv2.erode()</code>函数对图像进行腐蚀操作，同样可以指定腐蚀的次数。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>imshow()</code>函数显示原始图像、膨胀后的图像和腐蚀后的图像。</li>
</ul>
<p>膨胀和腐蚀是形态学图像处理中非常有用的工具，它们可以单独使用，也可以结合使用，或者与其他图像处理技术结合使用，以实现更复杂的图像分析任务。</p>
<h2 id="开运算与闭运算"><a href="#开运算与闭运算" class="headerlink" title="开运算与闭运算"></a>开运算与闭运算</h2><p>开运算和闭运算是两种用于图像处理的形态学操作。开运算首先进行腐蚀操作，然后是对腐蚀结果进行膨胀，目的是移除小的物体或细节（如噪声），并断开接近的物体。闭运算先进行膨胀操作，然后是腐蚀，目的是填充小的空洞和缝隙，以及平滑较大物体的边界。</p>
<p>以下是使用Python和OpenCV库进行开运算与闭运算的示例代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取图像</span></span><br><span class="line">image_path = <span class="string">&#x27;your_image_path_02.jpg&#x27;</span>  <span class="comment"># 替换为你的图像路径</span></span><br><span class="line">image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  <span class="comment"># 以灰度模式读取图像</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查图像是否正确加载</span></span><br><span class="line"><span class="keyword">if</span> image <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error: 图像未正确加载。请检查路径。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 设置阈值和最大值</span></span><br><span class="line">    threshold_value = <span class="number">127</span></span><br><span class="line">    max_value = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义卷积核</span></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">12</span>, <span class="number">12</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用Top-hat变换</span></span><br><span class="line">    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)</span><br><span class="line"></span><br><span class="line">    _, threshold_image = cv2.threshold(tophat, threshold_value, max_value, cv2.THRESH_BINARY)</span><br><span class="line"></span><br><span class="line">    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 应用开运算</span></span><br><span class="line">    opening = cv2.morphologyEx(threshold_image, cv2.MORPH_OPEN, kernel)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 应用闭运算</span></span><br><span class="line">    closing = cv2.morphologyEx(threshold_image, cv2.MORPH_CLOSE, kernel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示原始图像和Top-hat变换结果</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>, <span class="number">4</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">141</span>)</span><br><span class="line">    plt.imshow(image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Original Image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">142</span>)</span><br><span class="line">    plt.imshow(threshold_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Top-hat Transform&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">143</span>)</span><br><span class="line">    plt.imshow(opening, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;opening image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">144</span>)</span><br><span class="line">    plt.imshow(closing, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;closing image&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<ul>
<li>使用<code>cv2.getStructuringElement()</code>定义卷积核。</li>
<li>使用<code>cv2.morphologyEx()</code>函数进行开运算和闭运算，其中<code>cv2.MORPH_OPEN和cv2.MORPH_CLOSE</code>分别指定了开运算和闭运算。</li>
<li>使用<code>matplotlib.pyplot</code>的<code>subplot()</code>和<code>imshow()</code>函数显示原始图像、开运算结果和闭运算结果。</li>
</ul>
<h2 id="Watershed-算法"><a href="#Watershed-算法" class="headerlink" title="Watershed 算法"></a>Watershed 算法</h2><p>Watershed算法是一种基于图像分割的技术，用于在灰度图中区分重叠的物体或不同的区域。它模拟了水文学中的分水岭概念，将图像的灰度值视为地形高度，而将局部最小值（如空洞或凹陷）视为集水盆。</p>
<p>在图像处理中，Watershed算法通常用于将接触或重叠的对象分开，特别适用于分离那些在传统阈值分割中难以区分的相邻对象。算法首先标记图像中的已知区域（这些区域可以是用户定义的或通过其他分割技术获得的），然后模拟水流，让“水”从高到低流入这些区域，直到它们相遇或被边界阻挡。相遇的点形成了算法所说的“分水岭”。</p>
<p>&lt;img src&#x3D;”<a href="https://s21.ax1x.com/2024/05/14/pkmhpjJ.jpg">https://s21.ax1x.com/2024/05/14/pkmhpjJ.jpg</a>“ width &#x3D; 25% div align&#x3D;center &#x2F; title&#x3D;”watershed分割演示图像，请将此图存储为’water_coins.jpg’。”&gt;</p>
<p>下面我们将看到一个关于如何使用距离变换和分水岭分割相互接触的对象的示例。考虑下面的硬币图片，硬币互相接触。即使你启动它，它也会相互接触。我们从找到硬币的大致估计数开始。为此，我们可以使用Otsu的二值化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;water_coins.jpg&#x27;</span>)</span><br><span class="line">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class="line">ret, thresh = cv2.threshold(gray,<span class="number">0</span>,<span class="number">255</span>,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)</span><br><span class="line">plt.imshow(thresh)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>现在我们需要去除图像中的任何小的白噪声。为此，我们可以使用形态开口。要去除物体上的任何小孔，我们可以使用形态闭合。所以，现在我们可以确定靠近物体中心的区域是前景，而远离物体的区域是背景。唯一我们不确定的区域是硬币的边界区域。</p>
<p>所以我们需要提取出我们确定它们是硬币的区域。侵蚀移除边界像素。所以不管剩下什么，我们都可以确定是硬币。如果物体不互相接触，那就行了。但由于它们彼此接触，另一个好的选择是找到距离变换并应用适当的阈值。下一步我们需要找到我们确信它们不是硬币的地方。为此，我们扩大了结果。膨胀增加对象边界到背景。这样，我们就可以确定结果中背景中的任何区域都是真实的背景，因为边界区域被移除了。见下图。</p>
<p>剩下的区域是那些我们不知道的区域，无论是硬币还是背景。分水岭算法应该找到它。这些区域通常围绕着硬币的边界，前景和背景相交（甚至两个不同的硬币相交）。我们称之为边界。它可以从sure-bg区域减去sure-fg区域得到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># noise removal</span></span><br><span class="line">kernel = np.ones((<span class="number">3</span>,<span class="number">3</span>),np.uint8)</span><br><span class="line">opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sure background area</span></span><br><span class="line">sure_bg = cv2.dilate(opening,kernel,iterations=<span class="number">3</span>)</span><br><span class="line">plt.imshow(sure_bg)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Finding sure foreground area</span></span><br><span class="line">dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,<span class="number">5</span>)</span><br><span class="line">ret, sure_fg = cv2.threshold(dist_transform,<span class="number">0.7</span>*dist_transform.<span class="built_in">max</span>(),<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Finding unknown region</span></span><br><span class="line">sure_fg = np.uint8(sure_fg)</span><br><span class="line">unknown = cv2.subtract(sure_bg,sure_fg)</span><br><span class="line">plt.imshow(sure_fg)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>看看结果。在阈值图像中，我们得到一些区域的硬币，我们确定的硬币，他们现在分离。（在某些情况下，您可能只对前景分割感兴趣，而不是分离相互接触的对象。在这种情况下，你不需要使用距离变换，只要侵蚀就足够了。侵蚀只是另一种提取前景区域的方法，仅此而已。）</p>
<p>现在我们可以确定哪些是硬币的区域，哪些是背景和全部。因此，我们创建了marker（它是一个与原始图像大小相同的数组，但具有int32数据类型）并标记其中的区域。我们确定的区域（无论是前景还是背景）被标记为任何正整数，但是不同的整数，我们不确定的区域被保留为零。我们用这个 连接组件. 它用0标记图像的背景，然后用从1开始的整数标记其他对象。</p>
<p>但我们知道，如果背景标记为0，流域会将其视为未知区域。所以我们想用不同的整数来标记它。相反，我们将标记未知区域，定义为 <code>unknown</code>，使用0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Marker labelling</span></span><br><span class="line">ret, markers = cv2.connectedComponents(sure_fg)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add one to all labels so that sure background is not 0, but 1</span></span><br><span class="line">markers = markers+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, mark the region of unknown with zero</span></span><br><span class="line">markers[unknown==<span class="number">255</span>] = <span class="number">0</span></span><br><span class="line">plt.imshow(markers)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>请参见JET colormap中显示的结果。深蓝色区域显示未知区域。当然硬币有不同的颜色。与未知区域相比，确定背景显示为浅蓝色的剩余区域。</p>
<p>现在我们的标记准备好了。现在是最后一步，应用分水岭。然后标记图像将被修改。边界区域将标记为-1。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">markers = cv2.watershed(img,markers)</span><br><span class="line">img[markers == -<span class="number">1</span>] = [<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">plt.imshow(markers)</span><br><span class="line">pylab.show()</span><br></pre></td></tr></table></figure>

<p>请注意，分水岭算法的结果是一个标记图像，其中每个连通区域被赋予了一个唯一的标记值。通常，这个标记图像可以转换为二值图像以可视化分割结果。</p>
<h1 id="数据拟合"><a href="#数据拟合" class="headerlink" title="数据拟合"></a>数据拟合</h1><p>数据拟合是数据分析和科学计算中的一个重要环节，它涉及到使用数学模型来模拟或预测数据。Python是一个功能强大的编程语言，它提供了许多库来帮助我们进行数据拟合，其中最常用的是NumPy和SciPy库。</p>
<h2 id="线性拟合、多项式拟合"><a href="#线性拟合、多项式拟合" class="headerlink" title="线性拟合、多项式拟合"></a>线性拟合、多项式拟合</h2><p>多项式拟合是使用多项式函数来拟合数据的一种方法。在Python中，我们可以使用numpy库中的polyfit函数或者scipy库中的polyval函数来进行多项式拟合。下面是一个使用numpy进行多项式拟合的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们有一些数据点</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">12</span>, <span class="number">18</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numpy的polyfit进行多项式拟合，这里选择3次多项式</span></span><br><span class="line">p = np.polyfit(x, y, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合系数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;多项式系数:&quot;</span>, p)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用拟合系数生成多项式函数</span></span><br><span class="line">polynomial = np.poly1d(p)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">xx = np.arange(<span class="number">1</span>,<span class="number">5</span>,<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 生成拟合曲线的y值</span></span><br><span class="line">y_poly = polynomial(xx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据点和拟合曲线</span></span><br><span class="line">plt.scatter(x, y, label=<span class="string">&#x27;Data Points&#x27;</span>)</span><br><span class="line">plt.plot(xx, y_poly, label=<span class="string">&#x27;Polynomial Fit&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>在这个示例中，<code>np.polyfit</code>函数用于计算最佳拟合多项式的系数。参数3表示我们希望得到的是3次多项式（即包含x^3,x^2,x和常数项的多项式）。<code>np.poly1d</code>函数用于根据拟合得到的系数创建一个多项式函数对象，这个对象可以用来计算任意x值的多项式函数值。</p>
<p>最后，我们使用matplotlib库绘制了原始数据点和拟合的多项式曲线。通过调整多项式的阶数，我们可以得到与数据拟合程度不同的多项式曲线。</p>
<h2 id="非线性拟合"><a href="#非线性拟合" class="headerlink" title="非线性拟合"></a>非线性拟合</h2><p>指数函数拟合是一种常用的非线性拟合方法，特别适用于数据随时间或空间指数增长或衰减的情况。在Python中，我们可以使用scipy.optimize.curve_fit函数来实现指数函数的拟合。</p>
<p>下面是一个使用指数函数拟合数据的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义指数函数模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">exponential_func</span>(<span class="params">x, a, b, c</span>):</span><br><span class="line">    <span class="keyword">return</span> a * np.exp(-b * x) + c</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一些模拟数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">0</span>, <span class="number">4</span>, <span class="number">100</span>)  <span class="comment"># x值从0到4，生成100个点</span></span><br><span class="line">y_data = <span class="number">5</span> * np.exp(-<span class="number">0.5</span> * x_data) + <span class="number">2</span> + np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, x_data.size)  <span class="comment"># y值是指数函数加上一些噪声</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用curve_fit进行指数函数拟合</span></span><br><span class="line">params, _ = curve_fit(exponential_func, x_data, y_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拟合参数</span></span><br><span class="line">a, b, c = params</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;拟合参数: a = <span class="subst">&#123;a&#125;</span>, b = <span class="subst">&#123;b&#125;</span>, c = <span class="subst">&#123;c&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用拟合参数生成拟合数据</span></span><br><span class="line">y_fit = exponential_func(x_data, *params)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始数据点和拟合曲线</span></span><br><span class="line">plt.scatter(x_data, y_data, label=<span class="string">&#x27;Data Points&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.plot(x_data, y_fit, label=<span class="string">&#x27;Exponential Fit&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Exponential Function Fitting&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>我们首先定义了一个指数函数模型exponential_func，它具有三个参数a、b和c。</p>
<p>然后，我们生成了一些模拟的指数增长数据，并添加了一些正态分布的噪声。</p>
<p>使用curve_fit函数进行指数函数拟合。这个函数将我们的指数函数模型和数据作为输入，并返回最佳拟合参数。</p>
<p>我们打印出拟合得到的参数，并使用这些参数生成了拟合的y值。</p>
<p>最后，我们使用matplotlib库绘制了原始数据点和拟合的指数曲线。</p>
<p>请注意，指数函数拟合的准确性很大程度上取决于数据的质量和模型的选择。在实际应用中，你可能需要尝试不同的模型和参数来找到最佳的拟合结果。</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 12：聚类分析</title>
    <url>/PythonLes13/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>今天总结了最常见的五种聚类算法。涉及到的算法有：</p>
<ul>
<li>K均值聚类（K-Means Clustering）</li>
<li>层次聚类（Hierarchical Clustering）</li>
<li>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</li>
<li>高斯混合模型（Gaussian Mixture Model，GMM）</li>
<li>谱聚类（Spectral Clustering）</li>
</ul>
<span id="more"></span>

<h2 id="课程作业03-占总成绩25"><a href="#课程作业03-占总成绩25" class="headerlink" title="课程作业03 占总成绩25%"></a>课程作业03 占总成绩25%</h2><p>构建四组二维空间中的随机分布散点，每组散点符合二维高斯分布，高斯分布的中心点与两个方向的标准差均随机产生，且二维高斯分布的中心点落在[[0,100],[0,100]]的方形区域内。</p>
<p>通过K均值聚类分析方法对上述随机散点执行聚类分析，绘制分类结果，并计算K-means聚类分析的准确率。</p>
<h2 id="K均值聚类（K-Means-Clustering）"><a href="#K均值聚类（K-Means-Clustering）" class="headerlink" title="K均值聚类（K-Means Clustering）"></a>K均值聚类（K-Means Clustering）</h2><p>K均值聚类（K-Means Clustering）是一种常用的无监督学习算法，用于将数据集分成K个簇（clusters）。其目标是将相似的数据点归为同一簇，而将不同的数据点分到不同的簇中，从而使得每个簇内的数据点之间的相似度最大，而不同簇之间的相似度最小。</p>
<h3 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h3><p>K均值聚类的核心思想是通过迭代优化的方法，最小化簇内点到簇中心的总距离平方和。</p>
<p>基本步骤如下：</p>
<ol>
<li><p>初始化：随机选择K个点作为初始簇中心。</p>
</li>
<li><p>分配簇：将每个数据点分配到最近的簇中心。</p>
</li>
<li><p>更新簇中心：重新计算每个簇的中心（即簇内所有点的平均值）。</p>
</li>
<li><p>重复：重复步骤2和3，直到簇中心不再发生显著变化或达到预定的迭代次数。</p>
</li>
</ol>
<h3 id="核心公式"><a href="#核心公式" class="headerlink" title="核心公式"></a>核心公式</h3><p>假设数据集为$x_1,x_2,…,x_n$，每个数据点$x_i$有$d$维。簇的中心为$\mu_1,\mu_2,…,\mu_K$。</p>
<ol>
<li><p>距离计算：通常使用欧氏距离：<br>\begin{equation}<br>{\bf dist}(x_i,\mu_k) &#x3D; \Arrowvert x_i-\mu_k\Arrowvert_2 &#x3D; \sqrt{\sum^d_{j&#x3D;1} (x_{ij}-\mu_{kj})^2}<br>\end{equation}</p>
</li>
<li><p>簇分配：将每个点分配到最近的簇中心：<br>\begin{equation}<br>C_k &#x3D; {x_i:\Arrowvert x_i-\mu_k \Arrowvert_2 \leq \Arrowvert x_i - \mu_j\Arrowvert_2, \forall j,1 \leq j \leq K }<br>\end{equation}</p>
</li>
<li><p>更新簇中心：重新计算每个簇的中心：<br>\begin{equation}<br>\mu_k &#x3D; \frac{1}{|C_k|} \sum_{x_i \in C_k} x_i<br>\end{equation}</p>
</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUF3JP.png" width="75%" alt="" align=center />

<h4 id="Python示例代码"><a href="#Python示例代码" class="headerlink" title="Python示例代码"></a>Python示例代码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用KMeans进行聚类</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">4</span>)</span><br><span class="line">kmeans.fit(X)</span><br><span class="line">y_kmeans = kmeans.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_kmeans, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line">plt.title(<span class="string">&quot;K-Means Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成了500个二维数据点，分为4个簇。</p>
</li>
<li><p>训练模型：使用KMeans模型进行训练，设定簇数为4。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出簇中心。</p>
</li>
</ol>
<p>大家可以清晰地看到K均值聚类的效果，即每个簇内的数据点被分为同一种颜色，而不同簇的数据点被分为不同颜色，同时簇中心用红色圆点表示。</p>
<h2 id="层次聚类（Hierarchical-Clustering）"><a href="#层次聚类（Hierarchical-Clustering）" class="headerlink" title="层次聚类（Hierarchical Clustering）"></a>层次聚类（Hierarchical Clustering）</h2><p>层次聚类（Hierarchical Clustering）是一种常见的无监督学习算法，旨在通过构建层次树状结构将数据点进行分组。它可以分为两种类型：自底向上的聚合（agglomerative）和自顶向下的分裂（divisive）聚类方法。</p>
<h3 id="核心原理-1"><a href="#核心原理-1" class="headerlink" title="核心原理"></a>核心原理</h3><p>层次聚类的核心思想是通过递归地合并或分裂簇，构建一个层次树（树状图或树状图），表示数据的嵌套分组。这里我们以自底向上的聚合层次聚类为例：</p>
<ol>
<li><p>初始化：将每个数据点视为一个独立的簇。</p>
</li>
<li><p>计算距离：计算所有簇之间的距离矩阵。</p>
</li>
<li><p>合并簇：找到距离最近的两个簇并合并它们。</p>
</li>
<li><p>更新距离矩阵：更新合并后的簇与其他簇之间的距离。</p>
</li>
<li><p>重复：重复步骤3和4，直到所有数据点合并成一个簇。</p>
</li>
</ol>
<h3 id="核心公式-1"><a href="#核心公式-1" class="headerlink" title="核心公式"></a>核心公式</h3><p>假设数据集为$x_1, x_2, …,x_n$，簇之间的距离可以通过多种方式计算，包括最小距离（single linkage）、最大距离（complete linkage）和平均距离（average linkage）等。</p>
<ol>
<li>距离计算：假设簇$A$和簇$B$中的点分别为$a_1, a_2,…,a_p$和$b_1,b_2,…b_q$，则不同的距离计算方法如下：</li>
</ol>
<ul>
<li><p>最小距离（单链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \min_{i,j} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
<li><p>最大距离（全链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \max_{i,j} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
<li><p>平均距离（平均链法）：<br>\begin{equation}<br>d(A,B) &#x3D; \frac{1}{pq} \sum^{p}<em>{i&#x3D;1} \sum^{q}</em>{j&#x3D;1} \Arrowvert a_i-b_j \Arrowvert<br>\end{equation}</p>
</li>
</ul>
<img src="https://s21.ax1x.com/2024/06/11/pkUFMdA.png" width="75%" alt="" align=center />

<h4 id="Python案例"><a href="#Python案例" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">3</span>, random_state=<span class="number">0</span>, cluster_std=<span class="number">0.60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行层次聚类</span></span><br><span class="line">Z = linkage(X, method=<span class="string">&#x27;ward&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制树状图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">dendrogram(Z, truncate_mode=<span class="string">&#x27;lastp&#x27;</span>, p=<span class="number">12</span>, leaf_rotation=<span class="number">90.</span>, leaf_font_size=<span class="number">12.</span>, show_contracted=<span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Hierarchical Clustering Dendrogram&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Sample index or (Cluster size)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Distance&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成500个二维数据点，分为3个簇。</p>
</li>
<li><p>层次聚类：使用linkage函数进行层次聚类，采用Ward方法计算簇间距离。</p>
</li>
<li><p>绘制树状图：使用dendrogram函数绘制树状图，展示聚类的层次结构。</p>
</li>
</ol>
<p>通过树状图，大家可以清晰地看到层次聚类的合并过程，从最底层的单个数据点逐渐合并到最终的一个簇。树状图的高度表示簇之间的距离，合并越早的簇之间距离越近，合并越晚的簇之间距离越远。</p>
<h2 id="DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）"><a href="#DBSCAN（Density-Based-Spatial-Clustering-of-Applications-with-Noise）" class="headerlink" title="DBSCAN（Density-Based Spatial Clustering of Applications with Noise）"></a>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</h2><p>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）是一种基于密度的聚类算法，可以发现任意形状的簇，同时能够识别出噪声点。与K均值和层次聚类不同，DBSCAN不需要事先指定簇的数量。</p>
<h3 id="核心原理-2"><a href="#核心原理-2" class="headerlink" title="核心原理"></a>核心原理</h3><p>DBSCAN通过在数据点周围划定一个$\varepsilon$半径，计算半径内的数据点数量来定义簇。其基本思想是密度足够高的区域形成簇，而密度较低的区域被认为是噪声。主要步骤如下：</p>
<ol>
<li><p>定义核心点：对于数据集中每个点，如果在其ε半径内的点数大于或等于最小点数（minPts），则该点为核心点。</p>
</li>
<li><p>扩展簇：从核心点出发，将其邻域内的所有点（包括边界点和其他核心点）归入该簇，然后递归地将这些点的邻域内的点也归入该簇。</p>
</li>
<li><p>标记噪声点：如果一个点既不是核心点也不是边界点，则将其标记为噪声点。</p>
</li>
</ol>
<h3 id="核心公式-2"><a href="#核心公式-2" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>邻域定义：对于点$p$，其邻域定义为：<br>\begin{equation}<br>N_{\varepsilon}(p) &#x3D; { q \in D|{\bf dist}(p,q)\leq \varepsilon }<br>\end{equation}</li>
</ol>
<p>其中 $D$ 是数据集，${\bf dist}(p,q)$ 是点 $p$ 和点 $q$ 之间的距离，通常使用欧氏距离。</p>
<ol start="2">
<li>核心点：如果点 $p$ 的邻域包含至少 minPts 个点，则 $p$ 是核心点：<br>\begin{equation}<br>|N_{\varepsilon}(p)| \geq {\bf minPts}<br>\end{equation}</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUF1it.png" width="75%" alt="" align=center />

<h4 id="Python案例-1"><a href="#Python案例-1" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.1</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用DBSCAN进行聚类</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.2</span>, min_samples=<span class="number">5</span>)</span><br><span class="line">y_dbscan = dbscan.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y_dbscan, s=<span class="number">50</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标记噪声点</span></span><br><span class="line">core_samples_mask = np.zeros_like(y_dbscan, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[dbscan.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line">noise_mask = (y_dbscan == -<span class="number">1</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">50</span>, label=<span class="string">&#x27;Noise&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;DBSCAN Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_moons生成500个二维数据点，这些数据点形成两个半月形簇，并添加了一定的噪声。</p>
</li>
<li><p>训练模型：使用DBSCAN模型进行训练，设置$\varepsilon$为0.2，minPts为5。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出噪声点。</p>
</li>
</ol>
<p>大家可以清晰地看到DBSCAN的聚类效果，两个半月形的簇被正确识别出来，噪声点用红色标注。DBSCAN能够很好地处理复杂形状的簇，并且能够识别出数据中的噪声点。</p>
<h2 id="高斯混合模型（Gaussian-Mixture-Model，GMM）"><a href="#高斯混合模型（Gaussian-Mixture-Model，GMM）" class="headerlink" title="高斯混合模型（Gaussian Mixture Model，GMM）"></a>高斯混合模型（Gaussian Mixture Model，GMM）</h2><p>高斯混合模型（GMM）是一种概率模型，它假设所有的数据点是由若干个不同的高斯分布（即正态分布）组成的混合生成。GMM常用于聚类分析，特别适合于发现复杂数据分布中的潜在群体结构。</p>
<h3 id="核心原理-3"><a href="#核心原理-3" class="headerlink" title="核心原理"></a>核心原理</h3><p>GMM通过期望最大化（EM）算法来估计模型参数。EM算法是一个迭代优化算法，包括两个主要步骤：</p>
<ol>
<li><p>E步（Expectation）：计算给定当前参数下每个数据点属于每个高斯分布的概率（即责任）。</p>
</li>
<li><p>M步（Maximization）：根据计算出的责任，重新估计每个高斯分布的参数（均值、方差和权重）。</p>
</li>
</ol>
<h3 id="核心公式-3"><a href="#核心公式-3" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>高斯混合模型的概率密度函数：<br>\begin{equation}<br>p(x) &#x3D; \sum^{K}_{k &#x3D; 1}\pi_k \mathcal{N}(x|\mu_k,\Sigma_k)<br>\end{equation}</li>
</ol>
<p>其中，$\pi_k$是第$k$个高斯分布的权重，$\mathcal{N}(x|\mu_k,\sum_k)$是第$k$个高斯分布的概率密度函数，其参数为均值$\mu_k$和协方差矩阵$\Sigma_k$。</p>
<ol start="2">
<li>E步（计算责任）：<br>\begin{equation}<br>\gamma_{ik} &#x3D; \frac{\pi_k\mathcal{N}(x|\mu_k,\Sigma_k)}{\sum_{j &#x3D; 1}^{K}\pi_j \mathcal{N}(x|\mu_k,\Sigma_k)}<br>\end{equation}</li>
</ol>
<p>其中，$\gamma_{ik}$是数据点$x_i$属于第$k$个高斯分布的概率。</p>
<ol start="3">
<li>M步（更新参数）：</li>
</ol>
<p>更新权重：<br>\begin{equation}<br>\pi_k &#x3D; \frac{N_k}{N}<br>\end{equation}</p>
<p>其中，$N_k &#x3D; \sum_{i&#x3D;1}^{N} \gamma_{ik}$是第$k$个高斯分布的有效样本数，$N$是数据点总数。</p>
<p>更新均值：<br>\begin{equation}<br>\mu_k &#x3D; \frac{1}{N_k}\sum_{i&#x3D;1}^{N} \gamma_{ik}x_i<br>\end{equation}</p>
<p>更新协方差矩阵：<br>\begin{equation}<br>\Sigma_k &#x3D; \frac{1}{N_k}\sum_{i&#x3D;1}^{N}\gamma_{ik}(x_i-\mu_k)(x_i-\mu_k)^{T}<br>\end{equation}</p>
<img src="https://s21.ax1x.com/2024/06/11/pkUFKZd.png" width="75%" alt="" align=center />


<h4 id="Python案例-2"><a href="#Python案例-2" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">500</span>, centers=<span class="number">3</span>, random_state=<span class="number">42</span>, cluster_std=<span class="number">0.60</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GMM进行聚类</span></span><br><span class="line">gmm = GaussianMixture(n_components=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">gmm.fit(X)</span><br><span class="line">labels = gmm.predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, s=<span class="number">40</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.scatter(gmm.means_[:, <span class="number">0</span>], gmm.means_[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, alpha=<span class="number">0.75</span>, marker=<span class="string">&#x27;X&#x27;</span>)  <span class="comment"># 标记出中心点</span></span><br><span class="line">plt.title(<span class="string">&quot;Gaussian Mixture Model Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用make_blobs生成500个二维数据点，分为3个簇，并添加一定的噪声。</p>
</li>
<li><p>训练模型：使用GaussianMixture模型进行训练，设定簇数为3。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色，同时用红色标注出每个高斯分布的均值。</p>
</li>
</ol>
<p>大家可以看到GMM的聚类效果，每个簇用不同的颜色表示，红色的X标记出每个高斯分布的中心。GMM能够很好地处理复杂的簇结构，并且可以估计每个簇的概率分布。</p>
<h2 id="谱聚类（Spectral-Clustering）"><a href="#谱聚类（Spectral-Clustering）" class="headerlink" title="谱聚类（Spectral Clustering）"></a>谱聚类（Spectral Clustering）</h2><p>谱聚类（Spectral Clustering）是一种基于图论的聚类方法，通过利用数据点之间的相似性构建图，并利用图的谱（特征值和特征向量）进行聚类。它特别适合处理非凸形状的簇，并且能有效处理高维数据。</p>
<h3 id="核心原理-4"><a href="#核心原理-4" class="headerlink" title="核心原理"></a>核心原理</h3><p>谱聚类的核心思想是将数据点看作图中的节点，通过计算节点之间的相似性构建加权图，然后通过图的拉普拉斯矩阵的特征向量将数据映射到低维空间，再在低维空间中进行K均值聚类。</p>
<p>主要步骤如下：</p>
<ol>
<li><p>构建相似度矩阵：计算数据点之间的相似度，构建相似度矩阵。</p>
</li>
<li><p>构建拉普拉斯矩阵：根据相似度矩阵构建图的拉普拉斯矩阵。</p>
</li>
<li><p>计算特征向量：计算拉普拉斯矩阵的前k个特征向量，将数据点映射到低维空间。</p>
</li>
<li><p>聚类：在低维空间中对映射后的数据点进行K均值聚类。</p>
</li>
</ol>
<h3 id="核心公式-4"><a href="#核心公式-4" class="headerlink" title="核心公式"></a>核心公式</h3><ol>
<li>相似度矩阵$W$：<br>\begin{equation}<br>W_{ij} &#x3D; \exp\left(-\frac{\Arrowvert x_i-x_j \Arrowvert^2}{2\sigma^2}\right) \quad {\bf if} \quad \Arrowvert x_i - x_j \Arrowvert \leq \varepsilon, {\bf else} \quad 0<br>\end{equation}</li>
</ol>
<p>其中，$\sigma$是高斯核函数的参数，$\varepsilon$是邻域范围。</p>
<ol start="2">
<li><p>度矩阵$D$：<br>\begin{equation}<br>D_{ij} &#x3D; \sum_{j} W_{ij}<br>\end{equation}</p>
</li>
<li><p>拉普拉斯矩阵$L$：<br>\begin{equation}<br>L &#x3D; D-W<br>\end{equation}</p>
</li>
</ol>
<p>或归一化的拉普拉斯矩阵：<br>\begin{equation}<br>L_{sym} &#x3D; D^{-1&#x2F;2}LD^{-1&#x2F;2}<br>\end{equation}</p>
<ol start="4">
<li><p>特征向量：计算$L$或$L_{sym}$的前$k$个特征向量$u_1,u_2,…,u_k$。</p>
</li>
<li><p>聚类：将每个数据点$x_i$映射到特征向量组成的低维空间，再对这些向量进行$K$均值聚类。</p>
</li>
</ol>
<img src="https://s21.ax1x.com/2024/06/11/pkUFQII.png" width="75%" alt="" align=center />

<h4 id="Python案例-3"><a href="#Python案例-3" class="headerlink" title="Python案例"></a>Python案例</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> SpectralClustering</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成样本数据</span></span><br><span class="line">X, y = make_moons(n_samples=<span class="number">500</span>, noise=<span class="number">0.1</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用谱聚类进行聚类</span></span><br><span class="line">spectral = SpectralClustering(n_clusters=<span class="number">2</span>, affinity=<span class="string">&#x27;nearest_neighbors&#x27;</span>, assign_labels=<span class="string">&#x27;kmeans&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">labels = spectral.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果图</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, s=<span class="number">40</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Spectral Clustering&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Feature 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature 2&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<ol>
<li><p>生成数据：使用<code>make_moons</code>生成500个二维数据点，形成两个半月形簇，并添加一定的噪声。</p>
</li>
<li><p>训练模型：使用<code>SpectralClustering</code>模型进行训练，设定簇数为2，使用最近邻相似度计算，标签分配使用K均值。</p>
</li>
<li><p>预测与绘图：根据训练结果进行预测，并将数据点按簇绘制成不同颜色。</p>
</li>
</ol>
<p>可以看到谱聚类的效果，两个半月形的簇被正确识别出来，每个簇用不同的颜色表示。谱聚类通过利用数据点之间的相似性构建图结构，并通过图的谱（特征向量）进行聚类，有效地处理了复杂形状的簇结构。</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 11：Python 环境下的科研论文绘图</title>
    <url>/PythonLes12/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>在Python中进行科研论文绘图，有几个常用的库可以帮助你实现高质量的图表绘制，以满足学术期刊的要求。Matplotlib是Python中一个非常流行的绘图库，它提供了丰富的功能来创建各种图表。但是，默认的Matplotlib样式可能不符合某些期刊的特定要求。为了解决这个问题，可以使用自定义的样式或者样式库来调整图表的外观。SciencePlots是一个专门为科研图表设计的样式库，它提供了多种符合不同期刊发表要求的主题样式。你可以使用这个库来快速设置图表的样式，以满足期刊的标准。</p>
<p>本文总结了 Matplotlib 以及 Seaborn 用的最多的50个图形，掌握这些图形的绘制，对于数据分析的可视化有莫大的作用，强烈推荐大家阅读后续内容。来源：<a href="https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/">https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/</a></p>
<span id="more"></span>

<p>本文所使用示例数据链接：<a href="https://pan.baidu.com/s/15utfb0uuPu32YHv76S4WUw">https://pan.baidu.com/s/15utfb0uuPu32YHv76S4WUw</a>, 提取码：kn6p</p>
<h1 id="有效图表的重要特征"><a href="#有效图表的重要特征" class="headerlink" title="有效图表的重要特征"></a>有效图表的重要特征</h1><ul>
<li>在不歪曲事实的情况下传达正确和必要的信息。</li>
<li>设计简单，您不必太费力就能理解它。</li>
<li>从审美角度支持信息而不是掩盖信息。</li>
<li>信息没有超负荷。</li>
</ul>
<h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><p>在代码运行前先引入下面的设置内容。 当然，单独的图表，可以重新设置显示要素。其中设置了不显示warnings（由于版本变动导致的函数变动），图片以嵌入式方式展示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> warnings; warnings.filterwarnings(action=<span class="string">&#x27;once&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set the  fontsize and some other elements</span></span><br><span class="line">large = <span class="number">22</span>; med = <span class="number">16</span>; small = <span class="number">12</span></span><br><span class="line">params = &#123;<span class="string">&#x27;axes.titlesize&#x27;</span>: large,</span><br><span class="line">          <span class="string">&#x27;legend.fontsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;figure.figsize&#x27;</span>: (<span class="number">16</span>, <span class="number">10</span>),</span><br><span class="line">          <span class="string">&#x27;axes.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;xtick.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;ytick.labelsize&#x27;</span>: med,</span><br><span class="line">          <span class="string">&#x27;figure.titlesize&#x27;</span>: large&#125;</span><br><span class="line">plt.rcParams.update(params)</span><br><span class="line"><span class="comment"># plt.style.use(&#x27;seaborn-whitegrid&#x27;)</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print Version</span></span><br><span class="line"><span class="built_in">print</span>(mpl.__version__)  </span><br><span class="line"><span class="built_in">print</span>(sns.__version__)</span><br><span class="line"><span class="number">3.6</span><span class="number">.2</span></span><br><span class="line"><span class="number">0.12</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>


<h1 id="关联-（Correlation）"><a href="#关联-（Correlation）" class="headerlink" title="关联 （Correlation）"></a>关联 （Correlation）</h1><p>关联图表用于可视化2个或更多变量之间的关系。 也就是说，一个变量如何相对于另一个变化。</p>
<h2 id="点线图（Scatter-and-line-plot）"><a href="#点线图（Scatter-and-line-plot）" class="headerlink" title="点线图（Scatter and line plot）"></a>点线图（Scatter and line plot）</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">11</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line">y = np.cos(-x**<span class="number">2</span>/<span class="number">9.0</span>)</span><br><span class="line">f = interp1d(x, y)</span><br><span class="line">f2 = interp1d(x, y, kind=<span class="string">&#x27;cubic&#x27;</span>)</span><br><span class="line">xnew = np.linspace(<span class="number">0</span>, <span class="number">10</span>, num=<span class="number">41</span>, endpoint=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;o&#x27;</span>, xnew, f(xnew), <span class="string">&#x27;-&#x27;</span>, xnew, f2(xnew), <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;data&#x27;</span>, <span class="string">&#x27;linear&#x27;</span>, <span class="string">&#x27;cubic&#x27;</span>], loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;X-axis&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Y-axis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Multiple Lines Plot&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-1.png" width="75%" alt="" align=center />

<h3 id="plt-plot-函数"><a href="#plt-plot-函数" class="headerlink" title="plt.plot()函数"></a>plt.plot()函数</h3><p>函数<code>matplotlib.pyplot.plot()</code>将多组数据对绘制为点线图，形如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plot(x, y, color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>,linewidth=<span class="number">2</span>, markersize=<span class="number">12</span>)</span><br><span class="line"><span class="comment"># Plot y versus x as lines and/or markers.</span></span><br><span class="line"></span><br><span class="line">plot(x,y,data=obj)</span><br></pre></td></tr></table></figure>
<p>其中</p>
<ul>
<li><code>x,y</code>表示需要绘制的自变量与应变量；</li>
<li><code>color=&#39;green&#39;</code>可以指定该组数据绘制的颜色，可选项包括<code>b g r c m y k w</code>，详见<a href="https://matplotlib.org/stable/users/explain/colors/colors.html#colors-def">此处说明文档</a>。</li>
<li><code>Marker=&#39;o&#39;</code>表示绘制点的形状，可选项包括<code>.  ,  o  v  ^  &lt;  &gt;  1  2  3  4  8  s  p  P  *  h  H  +  x  X  D  d  |  _</code>；</li>
<li><code>linestyle = &#39;dashed&#39;</code>表示线的形状，可选项包括<code>-  --   -.   :</code></li>
</ul>
<p>一种比较特殊的写法是把这些标识组合在一起，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;b&#x27;</span>    <span class="comment"># blue markers with default shape</span></span><br><span class="line"><span class="string">&#x27;or&#x27;</span>   <span class="comment"># red circles</span></span><br><span class="line"><span class="string">&#x27;-g&#x27;</span>   <span class="comment"># green solid line</span></span><br><span class="line"><span class="string">&#x27;--&#x27;</span>   <span class="comment"># dashed line with default color</span></span><br><span class="line"><span class="string">&#x27;^k:&#x27;</span>  <span class="comment"># black triangle_up markers connected by a dotted line</span></span><br></pre></td></tr></table></figure>

<h3 id="单自变量多因变量的情况"><a href="#单自变量多因变量的情况" class="headerlink" title="单自变量多因变量的情况"></a>单自变量多因变量的情况</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> interp1d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">y = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">plt.plot(x, y,<span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line"><span class="comment"># is equivalent to:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># for col in range(y.shape[1]):</span></span><br><span class="line"><span class="comment">#     plt.plot(x, y[:, col])</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<h3 id="稍复杂些的情况"><a href="#稍复杂些的情况" class="headerlink" title="稍复杂些的情况"></a>稍复杂些的情况</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span></span><br><span class="line">r0 = <span class="number">0.6</span></span><br><span class="line">x = <span class="number">0.9</span> * np.random.rand(N)</span><br><span class="line">y = <span class="number">0.9</span> * np.random.rand(N)</span><br><span class="line">area = (<span class="number">20</span> * np.random.rand(N))**<span class="number">2</span>  <span class="comment"># 0 to 10 point radii</span></span><br><span class="line">c = np.sqrt(area)</span><br><span class="line">r = np.sqrt(x ** <span class="number">2</span> + y ** <span class="number">2</span>)</span><br><span class="line">area1 = np.ma.masked_where(r &lt; r0, area)</span><br><span class="line">area2 = np.ma.masked_where(r &gt;= r0, area)</span><br><span class="line">plt.scatter(x, y, s=area1, marker=<span class="string">&#x27;^&#x27;</span>, c=c)</span><br><span class="line">plt.scatter(x, y, s=area2, marker=<span class="string">&#x27;o&#x27;</span>, c=c)</span><br><span class="line"><span class="comment"># Show the boundary between the regions:</span></span><br><span class="line">theta = np.arange(<span class="number">0</span>, np.pi / <span class="number">2</span>, <span class="number">0.01</span>)</span><br><span class="line">plt.plot(r0 * np.cos(theta), r0 * np.sin(theta))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_scatter_masked_001.png" width="75%" alt="" align=center />

<h3 id="plt-scatter-函数"><a href="#plt-scatter-函数" class="headerlink" title="plt.scatter()函数"></a>plt.scatter()函数</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matplotlib.pyplot.scatter(x, y, s=<span class="literal">None</span>, c=<span class="literal">None</span>, marker=<span class="literal">None</span>, cmap=<span class="literal">None</span>, norm=<span class="literal">None</span>, vmin=<span class="literal">None</span>, vmax=<span class="literal">None</span>,</span><br><span class="line"> alpha=<span class="literal">None</span>, linewidths=<span class="literal">None</span>, *, edgecolors=<span class="literal">None</span>, plotnonfinite=<span class="literal">False</span>, data=<span class="literal">None</span>, **kwargs)</span><br><span class="line"><span class="comment"># A scatter plot of y vs. x with varying marker size and/or color.</span></span><br></pre></td></tr></table></figure>

<p>其中，</p>
<ul>
<li>x,y：指定自变量与应变量；</li>
<li>s：标记点的尺寸，如不指定默认值为<code>rcParams[&#39;lines.markersize&#39;] ** 2</code>；</li>
<li>c：标记点的颜色；</li>
<li>marker：标记的形状类别；</li>
<li>cmap：用于将标量数据映射到颜色的Colormap实例或已注册的Colormap名称。如果c为RGB(A)，则忽略此参数。</li>
<li>norm：在使用cmap映射到颜色之前，将标量数据缩放到[0,1]范围的归一化方法。默认情况下，使用线性缩放，将最低值映射为0，最高值映射为1。</li>
<li>alpha：不透明度，取值在[0,1]。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">N = <span class="number">50</span></span><br><span class="line">x = np.random.rand(N)</span><br><span class="line">y = np.random.rand(N)</span><br><span class="line">colors = np.random.rand(N)</span><br><span class="line">area = (<span class="number">30</span> * np.random.rand(N))**<span class="number">2</span>  <span class="comment"># 0 to 15 point radii</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x, y, s=area, c=colors, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_scatter_001.png" width="75%" alt="" align=center />

<h3 id="极图"><a href="#极图" class="headerlink" title="极图"></a>极图</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixing random state for reproducibility</span></span><br><span class="line">np.random.seed(<span class="number">19680801</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute areas and colors</span></span><br><span class="line">N = <span class="number">150</span></span><br><span class="line">r = <span class="number">2</span> * np.random.rand(N)</span><br><span class="line">theta = <span class="number">2</span> * np.pi * np.random.rand(N)</span><br><span class="line">area = <span class="number">200</span> * r**<span class="number">2</span></span><br><span class="line">colors = theta</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_001.png" width="75%" alt="" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line"></span><br><span class="line">ax.set_rorigin(-<span class="number">2.5</span>)</span><br><span class="line">ax.set_theta_zero_location(<span class="string">&#x27;W&#x27;</span>, offset=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_002.png" width="75%" alt="" align=center />


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(projection=<span class="string">&#x27;polar&#x27;</span>)</span><br><span class="line">c = ax.scatter(theta, r, c=colors, s=area, cmap=<span class="string">&#x27;hsv&#x27;</span>, alpha=<span class="number">0.75</span>)</span><br><span class="line"></span><br><span class="line">ax.set_thetamin(<span class="number">45</span>)</span><br><span class="line">ax.set_thetamax(<span class="number">135</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://matplotlib.org/stable/_images/sphx_glr_polar_scatter_003.png" width="75%" alt="" align=center />


<h2 id="二维信号的可视化"><a href="#二维信号的可视化" class="headerlink" title="二维信号的可视化"></a>二维信号的可视化</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> x*(<span class="number">1</span>-x)*np.cos(<span class="number">4</span>*np.pi*x) * np.sin(<span class="number">4</span>*np.pi*y**<span class="number">2</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">grid_x, grid_y = np.mgrid[<span class="number">0</span>:<span class="number">1</span>:<span class="number">100j</span>, <span class="number">0</span>:<span class="number">1</span>:<span class="number">200j</span>]</span><br><span class="line"></span><br><span class="line">np.mgrid[<span class="number">0</span>:<span class="number">5</span>, <span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line">array([[[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]],</span><br><span class="line">       [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]]])</span><br><span class="line"></span><br><span class="line">np.mgrid[-<span class="number">1</span>:<span class="number">1</span>:<span class="number">5j</span>]</span><br><span class="line">array([-<span class="number">1.</span> , -<span class="number">0.5</span>,  <span class="number">0.</span> ,  <span class="number">0.5</span>,  <span class="number">1.</span> ])</span><br></pre></td></tr></table></figure>

<p>但我们只知道它在1000个数据点的值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points = np.random.random((<span class="number">1000</span>, <span class="number">2</span>))</span><br><span class="line">values = func(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>这可以通过以下方式完成 <code>griddata</code> –下面我们将尝试所有的插值方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> griddata</span><br><span class="line"></span><br><span class="line">grid_z0 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">grid_z1 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">grid_z2 = griddata(points, values, (grid_x, grid_y), method=<span class="string">&#x27;cubic&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>可以看到，所有方法都在一定程度上重现了准确的结果，但对于此光滑函数，三次样条插值提供了最好的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.imshow(func(grid_x, grid_y).T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>,cmap = <span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">plt.plot(points[:,<span class="number">0</span>], points[:,<span class="number">1</span>], <span class="string">&#x27;k.&#x27;</span>, ms=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Original&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.imshow(grid_z0.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Nearest&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.imshow(grid_z1.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Linear&#x27;</span>)</span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.imshow(grid_z2.T, extent=(<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>), origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Cubic&#x27;</span>)</span><br><span class="line">plt.gcf().set_size_inches(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img src="https://www.osgeo.cn/scipy/_images/interpolate-3.png" width="80%" alt="" align=center />


<h2 id="散点图（Scatter-plot）"><a href="#散点图（Scatter-plot）" class="headerlink" title="散点图（Scatter plot）"></a>散点图（Scatter plot）</h2><p>散点图是用于研究两个变量之间关系的经典的和基本的图表。 如果数据中有多个组，则可能需要以不同颜色可视化每个组。 在 matplotlib 中，您可以使用 <code>plt.scatter()</code> 方便地执行此操作。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1QzOe.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import dataset </span></span><br><span class="line">midwest = pd.read_csv(<span class="string">&#x27;midwest_filter.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Data </span></span><br><span class="line"><span class="comment"># Create as many colors as there are unique midwest[&#x27;category&#x27;]</span></span><br><span class="line">categories = np.unique(midwest[<span class="string">&#x27;category&#x27;</span>])</span><br><span class="line">colors = [plt.cm.tab10(i/<span class="built_in">float</span>(<span class="built_in">len</span>(categories)-<span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(categories))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw Plot for Each Category</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, category <span class="keyword">in</span> <span class="built_in">enumerate</span>(categories):</span><br><span class="line">    plt.scatter(<span class="string">&#x27;area&#x27;</span>, <span class="string">&#x27;poptotal&#x27;</span>, data=midwest.loc[midwest.category==category, :], s=<span class="number">20</span>, cmap=colors[i], label=<span class="built_in">str</span>(category))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(xlim=(<span class="number">0.0</span>, <span class="number">0.1</span>), ylim=(<span class="number">0</span>, <span class="number">90000</span>),xlabel=<span class="string">&#x27;Area&#x27;</span>, ylabel=<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Scatterplot of Midwest Area vs Population&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.legend(fontsize=<span class="number">12</span>)    </span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># d:\anaconda3\lib\site-packages\ipykernel\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.</span></span><br><span class="line"><span class="comment">#  and should_run_async(code)</span></span><br></pre></td></tr></table></figure>

<p><code>np.unique()</code>:列表元素去重<br>当前的图表和子图可以使用<code>plt.gcf()</code>和<code>plt.gca()</code>获得,分别表示”Get Current Figure”和”Get Current Axes”，这样可以方便的设置x，y轴显示范围及标签。<br><code>enumerate(sequence, [start=0])</code>函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<h2 id="带边界的气泡图（Bubble-plot-with-Encircling）"><a href="#带边界的气泡图（Bubble-plot-with-Encircling）" class="headerlink" title="带边界的气泡图（Bubble plot with Encircling）"></a>带边界的气泡图（Bubble plot with Encircling）</h2><p>有时，您希望在边界内显示一组点以强调其重要性。 在这个例子中，你从数据框中获取记录，并用下面代码中描述的 encircle() 来使边界显示出来。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1lpeH.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> patches</span><br><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> ConvexHull</span><br><span class="line"><span class="keyword">import</span> warnings; warnings.simplefilter(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1: Prepare Data</span></span><br><span class="line">midwest = pd.read_csv(<span class="string">&quot;midwest_filter.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># As many colors as there are unique midwest[&#x27;category&#x27;]</span></span><br><span class="line">categories = np.unique(midwest[<span class="string">&#x27;category&#x27;</span>])</span><br><span class="line">colors = [plt.cm.tab10(i/<span class="built_in">float</span>(<span class="built_in">len</span>(categories)-<span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(categories))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2: Draw Scatterplot with unique color for each category</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)    </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, category <span class="keyword">in</span> <span class="built_in">enumerate</span>(categories):</span><br><span class="line">    plt.scatter(<span class="string">&#x27;area&#x27;</span>, <span class="string">&#x27;poptotal&#x27;</span>, data=midwest.loc[midwest.category==category, :], </span><br><span class="line">                s=<span class="string">&#x27;dot_size&#x27;</span>, cmap=colors[i], label=<span class="built_in">str</span>(category), edgecolors=<span class="string">&#x27;black&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3: Encircling</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/44575681/how-do-i-encircle-different-data-sets-in-scatter-plot</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">encircle</span>(<span class="params">x,y, ax=<span class="literal">None</span>, **kw</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> ax: ax=plt.gca()</span><br><span class="line">    p = np.c_[x,y]</span><br><span class="line">    hull = ConvexHull(p)</span><br><span class="line">    poly = plt.Polygon(p[hull.vertices,:], **kw)</span><br><span class="line">    ax.add_patch(poly)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select data to be encircled</span></span><br><span class="line">midwest_encircle_data = midwest.loc[midwest.state==<span class="string">&#x27;IN&#x27;</span>, :]                         </span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw polygon surrounding vertices    </span></span><br><span class="line">encircle(midwest_encircle_data.area, midwest_encircle_data.poptotal, ec=<span class="string">&quot;k&quot;</span>, fc=<span class="string">&quot;gold&quot;</span>, alpha=<span class="number">0.1</span>)</span><br><span class="line">encircle(midwest_encircle_data.area, midwest_encircle_data.poptotal, ec=<span class="string">&quot;firebrick&quot;</span>, fc=<span class="string">&quot;none&quot;</span>, linewidth=<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 4: Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(xlim=(<span class="number">0.0</span>, <span class="number">0.1</span>), ylim=(<span class="number">0</span>, <span class="number">90000</span>),xlabel=<span class="string">&#x27;Area&#x27;</span>, ylabel=<span class="string">&#x27;Population&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Bubble Plot with Encircling&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.legend(fontsize=<span class="number">12</span>)    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><code>np.r_</code>是按列连接两个矩阵，就是把两矩阵上下相加，要求列数相等，类似于pandas中的concat()。<br><code>np.c_</code>是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()。<br><code>ConvexHull</code>：给定二维平面上的点集，凸包就是将最外层的点连接起来构成的凸多边型，它能包含点集中所有的点。</p>
<h2 id="带线性回归最佳拟合线的散点图-（Scatter-plot-with-linear-regression-line-of-best-fit）"><a href="#带线性回归最佳拟合线的散点图-（Scatter-plot-with-linear-regression-line-of-best-fit）" class="headerlink" title="带线性回归最佳拟合线的散点图 （Scatter plot with linear regression line of best fit）"></a>带线性回归最佳拟合线的散点图 （Scatter plot with linear regression line of best fit）</h2><p>如果你想了解两个变量如何相互改变，那么最佳拟合线就是常用的方法。 下图显示了数据中各组之间最佳拟合线的差异。要禁用分组并仅为整个数据集绘制一条最佳拟合线，请从下面的<code>sns.lmplot()</code>调用中删除<code>hue =&#39;cyl&#39;</code>参数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fXy6.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df_select = df.loc[df.cyl.isin([<span class="number">4</span>,<span class="number">8</span>]), :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">gridobj = sns.lmplot(x=<span class="string">&quot;displ&quot;</span>, y=<span class="string">&quot;hwy&quot;</span>, hue=<span class="string">&quot;cyl&quot;</span>, data=df_select, </span><br><span class="line">                     aspect=<span class="number">1.6</span>, robust=<span class="literal">True</span>, palette=<span class="string">&#x27;tab10&#x27;</span>, </span><br><span class="line">                     scatter_kws=<span class="built_in">dict</span>(s=<span class="number">60</span>, linewidths=<span class="number">.7</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">gridobj.<span class="built_in">set</span>(xlim=(<span class="number">0.5</span>, <span class="number">7.5</span>), ylim=(<span class="number">0</span>, <span class="number">50</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Scatterplot with line of best fit grouped by number of cylinders&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>如果报错<code>No module named &#39;statsmodels&#39;</code>，执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install statsmodels</span><br></pre></td></tr></table></figure>

<h2 id="针对每列绘制线性回归线"><a href="#针对每列绘制线性回归线" class="headerlink" title="针对每列绘制线性回归线"></a>针对每列绘制线性回归线</h2><p>或者，可以在其每列中显示每个组的最佳拟合线。 可以通过在<code>sns.lmplot()</code>中设置<code>col=groupingcolumn</code>参数来实现，如下：</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fbWR.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df_select = df.loc[df.cyl.isin([<span class="number">4</span>,<span class="number">8</span>]), :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Each line in its own column</span></span><br><span class="line">sns.set_style(<span class="string">&quot;white&quot;</span>)</span><br><span class="line">gridobj = sns.lmplot(x=<span class="string">&quot;displ&quot;</span>, y=<span class="string">&quot;hwy&quot;</span>, </span><br><span class="line">                     data=df_select, </span><br><span class="line">                     robust=<span class="literal">True</span>, </span><br><span class="line">                     palette=<span class="string">&#x27;Set1&#x27;</span>, </span><br><span class="line">                     col=<span class="string">&quot;cyl&quot;</span>,</span><br><span class="line">                     scatter_kws=<span class="built_in">dict</span>(s=<span class="number">60</span>, linewidths=<span class="number">.7</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">gridobj.<span class="built_in">set</span>(xlim=(<span class="number">0.5</span>, <span class="number">7.5</span>), ylim=(<span class="number">0</span>, <span class="number">50</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="边缘直方图-（Marginal-Histogram）"><a href="#边缘直方图-（Marginal-Histogram）" class="headerlink" title="边缘直方图 （Marginal Histogram）"></a>边缘直方图 （Marginal Histogram）</h2><p>边缘直方图具有沿 X 和 Y 轴变量的直方图。 这用于可视化 X 和 Y 之间的关系以及单独的 X 和 Y 的单变量分布。 这种图经常用于探索性数据分析（EDA）。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fOQx.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Fig and gridspec</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">grid = plt.GridSpec(<span class="number">4</span>, <span class="number">4</span>, hspace=<span class="number">0.5</span>, wspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the axes</span></span><br><span class="line">ax_main = fig.add_subplot(grid[:-<span class="number">1</span>, :-<span class="number">1</span>])</span><br><span class="line">ax_right = fig.add_subplot(grid[:-<span class="number">1</span>, -<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line">ax_bottom = fig.add_subplot(grid[-<span class="number">1</span>, <span class="number">0</span>:-<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatterplot on main ax</span></span><br><span class="line">ax_main.scatter(<span class="string">&#x27;displ&#x27;</span>, <span class="string">&#x27;hwy&#x27;</span>, s=df.cty*<span class="number">4</span>, c=df.manufacturer.astype(<span class="string">&#x27;category&#x27;</span>).cat.codes, alpha=<span class="number">.9</span>, data=df, cmap=<span class="string">&quot;tab10&quot;</span>, edgecolors=<span class="string">&#x27;gray&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram on the right</span></span><br><span class="line">ax_bottom.hist(df.displ, <span class="number">40</span>, histtype=<span class="string">&#x27;stepfilled&#x27;</span>, orientation=<span class="string">&#x27;vertical&#x27;</span>, color=<span class="string">&#x27;deeppink&#x27;</span>)</span><br><span class="line">ax_bottom.invert_yaxis()</span><br><span class="line"></span><br><span class="line"><span class="comment"># histogram in the bottom</span></span><br><span class="line">ax_right.hist(df.hwy, <span class="number">40</span>, histtype=<span class="string">&#x27;stepfilled&#x27;</span>, orientation=<span class="string">&#x27;horizontal&#x27;</span>, color=<span class="string">&#x27;deeppink&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">ax_main.<span class="built_in">set</span>(title=<span class="string">&#x27;Scatterplot with Histograms \n displ vs hwy&#x27;</span>, xlabel=<span class="string">&#x27;displ&#x27;</span>, ylabel=<span class="string">&#x27;hwy&#x27;</span>)</span><br><span class="line">ax_main.title.set_fontsize(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):</span><br><span class="line">    item.set_fontsize(<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">xlabels = ax_main.get_xticks().tolist()</span><br><span class="line">ax_main.set_xticklabels(xlabels)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="边缘箱形图-（Marginal-Boxplot）"><a href="#边缘箱形图-（Marginal-Boxplot）" class="headerlink" title="边缘箱形图 （Marginal Boxplot）"></a>边缘箱形图 （Marginal Boxplot）</h2><p>边缘箱图与边缘直方图具有相似的用途。 然而，箱线图有助于精确定位 X 和 Y 的中位数、第25和第75百分位数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fLS1.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Fig and gridspec</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>, <span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">grid = plt.GridSpec(<span class="number">4</span>, <span class="number">4</span>, hspace=<span class="number">0.5</span>, wspace=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the axes</span></span><br><span class="line">ax_main = fig.add_subplot(grid[:-<span class="number">1</span>, :-<span class="number">1</span>])</span><br><span class="line">ax_right = fig.add_subplot(grid[:-<span class="number">1</span>, -<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line">ax_bottom = fig.add_subplot(grid[-<span class="number">1</span>, <span class="number">0</span>:-<span class="number">1</span>], xticklabels=[], yticklabels=[])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatterplot on main ax</span></span><br><span class="line">ax_main.scatter(<span class="string">&#x27;displ&#x27;</span>, <span class="string">&#x27;hwy&#x27;</span>, s=df.cty*<span class="number">5</span>, c=df.manufacturer.astype(<span class="string">&#x27;category&#x27;</span>).cat.codes, alpha=<span class="number">.9</span>, data=df, cmap=<span class="string">&quot;Set1&quot;</span>, edgecolors=<span class="string">&#x27;black&#x27;</span>, linewidths=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a graph in each part</span></span><br><span class="line">sns.boxplot(df.hwy, ax=ax_right, orient=<span class="string">&quot;v&quot;</span>)</span><br><span class="line">sns.boxplot(df.displ, ax=ax_bottom, orient=<span class="string">&quot;h&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations ------------------</span></span><br><span class="line"><span class="comment"># Remove x axis name for the boxplot</span></span><br><span class="line">ax_bottom.<span class="built_in">set</span>(xlabel=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">ax_right.<span class="built_in">set</span>(ylabel=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Main Title, Xlabel and YLabel</span></span><br><span class="line">ax_main.<span class="built_in">set</span>(title=<span class="string">&#x27;Scatterplot with Histograms \n displ vs hwy&#x27;</span>, xlabel=<span class="string">&#x27;displ&#x27;</span>, ylabel=<span class="string">&#x27;hwy&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set font size of different components</span></span><br><span class="line">ax_main.title.set_fontsize(<span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):</span><br><span class="line">    item.set_fontsize(<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="相关图-（Correllogram）"><a href="#相关图-（Correllogram）" class="headerlink" title="相关图 （Correllogram）"></a>相关图 （Correllogram）</h2><p>相关图用于直观地查看给定数据框（或二维数组）中所有可能的数值变量对之间的相关度量。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fHY9.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Import Dataset</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.heatmap(df.corr(), xticklabels=df.corr().columns, yticklabels=df.corr().columns, cmap=<span class="string">&#x27;RdYlGn&#x27;</span>, center=<span class="number">0</span>, annot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.title(<span class="string">&#x27;Correlogram of mtcars&#x27;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.yticks(fontsize=<span class="number">12</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="矩阵图-（Pairwise-Plot）"><a href="#矩阵图-（Pairwise-Plot）" class="headerlink" title="矩阵图 （Pairwise Plot）"></a>矩阵图 （Pairwise Plot）</h2><p>矩阵图是探索性分析中的最爱，用于理解所有可能的数值变量对之间的关系。 它是双变量分析的必备工具。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1hSTe.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load Dataset</span></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;iris&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.pairplot(df, kind=<span class="string">&quot;scatter&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, plot_kws=<span class="built_in">dict</span>(s=<span class="number">80</span>, edgecolor=<span class="string">&quot;white&quot;</span>, linewidth=<span class="number">2.5</span>))</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># &lt;Figure size 800x640 with 0 Axes&gt;</span></span><br></pre></td></tr></table></figure>

<img src="https://s21.ax1x.com/2024/05/28/pk1oUDx.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load Dataset</span></span><br><span class="line">df = sns.load_dataset(<span class="string">&#x27;iris&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">8</span>), dpi= <span class="number">80</span>)</span><br><span class="line">sns.pairplot(df, kind=<span class="string">&quot;reg&quot;</span>, hue=<span class="string">&quot;species&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># &lt;Figure size 800x640 with 0 Axes&gt;</span></span><br></pre></td></tr></table></figure>

<h1 id="偏差-（Deviation）"><a href="#偏差-（Deviation）" class="headerlink" title="偏差 （Deviation）"></a>偏差 （Deviation）</h1><h2 id="发散型条形图-（Diverging-Bars）"><a href="#发散型条形图-（Diverging-Bars）" class="headerlink" title="发散型条形图 （Diverging Bars）"></a>发散型条形图 （Diverging Bars）</h2><p>如果您想根据单个指标查看项目的变化情况，并可视化此差异的顺序和数量，那么散型条形图 （Diverging Bars） 是一个很好的工具。 它有助于快速区分数据中组的性能，并且非常直观，并且可以立即传达这一点。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fjOK.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z, color=df.colors, alpha=<span class="number">0.4</span>, linewidth=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">plt.gca().<span class="built_in">set</span>(ylabel=<span class="string">&#x27;$Model$&#x27;</span>, xlabel=<span class="string">&#x27;$Mileage$&#x27;</span>)</span><br><span class="line">plt.yticks(df.index, df.cars, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="发散型文本-（Diverging-Texts）"><a href="#发散型文本-（Diverging-Texts）" class="headerlink" title="发散型文本 （Diverging Texts）"></a>发散型文本 （Diverging Texts）</h2><p>发散型文本 （Diverging Texts）与发散型条形图 （Diverging Bars）相似，如果你想以一种漂亮和可呈现的方式显示图表中每个项目的价值，就可以使用这种方法。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fxeO.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">14</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z)</span><br><span class="line"><span class="keyword">for</span> x, y, tex <span class="keyword">in</span> <span class="built_in">zip</span>(df.mpg_z, df.index, df.mpg_z):</span><br><span class="line">    t = plt.text(x, y, <span class="built_in">round</span>(tex, <span class="number">2</span>), horizontalalignment=<span class="string">&#x27;right&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;left&#x27;</span>, </span><br><span class="line">                 verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations    </span></span><br><span class="line">plt.yticks(df.index, df.cars, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Text Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim(-<span class="number">2.5</span>, <span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="发散型包点图-（Diverging-Dot-Plot）"><a href="#发散型包点图-（Diverging-Dot-Plot）" class="headerlink" title="发散型包点图 （Diverging Dot Plot）"></a>发散型包点图 （Diverging Dot Plot）</h2><p>发散型包点图 （Diverging Dot Plot）也类似于发散型条形图 （Diverging Bars）。 然而，与发散型条形图 （Diverging Bars）相比，条的缺失减少了组之间的对比度和差异。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1fzwD.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> x &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;darkgreen&#x27;</span> <span class="keyword">for</span> x <span class="keyword">in</span> df[<span class="string">&#x27;mpg_z&#x27;</span>]]</span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">16</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.scatter(df.mpg_z, df.index, s=<span class="number">450</span>, alpha=<span class="number">.6</span>, color=df.colors)</span><br><span class="line"><span class="keyword">for</span> x, y, tex <span class="keyword">in</span> <span class="built_in">zip</span>(df.mpg_z, df.index, df.mpg_z):</span><br><span class="line">    t = plt.text(x, y, <span class="built_in">round</span>(tex, <span class="number">1</span>), horizontalalignment=<span class="string">&#x27;center&#x27;</span>, </span><br><span class="line">                 verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;white&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line"><span class="comment"># Lighten borders</span></span><br><span class="line">plt.gca().spines[<span class="string">&quot;top&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;bottom&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;right&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;left&quot;</span>].set_alpha(<span class="number">.3</span>)</span><br><span class="line"></span><br><span class="line">plt.yticks(df.index, df.cars)</span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Dotplot of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$Mileage$&#x27;</span>)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim(-<span class="number">2.5</span>, <span class="number">2.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="带标记的发散型棒棒糖图-（Diverging-Lollipop-Chart-with-Markers）"><a href="#带标记的发散型棒棒糖图-（Diverging-Lollipop-Chart-with-Markers）" class="headerlink" title="带标记的发散型棒棒糖图 （Diverging Lollipop Chart with Markers）"></a>带标记的发散型棒棒糖图 （Diverging Lollipop Chart with Markers）</h2><p>带标记的棒棒糖图通过强调您想要引起注意的任何重要数据点并在图表中适当地给出推理，提供了一种对差异进行可视化的灵活方式。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oJ29.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;mtcars.csv&quot;</span>)</span><br><span class="line">x = df.loc[:, [<span class="string">&#x27;mpg&#x27;</span>]]</span><br><span class="line">df[<span class="string">&#x27;mpg_z&#x27;</span>] = (x - x.mean())/x.std()</span><br><span class="line">df[<span class="string">&#x27;colors&#x27;</span>] = <span class="string">&#x27;black&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># color fiat differently</span></span><br><span class="line">df.loc[df.cars == <span class="string">&#x27;Fiat X1-9&#x27;</span>, <span class="string">&#x27;colors&#x27;</span>] = <span class="string">&#x27;darkorange&#x27;</span></span><br><span class="line">df.sort_values(<span class="string">&#x27;mpg_z&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">16</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.hlines(y=df.index, xmin=<span class="number">0</span>, xmax=df.mpg_z, color=df.colors, alpha=<span class="number">0.4</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.scatter(df.mpg_z, df.index, color=df.colors, s=[<span class="number">600</span> <span class="keyword">if</span> x == <span class="string">&#x27;Fiat X1-9&#x27;</span> <span class="keyword">else</span> <span class="number">300</span> <span class="keyword">for</span> x <span class="keyword">in</span> df.cars], alpha=<span class="number">0.6</span>)</span><br><span class="line">plt.yticks(df.index, df.cars)</span><br><span class="line">plt.xticks(fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line">plt.annotate(<span class="string">&#x27;Mercedes Models&#x27;</span>, xy=(<span class="number">0.0</span>, <span class="number">11.0</span>), xytext=(<span class="number">1.0</span>, <span class="number">11</span>), xycoords=<span class="string">&#x27;data&#x27;</span>, </span><br><span class="line">            fontsize=<span class="number">15</span>, ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;center&#x27;</span>,</span><br><span class="line">            bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&#x27;square&#x27;</span>, fc=<span class="string">&#x27;firebrick&#x27;</span>),</span><br><span class="line">            arrowprops=<span class="built_in">dict</span>(arrowstyle=<span class="string">&#x27;-[, widthB=2.0, lengthB=1.5&#x27;</span>, lw=<span class="number">2.0</span>, color=<span class="string">&#x27;steelblue&#x27;</span>), color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add Patches</span></span><br><span class="line">p1 = patches.Rectangle((-<span class="number">2.0</span>, -<span class="number">1</span>), width=<span class="number">.3</span>, height=<span class="number">3</span>, alpha=<span class="number">.2</span>, facecolor=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">p2 = patches.Rectangle((<span class="number">1.5</span>, <span class="number">27</span>), width=<span class="number">.8</span>, height=<span class="number">5</span>, alpha=<span class="number">.2</span>, facecolor=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">plt.gca().add_patch(p1)</span><br><span class="line">plt.gca().add_patch(p2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorate</span></span><br><span class="line">plt.title(<span class="string">&#x27;Diverging Bars of Car Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">20</span>&#125;)</span><br><span class="line">plt.grid(linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="面积图-（Area-Chart）"><a href="#面积图-（Area-Chart）" class="headerlink" title="面积图 （Area Chart）"></a>面积图 （Area Chart）</h2><p>通过对轴和线之间的区域进行着色，面积图不仅强调峰和谷，而且还强调高点和低点的持续时间。 高点持续时间越长，线下面积越大。<br>这里annotate的函数值得学习，台风路径信息的框框或者文字避让算法，都需要用到这个函数。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1o15F.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;economics.csv&quot;</span>, parse_dates=[<span class="string">&#x27;date&#x27;</span>]).head(<span class="number">100</span>)</span><br><span class="line">x = np.arange(df.shape[<span class="number">0</span>])</span><br><span class="line">y_returns = (df.psavert.diff().fillna(<span class="number">0</span>)/df.psavert.shift(<span class="number">1</span>)).fillna(<span class="number">0</span>) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">plt.fill_between(x[<span class="number">1</span>:], y_returns[<span class="number">1</span>:], <span class="number">0</span>, where=y_returns[<span class="number">1</span>:] &gt;= <span class="number">0</span>, facecolor=<span class="string">&#x27;green&#x27;</span>, interpolate=<span class="literal">True</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.fill_between(x[<span class="number">1</span>:], y_returns[<span class="number">1</span>:], <span class="number">0</span>, where=y_returns[<span class="number">1</span>:] &lt;= <span class="number">0</span>, facecolor=<span class="string">&#x27;red&#x27;</span>, interpolate=<span class="literal">True</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line">plt.annotate(<span class="string">&#x27;Peak \n1975&#x27;</span>, xy=(<span class="number">94.0</span>, <span class="number">21.0</span>), xytext=(<span class="number">88.0</span>, <span class="number">28</span>),</span><br><span class="line">             bbox=<span class="built_in">dict</span>(boxstyle=<span class="string">&#x27;square&#x27;</span>, fc=<span class="string">&#x27;firebrick&#x27;</span>),</span><br><span class="line">             arrowprops=<span class="built_in">dict</span>(facecolor=<span class="string">&#x27;steelblue&#x27;</span>, shrink=<span class="number">0.05</span>), fontsize=<span class="number">15</span>, color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decorations</span></span><br><span class="line">xtickvals = [<span class="built_in">str</span>(m)[:<span class="number">3</span>].upper()+<span class="string">&quot;-&quot;</span>+<span class="built_in">str</span>(y) <span class="keyword">for</span> y,m <span class="keyword">in</span> <span class="built_in">zip</span>(df.date.dt.year, df.date.dt.month_name())]</span><br><span class="line">plt.gca().set_xticks(x[::<span class="number">6</span>])</span><br><span class="line">plt.gca().set_xticklabels(xtickvals[::<span class="number">6</span>], rotation=<span class="number">90</span>, fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;center&#x27;</span>, <span class="string">&#x27;verticalalignment&#x27;</span>: <span class="string">&#x27;center_baseline&#x27;</span>&#125;)</span><br><span class="line">plt.ylim(-<span class="number">35</span>,<span class="number">35</span>)</span><br><span class="line">plt.xlim(<span class="number">1</span>,<span class="number">100</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Month Economics Return %&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Monthly returns %&#x27;</span>)</span><br><span class="line">plt.grid(alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="排序-（Ranking）"><a href="#排序-（Ranking）" class="headerlink" title="排序 （Ranking）"></a>排序 （Ranking）</h1><h2 id="有序条形图-（Ordered-Bar-Chart）"><a href="#有序条形图-（Ordered-Bar-Chart）" class="headerlink" title="有序条形图 （Ordered Bar Chart）"></a>有序条形图 （Ordered Bar Chart）</h2><p>有序条形图有效地传达了项目的排名顺序。 但是，在图表上方添加度量标准的值，用户可以从图表本身获取精确信息。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1o8C4.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> patches</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), facecolor=<span class="string">&#x27;white&#x27;</span>, dpi= <span class="number">80</span>)</span><br><span class="line">ax.vlines(x=df.index, ymin=<span class="number">0</span>, ymax=df.cty, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate Text</span></span><br><span class="line"><span class="keyword">for</span> i, cty <span class="keyword">in</span> <span class="built_in">enumerate</span>(df.cty):</span><br><span class="line">    ax.text(i, cty+<span class="number">0.5</span>, <span class="built_in">round</span>(cty, <span class="number">1</span>), horizontalalignment=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Bar Chart for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(ylabel=<span class="string">&#x27;Miles Per Gallon&#x27;</span>, ylim=(<span class="number">0</span>, <span class="number">30</span>))</span><br><span class="line">plt.xticks(df.index, df.manufacturer.<span class="built_in">str</span>.upper(), rotation=<span class="number">60</span>, horizontalalignment=<span class="string">&#x27;right&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add patches to color the X axis labels</span></span><br><span class="line">p1 = patches.Rectangle((<span class="number">.57</span>, -<span class="number">0.005</span>), width=<span class="number">.33</span>, height=<span class="number">.13</span>, alpha=<span class="number">.1</span>, facecolor=<span class="string">&#x27;green&#x27;</span>, transform=fig.transFigure)</span><br><span class="line">p2 = patches.Rectangle((<span class="number">.124</span>, -<span class="number">0.005</span>), width=<span class="number">.446</span>, height=<span class="number">.13</span>, alpha=<span class="number">.1</span>, facecolor=<span class="string">&#x27;red&#x27;</span>, transform=fig.transFigure)</span><br><span class="line">fig.add_artist(p1)</span><br><span class="line">fig.add_artist(p2)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="棒棒糖图-（Lollipop-Chart）"><a href="#棒棒糖图-（Lollipop-Chart）" class="headerlink" title="棒棒糖图 （Lollipop Chart）"></a>棒棒糖图 （Lollipop Chart）</h2><p>棒棒糖图表以一种视觉上令人愉悦的方式提供与有序条形图类似的目的。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1olUU.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">ax.vlines(x=df.index, ymin=<span class="number">0</span>, ymax=df.cty, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">ax.scatter(x=df.index, y=df.cty, s=<span class="number">75</span>, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Lollipop Chart for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Miles Per Gallon&#x27;</span>)</span><br><span class="line">ax.set_xticks(df.index)</span><br><span class="line">ax.set_xticklabels(df.manufacturer.<span class="built_in">str</span>.upper(), rotation=<span class="number">60</span>, fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;right&#x27;</span>, <span class="string">&#x27;size&#x27;</span>:<span class="number">12</span>&#125;)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Annotate</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():</span><br><span class="line">    ax.text(row.Index, row.cty+<span class="number">.5</span>, s=<span class="built_in">round</span>(row.cty, <span class="number">2</span>), horizontalalignment= <span class="string">&#x27;center&#x27;</span>, verticalalignment=<span class="string">&#x27;bottom&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="包点图-（Dot-Plot）"><a href="#包点图-（Dot-Plot）" class="headerlink" title="包点图 （Dot Plot）"></a>包点图 （Dot Plot）</h2><p>包点图表传达了项目的排名顺序，并且由于它沿水平轴对齐，因此您可以更容易地看到点彼此之间的距离。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oG8J.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Prepare Data</span></span><br><span class="line">df_raw = pd.read_csv(<span class="string">&quot;mpg_ggplot2.csv&quot;</span>)</span><br><span class="line">df = df_raw[[<span class="string">&#x27;cty&#x27;</span>, <span class="string">&#x27;manufacturer&#x27;</span>]].groupby(<span class="string">&#x27;manufacturer&#x27;</span>).apply(<span class="keyword">lambda</span> x: x.mean())</span><br><span class="line">df.sort_values(<span class="string">&#x27;cty&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Draw plot</span></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">10</span>), dpi= <span class="number">80</span>)</span><br><span class="line">ax.hlines(y=df.index, xmin=<span class="number">11</span>, xmax=<span class="number">26</span>, color=<span class="string">&#x27;gray&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dashdot&#x27;</span>)</span><br><span class="line">ax.scatter(y=df.index, x=df.cty, s=<span class="number">75</span>, color=<span class="string">&#x27;firebrick&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Title, Label, Ticks and Ylim</span></span><br><span class="line">ax.set_title(<span class="string">&#x27;Dot Plot for Highway Mileage&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Miles Per Gallon&#x27;</span>)</span><br><span class="line">ax.set_yticks(df.index)</span><br><span class="line">ax.set_yticklabels(df.manufacturer.<span class="built_in">str</span>.title(), fontdict=&#123;<span class="string">&#x27;horizontalalignment&#x27;</span>: <span class="string">&#x27;right&#x27;</span>&#125;)</span><br><span class="line">ax.set_xlim(<span class="number">10</span>, <span class="number">27</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="坡度图-（Slope-Chart）"><a href="#坡度图-（Slope-Chart）" class="headerlink" title="坡度图 （Slope Chart）"></a>坡度图 （Slope Chart）</h2><p>坡度图最适合比较给定人&#x2F;项目的“前”和“后”位置。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oYvR.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.lines <span class="keyword">as</span> mlines</span><br><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;gdppercap.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">left_label = [<span class="built_in">str</span>(c) + <span class="string">&#x27;, &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(y)) <span class="keyword">for</span> c, y <span class="keyword">in</span> <span class="built_in">zip</span>(df.continent, df[<span class="string">&#x27;1952&#x27;</span>])]</span><br><span class="line">right_label = [<span class="built_in">str</span>(c) + <span class="string">&#x27;, &#x27;</span>+ <span class="built_in">str</span>(<span class="built_in">round</span>(y)) <span class="keyword">for</span> c, y <span class="keyword">in</span> <span class="built_in">zip</span>(df.continent, df[<span class="string">&#x27;1957&#x27;</span>])]</span><br><span class="line">klass = [<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> (y1-y2) &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span> <span class="keyword">for</span> y1, y2 <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;1952&#x27;</span>], df[<span class="string">&#x27;1957&#x27;</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw line</span></span><br><span class="line"><span class="comment"># https://stackoverflow.com/questions/36470343/how-to-draw-a-line-with-matplotlib/36479941</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">newline</span>(<span class="params">p1, p2, color=<span class="string">&#x27;black&#x27;</span></span>):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    l = mlines.Line2D([p1[<span class="number">0</span>],p2[<span class="number">0</span>]], [p1[<span class="number">1</span>],p2[<span class="number">1</span>]], color=<span class="string">&#x27;red&#x27;</span> <span class="keyword">if</span> p1[<span class="number">1</span>]-p2[<span class="number">1</span>] &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">    ax.add_line(l)</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">14</span>,<span class="number">14</span>), dpi= <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Vertical Lines</span></span><br><span class="line">ax.vlines(x=<span class="number">1</span>, ymin=<span class="number">500</span>, ymax=<span class="number">13000</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">3</span>, ymin=<span class="number">500</span>, ymax=<span class="number">13000</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Points</span></span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;1952&#x27;</span>], x=np.repeat(<span class="number">1</span>, df.shape[<span class="number">0</span>]), s=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;1957&#x27;</span>], x=np.repeat(<span class="number">3</span>, df.shape[<span class="number">0</span>]), s=<span class="number">10</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Line Segmentsand Annotation</span></span><br><span class="line"><span class="keyword">for</span> p1, p2, c <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;1952&#x27;</span>], df[<span class="string">&#x27;1957&#x27;</span>], df[<span class="string">&#x27;continent&#x27;</span>]):</span><br><span class="line">    newline([<span class="number">1</span>,p1], [<span class="number">3</span>,p2])</span><br><span class="line">    ax.text(<span class="number">1</span>-<span class="number">0.05</span>, p1, c + <span class="string">&#x27;, &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(p1)), horizontalalignment=<span class="string">&#x27;right&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line">    ax.text(<span class="number">3</span>+<span class="number">0.05</span>, p2, c + <span class="string">&#x27;, &#x27;</span> + <span class="built_in">str</span>(<span class="built_in">round</span>(p2)), horizontalalignment=<span class="string">&#x27;left&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">14</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &#x27;Before&#x27; and &#x27;After&#x27; Annotations</span></span><br><span class="line">ax.text(<span class="number">1</span>-<span class="number">0.05</span>, <span class="number">13000</span>, <span class="string">&#x27;BEFORE&#x27;</span>, horizontalalignment=<span class="string">&#x27;right&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">18</span>, <span class="string">&#x27;weight&#x27;</span>:<span class="number">700</span>&#125;)</span><br><span class="line">ax.text(<span class="number">3</span>+<span class="number">0.05</span>, <span class="number">13000</span>, <span class="string">&#x27;AFTER&#x27;</span>, horizontalalignment=<span class="string">&#x27;left&#x27;</span>, verticalalignment=<span class="string">&#x27;center&#x27;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">18</span>, <span class="string">&#x27;weight&#x27;</span>:<span class="number">700</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoration</span></span><br><span class="line">ax.set_title(<span class="string">&quot;Slopechart: Comparing GDP Per Capita between 1952 vs 1957&quot;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(xlim=(<span class="number">0</span>,<span class="number">4</span>), ylim=(<span class="number">0</span>,<span class="number">14000</span>), ylabel=<span class="string">&#x27;Mean GDP Per Capita&#x27;</span>)</span><br><span class="line">ax.set_xticks([<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&quot;1952&quot;</span>, <span class="string">&quot;1957&quot;</span>])</span><br><span class="line">plt.yticks(np.arange(<span class="number">500</span>, <span class="number">13000</span>, <span class="number">2000</span>), fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Lighten borders</span></span><br><span class="line">plt.gca().spines[<span class="string">&quot;top&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;bottom&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;right&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.gca().spines[<span class="string">&quot;left&quot;</span>].set_alpha(<span class="number">.0</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="哑铃图-（Dumbbell-Plot）"><a href="#哑铃图-（Dumbbell-Plot）" class="headerlink" title="哑铃图 （Dumbbell Plot）"></a>哑铃图 （Dumbbell Plot）</h2><p>哑铃图表传达了各种项目的“前”和“后”位置以及项目的等级排序。 如果您想要将特定项目&#x2F;计划对不同对象的影响可视化，那么它非常有用。</p>
<img src="https://s21.ax1x.com/2024/05/28/pk1oNK1.png" width="100%" align=center />

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.lines <span class="keyword">as</span> mlines</span><br><span class="line"></span><br><span class="line"><span class="comment"># Import Data</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;health.csv&quot;</span>)</span><br><span class="line">df.sort_values(<span class="string">&#x27;pct_2014&#x27;</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Func to draw line segment</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">newline</span>(<span class="params">p1, p2, color=<span class="string">&#x27;black&#x27;</span></span>):</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    l = mlines.Line2D([p1[<span class="number">0</span>],p2[<span class="number">0</span>]], [p1[<span class="number">1</span>],p2[<span class="number">1</span>]], color=<span class="string">&#x27;skyblue&#x27;</span>)</span><br><span class="line">    ax.add_line(l)</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"><span class="comment"># Figure and Axes</span></span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">1</span>,figsize=(<span class="number">14</span>,<span class="number">14</span>), facecolor=<span class="string">&#x27;#f7f7f7&#x27;</span>, dpi= <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Vertical Lines</span></span><br><span class="line">ax.vlines(x=<span class="number">.05</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.10</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.15</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line">ax.vlines(x=<span class="number">.20</span>, ymin=<span class="number">0</span>, ymax=<span class="number">26</span>, color=<span class="string">&#x27;black&#x27;</span>, alpha=<span class="number">1</span>, linewidth=<span class="number">1</span>, linestyles=<span class="string">&#x27;dotted&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Points</span></span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;index&#x27;</span>], x=df[<span class="string">&#x27;pct_2013&#x27;</span>], s=<span class="number">50</span>, color=<span class="string">&#x27;#0e668b&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">ax.scatter(y=df[<span class="string">&#x27;index&#x27;</span>], x=df[<span class="string">&#x27;pct_2014&#x27;</span>], s=<span class="number">50</span>, color=<span class="string">&#x27;#a3c4dc&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Line Segments</span></span><br><span class="line"><span class="keyword">for</span> i, p1, p2 <span class="keyword">in</span> <span class="built_in">zip</span>(df[<span class="string">&#x27;index&#x27;</span>], df[<span class="string">&#x27;pct_2013&#x27;</span>], df[<span class="string">&#x27;pct_2014&#x27;</span>]):</span><br><span class="line">    newline([p1, i], [p2, i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decoration</span></span><br><span class="line">ax.set_facecolor(<span class="string">&#x27;#f7f7f7&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&quot;Dumbell Chart: Pct Change - 2013 vs 2014&quot;</span>, fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">22</span>&#125;)</span><br><span class="line">ax.<span class="built_in">set</span>(xlim=(<span class="number">0</span>,<span class="number">.25</span>), ylim=(-<span class="number">1</span>, <span class="number">27</span>), ylabel=<span class="string">&#x27;Mean GDP Per Capita&#x27;</span>)</span><br><span class="line">ax.set_xticks([<span class="number">.05</span>, <span class="number">.1</span>, <span class="number">.15</span>, <span class="number">.20</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;5%&#x27;</span>, <span class="string">&#x27;15%&#x27;</span>, <span class="string">&#x27;20%&#x27;</span>, <span class="string">&#x27;25%&#x27;</span>])</span><br><span class="line">ax.set_xticklabels([<span class="string">&#x27;5%&#x27;</span>, <span class="string">&#x27;15%&#x27;</span>, <span class="string">&#x27;20%&#x27;</span>, <span class="string">&#x27;25%&#x27;</span>])    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 13：课程作业及评分标准</title>
    <url>/PythonLes14/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>课程作业总结及评分标准。</p>
<span id="more"></span>

<h2 id="课程作业-01-Score-30"><a href="#课程作业-01-Score-30" class="headerlink" title="课程作业 01 (Score: 30%)"></a>课程作业 01 (Score: 30%)</h2><p>在二维平面中构建随机 Vornoi 结构，将交界处壁厚设置为随机数，生成Vornoi结构图像。要求：二维平面的像素画幅、Vornoi的初始种子的数密度、交界处壁厚的随机分布范围可设置，作为输入参数集放置在程序的最开始。输出：二维结构图像，并输出各个交界节点、棱边的结构信息至<code>txt</code>格式文件。 </p>
<h3 id="评分标准"><a href="#评分标准" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>10 分：生成标准Vornoi结构图形（Graph）</li>
<li>5 分：生成标准Vornoi结构图像（Image）</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：输出各个交界节点、棱边的结构信息至<code>txt</code>格式文件</li>
<li>5 分：总结报告完善程度和逻辑性</li>
<li>？ 分：Vornoi结构的节点（Node）位置进行特殊处理避免结构奇异（附加分）</li>
</ul>
<h2 id="课程作业02-Score-25"><a href="#课程作业02-Score-25" class="headerlink" title="课程作业02 (Score: 25%)"></a>课程作业02 (Score: 25%)</h2><p>给你一个长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成。字符串表示你在一条原点为 0 的数轴上的若干次移动。</p>
<p>你的初始位置就在原点（0），第 i 次移动过程中，你可以根据对应字符选择移动方向：</p>
<p>如果 <code>moves[i] = &#39;L&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向左移动一个单位距离<br>如果 <code>moves[i] = &#39;R&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向右移动一个单位距离<br>移动 n 次之后，请你找出可以到达的距离原点 最远 的点，并返回 从原点到这一点的距离 。</p>
<h3 id="评分标准-1"><a href="#评分标准-1" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>8 分：随机生成长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成</li>
<li>7 分：计算可以到达的距离原点最远的点</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：总结报告完善程度和逻辑性</li>
</ul>
<h2 id="课程作业03-Score-25"><a href="#课程作业03-Score-25" class="headerlink" title="课程作业03 (Score: 25%)"></a>课程作业03 (Score: 25%)</h2><p>构建四组二维空间中的随机分布散点，每组散点符合二维高斯分布，高斯分布的中心点与两个方向的标准差均随机产生，且二维高斯分布的中心点落在[[0,100],[0,100]]的方形区域内。</p>
<p>通过K均值聚类分析方法对上述随机散点执行聚类分析，绘制分类结果，并计算K-means聚类分析的准确率。</p>
<h3 id="评分标准-2"><a href="#评分标准-2" class="headerlink" title="评分标准"></a>评分标准</h3><ul>
<li>5 分：构建四组二维空间中的随机分布散点</li>
<li>5 分：K均值聚类分析方法对上述随机散点执行聚类分析</li>
<li>5 分：计算K-means聚类分析的准确率</li>
<li>5 分：各种结构参数可以调节</li>
<li>5 分：总结报告完善程度和逻辑性</li>
</ul>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 在科研中的应用 10：Python 环境下的数字图像目标检测</title>
    <url>/PythonLes11/</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUMSfI.png"></p>
<p>计算机视觉中的“目标检测”是指使用计算机视觉技术来识别图像或视频帧中的对象，并确定它们的位置。目标检测系统通常包括一个预处理步骤，用于改善图像质量，然后是特征提取，用于从图像中提取有用的信息。接下来，一个分类器会被用来确定图像中是否存在特定的对象。最后，一个定位器会提供一个边界框或更精确的轮廓来标记对象的位置。目标检测在自动驾驶、视频监控、医疗成像和许多其他应用中都有广泛的应用。</p>
<span id="more"></span>

<h1 id="课程作业-占总成绩25"><a href="#课程作业-占总成绩25" class="headerlink" title="课程作业 占总成绩25%"></a>课程作业 占总成绩25%</h1><p>给你一个长度为 n 的字符串 <code>moves</code>，该字符串仅由字符<code>L</code>、<code>R</code>和<code>_</code>组成。字符串表示你在一条原点为 0 的数轴上的若干次移动。</p>
<p>你的初始位置就在原点（0），第 i 次移动过程中，你可以根据对应字符选择移动方向：</p>
<p>如果 <code>moves[i] = &#39;L&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向左移动一个单位距离<br>如果 <code>moves[i] = &#39;R&#39;</code> 或 <code>moves[i] = &#39;_&#39;</code>，可以选择向右移动一个单位距离<br>移动 n 次之后，请你找出可以到达的距离原点 最远 的点，并返回 从原点到这一点的距离 。</p>
<h1 id="Harris-角点检测算法"><a href="#Harris-角点检测算法" class="headerlink" title="Harris 角点检测算法"></a>Harris 角点检测算法</h1><img src="https://s21.ax1x.com/2024/05/21/pkKzHiV.jpg" width="50%" alt="PMI航空泡沫材料" align=center />

<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;harristest.png&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#result is dilated for marking the corners, not important</span></span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Threshold for an optimal value, it may vary depending on the image.</span></span><br><span class="line">img[dst&gt;<span class="number">0.01</span>*dst.<span class="built_in">max</span>()]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line"></span><br><span class="line">image = Image.fromarray(cv.cvtColor(img,cv.COLOR_BGR2RGB))  </span><br><span class="line">image.show()</span><br></pre></td></tr></table></figure>

<img src="https://opencv24-python-tutorials.readthedocs.io/en/latest/_images/sift_keypoints.jpg" width="70%" alt="Harris 角点检测示例1" align=center />

<img src="https://s21.ax1x.com/2024/05/21/pkM9qRf.png" width="70%" alt="Harris 角点检测示例2" align=center />

<img src="https://s21.ax1x.com/2024/05/21/pkMCPJ0.png" width="70%" alt="Harris 角点检测示例3" align=center />

<p>通常，我们依据以下方式判断二维图像中的三种特征区域：</p>
<p>(1)平坦区域：以该点为中心沿任意方向的图像灰度梯度均较小。</p>
<p>(2)角点区域：以该点为中心沿任意方向的图像灰度梯度均较大。</p>
<p>(3)棱边区域：以该点为中心沿特定方向的图像灰度梯度较大，沿其正交方向图像灰度梯度较小。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzIZn.jpg" width="70%" alt="图像平坦区域、棱边区域与角点区域" align=center />

<p>这与上图中展示的三种区域的典型示例相匹配。Harris提出针对含有独特纹理特征的二维图像，利用基于其局部自相关函数的角点检测算子。它可以准确地检测出图像结构中的角点、棱边以及平坦区域。局部自相关性的定义为：<br>\begin{equation}<br>\label{harrisS1}<br>e(x,y) &#x3D; \sum_{x_i,y_i} W(x_i,y_i)[I(x_i+\Delta x,y_i+\Delta y)-I(x_i,y_i)]^2,<br>\end{equation}<br>这里$I(x_i,y_i)$为二维图像的灰度值，$W(x_i,y_i)$为以点$(x,y)$为中心的高斯函数在点$(x_i,y_i)$处的取值，高斯函数的半高全宽直接决定了检测算子的影响区域半径。$(\Delta x,\Delta y)$为$(x,y)$点指向$(x_i,y_i)$点的二维矢量。</p>
<p>将公式\ref{harrisS1}泰勒展开并保留到一阶分量有：<br>\begin{equation}<br>e(x,y) &#x3D; \hat{S} \begin{bmatrix} \sum_{x_i,y_i} W\cdot I_x^2 &amp; \sum_{x_i,y_i} W\cdot I_x\cdot I_y \\ \sum_{x_i,y_i} W\cdot I_x\cdot I_y &amp; \sum_{x_i,y_i} W\cdot I_y^2 \end{bmatrix} \hat{S}^T &#x3D; \hat{S}\cdot E(x,y)\cdot\hat{S}^T,<br>\end{equation}<br>这里$\hat{S} &#x3D; (\Delta x,\Delta y)$表示偏移矢量，$I_x,I_y$分别为初始二维图像$I(x,y)$沿$x,y$两个方向的偏微分。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzoaq.jpg" width="40%" alt="自相关特征值空间粗线给出角点、棱边、平坦区域分类，细线为响应函数等高线" align=center />

<p>Harris与Stephens教授提出可以通过分析矩阵$E$的一对特征值$\alpha,\beta$的特性来判别角点、棱边和平坦区域，这对特征值包含了足够的与邻域特征有关的局部结构信息。例如，当位于角点区域时，特征值$\alpha,\beta$均较大；而当位于棱边区域时，特征值$\alpha,\beta$总有一个较大而另一个较小；当位于平坦区域时，特征值$\alpha,\beta$均极小。根据这样的特性，Harris提出角点判别指标：<br>\begin{equation}<br>h(x,y) &#x3D; {\rm Det}(E)-k\cdot {\rm Tr}(E)^2 &#x3D; \alpha\beta - k\cdot(\alpha\beta)^2,<br>\end{equation}<br>这里，$k$为自适应参数。判别指标$h(x,y)$的等高线通过图\ref{harris02}中的细线表示，根据上图判断，$h(x,y)$值接近0时，为平坦区域；$h(x,y)$值大于0时，为角点区域；$h(x,y)$值小于0时，为棱边区域。</p>
<img src="https://s21.ax1x.com/2024/05/21/pkKzTI0.jpg" width="95%" alt="棱边切分技术流程效果图。(a)二值化后的切片图；(b)harris角点判别指标的二维分布；(c)在判别指标二维分布中寻找正值区域的极值点；(d)分离极值点球形邻域（绿色区域）；(e)PMI泡沫原始三维结构；(f)棱边切分技术效果图；(g)胞元尺度上的棱边切分效果。" align=center />

<p>Harris教授提出的方法在二维自然图像中能够获得优异的准确性与鲁棒性。然而当我们面临三维结构图像时，逻辑出现了本质的不同。在三维空间中，区域的分类出现了四种情况，分别是：孔隙、胞壁、棱边、角点区域，它们分别对应于3、2、1和0个维度的平移不变性。当我们考虑如何分离这四种区域时，我们可以从Harris指标的形式出发将其扩展至三维空间；或是从三维灰度图像出发，将三维图像分解为一幅幅二维图像并在二维图像中处理问题。这里作者选择了第二种方案，并取得了有效的结果。</p>
<h2 id="Corner-with-SubPixel-Accuracy"><a href="#Corner-with-SubPixel-Accuracy" class="headerlink" title="Corner with SubPixel Accuracy"></a>Corner with SubPixel Accuracy</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"> </span><br><span class="line">filename = <span class="string">&#x27;chessboard2.jpg&#x27;</span></span><br><span class="line">img = cv.imread(filename)</span><br><span class="line">gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find Harris corners</span></span><br><span class="line">gray = np.float32(gray)</span><br><span class="line">dst = cv.cornerHarris(gray,<span class="number">2</span>,<span class="number">3</span>,<span class="number">0.04</span>)</span><br><span class="line">dst = cv.dilate(dst,<span class="literal">None</span>)</span><br><span class="line">ret, dst = cv.threshold(dst,<span class="number">0.01</span>*dst.<span class="built_in">max</span>(),<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">dst = np.uint8(dst)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># find centroids</span></span><br><span class="line">ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># define the criteria to stop and refine the corners</span></span><br><span class="line">criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, <span class="number">100</span>, <span class="number">0.001</span>)</span><br><span class="line">corners = cv.cornerSubPix(gray,np.float32(centroids),(<span class="number">5</span>,<span class="number">5</span>),(-<span class="number">1</span>,-<span class="number">1</span>),criteria)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Now draw them</span></span><br><span class="line">res = np.hstack((centroids,corners))</span><br><span class="line">res = np.int0(res)</span><br><span class="line">img[res[:,<span class="number">1</span>],res[:,<span class="number">0</span>]]=[<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>]</span><br><span class="line">img[res[:,<span class="number">3</span>],res[:,<span class="number">2</span>]] = [<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>]</span><br><span class="line"> </span><br><span class="line">cv.imwrite(<span class="string">&#x27;subpixel5.png&#x27;</span>,img)</span><br></pre></td></tr></table></figure>

<img src="https://docs.opencv.org/4.x/subpixel3.png" width="40%"  align=center />

<h1 id="尺度不变特征变换匹配（SIFT）算法"><a href="#尺度不变特征变换匹配（SIFT）算法" class="headerlink" title="尺度不变特征变换匹配（SIFT）算法"></a>尺度不变特征变换匹配（SIFT）算法</h1><p>尺度不变特征变换匹配（Scale Invariant Feature Transform, SIFT）算法，是David G. Lowe[1]在1999年提出的高效区域检测算法，2004年[2]完善。SIFT算法将图像中检测到的特征点用128维的特征向量进行描述。其本质是在不同的空间尺度上查找特征点，并计算特征点方向。SIFT算法所查找到的特征点是一些十分突出的局部结构，对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是目前领域内非常成熟稳定的局部特征检测算法。</p>
<!-- more -->

<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><ul>
<li><a href="https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html">OpenCV: Introduction to SIFT (Scale-Invariant Feature Transform)</a></li>
</ul>
<figure class="highlight python"><figcaption><span>sift.py, For feature keypoints extraction</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># reading the image</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert to greyscale</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT feature extractor</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect features from the image</span></span><br><span class="line">keypoints, descriptors = sift.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># draw the detected key points</span></span><br><span class="line">sift_image = cv2.drawKeypoints(gray, keypoints, img)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, sift_image)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;table-sift.jpg&quot;</span>, sift_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>feature_match.py, For feature matching</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># read the images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">&#x27;book.jpg&#x27;</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert images to grayscale</span></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT object</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect SIFT features in both images</span></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># create feature matcher</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># match descriptors of both images</span></span><br><span class="line">matches = bf.<span class="keyword">match</span>(descriptors_1,descriptors_2)</span><br><span class="line"><span class="comment"># sort matches by distance</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"><span class="comment"># draw first 50 matches</span></span><br><span class="line">matched_img = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:<span class="number">50</span>], img2, flags=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, matched_img)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;matched_images.jpg&quot;</span>, matched_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>




<h2 id="逻辑框架"><a href="#逻辑框架" class="headerlink" title="逻辑框架"></a>逻辑框架</h2><p>Lowe教授将SIFT算法分解为如下四步：</p>
<blockquote>
<ol>
<li><strong>尺度空间极值检测</strong>：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li><strong>特征点精确定位</strong>：在每个候选的位置上，通过精细拟合模型确定位置和尺度。特征点的选择依赖它们的稳定程度。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li><strong>方向确定</strong>：基于图像局部梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li><strong>特征点描述</strong>：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li>
</ol>
</blockquote>
<h2 id="SIFT算法原理"><a href="#SIFT算法原理" class="headerlink" title="SIFT算法原理"></a>SIFT算法原理</h2><h3 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h3><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p>
<h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。二维空间高斯函数：</p>
<p>\begin{equation}<br>G(x_i,y_i,\sigma)&#x3D;\frac{1}{2\pi\sigma^2}{\rm exp}\left[-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\right]<br>\end{equation}</p>
<p>尺度空间为：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;G(x,y,\sigma)*I(x,y)<br>\end{equation}</p>
<p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma&#x3D;0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大约$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)^2$的矩阵就可以保证相关像素影响。</p>
<h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：</p>
<blockquote>
<ol>
<li>使用低通滤波器（LPF）平滑图像；</li>
<li>平滑图像降采样（通常</li>
</ol>
</blockquote>
<p> 该方式能得到系列尺寸缩小的图片。尺度空间表达和金字塔分辨率表达的明显区别有：</p>
<blockquote>
<ol>
<li>尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；</li>
<li>金字塔多分辨率表达每层分辨率减少固定比率。</li>
</ol>
</blockquote>
<p>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p>
<h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（5$*$5）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xox4Te.png" width="90%" alt="Fig.1 高斯金字塔与高斯差分金字塔。" align=center /></p>
<p>高斯金字塔的构建过程：</p>
<blockquote>
<ol>
<li>先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>将$\sigma$乘以一个比例系数$k$，得到新的平滑因子$\sigma&#x3D;k*\sigma_{old}$，用它来平滑第1组第2层图像，结果图像作为第3层。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为$\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。这样反复执行，就可以得到一共$O$组，每组$L$层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子是前一层图像平滑因子的$k$倍；在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</li>
</ol>
</blockquote>
<h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}<br>\end{equation}</p>
<p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p>
<p>\begin{align}<br>L_i &amp;&#x3D; G_i-Up(G_{i+1})\otimes g \<br>&amp;&#x3D;G_i - PyrUp(G_{i+1}) \<br>\end{align}</p>
<p>式中，$G_i$表示高斯金字塔中第层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p>
<h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示：</p>
<p>\begin{equation}<br>\sigma\nabla^2G &#x3D; \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}<br>\end{equation}</p>
<p>因此，有：</p>
<p>\begin{equation}<br>G(x,y,k\sigma) - G(x,y,\sigma) \approx (k-1)\sigma^2\nabla^2G<br>\end{equation}</p>
<p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。</p>
<h3 id="空间极值点检测"><a href="#空间极值点检测" class="headerlink" title="空间极值点检测"></a>空间极值点检测</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoxIFH.png" width="40%" alt="Fig.2 空间极值点检测。" align=center /></p>
<p>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时$S$在3到5之间。当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p>
<p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p>
<h3 id="特征点精确定位"><a href="#特征点精确定位" class="headerlink" title="特征点精确定位"></a>特征点精确定位</h3><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p>
<h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoz3nK.png" width="60%" alt=" " align=center /></p>
<p>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x,y)$。设$X_0 &#x3D; (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p>
<p>\begin{equation}<br>f(\left[\begin{matrix}x\y\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\y_0\\sigma_0\end{matrix}\right]) + \left[\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right] + \frac{1}{2}\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]^{\rm T}\left[\begin{matrix}<br>\frac{\partial^2 f}{\partial x^2}               &amp; \frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial x \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial y^2}               &amp; \frac{\partial^2 f}{\partial y \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial \sigma} &amp; \frac{\partial^2 f}{\partial y \partial \sigma} &amp; \frac{\partial^2 f}{\partial \sigma^2}          \<br>\end{matrix}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]<br>\end{equation}</p>
<p>若写成矢量形式，则为：</p>
<p>\begin{equation}<br>f(X) &#x3D; f(X_0）+\frac{\partial f^{\rm T}}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^{\rm T}\frac{\partial^2 f}{\partial X^2}(X-X_0)<br>\end{equation}</p>
<p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X}&#x3D;X-X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有：</p>
<p>\begin{equation}<br>\hat{X} &#x3D; -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}<br>\end{equation}</p>
<p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。</p>
<p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p>
<p>\begin{equation}<br>f(\hat{X}) &#x3D; f(X_0) + \frac{1}{2}\frac{\partial f^{\rm T}}{\partial X} \hat{X}<br>\end{equation}</p>
<p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p>
<h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p>
<p>\begin{equation}<br>H &#x3D; \left[\begin{matrix}D_{xx}(x,y)&amp;D_{xy}(x,y)\D_{xy}(x,y)&amp;D_{yy}(x,y)\end{matrix}\right]<br>\end{equation}</p>
<p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha &#x3D; \gamma\beta$，有如下公式：</p>
<p>\begin{align}<br>{\rm Tr}(H) &#x3D; \alpha +\beta\<br>{\rm Det}(H) &#x3D; \alpha\beta<br>\end{align}</p>
<p>其中${\rm Tr}(H)$表示矩阵的迹，${\rm Det}(H)$表示的矩阵的行列式。首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：<br>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &#x3D; \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} &#x3D; \frac{(\gamma+1)^2}{\gamma}<br>\end{equation}</p>
<p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p>
<p>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &lt; \frac{(\gamma_0+1)^2}{\gamma_0}<br>\end{equation}</p>
<p>Lowe论文中阈值为10。</p>
<h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p>
<h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像：</p>
<p>\begin{equation}<br>L(x,y) &#x3D; G(x,y,\sigma)\otimes I(x,y)<br>\end{equation}</p>
<p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下：</p>
<p>\begin{align}<br>m(x,y)      &amp;&#x3D; \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \<br>\theta(x,y) &amp;&#x3D; {\rm arctan}\left[\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right]<br>\end{align}</p>
<h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。</p>
<p>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma&#x3D;0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSeDf.png" width="60%" alt=" " align=center /></p>
<h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值80%能量的峰值时，则将这个方向认为是该特征点的辅方向。所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有15%特征点具有多方向，但这些点对匹配的稳定性至为关键。获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r&#x3D;2.5\sigma$），箭头表示主方向。具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSYrV.png" width="60%" alt=" " align=center /></p>
<h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p>
<h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d^2$个子区域，每个子区域尺寸为$m\sigma$个像元（$d&#x3D;4$，$m&#x3D;3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\sqrt{2}m\sigma(d+1)&#x2F;2$，如下图所示：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTco9A.png" width="35%" alt=" " align=center /></p>
<h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转角，即旋转为特征点的方向。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTc7ct.png" width="60%" alt=" " align=center /></p>
<p>旋转后区域内采样点新的坐标为：</p>
<p>\begin{equation}<br>\begin{pmatrix} x’ \ y’\end{pmatrix} &#x3D; \begin{pmatrix} cos\theta &amp; -sin\theta \ sin\theta &amp; cos\theta\end{pmatrix} \begin{pmatrix} x \ y\end{pmatrix}<br>\end{equation}</p>
<h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d^2$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d^2$，即16个子区域，所以最终共有128个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTcqnf.png" width="60%" alt=" " align=center /></p>
<p>对特征矢量需要加权处理，加权采用$m\sigma d&#x2F;2$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p>
<p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Lowe, David G. “Object recognition from local scale-invariant features.” Proceedings of the seventh IEEE international conference on computer vision. Vol. 2. Ieee, 1999.<br>[2] Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.</p>
]]></content>
      <categories>
        <category>Programming language</category>
      </categories>
      <tags>
        <tag>Image Segementation</tag>
      </tags>
  </entry>
  <entry>
    <title>Scholar</title>
    <url>/scholar/index.html</url>
    <content><![CDATA[<ul>
<li><a href="https://scholar.google.com/citations?hl=en&user=nF5s02gAAAAJ&view_op=list_works&sortby=pubdate">Hai-Wei Chai’s Google Scholar</a></li>
</ul>
<h2 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h2><ul>
<li><p>B. C. Huang, X. Y. Pan, <u><strong>H. W. Chai</strong></u>$^{\ast}$, F. Zhu, D. Liu, X. Y. Pan, “High Sample Rate Audio Generation Using Neural Large Language Models for Mitigating Device Manufacturing Defects,” The 44th IEEE International Conference on Consumer Electronics (IEEE ICCE 2026). (Accepted, Oral Presenter)</p>
</li>
<li><p>B. C. Huang, X. Y. Pan, <u><strong>H. W. Chai</strong></u>$^{\ast}$, F. Zhu, D. Liu, X. Y. Pan, “High Sample Rate Evaluation of Audio Playback Quality Using Deep Learning Audition Models,” The 44th IEEE International Conference on Consumer Electronics (IEEE ICCE 2026). (Accepted, Oral Presenter)</p>
</li>
<li><p>B. C. Huang, X. Y. Pan, <u><strong>H. W. Chai</strong></u>$^{\ast}$, D. Liu, F. Zhu, X. Y. Pan, “Imitation of Human Perceptual Processing of High-Resolution Audio Using Unsupervised Neural Large Language Model,” The 44th IEEE International Conference on Consumer Electronics (IEEE ICCE 2026). (Accepted, Oral Presenter)</p>
</li>
<li><p>G. D. Lai, H. Niu, K. Li, L. Lu, Y. Cai, Y.L. Bian$^{\ast}$,  <u><strong>H. W. Chai</strong></u>$^{\ast \ast}$, Deformation and damage of an Al&#x2F;PTFE composite under uniaxial compression: An in situ synchrotron X-ray tomography study, <em>Mater. Today Commun.</em>, 47, 112790 (2025). <a href="/download/2025_GDLai_MTC.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>R. C. Pan, B. X. Bie, Y. Cai, N. B. Zhang, L. Z. Chen, Y. X. Zhao, K. Li, H. W. Chai, L. Lu$^{\ast}$, S. N. Luo, Shock compression and spallation of polyamides 6 and 66, <em>Int. J. Mech. Sci.</em>, 291-292, 110127 (2025).</p>
</li>
<li><p>Z. Y. Hu, Y. X. Zhao, J. Xu, R. C. Pan$^{\ast}$, H. W. Chai, H. L. Xie, N. B. Zhang, L. Lu, S. N.  Luo, Shock compression and spallation of ABS and ABS&#x2F;PC blend under plate impact, <em>Eur. J. Mech. A-Solids</em>, 112, 105630 (2025).</p>
</li>
<li><p>S. W. Li, Y. L. Bian, Y. Cai, K. Li, J. Y. Hua$^{\ast}$, <u><strong>H. W. Chai</strong></u>$^{\ast \ast}$, S. N. Luo, Structure, mechanical properties, and finite-element modeling of an Al particle&#x2F;resin composite, <em>Compos. Sci. Technol.</em>, 261, 111043 (2025).</p>
</li>
<li><p>L. Lu, Q. X. Liu, W. D. Wang, Y. S. Liu$^{\ast}$, H. W. Chai, F. Zhao, H. L. Xie, N.B. Zhang, Y. Cai$^{\ast \ast}$, H. Chen, S. N. Luo, Impact response of a high-Nb TiAl alloy fabricated via electron beam melting, <em>J. Alloys Compd.</em>, 1014, 178556 (2025).</p>
</li>
<li><p>J. T. Li, J. Y. Hua, <u><strong>H. W. Chai</strong></u>$^{\ast}$, S. N. Luo, Deformation and damage of intermediate-thickness Mg6Gd3Y0.5Zr plate subjected to high-speed ballistic impact, <em>J. Phys. Conf. Ser.</em>, 2891, 6 (2024). <a href="https://iopscience.iop.org/article/10.1088/1742-6596/2891/6/062024/pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>J. Y. Huang, C. K. Lin, Y. L. Bian, H. L. Xie, <u><strong>H. W. Chai</strong></u>$^{\ast}$, Y. Y. Ding$^{\ast \ast}$, S. N. Luo, Strain rate effects on fragment morphology of ceramic alumina: A synchrotron-based study, <em>Int. J. Mech. Sci.</em>, 280, 109506 (2024). <a href="/download/2024_JYHuang_IJMS.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>G. D. Lai, L. P. Sang, Y. L. Bian, H. L. Xie, J. H. Liu, <u><strong>H. W. Chai</strong></u>$^{\ast}$, Interfacial debonding and cracking in a solid propellant composite under uniaxial tension: An in situ synchrotron X-ray tomography study, <em>Compos. Sci. Technol.</em>, 256, 110743 (2024). <a href="/download/2024_GDLai_CST.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>P. F. Han, D. Fan, Y. Cai, L. Z. Chen, H. L. Xie, H. W. Chai, B. X. Bie$^{\ast}$, S. N. Luo, Shock and spallation behavior of ultrahigh molecular weight polyethylene, <em>Int. J. Mech. Sci.</em>, 267, 108984 (2024). </p>
</li>
<li><p>N. B. Zhang, K. Yang, Y. C. Li, Z. H. Lin, Y. Cai, <u><strong>H. W. Chai</strong></u>$^{\ast}$, H. L. Xie, L. Lu, S. N. Luo, Anisotropic dynamic response of AlSi10Mg fabricated via laser powder bed fusion under plate impact, <em>Mater. Chem. Phys.</em>, 314, 128840 (2024). <a href="/download/2023_NBZhang_Mater.Cr..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. J. Deng, Y. W. Shi, Y. X. Li$^{\ast}$, G. D. Lai, H. W. Chai, H. L. Xie, N. B. Zhang$^{\ast \ast}$, S. N. Luo, In situ synchrotron x-ray imaging and diffraction study of additively manufactured AlSi10Mg alloy under uniaxial tension, <em>Mater. Sci. Eng. A</em>, 886, 145702 (2023). </p>
</li>
<li><p>B. X. Bie, R. C. Pan, J. Xu, H. W. Chai, S. Chen, G. H. Du, Y. L. Bian$^{\ast}$, Y. Cai$^{\ast \ast}$, S. N. Luo, Dynamic compression and fracture of poly (ether-ether-ketone) under plate impact, <em>Int. J. Mech. Sci.</em>, 246, 108138 (2023). </p>
</li>
<li><p><strong>H. W. Chai</strong>, D. Fan, J. C. Yuan, L. Hu$^{\ast}$, G. H. Du, H. L. Xie, Q. J. Feng, W. Zhou, J. Y. Huang$^{\ast \ast}$, Deformation dynamics of a neutron-irradiated aluminum alloy: an in-situ synchrotron tomography study, <em>Acta Mater.</em>, 243, 118493 (2023). <a href="/download/2023_hwchai_Acta_Mater..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>L. Hu, F. C. Wu, X. H. Li, H. W. Chai, J. Y. Huang, Q. J. Feng, W. Zhou, Y. Y. Yu, J. B. Hu$^{\ast}$, Fracture behaviors of long-term low-dose-rate neutron-irradiated Al-Mg-Si alloy, <em>Appl. Phys. Lett.</em>, 121, 18 (2022).</p>
</li>
<li><p>J. C. Cheng, S. P. Zhao, D. Fan, H. W. Chai, S. J. Ye, C. Li, S. N. Luo, Y. Cai$^{\ast}$, J. Y. Huang$^{\ast \ast}$, Multiple ballistic impacts on 2024-T4 aluminum alloy by spheres: Experiments and modelling, <em>J. Mater. Sci. Technol.</em>, 94, 164-174 (2021).</p>
</li>
<li><p><strong>H. W. Chai</strong>, Z. L. Xie$^{\ast}$, Z. D. Feng, S. N. Luo, J. Y. Huang$^{\ast \ast}$, Three-dimensional deformation dynamics of porous titanium under uniaxial compression, <em>Mater. Charact.</em>, 111494 (2021). <a href="/download/2021_hwchai_Mater.Charact..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. L. Bian, H. W. Chai, S. J. Ye, H. L. Xie, X. H. Yao$^{\ast}$, Y. Cai$^{\ast \ast}$, Compression and spallation properties of polyethylene terephthalate under plateimpact loading, <em>Int. J. Mech. Sci.</em>, 211, 106736 (2021).</p>
</li>
<li><p>J. C. Cheng$^\dagger$, <strong>H. W. Chai</strong>$^\ddagger$, G. L. Fan, Z. Q. Li, H. L. Xie, Z. Q. Tan$^{\ast}$, B. X. Bie$^{\ast \ast}$, J. Y. Huang, S. N. Luo, Anisotropic spall behavior of CNT&#x2F;2024Al laminar composite under plate impact, <em>Carbon</em>, 170, 589-599 (2020). <a href="/download/2020_jccheng_Carbon.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Z. H. Dai, L. Lu$^\ast$, <u><strong>H. W. Chai</strong></u>$^{\ast\ast}$, X. H. Xiao, X. L. Gong, S. N. Luo, Anisotropic deformation and damage of a textured magnesium alloy AZ31 under high strain rate loading, <em>Mater. Sci. Eng. A</em>, 789, 139690 (2020). <a href="/download/2020_ZHDai_Mater.Sci.Eng.A.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p><strong>H. W. Chai</strong>, Z. L. Xie, X. H. Xiao, H. L. Xie, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Microstructural characterization and constitutive modelling of deformation of closed-cell foams based on in-situ x-ray tomography, <em>Int. J. Plast.</em>, 131, 102730 (2020). <a href="/download/2020_hwchai_Int.J.Plast..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>H. Y. Li, H. W. Chai, X. H. Xiao, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Fractal breakage of porous sand particles: microstructures and mechanisms, <em>Powder Technol.</em>, 363, 112–121 (2020). <a href="/download/2020_HYL_PowderTechnol.pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>S. J. Ye, H. W. Chai, X. H. Xiao, Y. Cai$^{\ast}$, X. H. Yao$^{\ast \ast}$, S. N. Luo, Spallation of Polycarbonate under Plate Impact Loading, <em>J. Appl. Phys.</em>, 126, 085105 (2019). </p>
</li>
<li><p>C. Sen, H. W. Chai, A. M. He, Thomas Tschentscher, Yang Cai$^{\ast}$, S. N. Luo$^{\ast \ast}$, Resolving dynamic fragmentation of liquids at the nanoscale with ultrafast small-angle X-ray scattering. <em>J. Synchrotron Radiat.</em>, 26.5 (2019).</p>
</li>
<li><p><strong>H. W. Chai</strong>, H. Y. Li, X. H. Xiao, J. Y. Huang$^{\ast}$, S. N. Luo$^{\ast \ast}$, Correlation between Cell Wall Buckling and Deformation Banding in a Closed-Cell Foam, <em>Scr. Mater.</em>, 170, 177-182 (2019). <a href="/download/2019_hwchai_Script._Mater..pdf"><font color="#80b1d3">[PDF]</font></a></p>
</li>
<li><p>Y. Yao, H. W. Chai, C. Li, B. X. Bie, X. H. Xiao, J. Y. Huang$^{\ast}$, M. L. Qi$^{\ast \ast}$, S. N. Luo$^{\ast \ast \ast}$, Deformation and damage of sintered low-porosity aluminum under planar impact: microstructures and mechanisms, <em>J. Mater. Sci.</em>, 53, 4582-4597 (2018).</p>
</li>
<li><p>C. Li, J. Y. Huang, X. C. Tang, H. W. Chai, X. H. Xiao, Z. D. Feng$^{\ast}$, S. N. Luo$^{\ast \ast}$, Effects of structural anisotropy on deformation and damage of a duplex stainless steel under high strain rate loading, <em>Mater. Sci. Eng. A</em>, 705, 265-272 (2017).</p>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>数据科学：离散小波变换（Discrete Wavelet Transformation，DWT）</title>
    <url>/archive/AI-DWT.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUgUjP.png"></p>
<p>The world of signal processing is a fascinating blend of mathematics, engineering, and computer science. From audio to images, and even to more abstract concepts like financial time series, the ability to manipulate and analyze signals is crucial. Among the many tools available to the signal processing engineer, the Wavelet Transform stands out due to its flexibility and adaptability. In this article, we’ll delve deep into the intuition behind wavelets, show practical examples, and provide insightful visualizations using Python.</p>
<span id="more"></span>

<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://www.scicoding.com/introduction-to-wavelet-transform-using-python/">https://www.scicoding.com/introduction-to-wavelet-transform-using-python/</a></li>
<li><a href="https://pywavelets.readthedocs.io/en/latest/ref/dwt-discrete-wavelet-transform.html">https://pywavelets.readthedocs.io/en/latest/ref/dwt-discrete-wavelet-transform.html</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>人工智能：Pytorch训练可重复性（Reproducibility）</title>
    <url>/archive/AI-Repeatability.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUAM6J.jpg"></p>
<p>在不同的 PyTorch 版本或不同平台上，不能保证完全可复现的结果。此外，即使使用相同的随机种子，CPU 和 GPU 执行之间的结果也可能无法复现。但是，您可以采取措施来限制平台、设备和 PyTorch 版本的非确定性行为来源。首先，您可以控制随机性的来源，这些来源会导致应用程序的多次执行表现不同。其次，您可以将 PyTorch 配置为避免对某些操作使用非确定性算法，以便在给定相同输入的情况下，对这些操作的多次调用将产生相同的结果。最后，在执行多进程数据加载时还需注意控制加载的随机性工作进程种子。本文内容参考 Pytorch 官方文档：<a href="https://pytorch.org/docs/stable/notes/randomness.html#controlling-sources-of-randomness">https://pytorch.org/docs/stable/notes/randomness.html#controlling-sources-of-randomness</a></p>
<blockquote class="blockquote-center">
<p>Deterministic operations are often slower than nondeterministic operations, so single-run performance may decrease for your model. However, determinism may save time in development by facilitating experimentation, debugging, and regression testing.</p>

</blockquote>

<span id="more"></span>

<h2 id="控制随机性的来源"><a href="#控制随机性的来源" class="headerlink" title="控制随机性的来源"></a>控制随机性的来源</h2><h3 id="PyTorch-随机数生成器"><a href="#PyTorch-随机数生成器" class="headerlink" title="PyTorch 随机数生成器"></a>PyTorch 随机数生成器</h3><p>您可以使用 <code>torch.manual_seed()</code> 为所有设备（CPU 和 CUDA）的 RNG 设置种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.manual_seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>某些 PyTorch 操作可能会在内部使用随机数。例如，<code>torch.svd_lowrank()</code> 就会这样做。因此，使用相同的输入参数连续多次调用它可能会得到不同的结果。但是，只要在应用程序开始时将 <code>torch.manual_seed()</code> 设置为常量，并且消除了所有其他非确定性来源，则每次在相同环境中运行应用程序时，都会生成相同的随机数序列。</p>
<p>还可以通过在后续调用之间将 <code>torch.manual_seed()</code> 设置为相同的值，从使用随机数的操作中获得相同的结果。</p>
<h3 id="Python-随机数生成器"><a href="#Python-随机数生成器" class="headerlink" title="Python 随机数生成器"></a>Python 随机数生成器</h3><p>对于自定义运算符，您可能还需要设置 Python 种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h3 id="其他库中的随机数生成器"><a href="#其他库中的随机数生成器" class="headerlink" title="其他库中的随机数生成器"></a>其他库中的随机数生成器</h3><p>如果您或您正在使用的任何库依赖于 NumPy，则可以使用以下代码为全局 NumPy RNG 设置种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>但是，某些应用程序和库可能使用 NumPy 随机数生成器对象，而不是全局 RNG（<a href="https://numpy.com.cn/doc/stable/reference/random/generator.html">https://numpy.com.cn/doc/stable/reference/random/generator.html</a>），这些对象也需要一致地设置种子。</p>
<p>如果您正在使用任何其他使用随机数生成器的库，请参阅这些库的文档，以了解如何为它们设置一致的种子。</p>
<h3 id="CUDA-卷积基准测试"><a href="#CUDA-卷积基准测试" class="headerlink" title="CUDA 卷积基准测试"></a>CUDA 卷积基准测试</h3><p>由 CUDA 卷积操作使用的 cuDNN 库可能是应用程序多次执行之间非确定性的来源。当使用一组新的尺寸参数调用 cuDNN 卷积时，一个可选功能可以运行多个卷积算法，对它们进行基准测试以找到最快的算法。然后，在该过程的剩余时间内，将针对相应的尺寸参数集一致地使用最快的算法。由于基准测试噪声和不同的硬件，即使在同一台机器上，基准测试也可能会在后续运行中选择不同的算法。</p>
<p>使用 <code>torch.backends.cudnn.benchmark = False</code> 禁用基准测试功能会导致 cuDNN 确定性地选择算法，但可能会降低性能。</p>
<p>但是，如果您不需要在应用程序的多次执行之间保持可复现性，则启用基准测试功能 <code>torch.backends.cudnn.benchmark = True</code> 可能会提高性能。</p>
<p>请注意，此设置与下面讨论的 <code>torch.backends.cudnn.deterministic</code> 设置不同。</p>
<h2 id="避免非确定性算法"><a href="#避免非确定性算法" class="headerlink" title="避免非确定性算法"></a>避免非确定性算法</h2><p><code>torch.use_deterministic_algorithms()</code> 允许您将 PyTorch 配置为在可用时使用确定性算法而不是非确定性算法，并在已知操作是非确定性算法（并且没有确定性替代算法）时抛出错误。</p>
<p>有关受影响操作的完整列表，请参阅 <a href="https://pytorch.ac.cn/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms"><code>torch.use_deterministic_algorithms()</code></a> 的文档。如果某个操作没有按照文档正确执行，或者您需要一个没有确定性实现的操作的确定性实现，请提交问题：<a href="https://github.com/pytorch/pytorch/issues?q=label:%22module:%20determinism%22">https://github.com/pytorch/pytorch/issues?q=label:%22module:%20determinism%22</a></p>
<p>例如，运行 <code>torch.Tensor.index_add_()</code> 的非确定性 CUDA 实现将引发错误：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">2</span>, <span class="number">2</span>).cuda().index_add_(<span class="number">0</span>, torch.tensor([<span class="number">0</span>, <span class="number">1</span>]), torch.randn(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">RuntimeError: index_add_cuda_ does <span class="keyword">not</span> have a deterministic implementation, but you <span class="built_in">set</span></span><br><span class="line"><span class="string">&#x27;torch.use_deterministic_algorithms(True)&#x27;</span>. ...</span><br></pre></td></tr></table></figure>

<p>当使用稀疏密集 CUDA 张量调用 <code>torch.bmm()</code> 时，它通常使用非确定性算法，但当打开确定性标志时，将使用其备用的确定性实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.bmm(torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>).to_sparse().cuda(), torch.randn(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>).cuda())</span><br><span class="line">tensor([[[ <span class="number">1.1900</span>, -<span class="number">2.3409</span>],</span><br><span class="line">         [ <span class="number">0.4796</span>,  <span class="number">0.8003</span>]],</span><br><span class="line">        [[ <span class="number">0.1509</span>,  <span class="number">1.8027</span>],</span><br><span class="line">         [ <span class="number">0.0333</span>, -<span class="number">1.1444</span>]]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>此外，如果您正在使用 CUDA 张量，并且您的 CUDA 版本为 10.2 或更高版本，则应根据 CUDA 文档设置环境变量 CUBLAS_WORKSPACE_CONFIG：<a href="https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility">https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility</a></p>
<h3 id="CUDA-RNN-和-LSTM"><a href="#CUDA-RNN-和-LSTM" class="headerlink" title="CUDA RNN 和 LSTM"></a>CUDA RNN 和 LSTM</h3><p>在某些版本的 CUDA 中，RNN 和 LSTM 网络可能具有非确定性行为。有关详细信息和解决方法，请参阅 <code>torch.nn.RNN()</code> 和 <code>torch.nn.LSTM()</code>。</p>
<h3 id="填充未初始化的内存"><a href="#填充未初始化的内存" class="headerlink" title="填充未初始化的内存"></a>填充未初始化的内存</h3><p><code>torch.empty()</code> 和 <code>torch.Tensor.resize_()</code> 等操作可以返回包含未定义值的未初始化内存的张量。如果需要确定性，则使用此类张量作为另一个操作的输入是无效的，因为输出将是非确定性的。但实际上没有任何东西可以阻止运行此类无效代码。因此，为了安全起见，默认情况下 <code>torch.utils.deterministic.fill_uninitialized_memory</code> 设置为 <code>True</code>，如果设置了 <code>torch.use_deterministic_algorithms(True)</code>，它将使用已知值填充未初始化的内存。这将防止这种非确定性行为的可能性。</p>
<p>然而，填充未初始化的内存不利于性能。因此，如果您的程序有效并且不使用未初始化的内存作为操作的输入，则可以关闭此设置以获得更好的性能。</p>
<h2 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h2><p>DataLoader 将按照 <a href="https://pytorch.ac.cn/docs/stable/data.html#data-loading-randomness">多进程数据加载中的随机性</a> 算法重新设定工作进程的种子。使用 <code>worker_init_fn()</code> 和 <code>generator</code> 来保持可重复性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">seed_worker</span>(<span class="params">worker_id</span>):</span><br><span class="line">    worker_seed = torch.initial_seed() % <span class="number">2</span>**<span class="number">32</span></span><br><span class="line">    numpy.random.seed(worker_seed)</span><br><span class="line">    random.seed(worker_seed)</span><br><span class="line"></span><br><span class="line">g = torch.Generator()</span><br><span class="line">g.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">DataLoader(</span><br><span class="line">    train_dataset,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_workers=num_workers,</span><br><span class="line">    worker_init_fn=seed_worker,</span><br><span class="line">    generator=g,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="实际实践中的随机种子定义函数"><a href="#实际实践中的随机种子定义函数" class="headerlink" title="实际实践中的随机种子定义函数"></a>实际实践中的随机种子定义函数</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os, gzip, re, string, glob, time, random, shutil, itertools, json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.cuda.amp <span class="keyword">import</span> GradScaler, autocast</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> CrossEntropyLoss</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD, AdamW</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> LambdaLR,CosineAnnealingLR</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> IterableDataset, DataLoader, DistributedSampler</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer, TrainingArguments, AutoConfig, set_seed, Trainer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setup_seed</span>(<span class="params">seed</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Repeatability of model training process. Refer to the following link: </span></span><br><span class="line"><span class="string">https://pytorch.ac.cn/docs/stable/notes/randomness.html</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    </span><br><span class="line">    set_seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    </span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.use_deterministic_algorithms(<span class="literal">True</span>)</span><br><span class="line">    os.environ[<span class="string">&quot;CUBLAS_WORKSPACE_CONFIG&quot;</span>] = <span class="string">&quot;:4096:8&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>人工智能：语言大模型训练与部署流程</title>
    <url>/archive/AI-Gemma.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/17/pAUAupF.png"></p>
<p>Gemini是Google开发的一款多模态大模型，能够处理文本、图像、音频、视频和代码等信息。目前推出的Gemini模型分为Nano、Pro、Ultra以及1.5Pro，这些模型都可以在谷歌网站上进行访问：<a href="https://gemini.google.com/">https://gemini.google.com</a> 。此外，谷歌还提供了<a href="https://ai.google.dev/gemini-api/docs/models/gemini?hl=zh-cn">Gemini模型的API</a>，可在代码中调用模型，输入文本和图片然后，输出文本回复，以及一款<a href="https://www.kaggle.com/models/google/gemma">开源大语言模型gemma</a>，该模型基于Gemini的研究和技术开发，能处理文本信息。模型有2b和7b两种参数规模以及经过指令调优（2b-it &amp; 7b-it）和未调优的基础模型等版本，可通过多种框架构建：Keras、Pytorch、Transformers、Gemma C++、TensorRT-LLM、TensorFlow Lite、MaxText、Pax、Flax。感谢我过去的学生 Weizheng Wang, Hui Wu 对本文的贡献。</p>
<span id="more"></span>

<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="配置-CentOS-Stream-10"><a href="#配置-CentOS-Stream-10" class="headerlink" title="配置 CentOS Stream 10"></a>配置 CentOS Stream 10</h3><p>本文选用 CentOS Stream 10 操作系统，内核版本 6.12.0，并配置网络环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -r                        <span class="comment"># 查看内核版本</span></span></span><br><span class="line">6.12.0-89.el10.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum --exclude=kernel* update    <span class="comment"># 禁用 yum update，避免 kernel 更新导致的生产环境不稳定风险</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nmcli connection show</span></span><br><span class="line">NAME       UUID                                  TYPE      DEVICE</span><br><span class="line">enp0s31f6  52eaa752-25be-451f-a8c1-4037030e4cb4  ethernet  enp0s31f6</span><br><span class="line">lo         4d717253-e93b-404c-9487-38d706cb9308  loopback  lo</span><br><span class="line">enp2s0     7ef8d2c6-cd0a-3123-9fef-4218782fcf1b  ethernet  --</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/NetworkManager/system-connections/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">su vi enp0s31f6.nmconnection    <span class="comment"># 编辑对应网卡的配置文件</span></span></span><br></pre></td></tr></table></figure>

<p>编辑 enp031f6.connection 文件，示例信息如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[connection]</span><br><span class="line">id=enp0s31f6</span><br><span class="line">uuid=52eaa752-25be-451f-a8c1-4037030e4cb4</span><br><span class="line">type=ethernet</span><br><span class="line">autoconnect-priority=-999</span><br><span class="line">interface-name=enp0s31f6</span><br><span class="line">timestamp=1748939249</span><br><span class="line"></span><br><span class="line">[ethernet]</span><br><span class="line"></span><br><span class="line">[ipv4]</span><br><span class="line">address1=192.168.0.125/24</span><br><span class="line">dns=192.168.0.1;</span><br><span class="line">gateway=192.168.0.1</span><br><span class="line">method=manual</span><br><span class="line"></span><br><span class="line">[ipv6]</span><br><span class="line">addr-gen-mode=eui64</span><br><span class="line">method=auto</span><br><span class="line"></span><br><span class="line">[proxy]</span><br></pre></td></tr></table></figure>

<p>修改完成后重新启动网络服务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ systemctl restart NetworkManager</span><br><span class="line">$ nmcli c reload                           # 重新加载配置文件</span><br><span class="line">$ nmcli c up enp031f6                      # 重启ens33网卡</span><br><span class="line"></span><br><span class="line">$ ping www.baidu.com -c4                   # 验证网络连接</span><br><span class="line">PING www.a.shifen.com (39.156.66.14) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=1 ttl=50 time=38.5 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=2 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=3 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=4 ttl=50 time=38.2 ms</span><br></pre></td></tr></table></figure>

<p>配置硬盘分区永久挂载：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsblk   <span class="comment"># 查看磁盘硬件</span></span></span><br><span class="line">NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sda           8:0    0 21.8T  0 disk /mnt/disk1</span><br><span class="line">sdb           8:16   0 14.6T  0 disk /mnt/disk0</span><br><span class="line">sdc           8:32   0 21.8T  0 disk /mnt/disk2</span><br><span class="line">nvme0n1     259:0    0  1.8T  0 disk</span><br><span class="line">├─nvme0n1p1 259:1    0  600M  0 part /boot/efi</span><br><span class="line">                    ...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">fdisk /dev/sda                <span class="comment"># 修改该磁盘中的分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mkfs.ext4 /dev/sda            <span class="comment"># 按 ext4 文件系统格式化分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /mnt/mydrive            <span class="comment"># 创建挂载路径</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount /dev/sda /mnt/mydrive   <span class="comment"># 临时挂载该分区</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">blkid /dev/sda                <span class="comment"># 查看该磁盘的UUID与文件系统格式</span></span></span><br><span class="line">/dev/sda: UUID=&quot;E600-A571&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;exfat&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/fstab                 <span class="comment"># 修改 /etc/fstab 文件永久挂载磁盘</span></span></span><br><span class="line">UUID=04c21771-726f-42d0-a7d3-34f4b5cd88ab /                 xfs     defaults        0 0</span><br><span class="line">UUID=246017ac-59da-4dd2-9493-dbcba61a2958 /boot             xfs     defaults        0 0</span><br><span class="line">UUID=AD2B-E205                            /boot/efi         vfat    umask=0077,shortname=winnt 0 2</span><br><span class="line">UUID=35b358b4-d3c7-443f-866d-8db5d364a46b /home             xfs     defaults        0 0</span><br><span class="line">UUID=521947e5-c326-4436-9e2d-26a148d8f42f none              swap    defaults        0 0</span><br><span class="line">UUID=40948978-7d0f-4e63-9feb-ffa7ab03f2a4 /mnt/disk0        ext4    defaults        0 0</span><br><span class="line">UUID=E600-A571                            /mnt/disk1        exfat   defaults        0 0</span><br><span class="line">UUID=C839-78EB                            /mnt/disk2        exfat   defaults        0 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload        <span class="comment"># 修改 fstab 文件后重启 daemon</span></span></span><br></pre></td></tr></table></figure>

<p>为用户名为 hwchai 的普通用户创建 Ed25519 密钥：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ su hwchai                                              # 切换到 hwchai</span><br><span class="line">$ ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519             # 创建 Ed25519 密钥</span><br><span class="line">$ chmod 700 ~/.ssh</span><br><span class="line">$ chmod 600 ~/.ssh/id_ed25519</span><br><span class="line">$ chmod 644 ~/.ssh/id_ed25519.pub                        # 设置正确的权限</span><br><span class="line">$ cat ~/.ssh/id_ed25519.pub &gt;&gt; ~/.ssh/authorized_keys    # 将公钥加入到自己的 authorized_keys 中</span><br><span class="line">$ chmod 600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">$ su vi /etc/ssh/sshd_config                             # 回到 root 账号并编辑 ssh 配置文件</span><br><span class="line">PubkeyAuthentication yes                                 # 启用公钥认证</span><br><span class="line">PasswordAuthentication no                                # 禁用密码登录（提高安全性）</span><br><span class="line">PermitRootLogin prohibit-password                        # root 仅允许密钥登录</span><br><span class="line"></span><br><span class="line">$ systemctl restart sshd</span><br></pre></td></tr></table></figure>

<h3 id="安装-Nvidia-Driver-CUDA-及-cuDNN-环境"><a href="#安装-Nvidia-Driver-CUDA-及-cuDNN-环境" class="headerlink" title="安装 Nvidia Driver, CUDA 及 cuDNN 环境"></a>安装 Nvidia Driver, CUDA 及 cuDNN 环境</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum update -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install pciutils                                <span class="comment"># 使用 yum install pciutils 安装 lspci 工具</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lspci | grep -i nvidia                              <span class="comment"># 检查显卡连接状态</span></span></span><br><span class="line">16:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">34:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ac:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ca:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y gcc kernel-devel kernel-headers     <span class="comment"># 安装编译环境和内核开发包，确保与当前内核版本相匹配</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install <span class="string">&quot;kernel-devel-uname-r == <span class="subst">$(uname -r)</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/selinux/config         <span class="comment"># 修改SELINUX=disabled。保存退出</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">setenforce 0                   <span class="comment"># 临时关闭selinux</span></span></span><br></pre></td></tr></table></figure>

<h4 id="安装-Nvidia-driver"><a href="#安装-Nvidia-driver" class="headerlink" title="安装 Nvidia driver"></a>安装 Nvidia driver</h4><p>禁用 Linux 默认的显示驱动 nouveau：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep nouveau          <span class="comment"># 该命令若无输出，则跳过以下步骤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /lib/modprobe.d/dist-blacklist.conf</span> </span><br></pre></td></tr></table></figure>

<p>编辑 &#x2F;lib&#x2F;modprobe.d&#x2F;dist-blacklist.conf 文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># blacklist nvidiafb                 # 注释掉 blacklist nvidiafb</span><br><span class="line">blacklist nouveau                    # 文件末尾添加：blacklist nouveau</span><br><span class="line">options nouveau modeset=0            # 文件末尾添加：options nouveau modeset=0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">$ dracut /boot/initramfs-$(uname -r).img $(uname -r)             # 重建 initramfs image 镜像</span><br><span class="line">$ systemctl set-default multi-user.target                        # 修改运行模式为文本模式 </span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line">$ lsmod | grep nouveau                                           # 该命令若无输出，表示禁用 nouveau 成功</span><br></pre></td></tr></table></figure>

<p>在<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">Nvidia driver download</a>根据GPU型号及操作系统选择相应的驱动程序下载至本地后安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nvidia-smi                <span class="comment"># 查看 Nvidia GPU 实时信息，验证 Nvidia driver</span></span></span><br><span class="line">Thu Jun  5 22:19:43 2025</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA A100 80GB PCIe          Off |   00000000:16:00.0 Off |                    0 |</span><br><span class="line">| N/A   28C    P0             62W /  300W |       0MiB /  81920MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line"></span><br><span class="line">                                        ......</span><br></pre></td></tr></table></figure>

<h4 id="安装-CUDA-Toolkit"><a href="#安装-CUDA-Toolkit" class="headerlink" title="安装 CUDA Toolkit"></a>安装 CUDA Toolkit</h4><p>在<a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">CUDA Toolkit 12.9 Downloads</a>中下载 CUDA 工具包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cuda/12.9.0/local_installers/cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ rpm -i cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cuda-toolkit-12-9</span><br><span class="line"></span><br><span class="line">$ echo &#x27;export PATH=/usr/local/cuda/bin:$PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ echo &#x27;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ source ~/.bashrc</span><br><span class="line">$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2025 NVIDIA Corporation</span><br><span class="line">Built on Wed_Apr__9_19:24:57_PDT_2025</span><br><span class="line">Cuda compilation tools, release 12.9, V12.9.41</span><br><span class="line">Build cuda_12.9.r12.9/compiler.35813241_0</span><br></pre></td></tr></table></figure>

<h4 id="安装-cuDNN"><a href="#安装-cuDNN" class="headerlink" title="安装 cuDNN"></a>安装 cuDNN</h4><p>在<a href="https://developer.nvidia.com/cudnn-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">cuDNN 9.10.1 Downloads</a>中下载 cuDNN 包：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cudnn/9.10.1/local_installers/cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ rpm -i cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cudnn</span><br></pre></td></tr></table></figure>

<h4 id="安装Miniconda-3"><a href="#安装Miniconda-3" class="headerlink" title="安装Miniconda 3"></a>安装Miniconda 3</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda --version</span></span><br><span class="line">conda 24.4.0</span><br></pre></td></tr></table></figure>

<h3 id="安装-Pytorch-及-Transformers-等环境"><a href="#安装-Pytorch-及-Transformers-等环境" class="headerlink" title="安装 Pytorch 及 Transformers 等环境"></a>安装 Pytorch 及 Transformers 等环境</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda create -n hwchai python=3.13        <span class="comment"># 环境创建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda activate hwchai                     <span class="comment"># 激活环境</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install torch transformers bitsandbytes tensorboard trl datasets peft</span></span><br></pre></td></tr></table></figure>

<p>查看 Pytorch, CUDA 及 cuDNN 版本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.backends.cudnn.version())</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">2.7</span><span class="number">.1</span>+cu126</span><br><span class="line"><span class="number">12.6</span></span><br><span class="line"><span class="number">90501</span></span><br></pre></td></tr></table></figure>

<p>可能还有包未列出，可按照运行提示安装。</p>
<h3 id="部署-Gemma-训练环境及预训练模型"><a href="#部署-Gemma-训练环境及预训练模型" class="headerlink" title="部署 Gemma 训练环境及预训练模型"></a>部署 Gemma 训练环境及预训练模型</h3><p>注册Kaggle账号，在网站 <a href="https://www.kaggle.com/models/google/gemma">https://www.kaggle.com/models/google/gemma</a> 下载所需模型，配置要求：Python≥3.8，下载模型：</p>
<img src="https://s21.ax1x.com/2024/07/12/pk4n7AP.png" width = 95% div align=center />

<p>官方文档页面： <a href="https://github.com/google/gemma_pytorch">https://github.com/google/gemma_pytorch</a> ，文档中介绍了在Linux下使用docker配置环境并运行模型的方法，但未说明对模型进行调整的操作和对训练集的要求，使用常规Pytorch对NLP模型的训练方式即可。</p>
<p>下载的预训练模型分别存放在<code>/home/ai/gemma-2b</code>及<code>/home/ai/gemma-7b</code>中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-2b</span><br><span class="line">total 14712812</span><br><span class="line">drwxrwxr-x. 2 ai ai        4096 Jun  6 22:49 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--. 1 ai ai         634 Jun  6 22:49 config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai 10031780672 Jun  6 22:49 gemma-2b.gguf</span><br><span class="line">-rw-rw-r--. 1 ai ai         137 Jun  6 22:18 generation_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1620 Jun  6 22:49 .gitattributes</span><br><span class="line">-rw-rw-r--. 1 ai ai  4945242264 Jun  6 22:18 model-00001-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai    67121608 Jun  6 22:02 model-00002-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai       13489 Jun  6 22:02 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--. 1 ai ai         555 Jun  6 22:02 special_tokens_map.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1108 Jun  6 22:02 tokenizer_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai    17477553 Jun  6 22:02 tokenizer.json</span><br><span class="line">-rw-rw-r--. 1 ai ai     4241003 Jun  6 22:02 tokenizer.model</span><br><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-7b</span><br><span class="line">total 50054220</span><br><span class="line">drwxrwxr-x  3 ai ai        4096 Jun 29 06:13 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--  1 ai ai         636 Jun 29 06:13 config.json</span><br><span class="line">drwxrwxr-x  2 ai ai          88 Jun 29 06:13 examples</span><br><span class="line">-rw-rw-r--  1 ai ai 34158344288 Jun 29 06:13 gemma-7b.gguf</span><br><span class="line">-rw-rw-r--  1 ai ai         137 Jun 29 05:25 generation_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1620 Jun 29 06:13 .gitattributes</span><br><span class="line">-rw-rw-r--  1 ai ai  4995496656 Jun 29 05:25 model-00001-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953168 Jun 29 05:18 model-00002-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953200 Jun 29 05:11 model-00003-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  2113988336 Jun 29 05:04 model-00004-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai       20920 Jun 29 05:01 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--  1 ai ai         555 Jun 29 05:01 special_tokens_map.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1108 Jun 29 05:01 tokenizer_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai    17477553 Jun 29 05:01 tokenizer.json</span><br><span class="line">-rw-rw-r--  1 ai ai     4241003 Jun 29 05:01 tokenizer.model</span><br></pre></td></tr></table></figure>

<p>测试数据集保存在另一路径，数据形如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) [root@server01 ~]# less /dataset02/dataset/01.ont.seq/train/Exp001_shanzhu.aozhouhuangjin.raw.fastq.txt</span><br><span class="line">TGCTTCGTTCAGTTACGTATTGCTAAGGTTAAACAGACGACTACAAACTGAATCGACAGCACCTCTTTCTATTATGGTGGACTTTATGTATTATAGTTTTGATTTGTGTATTATGGATTATGGTTGGTTGCTTTGATTTAGCTAGATTATGGATTACTTAGCCTCGTAAAGTGGTATCGATCGAAATGAGTGTAATGGTCGTGATG</span><br><span class="line">ACATTTTGGAGGGTAACATCGATGTTTTGTTTAGATTGTAAAGAAGGGTGCCTATGGTATGTATGAGATGGGGTAAGAAGTGATTTTCTTGAATTGTCCATATTCCAATGTTTGGTTACTTAGTGAAATCGTCGGTGTTGATGCTTACTTGTTTTGTAGAATCATAATGGTGGCTAGC</span><br><span class="line">TACTTCAGTTTCGGTTACGTATTGCTAAGGTTAACAGACGACTACAAAACGGAATCGACAGCACCTTTATTTTGTGTTTGTCGTTGGAGAATTGATCTTTCTTCAATGAAATTTATCTCTAGAATTTATTTGTTGATTAATTTCTAGGTTGAAGAACATAAAGAAATTCATAGATTAAATCCTATCTGAATAACTGGGGCCGATCT</span><br><span class="line">ATGCGGCAATAAAAGGTTAATGATTTGTCTTTAATAAAGTTTATTTAAATCATGTATGATTAACCATGATCAATATAAATTTGGATAGGATTAATGTAATTTGATCGTAAGTACATTAATCAATCAAGATCACTATTTGGCTAGTAAAGGCAACAATTCAATTAGCATATCTATAGAAAATTGTCATATCATTACTTGGTTAAATT</span><br><span class="line">······</span><br></pre></td></tr></table></figure>

<h2 id="Gemma模型导入与配置"><a href="#Gemma模型导入与配置" class="headerlink" title="Gemma模型导入与配置"></a>Gemma模型导入与配置</h2><p>编写脚本，使用transformers加载本地模型和分词器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, PeftModel, prepare_model_for_kbit_training</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line"> AutoModelForCausalLM,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> BitsAndBytesConfig,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> TrainingArguments,</span><br><span class="line"> set_seed</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=<span class="literal">True</span>, use_fast=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.pad_token_id =  tokenizer.eos_token_id</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;left&#x27;</span></span><br><span class="line"></span><br><span class="line">data_files = &#123;<span class="string">&quot;train&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/train1.tsv&quot;</span>, <span class="string">&quot;test&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/dev1.tsv&quot;</span>&#125;</span><br><span class="line">ds = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line"></span><br><span class="line">compute_dtype = <span class="built_in">getattr</span>(torch, <span class="string">&quot;float16&quot;</span>)</span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">     load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">     bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">     bnb_4bit_compute_dtype=compute_dtype,</span><br><span class="line">     bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">       model_path, quantization_config=bnb_config, device_map=&#123;<span class="string">&quot;&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">)</span><br><span class="line">model = prepare_model_for_kbit_training(model)</span><br><span class="line"><span class="comment"># Configure the pad token in the model</span></span><br><span class="line">model.config.pad_token_id = tokenizer.pad_token_id</span><br><span class="line">model.config.use_cache = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 编辑微调配置</span></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">     lora_alpha=<span class="number">16</span>,</span><br><span class="line">     lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">     r=<span class="number">16</span>,</span><br><span class="line">     bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">     task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">     target_modules= [<span class="string">&#x27;k_proj&#x27;</span>, <span class="string">&#x27;q_proj&#x27;</span>, <span class="string">&#x27;v_proj&#x27;</span>, <span class="string">&#x27;o_proj&#x27;</span>, <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 设定训练参数</span></span><br><span class="line">training_arguments = TrainingArguments(</span><br><span class="line">     output_dir=<span class="string">&quot;./results_qlora&quot;</span>,</span><br><span class="line">     evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">     do_eval=<span class="literal">True</span>,</span><br><span class="line">     optim=<span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">     per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">     per_device_eval_batch_size=<span class="number">4</span>,</span><br><span class="line">     log_level=<span class="string">&quot;debug&quot;</span>,</span><br><span class="line">     save_steps=<span class="number">50</span>,</span><br><span class="line">     logging_steps=<span class="number">50</span>,</span><br><span class="line">     learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">     eval_steps=<span class="number">50</span>,</span><br><span class="line">     max_steps=<span class="number">300</span>,</span><br><span class="line">     warmup_steps=<span class="number">30</span>,</span><br><span class="line">     lr_scheduler_type=<span class="string">&quot;linear&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 载入训练配置</span></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">     model=model,</span><br><span class="line">     train_dataset=ds[<span class="string">&#x27;train&#x27;</span>],</span><br><span class="line">     eval_dataset=ds[<span class="string">&#x27;test&#x27;</span>],</span><br><span class="line">     peft_config=peft_config,</span><br><span class="line">     dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">     max_seq_length=<span class="number">128</span>,</span><br><span class="line">     tokenizer=tokenizer,</span><br><span class="line">     args=training_arguments,</span><br><span class="line">)</span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<p>将脚本保存为gemmatrain.py，命令行运行<code>python gemma.train.py</code> ，即可运行。</p>
<p>在上述脚本中导入了tsv格式的文本作为训练和测试集，实际上原始格式的文本并不能直接作为模型的输入，还需将一整行的文本内容（即单个输入输出对）记在同一标签“text”下。如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">text</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br></pre></td></tr></table></figure>

<p>以上格式仅为测试使用，后续会考虑数据集的具体内容和训练需求进行优化。</p>
]]></content>
  </entry>
  <entry>
    <title>数据科学：短时傅里叶变换（Short-Time Fourier Transform，STFT）</title>
    <url>/archive/AI-STFT.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUgbg1.png"></p>
<p>The short-time Fourier transform (STFT) is a Fourier-related transform used to determine the sinusoidal frequency and phase content of local sections of a signal as it changes over time. In practice, the procedure for computing STFTs is to divide a longer time signal into shorter segments of equal length and then compute the Fourier transform separately on each shorter segment. This reveals the Fourier spectrum on each shorter segment. One then usually plots the changing spectra as a function of time, known as a spectrogram or waterfall plot, such as commonly used in software defined radio (SDR) based spectrum displays. Full bandwidth displays covering the whole range of an SDR commonly use fast Fourier transforms (FFTs) with $2^24$ points on desktop computers.</p>
<span id="more"></span>]]></content>
  </entry>
  <entry>
    <title>人工智能：多头自注意力（Multi-Head Attention）机制</title>
    <url>/archive/AI-Multi-head.html</url>
    <content><![CDATA[<p><figure><img src="https://yjucho1.github.io/assets/img/2018-10-13/transformer.png" alt="Multi-Head Attention"><figcaption aria-hidden="true">Multi-Head Attention</figcaption></figure></p>
<p>Self Attention 利用 Q、K、V均为同一个输入向量映射而来的Encoder-Decoder Attention，它可以无视词之间的距离直接计算依赖关系，能够学习一个句子的内部结构，实现也较为简单并且可以并行计算。</p>
<p>Multi-Head Attention同时计算多个Attention，并最终得到合并结果，通过计算多次来捕获不同子空间上的相关信息。</p>
<span id="more"></span>

<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://sungwookyoo.github.io/tips/study/Multihead_Attention/">https://sungwookyoo.github.io/tips/study/Multihead_Attention&#x2F;</a></li>
<li><a href="https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention/">https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention/</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>数据科学：维格纳准概率分布（Wigner-Ville Distribution，WVD）</title>
    <url>/archive/AI-Wigner-Ville.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAU2JVU.png"></p>
<p>The Wigner distribution, often also Wigner-Ville distribution, is a time-frequency distribution, like the spectrogram, with very interesting properties and a high resolution in both the time and frequency domains. It has the benefits of ideal resolution properties [1] but it also includes signal-dependent interference terms [1] which are mathematical attributes but do not represent pure signal terms.</p>
<span id="more"></span>

<p>waitting ……</p>
<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://github.com/ljbkusters/python-wigner-distribution">https://github.com/ljbkusters/python-wigner-distribution</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>人工智能：梯度累计 GRADIENT_ACCUMULATION_STEPS</title>
    <url>/archive/AI-accumulation_steps.html</url>
    <content><![CDATA[<p><code>GRADIENT_ACCUMULATION_STEPS</code>（梯度累积步数）是一种在<strong>不增加显存（VRAM）消耗</strong>的情况下，<strong>模拟出更大批量（Batch Size）训练效果</strong>的关键技术。</p>
<span id="more"></span>
<hr>
<h3 id="技术原理详解"><a href="#技术原理详解" class="headerlink" title="技术原理详解"></a>技术原理详解</h3><p>在标准的神经网络训练中，一个训练步骤（step）包含以下过程：</p>
<ol>
<li><strong>前向传播</strong>: 输入一个批次的数据，模型计算出预测结果和损失（loss）。</li>
<li><strong>后向传播</strong>: 根据损失计算出每个参数的梯度（gradient），即参数应该调整的方向。</li>
<li><strong>优化器步骤</strong>: 优化器（如 AdamW）根据梯度来更新模型的权重。</li>
<li><strong>清空梯度</strong>: 为下一次计算做准备。</li>
</ol>
<p>而当使用梯度累积时，这个过程发生了变化：</p>
<p><strong>对于第 1 到 <code>N-1</code> 步 (N &#x3D; <code>GRADIENT_ACCUMULATION_STEPS</code>)</strong>:</p>
<ol>
<li><strong>前向传播</strong>: 正常执行。</li>
<li><strong>后向传播</strong>: 正常执行，计算出当前“微批次 (micro-batch)”的梯度。</li>
<li><strong>关键区别</strong>: <strong>跳过“优化器步骤”</strong>。我们不立即更新权重，而是让梯度<strong>累积</strong>在模型的 <code>.grad</code> 属性中。同时，我们也不清空梯度。</li>
</ol>
<p><strong>对于第 <code>N</code> 步</strong>:</p>
<ol>
<li><strong>前向传播</strong>: 正常执行。</li>
<li><strong>后向传播</strong>: 正常执行，计算出第 <code>N</code> 个微批次的梯度，并将其<strong>加到</strong>之前已经累积的梯度上。</li>
<li><strong>执行“优化器步骤”</strong>: 优化器使用<strong>累积了 N 步的总梯度</strong>来对模型权重进行<strong>一次</strong>更新。</li>
<li><strong>清空梯度</strong>: 更新完成后，将梯度清零，准备开始下一个累积周期。</li>
</ol>
<p>这样一来，虽然硬件上每次只处理了一个小批量，但参数的更新却是基于多个小批量梯度的总和，从而在数学效果上<strong>模拟了一个大批量</strong>的训练。</p>
<h4 id="核心公式"><a href="#核心公式" class="headerlink" title="核心公式"></a>核心公式</h4><p><code>有效批量大小 (Effective Batch Size) = PER_DEVICE_TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS * GPU数量</code></p>
<p>例如，在单张 A100 上，即使你的 <code>PER_DEVICE_TRAIN_BATCH_SIZE</code> 因为显存限制只能设为 <code>2</code>，但只要将 <code>GRADIENT_ACCUMULATION_STEPS</code> 设为 <code>32</code>，你就能达到 <code>2 * 32 = 64</code> 的有效批量大小。</p>
<hr>
<h3 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h3><h4 id="优点-Pros"><a href="#优点-Pros" class="headerlink" title="优点 (Pros)"></a>优点 (Pros)</h4><ol>
<li><strong>突破显存限制</strong>: 这是其最核心的优点。它允许我们在有限的硬件资源上训练需要大批量才能稳定收敛的超大型模型。</li>
<li><strong>训练过程更稳定</strong>: 更大的有效批量意味着每次权重更新所依据的梯度方向更准确、噪声更小，这使得整个训练过程更加平稳，允许你使用更高的学习率。</li>
<li><strong>可能提升模型性能</strong>: 稳定的训练过程和更准确的梯度方向，有助于模型找到更好的局部最小值，从而可能提升最终的泛化能力。</li>
</ol>
<h4 id="缺点-Cons"><a href="#缺点-Cons" class="headerlink" title="缺点 (Cons)"></a>缺点 (Cons)</h4><ol>
<li><strong>训练时间变长 (Wall-clock Time)</strong>: 这是最大的代价。虽然模拟了大批量，但计算过程仍然是串行的。权重更新的频率降低了，完成一个 epoch 所需的实际时间会相应增加。例如，累积32步才更新一次，意味着权重更新的频率是原来的 1&#x2F;32，完成一个 epoch 的总时间大约会是原来的数倍（具体取决于数据加载等其他开销）。</li>
<li><strong>对特定层（如 BatchNorm）的影响</strong>: 对于包含批归一化（Batch Normalization）层的模型，梯度累积可能会带来问题。因为 <code>BatchNorm</code> 是在每个微批次上计算均值和方差的，而不是在整个“有效批量”上。这可能导致训练和推理时的统计数据不匹配。不过，现代大型语言模型（LLM）大多使用 Layer Normalization 或 RMS Normalization，它们不受批量大小的影响，因此这个问题在 LLM 训练中基本不存在。</li>
</ol>
<p><strong>总结</strong>: <code>GRADIENT_ACCUMULATION_STEPS</code> 是一种典型的 <strong>用时间换显存</strong>的策略。它是大规模模型训练中不可或缺的利器，使得个人或小型机构在有限的硬件条件下训练强大的模型成为可能。</p>
]]></content>
  </entry>
  <entry>
    <title>About</title>
    <url>/about/index.html</url>
    <content><![CDATA[<h2 id="Self-Introduction"><a href="#Self-Introduction" class="headerlink" title="Self-Introduction:"></a>Self-Introduction:</h2><p>Hai-Wei Chai&ensp;[柴海伟]</p>
<ul>
<li>2025.08 - Now, Chief Executive Officer of Conceptual Computing AI Tech. LLC, Cambridge, MA, USA</li>
<li>2025.04 - Now, Chief Executive Officer of Yuance (Chengdu) AI Tech. Co. Ltd., Chengdu, Sichuan, China</li>
<li>2022.06 - 2025.03, Assistant Professor in School of Material Science and Engineering, Southwest Jiaotong University</li>
<li>2019.09 - 2021.12, Doctor of Condensed Matter Physics, in Peac Institute of Multiscale Sciences</li>
<li>2016.09 - 2019.06, Master of Condensed Matter Physics, in Peac Institute of Multiscale Sciences</li>
<li>2012.09 - 2016.06, Bachelor in School of Physical Sciences, University of Science and Technology of China</li>
</ul>
<h2 id="Skills"><a href="#Skills" class="headerlink" title="Skills:"></a>Skills:</h2><ul>
<li>Programming languages: C&#x2F;C++, Python, Matlab, CUDA</li>
<li>Major: Artificial Intelligence, X-ray Imaging and Diffraction, Computed Tomography</li>
<li>OS Platform: Linux, Mac OS, Windows</li>
<li>Language: English, Chinese</li>
</ul>
<h2 id="Contact-details"><a href="#Contact-details" class="headerlink" title="Contact details:"></a>Contact details:</h2><ul>
<li>E-mail: <a href="mailto:&#99;&#x68;&#119;&#x39;&#x34;&#48;&#x32;&#64;&#x6d;&#x61;&#x69;&#x6c;&#46;&#x75;&#x73;&#x74;&#99;&#x2e;&#101;&#100;&#117;&#46;&#99;&#110;">chw9402@mail.ustc.edu.cn</a></li>
</ul>
<h2 id="My-friends-me-at-USTC-2016"><a href="#My-friends-me-at-USTC-2016" class="headerlink" title="My friends &amp; me at USTC 2016:"></a>My friends &amp; me at USTC 2016:</h2><p><img src="https://s1.ax1x.com/2022/10/19/xsgD7F.jpg"></p>
]]></content>
  </entry>
  <entry>
    <title>近似最近邻搜索算法（Approximate Nearest Neighbors Oh Yeah, ANNOY）</title>
    <url>/archive/ANNOY.html</url>
    <content><![CDATA[<p><img src="https://zr9558.com/wp-content/uploads/2022/01/scann-tom-export.gif"></p>
<p>在搜索的业务场景下，基于一个现有的数据候选集（dataset），需要对新来的一个或者多个数据进行查询（query），返回在数据候选集中与该查询最相似的 Top K 数据。</p>
<span id="more"></span>]]></content>
  </entry>
  <entry>
    <title>【英语写作】 短语</title>
    <url>/archive/Exp002-writing.html</url>
    <content><![CDATA[<p>逐渐培养长期稳定阅读高水平 SCI 文章的习惯，不仅仅能了解专业的理论热点和学术前沿，同时还有益于学习高手写作科技论文时的行文逻辑、方法、技巧。这是对科研能力的培养，对养成独立思考习惯的努力。本文将记录阅读科技论文时发现的生僻短语及专业术语，旨在提高英语写作水平。</p>
<span id="more"></span>

<h2 id="常用短语"><a href="#常用短语" class="headerlink" title="常用短语"></a>常用短语</h2><table>
<thead>
<tr>
<th>短语</th>
<th>译文</th>
</tr>
</thead>
<tbody><tr>
<td>As a consequence, …</td>
<td>因此，结果，因而</td>
</tr>
<tr>
<td>In practice, …</td>
<td>事实上，实际上，在实践中</td>
</tr>
<tr>
<td>be employed primarily as …</td>
<td>主要用于 …</td>
</tr>
</tbody></table>
<h2 id="专业术语"><a href="#专业术语" class="headerlink" title="专业术语"></a>专业术语</h2><table>
<thead>
<tr>
<th>短语</th>
<th>译文</th>
</tr>
</thead>
<tbody><tr>
<td>twice continuously differentiable ($C^2$)</td>
<td>二次连续可微（$C^2$）</td>
</tr>
<tr>
<td>second order Taylor expansion</td>
<td>二阶泰勒展开</td>
</tr>
<tr>
<td>apparent density</td>
<td>表观密度</td>
</tr>
<tr>
<td>mechanical properties</td>
<td>机械性能，力学性能</td>
</tr>
<tr>
<td>renewable resources</td>
<td>可再生资源</td>
</tr>
<tr>
<td>the base polymer</td>
<td>聚合物基体</td>
</tr>
<tr>
<td>tensile strength</td>
<td>抗拉强度</td>
</tr>
</tbody></table>
]]></content>
  </entry>
  <entry>
    <title>人工智能：百川大模型训练与部署方法</title>
    <url>/archive/Baichuan.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/23/pAdsVL8.png"></p>
<p>Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练。 Baichuan 2 在多个权威的中文、英文和多语言的通用、领域 benchmark 上取得同尺寸最佳的效果。技术报告：<a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a>。本次发布包含有 7B、13B 的 Base 和 Chat 版本，并提供了 Chat 版本的 4-bits 量化。所有版本对学术研究完全开放。同时，开发者通过邮件申请并获得官方商用许可后，即可免费商用。</p>
<p>除了训练了 2.6 万亿 Tokens 的 Baichuan2-7B-Base 模型，还公开了在此之前的另外 11 个中间 checkpoints（分别对应训练了约 0.2 ~ 2.4 万亿 Tokens）供社区研究使用，<a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints">https://huggingface.co/baichuan-inc/Baichuan2-7B-Intermediate-Checkpoints</a>。</p>
<span id="more"></span>


<h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><ol>
<li><a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a></li>
<li><a href="https://www.tizi365.com/topic/9008.html">https://www.tizi365.com/topic/9008.html</a></li>
<li><a href="https://www.tizi365.com/topic/9008.html">https://www.tizi365.com/topic/9008.html</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>【英语写作】 审稿意见回复方法</title>
    <url>/archive/Exp003-Reply.html</url>
    <content><![CDATA[<p>李海洋关于南中国海钙质砂颗粒力学性能的研究工作去年十月整理成文，投给了 Scientific Report，因为一些特殊原因重新整理整理转投 Powder Technology ，近期终于得到Major revision 的返修意见。李海洋也早在 7 月就毕业入职了，由接下这个方向的师弟和我来纠错、整理、回复审稿意见。本文记录对审稿意见的回复技巧及近期对 Scr. Mater. 及 Powder Technol. 的两份审稿意见回复。</p>
<span id="more"></span>

<h2 id="Reply-for-Powder-Technol-HYLi"><a href="#Reply-for-Powder-Technol-HYLi" class="headerlink" title="Reply for Powder_Technol-HYLi"></a>Reply for Powder_Technol-HYLi</h2><h2 id="Reply-for-Scr-Mater-HWChai"><a href="#Reply-for-Scr-Mater-HWChai" class="headerlink" title="Reply for Scr_Mater-HWChai"></a>Reply for Scr_Mater-HWChai</h2><p><strong>Response to reviewer’s comments:</strong> “Correlation between cell wall buckling and deformation banding in a closed-cell foam” by H. W. Chai, H. Y. Li, X. H. Xiao, J. Y. Huang, and S. N. Luo, manuscript No. SMM-19-733.</p>
<p>&emsp;We appreciate the constructive remarks by the referee and have revised the manuscript accordingly. The comments raised are all addressed as follows. The revision details are marked in red in the revised manuscript. </p>
<h3 id="Reviewer-1"><a href="#Reviewer-1" class="headerlink" title="Reviewer #1"></a>Reviewer #1</h3><p>&emsp;This work investigates deformation dynamics in closed-cell foam of polymethacrylimide under uniaxial compression with in situ x-ray computed tomography and digital volume correlation. It is an interesting topic which it has to more study. The paper is good and well-written, but some issues have to be explained better.</p>
<ol>
<li>What is the difference to calculate mechanical properties in 2D or in 3D system?</li>
</ol>
<p><font color=Blue>Response</font>: It is common to analyze mechanical properties of foams in 2D, e.g. via scanning electron microscopy. However, the microstructures of real foam materials are 3D in nature. There are distinct differences in quantification of the relative density, cell size, cell morphology and cell wall thickness of foams between the 2D and 3D systems, so 3D calculations of mechanical properties should be used if possible.</p>
<ol start="2">
<li>Could Voronoi systems be phenomenological models for representing these morphologies?</li>
</ol>
<p><font color=Blue>Response</font>: Yes, to some extent. The 3D Voronoi technique (<font color=Blue>Okabe et al., 1992</font>) has been widely employed to generate closed-cell foams with irregular cells. It is useful for investigating the effects of structural parameters on the mechanical properties of foams. However, the Voronoi foam system cannot reproduce two characteristics of a real foam: the thickness distribution of walls, and the thickness variations along walls and between walls and edges. In a Voronoi system, wall thickness is normally constant across the sample, and is equal to the edge thickness.</p>
<ol start="3">
<li>What is the real perspective of this approach?</li>
</ol>
<p><font color=Blue>Response</font>: Edge segmentation separates the initial structure of a foam sample into two parts, i.e., edges and walls. The edge and wall morphologies can be quantified, and used to predict deformation processes (e.g., location and temporal sequence of deformation banding) and collapse strength of a foam. They also serve a basis for tailoring local strength and energy absorption of foams. Combined with finite element method analysis, foam structure can be manipulated to study the effect of local heterogeneity or defects on foam deformation. Clarification has been made in the last paragraph.</p>
<ol start="4">
<li>Is it possible to perform a calculation based on beam elastic deformation?</li>
</ol>
<p><font color=Blue>Response</font>: Not in our case. For open-cell foams or some closed-cell foams with large edge volume fractions, the calculation of mechanical properties based on elastic deformation of beams is appropriate. The mechanical support comes mainly from the edges in these foams. However, tomographic images in our case show that cell collapse is generally preceded by elastic buckling of cell walls. The solid fraction of edges in our foams is much lower than that of conventional polymer foams with curved, thin cell walls. Such a difference contributes to the difference in the dominant deformation modes during the collapse stage. Clarification has been made in line 1–5, paragraph 2, page 3, and line 17–23, paragraph 2, page 4.</p>
<ol start="5">
<li>Is it possible to consider Fig. 3a as a system of beams?</li>
</ol>
<p><font color=Blue>Response</font>: Fig. 3a actually shows a $xy$-slice of the tomographic image, and is a cross-section of a 3D structure. In this slice, cell walls become lines while edges become corners or lines (for edges parallel to the $xy$-plane). So it is inappropriate to considered it as a system of beams. Clarification has been made in line 1–3, paragraph 1, page 4.</p>
<ol start="6">
<li>Is tomography representative for studying mechanical properties?</li>
</ol>
<p><font color=Blue>Response</font>: Yes in our case. A previous study (<font color=Blue>Andrews et al., 2001</font>) showed that the mechanical properties of foams are independent of sample size when it is six times greater than the average cell size in both the horizontal and longitudinal directions. Our sample contains over 10 cell layers in both directions and the mechanical properties obtained from tomography are representative. Clarification has been made in line 8–9, the last paragraph, page 1, and line 1, paragraph 1, page 2.</p>
<ol start="7">
<li>How could be solved the homogeneity problem?</li>
</ol>
<p><font color=Blue>Response</font>: See the reply to the preceding comment. In addition, this can also be verified by a good repeatability of stress–strain curves between different samples.</p>
<ol start="8">
<li>Graphical Abstract is not appropriate. It must be more explanatory and immediate.</li>
</ol>
<p><font color=Blue>Response</font>: Thanks for your suggestion. The graphical abstract has been revised.</p>
<h3 id="Reviewer-2"><a href="#Reviewer-2" class="headerlink" title="Reviewer #2"></a>Reviewer #2</h3><p>&emsp;The limitation of the well-known empirical relationships between mechanical properties and relative density of cellular solids [1] has been realised and overcome through taking account of morphological parameters of individual or collective cells for more accurate structure-property correlation [12, 14]. However, these cell-level parameters are not directly linked to the deformation mechanism of base material. Recently, cell-wall parameters have been demonstrated to determine the compressive strength of a virtual 2D foam [<font color=Blue>Materials Sci. Eng. A 688 (2017), 27-39</font>], but no similar work has yet been reported for an actual 3D foam. In such a context, the study presented in this manuscript is a good and timely contribution to the progress in this research field. The manuscript is well written and the characterisation method is solid. The reviewer suggests the following aspects be revised to strengthen the analysis.</p>
<ul>
<li>Fig. 4 shows the distribution of cells with strength index smaller than 0.0037. However, these cells are not fully connected within each band that is indicated in Fig. 4b. In other words, the neighbour cells of the filtered cells within the indicated band have strength index larger than 0.0037, but they are excluded when evaluating the probability to form a band. This treatment is not appropriate, since the cause of the localised deformation band is the collective weakness of all the cells within the band rather than the inclusion of some weak cells in the band. Therefore, the authors should also calculate the strength index values for all the cells within each observed band (i.e. E1, E2, E3, E4 or E5, as shown in Fig. 2a) and then compare the averaged strength index values between different observed bands.</li>
</ul>
<p><font color=Blue>Response</font>: We think that deformation band nucleation is dominated by the weakest cell walls in the band, rather than by the average strength of all walls. The axial stress is uniformly distributed on cell walls and edges across the sample section. When the stress reaches the critical buckling strength of the weakest cell walls, they buckle and change the mechanical (stress, support) state of their neighbors, making these cell walls fragile. The tomographic images also show that buckling occurs firstly in some (rather than all) cell walls in a band, and “propagates” to other walls, rendering all cells in the band collapse approximately at the same time.<br>&emsp;The average values of the buckling strength index for five observed bands (E1–E5) are 0.092, 0.820, 0.137, 0.242 and 0.294, respectively. The results are inconsistent with the temporal sequence of deformation banding, and cannot predict a collapse strength comparable to the experimental measurement. In fact, the cell walls are randomly oriented and those (nearly) perpendicular to the loading direction have large strength indices. These walls can increase the average value of strength index in a band. In addition, the deformation bands are not strictly perpendicular to the loading direction (inclination angle $4^\circ-10^\circ$). Averaging across the sample section along the loading direction or sample height may smooth out the strength index distribution.</p>
<ul>
<li>The authors should attempt to obtain the axial distribution of strength index. A plot for strength index similar to the plot for Minkowski anisotropic index (Fig. S1) should be added.</li>
</ul>
<p><font color=Blue>Response</font>: The distribution of the average buckling strength index of cell walls along the sample height is shown in Fig.R1. The curve from averaging all walls exhibits very large oscillations and does not show clearly the weak zones in the foam sample. Since the walls (nearly) perpendicular to the loading direction have large strength indices, we apply a filter process to exclude walls with $\beta&lt;30^\circ$ ($\beta$ the angle between the loading direction and a wall normal). The wall with a higher $\beta$ is more prone to buckle.<br>&emsp;In this way, the oscillations are reduced, but the distribution curve still does not show obvious features of deformation banding, compared to the 3D distribution of weakest walls. The probable reason is that the deformation bands are not strictly perpendicular to the loading direction (especially band E3). Averaging on the strength index of cell walls across the sample section along the height direction is not appropriate to probe the weak zones of foam sample. This may also be responsible for why the distribution of the Minkowski anisotropic index cannot predict deformation banding.</p>
<img src="https://raw.githubusercontent.com/haiweichai/gallery/master/Exp003/Exp001_image001.jpg" width = 70% div align=center />
<font size=2px>Fig.R1: Distribution of the average buckling strength index $\lambda_{\rm w}$ of cell walls along the sample height direction. Each data point is averaged within a $200\mu m$ segment along the height direction. $\beta$ is the angle between the loading direction and a wall normal. The wall with a higher $\beta$ value is more prone to buckle.</font>

<ul>
<li>Undoubtedly, structure-property correlation based on 3D quantification of the cell walls is more accurate and reliable than that based on 2D structural data. However, 3D data is not always accessible while 2D data can be easily obtained via processing cross-sectional images. Therefore, it is of practical value and interest to evaluate the usefulness of 2D analysis, but such evaluation cannot be possible without 3D results as reference. Given the established 3D correlation by the authors, the reviewer suggests the authors also perform a 2D correlation based on the CT slices and then address the limitation of the 2D analysis. It is indeed necessary because sometimes 2D and 3D analyses may lead to same conclusions (e.g. same location of the weakest site).</li>
</ul>
<p><font color=Blue>Response</font>: The 2D analyses can provide a preliminary estimation of the cell size and solid fraction of foams. In terms of the cell wall thickness, 2D and 3D structural data can give similar results. If cell wall strength is controlled mainly by wall thickness, 2D and 3D analyses may lead to similar conclusions, as demonstrated in the previous work (<font color=Blue>Sun et al., 2017</font>).<br>&emsp;However, the width and height of cell walls cannot be accessed simultaneously in 2D analyses. The width and height distributions of cell walls from 2D analyses are also quite different from those in 3D analyses. Therefore, the 2D analysis is not appropriate for quantifying the cell wall strength in our case. In fact, it is impossible to accurately quantify local structural parameters in two dimensions, which hinders a full understanding of the cell strength of foam samples. In addition, the 2D analyses may lead to different conclusions in different sections.</p>
<ul>
<li>In the caption of Figure 1, “color-coding refers to axial strain” should be “color-coding refers to increments of axial strain”. The crushed cells at a nominal strain of 0.5 (Fig. 1b) are indicated in red which corresponds to a value of zero, so the color code cannot be based on absolute strain.</li>
</ul>
<p><font color=Blue>Response</font>: Thanks for your suggestion. Correction has been made in the caption of Fig.1.</p>
<ul>
<li>The authors could include greater reference to previous work on X-ray imaging of the deformation behaviour of cellular materials and foams, particularly in situ measurements of the deformation.</li>
</ul>
<p><font color=Blue>Response</font>: Thanks for your suggestion. We have added more references on this topic; see Refs. [13], [18] and [27] in the revised manuscript.</p>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p>[1] Okabe, A., Boots, B., Sugihara, K., 1992. Spatial tessellations: concepts and applications of Voronoi diagrams. Wiley, Chichester.<br>[2] Andrews, E. W., et al. “Size effects in ductile cellular solids. Part II: experimental results.” International Journal of Mechanical Sciences 43 (2001): 701-713.<br>[3] Sun, Yongle, et al. “Image-based correlation between the meso-scale structure and deformation of closed-cell foam.” Materials Science and Engineering: A 688 (2017): 27-39.</p>
]]></content>
  </entry>
  <entry>
    <title>人工智能：Pytorch DataLoader</title>
    <url>/archive/AI-DataLoader.html</url>
    <content><![CDATA[<p><img src="https://s21.ax1x.com/2024/10/18/pAUyxEQ.png"></p>
<p>PyTorch 数据加载实用程序的核心是 <a href="https://pytorch.ac.cn/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a> 类。它表示数据集上的 Python 可迭代对象，支持：映射式和可迭代式数据集；自定义数据加载顺序；自动批处理；单进程和多进程数据加载；自动内存固定。这些选项由 <code>DataLoader</code> 的构造函数参数配置，其签名为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>,</span><br><span class="line">           batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>,</span><br><span class="line">           pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>,</span><br><span class="line">           worker_init_fn=<span class="literal">None</span>, *, prefetch_factor=<span class="number">2</span>,</span><br><span class="line">           persistent_workers=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>本文将详细介绍了这些选项的效果和用法。内容参考 Pytorch 官方文档：<a href="https://pytorch.org/docs/stable/data.html#module-torch.utils.data">https://pytorch.org/docs/stable/data.html#module-torch.utils.data</a></p>
<span id="more"></span>

<h2 id="数据集类型"><a href="#数据集类型" class="headerlink" title="数据集类型"></a>数据集类型</h2><p><code>DataLoader</code> 构造函数最重要的参数是 dataset，它指示要从中加载数据的 “映射式数据集” 与 “可迭代式数据集”。</p>
<h3 id="映射式数据集"><a href="#映射式数据集" class="headerlink" title="映射式数据集"></a>映射式数据集</h3><p>映射式数据集是实现了 <code>__getitem__()</code> 和 <code>__len__()</code> 协议的数据集，它表示从（可能是非整数）索引&#x2F;键到数据样本的映射。</p>
<p>例如，当使用 <code>dataset[idx]</code> 访问此类数据集时，它可以从磁盘上的文件夹读取第 <code>idx</code> 个图像及其相应的标签文件。有关更多详细信息，请参阅 <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">Dataset</a>。</p>
<h3 id="可迭代式数据集"><a href="#可迭代式数据集" class="headerlink" title="可迭代式数据集"></a>可迭代式数据集</h3><p>可迭代式数据集是 <code>IterableDataset</code> 子类的实例，它实现了 <code>__iter__()</code> 协议，</p>
<p>例如，当调用 <code>iter(dataset)</code> 时，此类数据集可以返回从数据库、远程服务器读取的数据流，甚至是实时生成的日志。有关更多详细信息，请参阅 <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset">IterableDataset</a>。</p>
<p>当使用多进程数据加载的 IterableDataset 时。在每个工作进程上复制相同的数据集对象，因此必须对副本进行不同的配置，以避免重复数据。请参阅 IterableDataset 文档了解如何实现这一点。</p>
<h2 id="数据加载顺序和-Sampler"><a href="#数据加载顺序和-Sampler" class="headerlink" title="数据加载顺序和 Sampler"></a>数据加载顺序和 Sampler</h2><p>对于 可迭代式数据集，数据加载顺序完全由用户定义的可迭代对象控制。</p>
<p>本节的其余部分涉及 映射式数据集 的情况。</p>
<p>基于shuffle参数，DataLoader会自动构建顺序或随机采样器。 另外，用户可以使用sampler参数指定一个自定义的Sampler对象，该对象每次都会生成下一个要获取的索引&#x2F;键。</p>
<p>一个自定义的Sampler，每次生成一个批次索引列表，可以作为batch_sampler参数传递。 也可以通过batch_size和drop_last参数启用自动批处理。 有关详细信息，请参阅下一节。</p>
<p>注意</p>
<p>sampler和batch_sampler都不兼容可迭代数据集，因为此类数据集没有键或索引的概念。</p>
<h2 id="加载批处理和非批处理数据"><a href="#加载批处理和非批处理数据" class="headerlink" title="加载批处理和非批处理数据"></a>加载批处理和非批处理数据</h2><p>DataLoader支持通过参数batch_size、drop_last、batch_sampler和collate_fn（具有默认函数）自动将获取的单个数据样本整理成批次。</p>
<h3 id="自动批处理（默认）"><a href="#自动批处理（默认）" class="headerlink" title="自动批处理（默认）"></a>自动批处理（默认）</h3><p>这是最常见的情况，对应于获取一个数据小批量并将其整理成批处理样本，即包含一个维度为批次维度的张量（通常是第一个）。</p>
<p>当batch_size（默认1）不为None时，数据加载器会生成批处理样本，而不是单个样本。 batch_size和drop_last参数用于指定数据加载器如何获取数据集键的批次。 对于映射式数据集，用户可以另外指定batch_sampler，它每次生成一个键列表。</p>
<p>注意</p>
<p>batch_size和drop_last参数本质上用于从sampler构造batch_sampler。 对于映射式数据集，sampler由用户提供或根据shuffle参数构建。 对于可迭代数据集，sampler是一个虚拟的无限采样器。 有关采样器的更多详细信息，请参阅此节。</p>
<p>注意</p>
<p>当使用多进程从可迭代数据集中获取数据时，drop_last参数会删除每个工作程序的数据集副本的最后一个非满批次。</p>
<p>使用采样器中的索引获取样本列表后，作为collate_fn参数传递的函数用于将样本列表整理成批次。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([<span class="built_in">next</span>(dataset_iter) <span class="keyword">for</span> _ <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>可以使用自定义的collate_fn来自定义整理，例如，将顺序数据填充到批次的最大长度。 有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="禁用自动批处理"><a href="#禁用自动批处理" class="headerlink" title="禁用自动批处理"></a>禁用自动批处理</h3><p>在某些情况下，用户可能希望在数据集代码中手动处理批处理，或者只是加载单个样本。 例如，直接加载批处理数据可能更便宜（例如，从数据库中批量读取或读取连续的内存块），或者批次大小取决于数据，或者程序被设计为处理单个样本。 在这些情况下，最好不要使用自动批处理（其中collate_fn用于整理样本），而是让数据加载器直接返回dataset对象的每个成员。</p>
<p>当batch_size和batch_sampler都为None（batch_sampler的默认值为None）时，自动批处理将被禁用。 从dataset中获取的每个样本都会使用作为collate_fn参数传递的函数进行处理。</p>
<p><strong>禁用自动批处理时</strong>，默认的collate_fn只会将NumPy数组转换为PyTorch张量，其他一切保持不变。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(dataset[index])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> <span class="built_in">iter</span>(dataset):</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(data)</span><br></pre></td></tr></table></figure>

<p>有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="使用collate-fn"><a href="#使用collate-fn" class="headerlink" title="使用collate_fn"></a>使用collate_fn</h3><p>启用或禁用自动批处理时，collate_fn的使用略有不同。</p>
<p><strong>禁用自动批处理时</strong>，collate_fn会针对每个单独的数据样本进行调用，并从数据加载器迭代器中生成输出。 在这种情况下，默认的collate_fn只会将NumPy数组转换为PyTorch张量。</p>
<p><strong>启用自动批处理时</strong>，collate_fn会每次针对一个数据样本列表进行调用。 它应该将输入样本整理成一个批次，以便从数据加载器迭代器中生成。 本节的其余部分描述了默认collate_fn（default_collate()）的行为。</p>
<p>例如，如果每个数据样本包含一个 3 通道图像和一个整型类标签，即数据集的每个元素返回一个元组(image, class_index)，则默认的collate_fn会将此类元组列表整理成一个包含批处理图像张量和批处理类标签张量的单个元组。 特别是，默认的collate_fn具有以下属性</p>
<p>它始终将一个新的维度作为批处理维度前置。</p>
<p>它会自动将NumPy数组和Python数值转换为PyTorch张量。</p>
<p>它会保留数据结构，例如，如果每个样本都是一个字典，它会输出一个具有相同键集但批处理张量作为值的字典（如果值不能转换为张量，则为列表）。 list、tuple、namedtuple等也是如此。</p>
<p>用户可以使用自定义的collate_fn来实现自定义批处理，例如，沿除第一个维度以外的维度整理，填充不同长度的序列，或添加对自定义数据类型的支持。</p>
<p>如果您遇到DataLoader的输出具有与预期不同的维度或类型的情况，您可能需要检查您的collate_fn。</p>
<h2 id="单进程和多进程数据加载"><a href="#单进程和多进程数据加载" class="headerlink" title="单进程和多进程数据加载"></a>单进程和多进程数据加载</h2><p>DataLoader默认使用单进程数据加载。</p>
<p>在 Python 进程中，全局解释器锁 (GIL)阻止了跨线程真正地完全并行化 Python 代码。 为了避免数据加载阻塞计算代码，PyTorch 提供了一个简单的开关来执行多进程数据加载，只需将参数num_workers设置为正整数即可。</p>
<h3 id="单进程数据加载（默认）"><a href="#单进程数据加载（默认）" class="headerlink" title="单进程数据加载（默认）"></a>单进程数据加载（默认）</h3><p>在此模式下，数据获取在DataLoader初始化的同一个进程中完成。 因此，数据加载可能会阻塞计算。 但是，当用于在进程之间共享数据的资源（例如，共享内存、文件描述符）有限，或者当整个数据集很小且可以完全加载到内存中时，此模式可能更受欢迎。 此外，单进程加载通常显示更易读的错误跟踪，因此对调试很有用。</p>
<h3 id="多进程数据加载"><a href="#多进程数据加载" class="headerlink" title="多进程数据加载"></a>多进程数据加载</h3><p>将参数num_workers设置为正整数将打开使用指定数量的加载器工作程序进程的多进程数据加载。</p>
<p>警告</p>
<p>经过多次迭代后，加载器工作进程将消耗与父进程相同的 CPU 内存，用于父进程中所有从工作进程访问的 Python 对象。如果数据集包含大量数据（例如，您在数据集构建时加载了非常大的文件名列表）和&#x2F;或您使用了很多工作进程（总内存使用量为 number of workers * size of parent process），这可能会带来问题。最简单的解决方法是用非引用计数表示替换 Python 对象，例如 Pandas、Numpy 或 PyArrow 对象。查看 问题 #13246 了解更多关于为什么会出现这种情况以及如何解决这些问题的示例代码。</p>
<p>在此模式下，每次创建 DataLoader 的迭代器（例如，当您调用 enumerate(dataloader) 时），都会创建 num_workers 个工作进程。此时，dataset、collate_fn 和 worker_init_fn 会传递给每个工作进程，并在其中用于初始化和获取数据。这意味着数据集访问及其内部 IO、转换（包括 collate_fn）将在工作进程中运行。</p>
<p>torch.utils.data.get_worker_info() 在工作进程中返回各种有用的信息（包括工作进程 ID、数据集副本、初始种子等），并在主进程中返回 None。用户可以在数据集代码和&#x2F;或 worker_init_fn 中使用此函数来单独配置每个数据集副本，并确定代码是否在工作进程中运行。例如，这在对数据集进行分片时尤其有用。</p>
<p>对于映射式数据集，主进程使用 sampler 生成索引，并将其发送给工作进程。因此，任何洗牌随机化操作都在主进程中完成，该操作通过分配要加载的索引来指导加载。</p>
<p>对于可迭代式数据集，由于每个工作进程都获得了 dataset 对象的副本，因此简单的多进程加载通常会导致数据重复。使用 torch.utils.data.get_worker_info() 和&#x2F;或 worker_init_fn，用户可以独立地配置每个副本。（请参阅 IterableDataset 文档了解如何实现这一点。）出于类似原因，在多进程加载中，drop_last 参数将丢弃每个工作进程的可迭代式数据集副本的最后一个非完整批次。</p>
<p>当迭代结束时或当迭代器被垃圾回收时，工作进程将关闭。</p>
<p>警告</p>
<p>一般不建议在多进程加载中返回 CUDA 张量，因为在多进程中使用 CUDA 和共享 CUDA 张量时存在许多细微之处（请参阅 多进程中的 CUDA）。相反，我们建议使用 自动内存锁定（即，设置 pin_memory&#x3D;True），它可以实现快速将数据传输到支持 CUDA 的 GPU。</p>
<p>特定于平台的行为<br>由于工作进程依赖于 Python multiprocessing，因此工作进程启动行为在 Windows 上与 Unix 上不同。</p>
<p>在 Unix 上，fork() 是默认的 multiprocessing 启动方法。使用 fork()，子工作进程通常可以通过克隆的地址空间直接访问 dataset 和 Python 参数函数。</p>
<p>在 Windows 或 MacOS 上，spawn() 是默认的 multiprocessing 启动方法。使用 spawn()，会启动另一个解释器来运行您的主脚本，然后是接收 dataset、collate_fn 和其他参数的内部工作进程函数，这些参数通过 pickle 序列化。</p>
<p>这种单独的序列化意味着您应该采取两个步骤来确保在使用多进程数据加载时与 Windows 兼容。</p>
<p>将您的大部分主脚本代码包装在 if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘: 块中，以确保它在每个工作进程启动时不会再次运行（很可能生成错误）。您可以将您的数据集和 DataLoader 实例创建逻辑放在这里，因为它不需要在工作进程中重新执行。</p>
<p>确保任何自定义 collate_fn、worker_init_fn 或 dataset 代码都声明为顶层定义，位于 <strong>main</strong> 检查之外。这确保它们在工作进程中可用。（这是必要的，因为函数仅以引用形式被腌制，而不是 bytecode。）</p>
<p>多进程数据加载中的随机性<br>默认情况下，每个工作进程的 PyTorch 种子将设置为 base_seed + worker_id，其中 base_seed 是主进程使用其 RNG 生成的长整型数（因此，强制性地消耗 RNG 状态）或指定的 generator。但是，在初始化工作进程时，其他库的种子可能会重复，导致每个工作进程返回相同的随机数。（请参阅常见问题解答中的 此部分。）</p>
<p>在 worker_init_fn 中，您可以使用 torch.utils.data.get_worker_info().seed 或 torch.initial_seed() 访问为每个工作进程设置的 PyTorch 种子，并在数据加载之前使用它来设置其他库的种子。</p>
<h2 id="内存锁定"><a href="#内存锁定" class="headerlink" title="内存锁定"></a>内存锁定</h2><p>当主机到 GPU 的复制来自锁定页面（页面锁定）内存时，速度会快得多。请参阅 使用锁定页面内存缓冲区，了解何时以及如何一般性地使用锁定页面内存。</p>
<p>对于数据加载，将 pin_memory&#x3D;True 传递给 DataLoader 将自动将获取的数据张量放入锁定页面内存中，从而可以更快地将数据传输到支持 CUDA 的 GPU。</p>
<p>默认内存锁定逻辑仅识别张量以及包含张量的映射和可迭代对象。默认情况下，如果锁定页面逻辑看到一个自定义类型（如果您的 collate_fn 返回自定义批次类型，就会发生这种情况），或者如果批次的每个元素都是自定义类型，则锁定页面逻辑将无法识别它们，并且它将返回该批次（或这些元素）而不锁定页面内存。要为自定义批次或数据类型启用内存锁定，请在自定义类型上定义 pin_memory() 方法。</p>
<p>请参阅下面的示例。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class SimpleCustomBatch:</span><br><span class="line">    def __init__(self, data):</span><br><span class="line">        transposed_data = list(zip(*data))</span><br><span class="line">        self.inp = torch.stack(transposed_data[0], 0)</span><br><span class="line">        self.tgt = torch.stack(transposed_data[1], 0)</span><br><span class="line"></span><br><span class="line">    # custom memory pinning method on custom type</span><br><span class="line">    def pin_memory(self):</span><br><span class="line">        self.inp = self.inp.pin_memory()</span><br><span class="line">        self.tgt = self.tgt.pin_memory()</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">def collate_wrapper(batch):</span><br><span class="line">    return SimpleCustomBatch(batch)</span><br><span class="line"></span><br><span class="line">inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">dataset = TensorDataset(inps, tgts)</span><br><span class="line"></span><br><span class="line">loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,</span><br><span class="line">                    pin_memory=True)</span><br><span class="line"></span><br><span class="line">for batch_ndx, sample in enumerate(loader):</span><br><span class="line">    print(sample.inp.is_pinned())</span><br><span class="line">    print(sample.tgt.is_pinned())</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Class torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">None</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span>, multiprocessing_context=<span class="literal">None</span>, generator=<span class="literal">None</span>, *, prefetch_factor=<span class="literal">None</span>, persistent_workers=<span class="literal">False</span>, pin_memory_device=<span class="string">&#x27;&#x27;</span>)[source]</span><br></pre></td></tr></table></figure>

<p>数据加载器将数据集和采样器组合在一起，并提供一个遍历给定数据集的可迭代对象。</p>
<p>DataLoader 支持映射风格和可迭代风格的数据集，包含单进程或多进程加载、自定义加载顺序以及可选的自动批处理（整理）和内存固定。</p>
<p>更多细节请参见 torch.utils.data 文档页面。</p>
<p>参数<br>** dataset (Dataset) – 要加载数据的 dataset。<br>** batch_size (int, optional) – 每次加载多少个样本（默认：1）。<br>** shuffle (bool, optional) – 设置为 True 则在每个 epoch 时重新洗牌数据（默认：False）。<br>** sampler (Sampler or Iterable, optional) – 定义从 dataset 中抽取样本的策略。可以是任何实现了 <strong>len</strong> 的 Iterable。如果指定，则不能指定 shuffle。<br>** batch_sampler (Sampler or Iterable, optional) – 与 sampler 相似，但一次返回一批索引。与 batch_size、shuffle、sampler 和 drop_last 互斥。<br>** num_workers (int, optional) – 用于数据加载的子进程数量。0 表示数据将在主进程中加载。（默认：0）<br>** collate_fn (Callable, optional) – 将样本列表合并成一个包含张量（Tensor）的小批量。在使用映射风格数据集的批量加载时使用。<br>** pin_memory (bool, optional) – 如果为 True，数据加载器将在返回之前将张量复制到设备&#x2F;CUDA 固定内存中。如果你的数据元素是自定义类型，或者你的 collate_fn 返回一个自定义类型的批次，请参阅下面的示例。<br>** drop_last (bool, optional) – 设置为 True 以丢弃最后一个不完整的批次，如果数据集的大小不能被批次大小整除。如果为 False 且数据集大小不能被批次大小整除，则最后一个批次将更小。（默认：False）<br>** timeout (numeric, optional) – 如果为正数，则为从工作进程收集批次的超时值。应该始终为非负数。（默认：0）<br>** worker_init_fn (Callable, optional) – 如果不为 None，这将在每个工作进程子进程上调用，并将工作进程 ID（[0, num_workers - 1] 中的整数）作为输入，在播种和数据加载之前。（默认：None）<br>** multiprocessing_context (str or multiprocessing.context.BaseContext, optional) – 如果为 None，将使用操作系统的默认 多进程上下文。（默认：None）<br>** generator (torch.Generator, optional) – 如果不为 None，则随机采样器将使用此 RNG 生成随机索引，多进程将使用此 RNG 为工作进程生成 base_seed。（默认：None）<br>** prefetch_factor (int, optional, keyword-only arg) – 每个工作进程预先加载的批次数量。2 表示所有工作进程总共预取 2 * num_workers 个批次。（默认值取决于 num_workers 的设置值。如果 num_workers &#x3D; 0，则默认值为 ** None。否则，如果 num_workers &gt; 0，则默认值为 2）。<br>** persistent_workers (bool, optional) – 如果为 True，数据加载器在数据集被消费一次后不会关闭工作进程。这允许将工作进程的 Dataset 实例保持活动。（默认：False）<br>** pin_memory_device (str, optional) – 如果 pin_memory 为 True，则为要 pin_memory 的设备。</p>
<p>警告</p>
<p>如果使用 spawn 启动方法，则 worker_init_fn 不能是不可腌制的对象，例如 lambda 函数。有关 PyTorch 中多进程的更多详细信息，请参阅 多进程最佳实践。</p>
<p>警告</p>
<p>len(dataloader) 启发式基于所用采样器的长度。当 dataset 是一个 IterableDataset 时，它将返回一个基于 len(dataset) &#x2F; batch_size 的估计值，并根据 drop_last 进行适当的舍入，而与多进程加载配置无关。这代表了 PyTorch 可以做出的最佳猜测，因为 PyTorch 相信用户 dataset 代码在正确处理多进程加载以避免重复数据方面。</p>
<p>但是，如果分片导致多个工作进程具有不完整的最后一个批次，则此估计仍然可能不准确，因为 (1) 一个原本完整的批次可以被分成多个批次，(2) 当设置了 drop_last 时，可以丢弃多个批次。不幸的是，PyTorch 通常无法检测到此类情况。</p>
<p>有关这两种类型的数据集以及 IterableDataset 如何与 多进程数据加载 相互作用的更多详细信息，请参阅 数据集类型。</p>
<p>警告</p>
<p>有关随机种子相关问题的更多信息，请参阅 可重复性，以及 我的数据加载器工作进程返回相同的随机数 和 多进程数据加载中的随机性 说明。</p>
<p>classtorch.utils.data.Dataset(*args, **kwds)[source]<br>一个表示 Dataset 的抽象类。</p>
<p>所有表示从键到数据样本的映射的数据集都应该继承它。所有子类都应该覆盖 <strong>getitem</strong>()，支持获取给定键的数据样本。子类还可以选择覆盖 <strong>len</strong>()，这将返回许多 Sampler 实现和 DataLoader 的默认选项的数据集大小。子类还可以选择实现 <strong>getitems</strong>()，以加快批处理样本加载速度。此方法接受批次样本索引列表并返回样本列表。</p>
<p>注意</p>
<p>DataLoader 默认情况下会构造一个生成整数索引的索引采样器。要使其与具有非整数索引&#x2F;键的映射式数据集一起使用，必须提供自定义采样器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.IterableDataset(*args, **kwds)[source]</span><br></pre></td></tr></table></figure>

<p>一个可迭代的 Dataset。</p>
<p>所有表示数据样本可迭代的数据集都应该继承它。这种形式的数据集在数据来自流时特别有用。</p>
<p>所有子类都应该覆盖 <strong>iter</strong>()，它将返回此数据集中样本的迭代器。</p>
<p>当子类与 DataLoader 一起使用时，数据集中的每个项目都将从 DataLoader 迭代器中生成。当 num_workers &gt; 0 时，每个工作进程将拥有数据集对象的副本，因此通常需要独立配置每个副本，以避免工作进程返回重复数据。 get_worker_info()，在工作进程中调用时，返回有关工作进程的信息。它可以在数据集的 <strong>iter</strong>() 方法或 DataLoader 的 worker_init_fn 选项中使用，以修改每个副本的行为。</p>
<p>示例 1：在 <strong>iter</strong>() 中将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> worker_info <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># single-process data loading, return the full iterator</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="variable language_">self</span>.end</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">else</span>:  <span class="comment"># in a worker process</span></span><br><span class="line"><span class="meta">... </span>            <span class="comment"># split workload</span></span><br><span class="line"><span class="meta">... </span>            per_worker = <span class="built_in">int</span>(math.ceil((<span class="variable language_">self</span>.end - <span class="variable language_">self</span>.start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>            worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="built_in">min</span>(iter_start + per_worker, <span class="variable language_">self</span>.end)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(iter_start, iter_end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with two worker processes</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br></pre></td></tr></table></figure>

<p>示例 2：使用 worker_init_fn 将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.start, <span class="variable language_">self</span>.end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Directly doing multi-process loading yields duplicate data</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Define a `worker_init_fn` that configures each dataset copy differently</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">worker_init_fn</span>(<span class="params">worker_id</span>):</span><br><span class="line"><span class="meta">... </span>    worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>    dataset = worker_info.dataset  <span class="comment"># the dataset copy in this worker process</span></span><br><span class="line"><span class="meta">... </span>    overall_start = dataset.start</span><br><span class="line"><span class="meta">... </span>    overall_end = dataset.end</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># configure the dataset to only process the split workload</span></span><br><span class="line"><span class="meta">... </span>    per_worker = <span class="built_in">int</span>(math.ceil((overall_end - overall_start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>    worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>    dataset.start = overall_start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>    dataset.end = <span class="built_in">min</span>(dataset.start + per_worker, overall_end)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with the custom `worker_init_fn`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.TensorDataset(*tensors)[source]</span><br></pre></td></tr></table></figure>

<p>包装张量的 Dataset。</p>
<p>每个样本将通过沿第一维索引张量来检索。</p>
<p>参数<br>** tensors (Tensor) – 具有相同第一维大小的张量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.StackDataset(*args, **kwargs)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集堆叠在一起的 Dataset。</p>
<p>此类对于将作为数据集给出的复杂输入数据的不同部分组合在一起非常有用。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>images = ImageDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>texts = TextDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack = StackDataset(images, texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack[<span class="number">0</span>] == (images[<span class="number">0</span>], texts[<span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack = StackDataset(image=images, text=texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack[<span class="number">0</span>] == &#123;<span class="string">&#x27;image&#x27;</span>: images[<span class="number">0</span>], <span class="string">&#x27;text&#x27;</span>: texts[<span class="number">0</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>参数<br>** args (Dataset) – 堆叠的数据集，作为元组返回。<br>** kwargs (Dataset) – 堆叠的数据集，作为字典返回。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ConcatDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集组合在一起非常有用。</p>
<p>参数<br>** datasets (sequence) – 要连接的数据集列表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ChainDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>用于将多个 IterableDataset 连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集流组合在一起非常有用。连接操作是在运行时完成的，因此使用此类连接大型数据集将非常高效。</p>
<p>参数<br>** datasets (iterable of IterableDataset) – 要连接在一起的数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.Subset(dataset, indices)[source]</span><br></pre></td></tr></table></figure>

<p>在指定索引处的数据集的子集。</p>
<p>参数<br>** dataset (Dataset) – 整个 Dataset<br>** indices (sequence) – 为子集选择的整个集合中的索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data._utils.collate.collate(batch, *, collate_fn_map=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>处理每个批次中元素的集合类型的通用整理函数。</p>
<p>该函数还打开函数注册表以处理特定的元素类型。 default_collate_fn_map 为张量、NumPy 数组、数字和字符串提供默认的整理函数。</p>
<p>参数<br>** batch – 要整理的单个批次</p>
<p>collate_fn_map (Optional[Dict[Union[Type, Tuple[Type, …]], Callable]]) – 可选字典，将元素类型映射到相应的整理函数。如果元素类型不在此字典中，则此函数将按插入顺序遍历字典中的每个键，如果元素类型是键的子类，则调用相应的整理函数。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_tensor_fn</span>(<span class="params">batch, *, collate_fn_map</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># Extend this function to handle batch of tensors</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> torch.stack(batch, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    collate_map = &#123;torch.Tensor: collate_tensor_fn&#125;</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> collate(batch, collate_fn_map=collate_map)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Extend `default_collate` by in-place modifying `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(&#123;torch.Tensor: collate_tensor_fn&#125;)</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p>每个整理函数都需要一个批次的定位参数和一个整理函数字典的关键字参数，作为 collate_fn_map。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.default_collate(batch)[source]</span><br></pre></td></tr></table></figure>
<p>接收一批数据，并将批次中的元素放入一个具有额外的外部维度（批次大小）的张量中。</p>
<p>确切的输出类型可以是 torch.Tensor、Sequence 的 torch.Tensor、torch.Tensor 的集合，或者保持不变，具体取决于输入类型。 当在 DataLoader 中定义了 batch_size 或 batch_sampler 时，这将用作合并的默认函数。</p>
<p>以下是通用输入类型（基于批次内元素的类型）到输出类型映射</p>
<p>torch.Tensor -&gt; torch.Tensor（添加了外部维度批次大小）</p>
<p>NumPy 数组 -&gt; torch.Tensor</p>
<p>float -&gt; torch.Tensor</p>
<p>int -&gt; torch.Tensor</p>
<p>str -&gt; str（保持不变）</p>
<p>bytes -&gt; bytes（保持不变）</p>
<p>Mapping[K, V_i] -&gt; Mapping[K, default_collate([V_1, V_2, …])]</p>
<p>NamedTuple[V1_i, V2_i, …] -&gt; NamedTuple[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>Sequence[V1_i, V2_i, …] -&gt; Sequence[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>参数<br>batch – 要整理的单个批次</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `int`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `str`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Map` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([&#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">1</span>&#125;, &#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">100</span>&#125;])</span><br><span class="line">&#123;<span class="string">&#x27;A&#x27;</span>: tensor([  <span class="number">0</span>, <span class="number">100</span>]), <span class="string">&#x27;B&#x27;</span>: tensor([  <span class="number">1</span>, <span class="number">100</span>])&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `NamedTuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([Point(<span class="number">0</span>, <span class="number">0</span>), Point(<span class="number">1</span>, <span class="number">1</span>)])</span><br><span class="line">Point(x=tensor([<span class="number">0</span>, <span class="number">1</span>]), y=tensor([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Tuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">3</span>)])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `List` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Two options to extend `default_collate` to handle specific type</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 1: Write custom collate function and invoke `default_collate`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    elem = batch[<span class="number">0</span>]</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> <span class="built_in">isinstance</span>(elem, CustomType):  <span class="comment"># Some custom condition</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:  <span class="comment"># Fall back to `default_collate`</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> default_collate(batch)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 2: In-place modify `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_customtype_fn</span>(<span class="params">batch, *, collate_fn_map=<span class="literal">None</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(CustomType, collate_customtype_fn)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate(batch)  <span class="comment"># Handle `CustomType` automatically</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.default_convert(data)[source]</span><br></pre></td></tr></table></figure>
<p>将每个 NumPy 数组元素转换为 torch.Tensor。</p>
<p>如果输入是 Sequence、Collection 或 Mapping，它会尝试将内部的每个元素转换为 torch.Tensor。 如果输入不是 NumPy 数组，则保持不变。 当在 DataLoader 中未定义 batch_sampler 和 batch_size 时，这将用作合并的默认函数。</p>
<p>通用输入类型到输出类型映射类似于 default_collate()。 有关更多详细信息，请参阅那里的描述。</p>
<p>参数<br>data – 要转换的单个数据点</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `int`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(<span class="number">0</span>)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NumPy array</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(np.array([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NamedTuple</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">Point(x=<span class="number">0</span>, y=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(np.array(<span class="number">0</span>), np.array(<span class="number">0</span>)))</span><br><span class="line">Point(x=tensor(<span class="number">0</span>), y=tensor(<span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with List</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert([np.array([<span class="number">0</span>, <span class="number">1</span>]), np.array([<span class="number">2</span>, <span class="number">3</span>])])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">1</span>]), tensor([<span class="number">2</span>, <span class="number">3</span>])]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.get_worker_info()[source]</span><br></pre></td></tr></table></figure>

<p>返回有关当前 DataLoader 迭代器工作进程的信息。</p>
<p>在工作进程中调用时，这将返回一个保证具有以下属性的对象</p>
<p>id：当前工作进程 ID。</p>
<p>num_workers：工作进程的总数。</p>
<p>seed：为当前工作进程设置的随机种子。 此值由主进程 RNG 和工作进程 ID 确定。 有关更多详细信息，请参阅 DataLoader 的文档。</p>
<p>dataset：此进程中数据集对象的副本。 请注意，这将在与主进程不同的进程中成为不同的对象。</p>
<p>在主进程中调用时，这将返回 None。</p>
<p>注意</p>
<p>当在传递给 DataLoader 的 worker_init_fn 中使用时，此方法可用于以不同的方式设置每个工作进程，例如，使用 worker_id 配置 dataset 对象以仅读取分片数据集的特定部分，或使用 seed 为数据集代码中使用的其他库设置种子。</p>
<p>返回类型<br>Optional[WorkerInfo]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.utils.data.random_split(dataset, lengths, generator=&lt;torch._C.Generator <span class="built_in">object</span>&gt;)[source]</span><br></pre></td></tr></table></figure>
<p>将数据集随机拆分为给定长度的非重叠新数据集。</p>
<p>如果给定一个加起来为 1 的分数列表，则长度将自动计算为每个提供的分数的 floor(frac * len(dataset))。</p>
<p>计算长度后，如果存在任何余数，将以循环方式将 1 个计数分配给长度，直到没有余数为止。</p>
<p>可以选择固定生成器以获得可重复的结果，例如：</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator1 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator2 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">10</span>), [<span class="number">3</span>, <span class="number">7</span>], generator=generator1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">30</span>), [<span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.4</span>], generator=generator2)</span><br></pre></td></tr></table></figure>

<p>参数<br>dataset (Dataset) – 要拆分的Dataset</p>
<p>lengths (sequence) – 要生成的拆分的长度或分数</p>
<p>generator (Generator) – 用于随机排列的生成器。</p>
<p>返回类型<br>List[Subset[T]]</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.Sampler(data_source=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>所有 Sampler 的基类。</p>
<p>每个 Sampler 子类都必须提供一个 <strong>iter</strong>() 方法，提供一种方法来迭代数据集元素的索引或索引列表（批次），并且可以提供一个 <strong>len</strong>() 方法，该方法返回返回的迭代器的长度。</p>
<p>参数<br>data_source (Dataset) – 此参数未使用，将在 2.2.0 中删除。 您可能仍然拥有利用它的自定义实现。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthSampler</span>(Sampler[<span class="built_in">int</span>]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="built_in">int</span>]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">yield</span> <span class="keyword">from</span> torch.argsort(sizes).tolist()</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthBatchSampler</span>(Sampler[<span class="type">List</span>[<span class="built_in">int</span>]]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> (<span class="built_in">len</span>(<span class="variable language_">self</span>.data) + <span class="variable language_">self</span>.batch_size - <span class="number">1</span>) // <span class="variable language_">self</span>.batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">for</span> batch <span class="keyword">in</span> torch.chunk(torch.argsort(sizes), <span class="built_in">len</span>(<span class="variable language_">self</span>)):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>            <span class="keyword">yield</span> batch.tolist()</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p><strong>len</strong>() 方法不是 DataLoader 严格要求的，但预期在涉及 DataLoader 长度的任何计算中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.SequentialSampler(data_source)[source]</span><br></pre></td></tr></table></figure>

<p>按顺序采样元素，始终以相同的顺序。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>classtorch.utils.data.RandomSampler(data_source, replacement&#x3D;False, num_samples&#x3D;None, generator&#x3D;None)[source]<br>随机采样元素。 如果没有替换，则从洗牌后的数据集采样。</p>
<p>如果替换，则用户可以指定 num_samples 以进行抽取。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>replacement (bool) – 如果 True，则按需从替换中抽取样本，默认值为 <code>False</code></p>
<p>num_samples (int) – 要抽取的样本数量，默认值为 <code>len(dataset)</code>。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.SubsetRandomSampler(indices, generator&#x3D;None)[source]<br>从给定的索引列表中随机采样元素，不进行替换。</p>
<p>参数<br>indices (sequence) – 索引序列</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.WeightedRandomSampler(weights, num_samples, replacement&#x3D;True, generator&#x3D;None)[source]<br>从 [0,..,len(weights)-1] 中根据给定的概率（权重）采样元素。</p>
<p>参数<br>weights (sequence) – 权重序列，不必加起来为1</p>
<p>num_samples (int) – 要抽取的样本数</p>
<p>replacement (bool) – 如果为 True，则有放回地抽取样本。否则，则无放回地抽取样本，这意味着当为一行抽取一个样本索引时，就不能再为该行抽取该索引。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.1</span>, <span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.7</span>, <span class="number">3.0</span>, <span class="number">0.6</span>], <span class="number">5</span>, replacement=<span class="literal">True</span>))</span><br><span class="line">[<span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.05</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.1</span>], <span class="number">5</span>, replacement=<span class="literal">False</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.BatchSampler(sampler, batch_size, drop_last)[source]</span><br></pre></td></tr></table></figure>
<p>封装另一个采样器以生成一个索引小批量。</p>
<p>参数<br>sampler (Sampler or Iterable) – 基本采样器。可以是任何可迭代对象</p>
<p>batch_size (int) – 小批量的尺寸。</p>
<p>drop_last (bool) – 如果为 True，则采样器将丢弃最后一个小批量，如果其尺寸小于 batch_size</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">True</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classtorch.utils.data.distributed.DistributedSampler(dataset, num_replicas=<span class="literal">None</span>, rank=<span class="literal">None</span>, shuffle=<span class="literal">True</span>, seed=<span class="number">0</span>, drop_last=<span class="literal">False</span>)[source]</span><br></pre></td></tr></table></figure>
<p>限制数据加载到数据集子集的采样器。</p>
<p>它在与 torch.nn.parallel.DistributedDataParallel 结合使用时特别有用。在这种情况下，每个进程都可以将 DistributedSampler 实例作为 DataLoader 采样器传递，并加载一个独属于它的原始数据集的子集。</p>
<p>注意</p>
<p>假设数据集大小恒定，并且任何实例都始终以相同的顺序返回相同的元素。</p>
<p>参数<br>dataset – 用于采样的数据集。</p>
<p>num_replicas (int, optional) – 参与分布式训练的进程数。默认情况下，world_size 从当前分布式组中获取。</p>
<p>rank (int, optional) – 当前进程在 num_replicas 中的排名。默认情况下，rank 从当前分布式组中获取。</p>
<p>shuffle (bool, optional) – 如果为 True（默认），则采样器将随机打乱索引。</p>
<p>seed (int, optional) – 如果 shuffle&#x3D;True，则用于随机打乱采样器的随机种子。此数字在分布式组中的所有进程中应该相同。默认值：0。</p>
<p>drop_last (bool, optional) – 如果为 True，则采样器将丢弃数据的尾部，使其在副本数上均匀可分。如果为 False，则采样器将添加额外的索引以使数据在副本上均匀可分。默认值：False。</p>
<p>警告</p>
<p>在分布式模式下，在每个纪元开始时调用 set_epoch() 方法，在创建 DataLoader 迭代器之前，对于在多个纪元中使随机打乱正常工作是必要的。否则，将始终使用相同的排序。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sampler = DistributedSampler(dataset) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loader = DataLoader(dataset, shuffle=(sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line"><span class="meta">... </span>                    sampler=sampler)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, n_epochs):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> is_distributed:</span><br><span class="line"><span class="meta">... </span>        sampler.set_epoch(epoch)</span><br><span class="line"><span class="meta">... </span>    train(loader)</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>实验室显微CT建设</title>
    <url>/archive/Exp005-labCT.html</url>
    <content><![CDATA[<p>为配合同步辐射CT技术的研发，本团队计划 2020 年内完成实验室显微CT平台的搭建工作。实验室显微CT的主要特色是能够对目标试样内部的三维形貌进行无损表征，建设完成后，除其基本表征功能外，仍可为诸多研发工作提供便利： (1)同步辐射超快X射线成像系统中将使用的光学器件、机电设备等可以首先使用这套系统进行试错、标定。 (2)原本需在同步辐射进行测试的样品，可首先使用这套系统进行预实验，检验同步辐射实验的可行性。 (3)诸多同步辐射成像、CT相关的后处理算法也可首先使用这套系统进行验证性实验，如 XPIV、XDIC、XDVC 等。</p>
<p>目前，实验室显微CT平台建设已提上日程，本文将记录实验室CT建设过程中的详细信息。</p>
<span id="more"></span>

<h2 id="微焦点X射线源"><a href="#微焦点X射线源" class="headerlink" title="微焦点X射线源"></a>微焦点X射线源</h2><p>&emsp;&emsp;目前所用射线源产自 X-RAY WorX GmbH 公司，型号 <a href="https://www.x-ray-worx.com/index.php/en/microfocus-x-ray-tubes-overview/microfocus-transmission-tubes/product-line-tcnf">XWT-190-TCNF</a>。该公司 2010 年 2 月始建于 Hanover。这家德国高科技公司主营开发生产开放式、高分辨率的微焦点X射线源，用于无损X射线检测及计算机层析成像。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image003.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”Microfocus X-ray tube XWT-160-TCNF”&gt;</p>
<p>XWT-190-TCNF 微焦点X射线源有如下数条亮点：</p>
<ul>
<li>为半导体、电子元件、复合材料等的X射线成像效果提供了极致的 JIMA card 分辨能力</li>
<li>内置射线管头液体冷却装置，极大提高焦点位置稳定性，焦点运动范围$\pm 1\ \mu m$</li>
<li>内置自动排气阀，延长真空部件的使用寿命</li>
</ul>
<p>XWT-190-TCNF 微焦点X射线源的详细参数如下：</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image004.bmp” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Technical Details of Microfocus X-ray tube XWT-190-TCNF”&gt;</p>
<h2 id="PIXIS-2048B-相机"><a href="#PIXIS-2048B-相机" class="headerlink" title="PIXIS 2048B 相机"></a>PIXIS 2048B 相机</h2><p>&emsp;&emsp;来自普林斯顿仪器公司（Princeton Instruments, PI）的 <a href="http://www.princetoninstruments.com.cn/userfiles/files/assetLibrary/Datasheets/Princeton_Instruments_PIXIS_2048_eXcelon-N5_1-10_22_14.pdf">PIXIS 2048 系列相机</a>是专为定量科学成像而设计的全集成低噪声相机。背照型（B）提供近$95%$的可见光波段量子效率（Quantum efficiency）。利用PI独家设计的XP冷却技术，可提供$-55^\circ C$冷却，极大抑制暗电流。外壳采用全金属密封设计，提供行业内唯一终身真空质保。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image005.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Control software interface”&gt;</p>
<p>PIXIS 2048B 相机的详细参数如下：</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image006.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Technical Details of PIXIS 2048B”&gt;</p>
<h2 id="8-3维位移台"><a href="#8-3维位移台" class="headerlink" title="8+3维位移台"></a>8+3维位移台</h2><p>&emsp;&emsp;考虑到锥束CT扫描前必备的几何校正环节，实验室CT系统共需两套位移台，分别为样品下的八维载物台，及相机下三维位移台，均采购自日本KOHZU公司，详细参数见下表：</p>
<table>
<thead>
<tr>
<th align="center">轴号</th>
<th align="center">八维载物台@Z轴</th>
<th align="center">八维载物台@XY轴</th>
<th align="center">八维载物台@uv轴</th>
<th align="center">八维载物台@旋转轴</th>
</tr>
</thead>
<tbody><tr>
<td align="center">型号</td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/z-stage/motorized-z-stage/product/424/3/ZA07A-W201/1279/">ZA07A-W201</a></td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1%2C2/YA07A-R102/1265/">YA07A-R102</a></td>
<td align="center"><a href="https://www.kohzuchina.com/products/positioning-stages/swivel-tilt-stage/motorized-swivel-stage/product/76/5,20/SA07A-RL01/1292/">SA07A-RL01</a></td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/rotation-stage/motorized-rotation-stage/product/426/4/RA07A-W01/1243/">RA07A-W01</a></td>
</tr>
<tr>
<td align="center">行程</td>
<td align="center">$\pm$ 4 mm</td>
<td align="center">$\pm$ 10 mm</td>
<td align="center">$\pm$ 8$^\circ$ &amp; $\pm$10$^\circ$</td>
<td align="center">$\pm$ 135$^\circ$(@360$^\circ$)</td>
</tr>
<tr>
<td align="center">例图</td>
<td align="center"><img src="/Exp012_image007.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image008.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image009.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image010.jpg" width = 100% div align=center /></td>
</tr>
<tr>
<td align="center">轴号</td>
<td align="center"><strong>八维载物台@xy轴</strong></td>
<td align="center"><strong>三维位移台@XY轴</strong></td>
<td align="center"><strong>三维位移台@Z轴</strong></td>
<td align="center"><strong>PCIe1040&#x2F;1020控制器</strong></td>
</tr>
<tr>
<td align="center">型号</td>
<td align="center"><a href="https://www.kohzuprecision.com/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1%2C2/YA05A-R101/1259/">YA05A-R101</a></td>
<td align="center"><a href="https://www.kohzu.co.jp/products/positioning-stages/x-xy-stage/motorized-x-xy-stage/product/421/1,2/YA10A-R1/442/">YA10A-R1</a></td>
<td align="center"><a href="http://www.himotion.co.kr/kor/download/pdf/0106.pdf">ZA10A-V1</a></td>
<td align="center">王奕超</td>
</tr>
<tr>
<td align="center">行程</td>
<td align="center">$\pm$ 7.5 mm</td>
<td align="center">$\pm$ 12.5 mm</td>
<td align="center">$\pm$ 5 mm</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">例图</td>
<td align="center"><img src="/Exp012_image011.jpg" width = 100% div align=center /></td>
<td align="center"><img src="/Exp012_image012.jpg" width = 80% div align=center /></td>
<td align="center"><img src="/Exp012_image013.bmp" width = 100% div align=center /></td>
<td align="center">&lt;img src&#x3D;”&#x2F;Exp012_image014.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; &gt;</td>
</tr>
</tbody></table>
<h2 id="闪烁体及可见光光路"><a href="#闪烁体及可见光光路" class="headerlink" title="闪烁体及可见光光路"></a>闪烁体及可见光光路</h2><p>&emsp;&emsp;闪烁体是 X 射线成像探测器的重要组成部分，它将入射 X 射线转换为可见光，再由可见光成像探测器接收成像。闪烁体的厚度对成像的空间分辨能力、图像衬度有较大的影响，选取合适的厚度的闪烁体，与探测器物镜（数值孔径）等实验条件达到最理想的匹配，将有助于获得高质量的 X 射线成像结果。</p>
<h2 id="成像几何校正"><a href="#成像几何校正" class="headerlink" title="成像几何校正"></a>成像几何校正</h2><p>&emsp;&emsp;不妨令探测器中心与射线源的连线为基线，定义为Z轴，如下图，探测器自身纵向阵列在Z轴法平面上的投影定义为Y轴，根据右手坐标系法则确定X轴。在理想的成像几何下，探测器平面理应与Z轴严格垂直，且样品旋转轴应与Y轴严格重合。然而，实际实验中往往会偏离理想成像几何，几何偏差又分为如下四种情况：(1)探测器平面绕X轴偏转；(2) 探测器平面绕Y轴偏转；(3) 旋转轴绕Z轴偏转；(4) 旋转轴绕X轴偏转。下图列出了前三种偏转独立发生时所产生的影响。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image015.bmp” width &#x3D; 100% div align&#x3D;mid &#x2F;title&#x3D;”Reconstructed volume in the presence of detector tilt +10° (rotation around X-axis), detector slant +10° (rotation around Y-axis), and detector skew +2° (rotation around Z-axis).”&gt;</p>
<p>&emsp;&emsp;图中可见，(2,3)类几何偏差对重建结果产生了极大的畸变，对检测精密结构三维形貌十分不利，因而必须在进行CT扫描前将成像几何校正至理想情况，并确保在扫描过程中不发生变化。</p>
<p>&emsp;&emsp;(1,2)类几何偏差的校正方法可以等价为如何将射线源在探测器平面上的投影调整至探测器中心处。首先需准备一尺寸适中的标准球（如轴承钢珠），不断横向移动相机并记录相机坐标，采集标准球的投影图像。显然，投影图像理应为圆锥曲线，当投影图像完全在视野内时则必定为椭圆图样，且射线源在探测器平面上的投影恰恰就落在该椭圆的长轴所在直线上。从不同位置多次采集椭圆投影图像，即可确定射线源在探测器平面上的投影坐标。将射线源投影移动至探测器中心处，则(1,2)类几何偏差得以校正。</p>
<p>&emsp;&emsp;(3,4)类几何偏差的校正方法与同步辐射成像下几何校正无异，差异只在于必须在探测器纵向中心层进行几何校正，否则校正无效，细节在此不做赘述，注意需准备医用注射器针尖。</p>
<h2 id="实验操作及数据存储规范"><a href="#实验操作及数据存储规范" class="headerlink" title="实验操作及数据存储规范"></a>实验操作及数据存储规范</h2><h2 id="反卷积算法"><a href="#反卷积算法" class="headerlink" title="反卷积算法"></a>反卷积算法</h2><p>&emsp;&emsp;目前已实现经GPU加速的FDK三维重建算法，基于模拟的测试结果如下，左侧为模拟输入图像，右侧为重建输出图像。后续将逐步拓展，补全领域内主流算法。由于内容过于繁杂，对反卷积算法系统性的总结介绍请见下篇文章，此处只展示测试结果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp012_image018.jpg” width &#x3D; 80% div align&#x3D;mid &#x2F;title&#x3D;”Simulation and Verification of FDK Reconstruction Algorithm.”&gt;</p>
<h2 id="抗干扰算法"><a href="#抗干扰算法" class="headerlink" title="抗干扰算法"></a>抗干扰算法</h2><p>&emsp;&emsp;仅有反卷积算法还远远不够，微焦点源实验室显微CT中将会出现诸多干扰因素，若放任不管直接应用反卷积算法则会得到极糟糕的切片图像，于精确提取、量化分析不利。下表列出了实验室显微CT系统中常常面临的数种干扰因素及大致解决办法，各项具体细节将分别在其他博文中介绍。</p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="center">成因</th>
<th align="center">特点</th>
<th align="center">解决方案</th>
</tr>
</thead>
<tbody><tr>
<td align="center">椒盐噪声</td>
<td align="center">射线源散射探测像元</td>
<td align="center">随机出现，尺寸极小，强度极高</td>
<td align="center">Remove Outliers</td>
</tr>
<tr>
<td align="center">S1环状伪影</td>
<td align="center">探测器坏点</td>
<td align="center">该像元始终返回固定值</td>
<td align="center">Bicubic Interpolation</td>
</tr>
<tr>
<td align="center">S2环状伪影</td>
<td align="center">闪烁体缺陷</td>
<td align="center">固定存在，尺寸不定</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">S3环状伪影</td>
<td align="center">探测系统非线性相应</td>
<td align="center">投影图像中极难察觉</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">背底震荡</td>
<td align="center">光源输出功率振荡</td>
<td align="center">Sinogram图像呈现大量横向条纹</td>
<td align="center">Total Variation Filter</td>
</tr>
<tr>
<td align="center">射线硬化</td>
<td align="center">射线源能谱过宽</td>
<td align="center">&emsp;</td>
<td align="center">滤片</td>
</tr>
</tbody></table>
<h2 id="待采购清单"><a href="#待采购清单" class="headerlink" title="待采购清单"></a>待采购清单</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="right">数量</th>
<th align="right">参考价格</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><a href="https://vsp.jd.com/sku/100006476938">内六角全套套装</a></td>
<td align="right">1</td>
<td align="right">75.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100000652973.html">多功能螺丝刀套装</a></td>
<td align="right">1</td>
<td align="right">87.20</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://item.jd.com/30195663980.html#crumb-wrap">分隔收纳盒小号8格</a></td>
<td align="right">5</td>
<td align="right">5.10</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100006890641">干湿表</a></td>
<td align="right">1</td>
<td align="right">49.90</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/8063953">无尘布4寸</a></td>
<td align="right">2</td>
<td align="right">48.45</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/7831134">F型夹具</a></td>
<td align="right">2</td>
<td align="right">15.20</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100001946704">玻璃滴瓶</a></td>
<td align="right">2</td>
<td align="right">45.73</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/5833171">隐形胶带</a></td>
<td align="right">5</td>
<td align="right">8.91</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100011490188.html">胶带切割器</a></td>
<td align="right">1</td>
<td align="right">20.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100014305790.html">压缩空气除尘剂</a></td>
<td align="right">2</td>
<td align="right">79.57</td>
<td align="center">光学元件除尘</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100013533578">小型超声波清洗机</a></td>
<td align="right">1</td>
<td align="right">219.00</td>
<td align="center">闪烁体、试样清洁</td>
</tr>
<tr>
<td align="center">异丙醇</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">射线源阴极栅格罩清洁</td>
</tr>
<tr>
<td align="center">无水乙醇</td>
<td align="right">3</td>
<td align="right">50.00</td>
<td align="center">闪烁体清洁</td>
</tr>
<tr>
<td align="center"><a href="https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1430">THORLABS 607扳手</a></td>
<td align="right">1</td>
<td align="right">200.00</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center"><a href="https://vsp.jd.com/sku/100000381447">照明灯</a></td>
<td align="right">1</td>
<td align="right">29.90</td>
<td align="center">工具</td>
</tr>
<tr>
<td align="center">Kapton膜</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">闪烁体前防尘</td>
</tr>
<tr>
<td align="center">石墨、铝、铁、铜250um左右薄片</td>
<td align="right">10</td>
<td align="right">50.00</td>
<td align="center">频谱收窄</td>
</tr>
<tr>
<td align="center">XX薄膜</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">闪烁体后防尘</td>
</tr>
<tr>
<td align="center">Kapton管</td>
<td align="right">1</td>
<td align="right">50.00</td>
<td align="center">样品容器</td>
</tr>
<tr>
<td align="center">5X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">10X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">20X镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">目镜镜头</td>
<td align="right">1</td>
<td align="right">7000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">YaG闪烁晶体</td>
<td align="right">1</td>
<td align="right">5000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">LuAG闪烁晶体</td>
<td align="right">1</td>
<td align="right">5000.00</td>
<td align="center">&emsp;</td>
</tr>
<tr>
<td align="center">3D 分辨率板</td>
<td align="right">1</td>
<td align="right">23000.00</td>
<td align="center">&emsp;</td>
</tr>
</tbody></table>
]]></content>
  </entry>
  <entry>
    <title>2019年11月6日上海光源动态CT实验</title>
    <url>/archive/Exp004-PUplan.html</url>
    <content><![CDATA[<p>本团队计划近期赴上海同步辐射源（Shanghai Synchrotron Radiation Facility, SSRF） BL09B 测试线站搭建并测试秒级快速 CT 系统。用于测试的课题为聚氨酯泡沫发泡过程。依靠秒级快速 CT 系统连续观测聚氨酯泡沫发泡过程中三维结构形貌的演化，以及加入不同催化剂、添加剂时结构演化过程的差异。以期揭示聚氨酯泡沫发泡的动力学机理，同时探究催化剂、添加剂等对聚氨酯泡沫发泡成型过程的介入作用。</p>
<p>本次实验已于2019年11月09日圆满结束，感谢张抑扬，谢政良，蒋雪萍，刘子健等的协助。本文列出本次实验详细信息，以备查验。</p>
<span id="more"></span>

<h2 id="实验总结"><a href="#实验总结" class="headerlink" title="实验总结"></a>实验总结</h2><p>实验编号|配料方案|视野（${\rm mm}$）|像素尺寸（$${\rm \mu m}$$）|曝光时间（$${\rm \mu s}$$）|幅间隔（$${\rm ms}$$）|转速（$${\rm ^\circ&#x2F;sec}$$）|$${\rm CT}$$间隔（$${\rm sec}$$）|$${\rm CT}$$数|光子能量（$${\rm keV}$$）|$${\rm SSD}$$（$${\rm mm}$$）|$${\rm Filter}$$（$${\rm mmAl}$$）<br>:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|<br>Exp001 |<font color =#e9a3c9 > A01 </font>| 3.79 | 3.70 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp002 |<font color =#e9a3c9 > A01 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp003 |<font color =#e9a3c9 > A02 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp004 |<font color =#e9a3c9 > A03 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp005 |<font color =#e9a3c9 > A04 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp006 |<font color =#e9a3c9 > A05 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp007 |<font color =#e9a3c9 > A06 </font>| 9.47 | 9.25 | 250 | 1.0 | 360 | 20 | 80 | 15 | 310 | 1.0<br>Exp008 |<font color =#e9a3c9 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp009 |<font color =#c2a5cf > B01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp010 |<font color =#c2a5cf > B02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp011 |<font color =#c2a5cf > B03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp012 |<font color =#c2a5cf > B04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp013 |<font color =#c2a5cf > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp014 |<font color =#f4a582 > C01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp015 |<font color =#f4a582 > C02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp016 |<font color =#f4a582 > C03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp017 |<font color =#f4a582 > C04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp018 |<font color =#f4a582 > C01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp019 |<font color =#f4a582 > C02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp020 |<font color =#f4a582 > C03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp021 |<font color =#f4a582 > C04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp022 |<font color =#f4a582 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp023 |<font color =#e9a3c9 > A02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp024 |<font color =#e9a3c9 > A03 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp025 |<font color =#e9a3c9 > A04 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp026 |<font color =#e9a3c9 > A05 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp027 |<font color =#c2a5cf > B01 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp028 |<font color =#c2a5cf > B02 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>Exp029 |<font color =#c2a5cf > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST01 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST02 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 760 | 2.0 | 180 | 20 | 80 | 15 | 310 | 0.5<br>TEST03 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 200 | 0.4 | 900 | .2 | 30 | 15 | 310 | ——<br>TEST04 |<font color =#000000 > A07 </font>| 9.47 | 9.25 | 200 | 0.4 | 900 | .2 | 30 | 15 | 310 | ——  </p>
<p>&emsp;&emsp;Exp011-Exp012、Exp018-Exp029 构成一套完整对照试验。Exp001 无效；Exp007 及以前所有实验图像质量差；Exp010 及以前所有实验液量不稳；Exp013-Exp017 现场人员 Xie；TEST01 20 mm 大容器成像测试；TEST02 偏心拍法测试；TEST03 450 sec 处 5 Hz 连续 CT；TEST04 50 sec 处 5 Hz 连续 CT。</p>
<p>&emsp;&emsp;考虑到现场实验时光斑高度方向只有 7 mm，配料方案做出略微调整，下表列出详细的配料方案。</p>
<table>
<thead>
<tr>
<th align="center">配料方案</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><font color = #e9a3c9>$${\rm A01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.30\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A05}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A06}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.20\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #e9a3c9>$${\rm A07}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.24\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #c2a5cf>$${\rm B04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.03\ {\rm g}$$</td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C01}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C02}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.06\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.06\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C03}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.09\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.09\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center"><font color = #f4a582>$${\rm C04}$$</font></td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.12\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.24\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.12\ {\rm g}$$</font></td>
</tr>
</tbody></table>
<h2 id="物品清单"><a href="#物品清单" class="headerlink" title="物品清单"></a>物品清单</h2><p>&emsp;&emsp;本次动态 CT 实验的主要研究对象为聚氨酯泡沫发泡的三维结构演化过程。聚氨酯泡沫发泡实验需提前准备发泡原料 PAPI、聚醚多元醇、去离子水，发泡助剂，容器，滴泵等，共需三个托运箱，下表已列出详细的物品清单。</p>
<table>
<thead>
<tr>
<th>名称</th>
<th>负责人</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>探测：SA-Z高速相机</td>
<td>张抑扬</td>
<td>1024$\times$1024, 12 bit, 20 $\mu m$</td>
</tr>
<tr>
<td>容器：内径 $$9\ {\rm mm}$$，壁厚 $$1\ {\rm mm}$$，封底</td>
<td>蒋雪萍</td>
<td>定制 PMMA 容器各 $50$ 个，高 $$30\ {\rm mm}$$</td>
</tr>
<tr>
<td>原料（黑）：<a href="https://b2b.baidu.com/land?url=http://www.qianyuwang.com/offer/320595749.html?bdb2b8a2d=3101263341968821723&query=%E5%A4%9A%E4%BA%9A%E7%94%B2%E5%9F%BA%E5%A4%9A%E8%8B%AF%E5%9F%BA%E5%A4%9A%E5%BC%82%E6%B0%B0%E9%85%B8%E9%85%AF+%E6%88%90%E9%83%BD&category=%E5%8C%96%E5%B7%A5%E8%83%BD%E6%BA%90;%E5%8C%96%E5%AD%A6%E8%AF%95%E5%89%82;%E5%85%B6%E4%BB%96%E5%8C%96%E5%AD%A6%E8%AF%95%E5%89%82&iswapurl=&qq-pf-to=pcqq.c2c">多亚甲基多苯基多异氰酸酯 PAPI</a></td>
<td>谢政良</td>
<td>CAS号：9016-87-9；纯度 $98%$</td>
</tr>
<tr>
<td>原料（白）：聚醚多元醇</td>
<td>谢政良</td>
<td>CAS号：9003-11-6；</td>
</tr>
<tr>
<td>原料（白）：去离子水</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>助剂（匀泡剂）：<a href="http://www.maysta.com/pro/detail.aspx?id=1&mtt=0">硅油</a></td>
<td>谢政良</td>
<td>AK8805</td>
</tr>
<tr>
<td><font color=#e9a3c9>助剂（开孔剂）：</font><a href="http://www.maysta.com/pro/detail.aspx?id=7&mtt=0"><font color=#e9a3c9>硅油</font></a></td>
<td>谢政良</td>
<td>AK9903</td>
</tr>
<tr>
<td>助剂（催化剂）：<a href="http://www.adamas-beta.com/productDetail!doProductDetail.action?pm=cat&attr9=5%5Ecmdfafi">辛酸亚锡</a></td>
<td>谢政良</td>
<td>CAS号：301-10-0；纯度 $95%$</td>
</tr>
<tr>
<td>助剂（成核剂）：<a href="https://www.rhawn.cn/products/detail/19617">硬脂酸钙</a></td>
<td>谢政良</td>
<td>上海凛恩科技发展有限公司 R019842</td>
</tr>
<tr>
<td>滴泵：滴泵出液口陶瓷管</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>滴泵：滴泵支架</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>滴泵：滴泵控制系统</td>
<td>王奕超</td>
<td>延长控制线，检验</td>
</tr>
<tr>
<td>滴泵：三维位移台，及转台上位移台</td>
<td>谢政良</td>
<td></td>
</tr>
<tr>
<td>其他：铝板，医用注射器，塑料杯，搅拌棒，底部针脚，502胶</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>其他：内六角，机米螺丝，标签纸，记号笔，封泥，鼓气工具</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>其他：回收桶及垃圾袋</td>
<td>刘子健</td>
<td></td>
</tr>
<tr>
<td>存储：机械硬盘，移动硬盘，机械硬盘外接盒，SD Card，读卡器</td>
<td>柴海伟</td>
<td></td>
</tr>
</tbody></table>
<h2 id="预实验"><a href="#预实验" class="headerlink" title="预实验"></a>预实验</h2><p>预实验旨在给出如下问题的答案，为现场实验指明配料方案。感谢谢政良、蒋雪平完成此处工作。</p>
<h3 id="PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？"><a href="#PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？" class="headerlink" title="PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？"></a>PAPI、聚醚多元醇、去离子水三项主要原料以何种配比发泡最佳？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.30\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$0.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.00\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，<font color=#e9a3c9>水 $$1.50\ {\rm mL}$$</font>，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
</tbody></table>
<p>现象总结：文献报道水分占比将直接影响泡孔占比、宏观密度，恰当的水分占比对调控泡沫结构至关重要。在预实验中我们观察到A，B组分液量控制在$$0.06\ {\rm mL}$$，前三组反应终态大致稳定在9mm高，尚未超出视野范围，前四组反应至$$20\ {\rm min}$$即大致稳定，第五组反应仍未停止。水分对终态宏观密度，胞壁形貌，反应速度等影响显著。</p>
<h3 id="硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？"><a href="#硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？" class="headerlink" title="硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？"></a>硅油对聚氨酯泡沫发泡体系呈现何种影响？哪种型号的硅油效果最好？该种硅油在反应液中占多大比例影响最好？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.0\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.1\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.2\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.3\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，<font color=#c2a5cf>硅油 $$0.4\ {\rm mL}$$</font>，硬脂酸钙 $$0.02\ {\rm g}$$</td>
</tr>
</tbody></table>
<p>现象总结：硅油AK8805与PAPI混合即产生大量气泡及絮状物，硅油AK8860与PAPI混合均匀且无气泡、絮状物。经测试，硅油AK8805有明显稳泡效果，加入$$0.2\ {\rm mL}$$时效果最好，加入更多比例效果提升不明显。AK8860现象仍然明显。</p>
<h3 id="硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？"><a href="#硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？" class="headerlink" title="硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？"></a>硬脂酸钙对聚氨酯泡沫发泡体系呈何种影响？最佳比例？</h3><table>
<thead>
<tr>
<th align="center">编号</th>
<th align="center">A 组分</th>
<th align="center">B 组分</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Exp001</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.00\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp002</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.01\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.01\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp003</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.02\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.02\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp004</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.03\ {\rm g}$$</font></td>
</tr>
<tr>
<td align="center">Exp005</td>
<td align="center">PAPI $$5\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.04\ {\rm g}$$</font></td>
<td align="center">聚醚 $$5\ {\rm mL}$$，水 $$0.30\ {\rm mL}$$，辛酸亚锡 $$0.1\ {\rm mL}$$，硅油 $$0.2\ {\rm mL}$$，<font color=#f4a582>硬脂酸钙 $$0.04\ {\rm g}$$</font></td>
</tr>
</tbody></table>
<p>现象总结：硬脂酸钙粉末的细孔效果不明显。硬脂酸钙粉末含量达到$$0.12\ {\rm g}$$时现象明显，更改实验方案。</p>
<h3 id="预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径-6-rm-mm-的容器内，多次重复。"><a href="#预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径-6-rm-mm-的容器内，多次重复。" class="headerlink" title="预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径 $$6\ {\rm mm}$$的容器内，多次重复。"></a>预装滴泵支架，固定滴泵至支架上，通过控制程序将去离子水滴至内径 $$6\ {\rm mm}$$的容器内，多次重复。</h3><p>&emsp;&emsp;支架部件：三维位移台一套；$$300\ {\rm mm\ M6\ }$$支杆 $\times6$，$$200\ {\rm mm\ M6\ }$$支杆 $\times6$，$$100\ {\rm mm\ M4\ }$$支杆 $\times2$，$${\rm M6\ }$$垫脚 $\times1$，压板 $\times1$，$${\rm M6\ }$$机米螺丝$\times10$，$${\rm M6\ }$$六角螺丝$\times5$，$${\rm M4\ }$$机米螺丝$\times3$，$${\rm M3\ }$$六角螺丝$\times2$，弹性垫片$\times2$。</p>
<p>&emsp;&emsp;滴泵部件：滴泵本体；滴泵电源线；滴泵控制线；笔记本电脑；滴泵口转接头；陶瓷管。</p>
<p>&emsp;&emsp;经检验，滴泵及支架运行正常，可以满足实验需求。</p>
<h3 id="滴泵清洗方案"><a href="#滴泵清洗方案" class="headerlink" title="滴泵清洗方案"></a>滴泵清洗方案</h3><p>&emsp;&emsp;滴泵排出所有组分B后，抽取清水$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空液体。重复上述操作$3$次，抽取空气$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空，抽取清水$$3\ {\rm mL}$$，等待$$10\ {\rm sec}$$，排空。再抽取空气排空。最后取出陶瓷管吹干，棉签擦干滴泵出口。</p>
<p>&emsp;&emsp;总结：抽水排出三次，抽空气及抽水排出交替进行各三次，最后以抽空气排出收尾，吹干陶瓷管，棉签擦拭滴泵出口。</p>
]]></content>
  </entry>
  <entry>
    <title>人工智能：TrainingArguments 中 optim 参数详解</title>
    <url>/archive/AI-optim.html</url>
    <content><![CDATA[<p>这份指南详细介绍了 Hugging Face <code>transformers</code> 库中 <code>optim</code> 参数所有可用的选项。该列表直接来源于 <code>transformers</code> 源代码，涵盖了从稳定可靠的基准到内存优化、实验性算法和特定硬件的各类优化器。</p>
<span id="more"></span>
<hr>
<h2 id="优化器分类概览"><a href="#优化器分类概览" class="headerlink" title="优化器分类概览"></a>优化器分类概览</h2><p>为了系统地理解这些选项，我们将它们分为以下几大类：</p>
<p><strong>主流与推荐 (AdamW 家族)</strong>: 训练 Transformer 模型的核心与首选。<br>    * <code>adamw_torch</code>, <code>adamw_torch_fused</code></p>
<p><strong>内存节省型优化器 (核心技术)</strong>: 当显存（VRAM）成为主要瓶颈时，这些技术至关重要。<br><strong>8-bit 量化优化器</strong>: 将优化器状态从32位浮点数压缩到8位整数，极大节省内存。<br>        * <code>adamw_8bit</code> (别名 <code>adamw_bnb_8bit</code>), <code>lion_8bit</code>, <code>rmsprop_8bit</code><br>    * <strong>Paged 优化器</strong>: 一种更先进的内存管理技术，当GPU显存不足时，它能自动将优化器状态“分页”到CPU内存，防止程序因OOM（Out-of-Memory）而崩溃。<br>        * <code>paged_adamw_8bit</code>, <code>paged_lion_8bit</code><br>    * <strong>Adafactor</strong>: 通过数学分解来近似存储优化器状态，是另一种经典的内存节省方案。<br>        * <code>adafactor</code></p>
<p><strong>梯度低秩投影 (GaLore)</strong>: 一种前沿的内存优化技术，尤其适合全参数微调。<br><strong>低内存优化 (LOMO &amp; AdaLOMO)</strong>: 另一种创新的内存节省方法。<br><strong>新型与实验性优化器</strong>: 来自最新研究，可能在特定任务上表现更优。<br><strong>特定硬件&#x2F;库的优化器</strong>: 为特定硬件或旧版库设计。<br><strong>经典与遗留优化器</strong>: 深度学习领域的经典算法。</p>
<hr>
<h2 id="全量选项详细分析"><a href="#全量选项详细分析" class="headerlink" title="全量选项详细分析"></a>全量选项详细分析</h2><h3 id="1-主流与推荐-AdamW-家族"><a href="#1-主流与推荐-AdamW-家族" class="headerlink" title="1. 主流与推荐 (AdamW 家族)"></a>1. 主流与推荐 (AdamW 家族)</h3><p>这是训练现代大模型的起点和最可靠的选择。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖与要求</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_torch</code></strong></td>
<td align="left">PyTorch 标准实现，<strong>默认选项</strong></td>
<td align="left"><strong>最稳定、最通用</strong>，无需额外依赖，行为可预测。</td>
<td align="left">在现代 GPU 上性能非最优。</td>
<td align="left">PyTorch</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_torch_fused</code></strong></td>
<td align="left"><strong>性能之选 (推荐)</strong>，融合内核</td>
<td align="left">在现代 NVIDIA GPU 上<strong>速度显著提升</strong>，通过融合操作减少 GPU 内核启动开销。</td>
<td align="left">需要 PyTorch 2.0 或更高版本。</td>
<td align="left"><code>torch&gt;=2.0</code></td>
</tr>
</tbody></table>
<h3 id="2-内存节省型优化器"><a href="#2-内存节省型优化器" class="headerlink" title="2. 内存节省型优化器"></a>2. 内存节省型优化器</h3><p>当显存不足时，以下技术是你的救星。它们通常可以组合使用。</p>
<h4 id="2-1-8-bit-量化优化器"><a href="#2-1-8-bit-量化优化器" class="headerlink" title="2.1 8-bit 量化优化器"></a>2.1 8-bit 量化优化器</h4><p><strong>技术核心</strong>：使用 <code>bitsandbytes</code> 库将32位的优化器状态（如动量和方差）量化为8位整数，从而<strong>将优化器的内存占用减少约75%</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_8bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">8位量化的 <code>AdamW</code>。<strong>最常用、最推荐的内存节省方案</strong>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left">(<code>adamw_bnb_8bit</code>)</td>
<td align="left"></td>
<td align="left">(这是 <code>adamw_8bit</code> 的一个别名)</td>
<td align="left"></td>
</tr>
<tr>
<td align="left"><strong><code>lion_8bit</code></strong></td>
<td align="left">Lion</td>
<td align="left">8位量化的 <code>Lion</code> 优化器。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>rmsprop_8bit</code></strong></td>
<td align="left">RMSprop</td>
<td align="left">8位量化的 <code>RMSprop</code>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left">(<code>rmsprop_bnb_8bit</code>)</td>
<td align="left"></td>
<td align="left">(这是 <code>rmsprop_8bit</code> 的一个别名)</td>
<td align="left"></td>
</tr>
</tbody></table>
<h4 id="2-2-Paged-优化器"><a href="#2-2-Paged-优化器" class="headerlink" title="2.2 Paged 优化器"></a>2.2 Paged 优化器</h4><p><strong>技术核心</strong>：在8-bit优化的基础上，当GPU显存依然不足时，它能利用NVIDIA的统一内存功能，自动将不常用的优化器状态**“分页”到CPU主内存**，并在需要时再调回GPU。这可以<strong>防止在训练中因显存波动导致的崩溃 (OOM Error)</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>paged_adamw_8bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">结合了8位量化和分页技术，<strong>是目前最稳健的内存优化方案</strong>。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>paged_lion_8bit</code></strong></td>
<td align="left">Lion</td>
<td align="left">结合了8位量化和分页技术的 <code>Lion</code> 优化器。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>paged_adamw_32bit</code></strong></td>
<td align="left">AdamW</td>
<td align="left">如果你不想使用8位量化但仍想利用分页技术防止崩溃，可以使用这个32位版本。</td>
<td align="left"><code>bitsandbytes</code></td>
</tr>
</tbody></table>
<h4 id="2-3-Adafactor"><a href="#2-3-Adafactor" class="headerlink" title="2.3 Adafactor"></a>2.3 Adafactor</h4><p><strong>技术核心</strong>：通过数学上的矩阵分解技巧来近似存储优化器状态，从而达到节省内存的目的。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adafactor</code></strong></td>
<td align="left">Google 设计的内存优化器</td>
<td align="left"><strong>显著降低内存占用</strong>，不存储完整的动量信息，且不依赖 <code>bitsandbytes</code> 库。</td>
<td align="left">收敛性有时不如 AdamW 稳定，可能需要更仔细地调整学习率。</td>
<td align="left"><code>transformers</code> 自带</td>
</tr>
</tbody></table>
<h3 id="3-GaLore-Gradient-Low-Rank-Projection"><a href="#3-GaLore-Gradient-Low-Rank-Projection" class="headerlink" title="3. GaLore (Gradient Low-Rank Projection)"></a>3. GaLore (Gradient Low-Rank Projection)</h3><p><strong>技术核心</strong>：一种非常新颖且高效的内存优化技术，它假设梯度矩阵是低秩的，因此只存储和更新梯度的低秩投影，而不是完整的梯度矩阵。这使得<strong>全参数微调的内存消耗可以接近甚至低于LoRA等参数高效微调方法</strong>。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">基础优化器</th>
<th align="left">特点与用途</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>galore_adamw</code></strong></td>
<td align="left">AdamW</td>
<td align="left">将 GaLore 技术应用于 AdamW。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_adafactor</code></strong></td>
<td align="left">Adafactor</td>
<td align="left">将 GaLore 技术应用于 Adafactor，进一步节省内存。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_adamw_8bit</code></strong></td>
<td align="left">AdamW + 8-bit</td>
<td align="left">结合了 GaLore 和8位量化，实现极致的内存节省。</td>
<td align="left"><code>galore_torch</code>, <code>bitsandbytes</code></td>
</tr>
<tr>
<td align="left"><strong><code>galore_..._layerwise</code></strong></td>
<td align="left">(所有GaLore变体)</td>
<td align="left">为模型的不同层应用不同的秩，可能比全局秩更高效。</td>
<td align="left"><code>galore_torch</code></td>
</tr>
</tbody></table>
<h3 id="4-LOMO-Low-Memory-Optimization-AdaLOMO"><a href="#4-LOMO-Low-Memory-Optimization-AdaLOMO" class="headerlink" title="4. LOMO (Low-Memory Optimization) &amp; AdaLOMO"></a>4. LOMO (Low-Memory Optimization) &amp; AdaLOMO</h3><p><strong>技术核心</strong>：LOMO通过将梯度计算、梯度收集和参数更新步骤融合成一个步骤，从而避免了存储完整的模型梯度，<strong>极大地节省了内存</strong>。AdaLOMO是其自适应版本。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点</th>
<th align="left">优点</th>
<th align="left">缺点</th>
<th align="left">依赖</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>lomo</code></strong></td>
<td align="left">低内存优化</td>
<td align="left">将多步融为一步，无需存储完整梯度，内存效率极高。</td>
<td align="left">实验性强，实现较为复杂。</td>
<td align="left"><code>lomo_optim</code></td>
</tr>
<tr>
<td align="left"><strong><code>adalomo</code></strong></td>
<td align="left">带自适应学习率的LOMO</td>
<td align="left">在 LOMO 基础上增加了学习率的自适应调整。</td>
<td align="left">实验性强。</td>
<td align="left"><code>lomo_optim</code></td>
</tr>
</tbody></table>
<h3 id="5-新型与实验性优化器"><a href="#5-新型与实验性优化器" class="headerlink" title="5. 新型与实验性优化器"></a>5. 新型与实验性优化器</h3><p>这些优化器来自最新的学术研究，可能在特定任务上表现更优，但需要更多实验和调整。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心思想</th>
<th align="left">何时使用</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>lion</code></strong> (或 <code>lion_32bit</code>)</td>
<td align="left">简化更新规则（只用动量），由Google提出。</td>
<td align="left">当你乐于探索时。<code>lion</code> 宣称比 AdamW 更省内存、性能更优。通常需要更小的学习率和更大的权重衰减。</td>
</tr>
<tr>
<td align="left"><strong><code>apollo_adamw</code></strong></td>
<td align="left">解耦学习率和权重衰减来改进 AdamW。</td>
<td align="left">当你希望探索可能比标准AdamW收敛更好、性能更优的替代方案时。</td>
</tr>
<tr>
<td align="left"><strong><code>schedule_free_...</code></strong></td>
<td align="left">在训练中自动调整步长。</td>
<td align="left"><strong>当你不想费心设计学习率调度器时</strong>。非常适合快速实验，但最终性能不一定最优。</td>
</tr>
<tr>
<td align="left"><strong><code>grokadamw</code></strong></td>
<td align="left">为复现 “Grokking” 现象而设计。</td>
<td align="left">仅用于学术研究，探索模型在训练后期泛化能力突然提升的现象。</td>
</tr>
</tbody></table>
<h3 id="6-特定硬件-库的优化器"><a href="#6-特定硬件-库的优化器" class="headerlink" title="6. 特定硬件&#x2F;库的优化器"></a>6. 特定硬件&#x2F;库的优化器</h3><table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>adamw_torch_xla</code></strong></td>
<td align="left"><strong>仅在 Google TPU 上使用</strong>。</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_torch_npu_fused</code></strong></td>
<td align="left"><strong>仅在华为 Ascend NPU 上使用</strong>。</td>
</tr>
<tr>
<td align="left"><strong><code>adamw_apex_fused</code></strong></td>
<td align="left">仅在 <code>torch&lt;2.0</code> 的旧环境中，配合NVIDIA APEX库使用。已被 <code>adamw_torch_fused</code> 取代。</td>
</tr>
</tbody></table>
<h3 id="7-经典与遗留优化器"><a href="#7-经典与遗留优化器" class="headerlink" title="7. 经典与遗留优化器"></a>7. 经典与遗留优化器</h3><p>这些算法是深度学习的基石，但对于现代 Transformer 模型，通常不是最佳选择。</p>
<table>
<thead>
<tr>
<th align="left">选项 (<code>optim</code>)</th>
<th align="left">核心特点与局限</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>sgd</code></strong></td>
<td align="left"><strong>随机梯度下降</strong>。对于Transformer模型这样复杂的损失曲面，SGD收敛极慢且容易陷入局部最优。</td>
</tr>
<tr>
<td align="left"><strong><code>adagrad</code></strong></td>
<td align="left"><strong>适应性梯度算法</strong>。学习率会随时间单调递减，后期可能过小导致训练停滞，不推荐用于Transformer。</td>
</tr>
<tr>
<td align="left"><strong><code>rmsprop</code></strong></td>
<td align="left"><strong>Adagrad的改进版</strong>。缓解了学习率快速下降的问题，但性能和稳定性通常不如AdamW。</td>
</tr>
</tbody></table>
<hr>
<h2 id="终极决策流程"><a href="#终极决策流程" class="headerlink" title="终极决策流程"></a>终极决策流程</h2><ol>
<li><p><strong>【性能优先】</strong> 如果你有现代NVIDIA GPU和PyTorch 2.0+，<strong><code>adamw_torch_fused</code></strong> 是你的不二之选。</p>
</li>
<li><p><strong>【内存优先】</strong> 如果显存不足是首要问题：</p>
<ul>
<li><strong>首选 <code>paged_adamw_8bit</code></strong>。它结合了8位量化和分页，既省内存又防崩溃。</li>
<li>如果想在<strong>全参数微调</strong>时达到LoRA级的内存效率，大胆尝试 <strong><code>galore_adamw_8bit</code></strong>。</li>
<li>如果安装 <code>bitsandbytes</code> 困难，退而求其次选择 <strong><code>adafactor</code></strong>。</li>
</ul>
</li>
<li><p><strong>【简化实验】</strong> 如果你想快速迭代，不想费心设计学习率调度器：</p>
<ul>
<li>尝试 <strong><code>schedule_free_adamw</code></strong>。</li>
</ul>
</li>
<li><p><strong>【探索前沿】</strong> 如果你热衷于尝试最新的研究成果：</p>
<ul>
<li><strong><code>lion</code></strong> 是一个很好的起点，但请准备好调整超参数。</li>
</ul>
</li>
<li><p><strong>【不确定或环境受限】</strong> 如果你不确定选哪个：</p>
<ul>
<li>使用默认的 <strong><code>adamw_torch</code></strong>，它永远是稳定可靠的基准。</li>
</ul>
</li>
<li><p><strong>【特定硬件】</strong> 如果你在TPU或NPU上：</p>
<ul>
<li>分别使用 <strong><code>adamw_torch_xla</code></strong> 或 <strong><code>adamw_torch_npu_fused</code></strong>。</li>
</ul>
</li>
</ol>
<h2 id="官方文档地址"><a href="#官方文档地址" class="headerlink" title="官方文档地址"></a>官方文档地址</h2><p>您可以在 Hugging Face <code>transformers</code> 官方文档的 <code>TrainingArguments</code> 页面找到关于 <code>optim</code> 参数的权威说明。官方文档链接: <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments.optim">https://huggingface.co/docs/transformers/main/en/main_classes&#x2F;trainer#transformers.TrainingArguments.optim</a></p>
]]></content>
  </entry>
  <entry>
    <title>聚氨酯泡沫制备工艺</title>
    <url>/archive/Exp006-PU-foam.html</url>
    <content><![CDATA[<p>&emsp;&emsp;聚氨酯（Polyurethane, PU）是聚氨基甲酸酯的简称，凡是主链上含有许多重复的 $$ {\rm -NHCOO-} $$ 基团的高分子化合物通称为聚氨酯。多异氰酸酯与多元醇进行化学反应，即可生成聚氨酯。硬质聚氨醋泡沫塑料具有优良的力学性能、较高的比强度、良好的冲击吸能特性及隔音绝热性能，作为结构支撑材料和减震缓冲材料在武器方面有着重要的应用。本文将简单介绍聚氨酯泡沫制备工艺，为本次上海光源开展的动态 CT 实验样品制备提供参考。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;制备聚氨酯所需的主要原料为有机异氰酸酯、多元醇化合物及助剂。用于聚氨酯泡沫塑料制备的有机异氰酸酯通常有：甲苯二异氰酸酯（<strong>TDI</strong>）、二苯基甲烷二异氰酸酯（<strong>MDI</strong>）、<u>多亚甲基多苯基多异氰酸酯（<strong>PAPI</strong>）</u>等。多元醇又分为<u>聚醚多元醇</u>、聚酯多元醇两大类。助剂主要包括：催化剂、发泡剂、泡沫稳定剂、交联剂、阻燃剂、防老剂、填料、颜料等等。聚氨酷泡珠塑料的密度、孔径、软硬程度均可随原料、助剂的种类及配比不同而改变。</p>
<ul>
<li>注：聚合，指单体小分子相互连接成为链状大分子,一般分子量达到 5000 以上，甚至可以达到几千万，形成高分子材料。</li>
</ul>
<p>&emsp;&emsp;工业聚氨酯泡沫黑白料作为一步法制备聚氨酯泡沫的主要原料，白料通常为为组合聚醚多元醇、匀泡剂、交联剂、催化剂、发泡剂等的预混合液，黑料为聚合二苯甲烷二异氰酸酯（<strong>MDI</strong>），因而使用工业聚氨酯泡沫黑白料为原料探究助剂的影响是不可取的。</p>
<h2 id="异氰酸酯的反应特性"><a href="#异氰酸酯的反应特性" class="headerlink" title="异氰酸酯的反应特性"></a>异氰酸酯的反应特性</h2><p>&emsp;&emsp;由于异氰酸酯的化学特性，它不但能和多羟基化合物反应生成氨基甲酸酯，而且还可以和其他具有“活性氢”的化合物反应生成各种相应的化学链节，从而改变聚氨酯的链节结构和性能。人们不断以此为基础，发展聚氨酯的改性手段，有目的的引入各种链节及基团，改变基体聚合物的性能。因此聚氨酯类聚合物有“可缝制的聚合物”之称，日益收到人们的重视。</p>
<h3 id="异氰酸酯与-rm-NH-基反应"><a href="#异氰酸酯与-rm-NH-基反应" class="headerlink" title="异氰酸酯与 ${\rm NH}$ 基反应"></a>异氰酸酯与 ${\rm NH}$ 基反应</h3><h4 id="与胺基（-rm-NH-2-）反应"><a href="#与胺基（-rm-NH-2-）反应" class="headerlink" title="与胺基（${\rm -NH_2}$）反应"></a>与胺基（${\rm -NH_2}$）反应</h4><p>&emsp;&emsp;凡存在 ${\rm -NH_2}$ 基团的化合物，除具有较大的位阻效应外，基本都能与异氰酸酯发生反应（式\eqref{1}）。碱性越强的胺基化合物与异氰酸酯的反应能力越强，例如脂肪族伯胺在 $0\sim25^\circ{\rm C}$ 下即能与异氰酸酯反应生成对应脲类化合物。</p>
<p>$$ {\rm RNCO + R’NH_2 \Longrightarrow RNHCONHR’} {\tag{1}\label{1}}$$</p>
<p>&emsp;&emsp;总的来说，胺基化合物与异氰酸酯的反应活性相较其他一般活性氢化合物要高。与胺基化合物具有同样强碱性的其他含氮化合物，例如联胺等也能很快地与异氰酸酯发生反应（式\eqref{2}）。在聚氨酯制备中，胺基与异氰酸酯的反应是较为重要的反应之一。<br>$$ {\rm RNCO + R’NH!!-!!NH_2 \Longrightarrow RNHCONHNHR’} \tag{2}\label{2}$$</p>
<ul>
<li>注：位阻效应，分子中某些原子或基团彼此接近而引起的空间阻碍，阻碍化学反应的进行。（<font color=Green>不严谨</font>）</li>
</ul>
<h4 id="与酰胺基（-rm-CONH-2-）反应"><a href="#与酰胺基（-rm-CONH-2-）反应" class="headerlink" title="与酰胺基（${\rm -CONH_2}$）反应"></a>与酰胺基（${\rm -CONH_2}$）反应</h4><p>&emsp;&emsp;异氰酸酯可与酰胺基化合物反应生成对应酰基脲化合物（式\eqref{3}）。</p>
<p>$$ {\rm RNCO + R’CONH_2 \Longrightarrow RNHCONHCOR’} \tag{3}\label{3}$$</p>
<p>&emsp;&emsp;由于酰胺基中 $$ {\rm N!!-!!H}$$ 基团上氮原子带有负电荷，降低了其与异氰酸酯的反应速率。因而，在聚氨酯制备中该反应的利用率不高。</p>
<h4 id="与脲基（-rm-NHCONH-）反应"><a href="#与脲基（-rm-NHCONH-）反应" class="headerlink" title="与脲基（${\rm -NHCONH-}$）反应"></a>与脲基（${\rm -NHCONH-}$）反应</h4><p>&emsp;&emsp;此项反应是在高温条件下制备聚氨酯涉及到的重要反应之一。异氰酸酯与脲基化合物反应可生成对应缩二脲（式\eqref{4}）。</p>
<p>$$ {\rm R’NCO + RNHCONHR \Longrightarrow R’N(-CONHR)2} \tag{4}\label{4}$$</p>
<p>&emsp;&emsp;该反应在没有催化剂存在下，一般需在 $100^\circ{\rm C}$ 或更高温度下才能发生。大部分叔胺对此并不呈现较强的催化作用，而强碱和某些金属化合物则具有较强的催化能力。</p>
<h4 id="与氨基甲酸酯（-rm-NHCOO-）反应"><a href="#与氨基甲酸酯（-rm-NHCOO-）反应" class="headerlink" title="与氨基甲酸酯（${\rm -NHCOO-}$）反应"></a>与氨基甲酸酯（${\rm -NHCOO-}$）反应</h4><p>&emsp;&emsp;异氰酸酯与氨基甲酸酯的反应没有与脲基反应那么容易。无催化剂情况下，一般需在 $120\sim140^\circ{\rm C}$下才能得到较为满意的反应速率。在通常的反应条件下，所得最终产物为脲基甲酸酯（式\eqref{5}）。</p>
<p>$$ {\rm RNCO + RNHCOOR’ \Longrightarrow RN(-CONHR)COOR’} \tag{5}\label{5}$$</p>
<p>&emsp;&emsp;此类反应类似异氰酸酯与脲基化合物的反应，一般叔胺类对该反应不起催化作用，只有强碱或某些金属化合物才具有一定的催化作用。在进一步升温后，还将产生其他副反应，在此不做介绍。</p>
<h3 id="异氰酸酯与-rm-OH-基反应"><a href="#异氰酸酯与-rm-OH-基反应" class="headerlink" title="异氰酸酯与 ${\rm OH}$ 基反应"></a>异氰酸酯与 ${\rm OH}$ 基反应</h3><h4 id="与醇类反应"><a href="#与醇类反应" class="headerlink" title="与醇类反应"></a>与醇类反应</h4><p>&emsp;&emsp;此类反应为聚氨酯制备中的主要反应。通常情况，凡与氧原子相连接的氢原子都能与异氰酸酯发生反应，其中最活泼的就是醇类化合物，它可以与异氰酸酯反应生成对应氨基甲酸酯（式\eqref{6}）。</p>
<p>$$ {\rm RNCO + R’OH   \Longrightarrow RNHCOOR’} \tag{6}\label{6}$$</p>
<p>&emsp;&emsp;醇类化合物与其他化合物一样，其化学结构中的位阻效应会对反应带来较大的影响。在 $25\sim30^\circ{\rm C}$ 下，伯醇和异氰酸酯即可立即反应；而同样情况下，仲醇的反应速率只有伯醇的 $0.3$ 倍；叔醇的反应速率则更慢，仅有伯醇的 $0.005$ 倍。又如三苯基甲醇由于位阻效应更大，甚至于异氰酸酯不发生反应。</p>
<p>&emsp;&emsp;一般的强碱和较为缓和的碱性化合物，以及许多金属化合物都能对此反应呈现较强的催化作用，而酸性条件则能减弱反应。通常在聚氨酯泡沫塑料、弹性体、涂料等的制备中，带有多羟基的低聚物和异氰酸酯反应时，不同酸、碱催化剂的相应催化效果十分明显。此外，很多金属化合物对羟基和异氰酸酯的反应呈现较高的催化效果。根据催化活性不同，大致排列顺序如下：铋、铅、锡、三乙胺、强碱、钛、铁、锑、铀、镉、钴、铝、汞、锌、镍、二烷基胺、锶、钼、钒、铜、锰、锆等化合物及三烷基磷等。砷、硼、钙、钡等化合物对此过程不起催化作用。</p>
<ul>
<li>注：醇类化合物根据羟基（${\rm -OH}$）所连接碳原子的类型，分为伯醇、仲醇、叔醇。</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>结构简式</th>
</tr>
</thead>
<tbody><tr>
<td>伯醇</td>
<td>与羟基相连的碳原子上连有一个碳（或取代基）的醇</td>
<td>$$ {\rm R!!-!!CH2!!-!!OH} $$</td>
</tr>
<tr>
<td>仲醇</td>
<td>与羟基相连的碳原子上连有两个碳（或取代基）的醇</td>
<td>$$ {\rm R1!!-!!CH(R2)!!-!!OH} $$</td>
</tr>
<tr>
<td>叔醇</td>
<td>与羟基相连的碳原子上连有三个碳（或取代基）的醇</td>
<td>$$ {\rm R1!!-!!C(R2)(R3)!!-!!OH} $$</td>
</tr>
</tbody></table>
<h4 id="与水反应"><a href="#与水反应" class="headerlink" title="与水反应"></a>与水反应</h4><p>&emsp;&emsp;异氰酸酯与水的反应活性和它与仲醇的反应活性相当，如果水和仲醇二者同时溶于反应介质和异氰酸酯反应，二者反应活性几乎相等。然而异氰酸酯与水反应的生成物不如氨基甲酸酯那么简单，它第一步加成反应先生成不稳定的氨基甲酸，然后立即分解，放出二氧化碳，生成对应胺基化合物（式\eqref{7}）。</p>
<p>$$ {\rm RNCO + H_2O \Longrightarrow RNHCOOH \Longrightarrow RNH_2 + CO_2\uparrow} \tag{7}\label{7}$$</p>
<p>&emsp;&emsp;该胺基又进一步与异氰酸酯反应生成对应脲类化合物（式\eqref{1}），这一反应速率甚至高于式\eqref{7}。</p>
<p>$$ {\rm R’NCO + RNH_2 \Longrightarrow R’NHCONHR} $$</p>
<p>&emsp;&emsp;因此，完整的反应为 $ 2 {\rm mol}$ 异氰酸酯基团与 $ 1 {\rm mol}$ 水发生反应，生成 $ 1 {\rm mol}$ 对应脲类化合物并放出 $ 1 {\rm mol}$ 二氧化碳（式\eqref{8}）。</p>
<p>$$ {\rm 2RNCO + H_2O \Longrightarrow RNHCONHR + CO_2\uparrow} \tag{8}\label{8}$$</p>
<p>&emsp;&emsp;这个反应是聚氨酯泡沫塑料制造过程中最关键的反应之一，它能使多异氰酸酯或两个以上端基带有异氰酸酯的预聚体进行链增长或交联反应，从而形成聚合物。同时，反应中产生的二氧化碳气体也是制造泡沫塑料气孔关键。</p>
<p>&emsp;&emsp;在聚氨酯的反应体系中，水和异氰酸酯是不互溶的，因而二者反应速度极慢，一般需要合适的溶剂或乳化剂存在下充分混合才能顺利进行反应。叔胺、碱性物质及某些金属化合物对此反应都有较强的催化作用。</p>
<p>&emsp;&emsp;大多数异氰酸酯都能与水反应生成脲类化合物。然而也有例外，例如苯环上带有硝基的芳香族异氰酸酯和水反应，则仅能生成胺而不容易得到脲。其主要原因是具有足够量的带负电荷的硝基会减弱胺基的碱性。同时，在胺基的邻位上带有的硝基也会因位阻效应而降低反应速率。这样，胺基与异氰酸酯的反应活性远低于水与异氰酸酯。典型的如 $3,5-$二硝基苯异氰酸酯与水反应所得到的是胺、脲混合物。而 $2,4-$二硝基或 $2,4,6-$三硝基苯异氰酸酯和水反应仅能得到较高收率的胺，很少得到或基本没有脲。相反，在邻位上带有正电荷（如甲基）的芳香族异氰酸酯和水反应，则会加强其反应选择性，例如 $ 2 {\rm mol}$ 的甲苯二异氰酸酯（<strong>TDI</strong>）和 $1{\rm mol}$ 水反应则能得到极高收率的相应取代脲（式\eqref{9}）。</p>
<p>$$ Markdown 不支持含苯环的有机化学方程式 \tag{9}\label{9}$$</p>
<p>&emsp;&emsp;异氰酸酯和水的反应在聚氨酯化学中非常重要，这是制造二氧化碳发泡型泡沫中必不可少的步骤。同时，在储藏、运输过程中这也是需要尽量避免的副反应，必须密封贮藏，以免和水蒸气发生反应。</p>
<h4 id="与酚类反应"><a href="#与酚类反应" class="headerlink" title="与酚类反应"></a>与酚类反应</h4><p>&emsp;&emsp;酚类与脂肪族醇类相比，具有一定酸度，因而与异氰酸酯的反应活性较醇类远弱。大部分异氰酸酯与酚类的反应（式\eqref{10}）在 $50\sim75^\circ {\rm C}$ 时极为缓慢，通常需加入叔胺或其他催化剂来加速反应。</p>
<p>$$ {\rm RNCO + ArOH   \Longrightarrow RNHCOOAr} \tag{10}\label{10}$$</p>
<p>&emsp;&emsp;在苯环上带有负电荷取代基的酚类都能抑制它与异氰酸酯的反应，其主要原因是由于这些基团会减弱羟基的碱度。</p>
<ul>
<li>注：酚（phenol），结构简式为 ${\rm ArOH}$，是芳香烃环上的氢被羟基取代的一类芳香族化合物。一般使用 ${\rm Ar}$ 表示芳香基团，${\rm Ph}$ 表示苯基。</li>
</ul>
<h3 id="异氰酸酯其他重要反应"><a href="#异氰酸酯其他重要反应" class="headerlink" title="异氰酸酯其他重要反应"></a>异氰酸酯其他重要反应</h3><h4 id="二聚反应"><a href="#二聚反应" class="headerlink" title="二聚反应"></a>二聚反应</h4><p>同时芳香族异氰酸酯和不饱和化合物反应时，自身容易发生二聚反应，形成二聚体。脂肪族异氰酸酯在一般条件下不生成二聚体而生成三聚体。某些芳香族异氰酸酯如 $4,4’-$二苯甲烷二异氰酸酯，即使在无催化剂环境下，长期放置也会逐渐产生二聚体。而邻位具有取代基的大部分芳香族异氰酸酯则会阻碍自身二聚化。</p>
<p>&emsp;&emsp;二聚体在加热情况下，一般能分解为异氰酸酯单体。此外，异氰酸酯二聚体还能和活性氢化合物直接反应，二期所用催化剂与单体异氰酸酯所用催化剂基本相同。甲苯二异氰酸酯（<strong>TDI</strong>）二聚体在聚氨酯制备中常用作交联剂，在常温下贮藏稳定性远好于单体异氰酸酯，它可以和活性氢化合物在室温下混合，而在加热和催化剂存在下分解为异氰酸酯单体，进行所需反应。</p>
<p>&emsp;&emsp;另一种异氰酸酯的二分子缩合体也引起人们较大的兴趣，两个异氰酸酯基团融合为 $${\rm -N!!&#x3D;!!C!!&#x3D;!!N-}$$ 基团，它是以 $2,4,6-$三（二乙基胺基）对称三嗪等为催化剂，缩合后放出二氧化碳，生成碳化二亚胺的反应。以苯基异氰酸酯为例，收率可达 $90 %$ 左右。</p>
<p>$$ {\rm 2Ar!!-!!NCO \underset{催化剂}{\overset{&gt;40^\circ C}\Longrightarrow} Ar!!-!!N!!&#x3D;!!C!!&#x3D;!!N!!-!!Ar + CO_2\uparrow}$$</p>
<p>&emsp;&emsp;利用这个反应，可将常温下为固态的二苯基甲烷二异氰酸酯（<strong>MDI</strong>）制成含有碳化二亚胺的液态 <strong>MDI</strong>。由液态 <strong>MDI</strong> 制得的聚氨酯制品具有良好的耐焰性和低发烟密度，他可作为整皮模塑泡沫塑料的多异氰酸酯原料。</p>
<p>$$ {\rm n OCN-Ar-CH_2-Ar-NCO \underset{催化剂}{\overset{300^\circ C, 45 min}\Longrightarrow} \lbrack!!!-!N!&#x3D;!C!&#x3D;!N!-!Ar!-!CH_2!-!Ar!-!!!\rbrack_n}$$</p>
<p>&emsp;&emsp;碳化二亚胺还能抑制聚酯的湿老化，提高聚氨酯的耐水性，因此根据需要，可以在聚氨酯分子中引入碳化二亚胺链节，作为结构型的改性手段。</p>
<h4 id="三聚反应"><a href="#三聚反应" class="headerlink" title="三聚反应"></a>三聚反应</h4><p>&emsp;&emsp;脂肪族与芳香族异氰酸酯在适当条件下都能形成三聚体，得到的是含有异氰脲酸酯环的衍生物。这类反应是异氰酸酯和不饱和化合物加成反应的另一特例。生成的异氰脲酸酯杂环很稳定，在 $150\sim200^\circ{\rm C}$ 下不分解。和其他反应一样，位阻效应对三聚反应也有较大影响，如叔丁基异氰酸酯就不易发生三聚反应，芳香族异氰酸酯在邻位基团上有取代基时也不易发生三聚反应。</p>
<h4 id="与羧基反应"><a href="#与羧基反应" class="headerlink" title="与羧基反应"></a>与羧基反应</h4><p>&emsp;&emsp;羧基（${\rm -COOH}$）中也具有 ${\rm -OH}$ 基，因而也能与异氰酸酯反应，其反应能力根据酸度不同而不同，一般而言，它的反应活性低于伯醇、水。</p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>&emsp;&emsp;异氰酸酯除与 ${\rm -NH}$ 基、${\rm -OH}$ 基发生反应外，还将与带有活性氢的硫基（${\rm -SH}$）化合物发生反应，与羟基过程类似，只是反应活性较弱。</p>
<p>&emsp;&emsp;异氰酸酯是一类反应性极高的化合物，这是由他本身的化学结构决定的，它具有较多的不饱和基团 $ {\rm -N&#x3D;C&#x3D;O} $，除能和许多化合物进行加成反应外，还可本身加热或在催化剂作用下发生自聚及脱碳（存疑）等反应：</p>
<p>$$ {\rm RNCO + R’NH_2 \Longrightarrow RNHCONHR’}$$<br>$$ {\rm RNCO + R’OH   \Longrightarrow RNHCOOR’}$$<br>$$ {\rm RNCO + ArOH   \Longrightarrow RNHCOOAr}$$<br>$$ {\rm 2RNCO + HOH   \Longrightarrow RNHCONHR + CO_2}$$<br>$$ {\rm RNCO + R’SH   \Longrightarrow RNHCOSR’} $$<br>$$ {\rm RNCO + R’COOH \Longrightarrow RNHCOR’ + CO_2} $$<br>$$ {\rm \qquad\qquad\qquad\qquad\qquad\qquad\qquad\ or \Longrightarrow RNHCONHR + \lgroup R’CO\rgroup_2O + CO_2} $$<br>$$ {\rm RNCO + HCN \Longrightarrow RNHCOCN} $$<br>$$ {\rm RNCO + NH_2OH \Longrightarrow RNHCONHOH} $$<br>$$ {\rm RNCO + NH_3 \Longrightarrow RNHCONH_2} $$<br>$$ {\rm RNCO + CH_2(CN)COOR’ \Longrightarrow RNHCOCH(CN)COOR’} $$<br>$$ {\rm RNCO + R’CH_2NO_2 \Longrightarrow RNHCOCHR’NO_2} $$</p>
<p>&emsp;&emsp;异氰酸酯自聚及其他反应：</p>
<p>$$　{\rm RNCO + ArNO \Longrightarrow RN!!&#x3D;!!OAr + NO_2} $$<br>$$ {\rm RNCO + ArCHO \Longrightarrow RN!!&#x3D;!!CHAr + CO_2} $$<br>$$ {\rm RNCO + Ar_2CS \Longrightarrow RN!!&#x3D;!!CAr_2 + COS} $$<br>$$ {\rm 2RNCO \overset{\bigtriangleup}\Longrightarrow RN!!&#x3D;!!C!!&#x3D;!!NR + CO_2} $$</p>
<h2 id="聚氨酯泡沫塑料的合成原理"><a href="#聚氨酯泡沫塑料的合成原理" class="headerlink" title="聚氨酯泡沫塑料的合成原理"></a>聚氨酯泡沫塑料的合成原理</h2><h3 id="基本反应"><a href="#基本反应" class="headerlink" title="基本反应"></a>基本反应</h3><p>在聚氨酯泡沫塑料的成型过程中，主要的反应如下：</p>
<ul>
<li>异氰酸酯与羟基反应  多异氰酸酯与多元醇反应生成聚氨酯：</li>
</ul>
<p>$$ {\rm nOCN!!-!!R!!-!!NCO + nHO!!-!!R’!!-!!OH \Longrightarrow \lbrack!!-!!\overset{O} {\overset{\Vert} C}NH!!-!!R!!-!!NH!!-\overset{O} {\overset{\Vert} C}!!-!!O!!-!!R’!!-!!O!!-!!\rbrack_n}$$</p>
<ul>
<li>异氰酸酯与谁反应  带有异氰酸酯基团的化合物和水反应，先生成不稳定的氨基甲酸，而后分解为胺与二氧化碳：</li>
</ul>
<p>$$ {\rm RNCO + H_2O \Longrightarrow RNHCOOH \Longrightarrow RNH_2 + CO_2\uparrow}$$</p>
<p>而后，胺基进一步和异氰酸酯基团反应生成含脲基的聚合物：</p>
<p>$$ {\rm R-NCO + R’-NH_2 \Longrightarrow R-\overset{H} {\overset{\vert} N}- \overset{O} {\overset{\Vert} C} - \overset{H} {\overset{\vert} N} - R’}$$</p>
<p>上述两项反应都属链增长反应，后者还生成二氧化碳。通常在无催化剂情况下，异氰酸酯与胺基反应速率很快，所以在反应中不但使过量的水</p>
<h3 id="硬质聚氨酯泡沫成型工艺"><a href="#硬质聚氨酯泡沫成型工艺" class="headerlink" title="硬质聚氨酯泡沫成型工艺"></a>硬质聚氨酯泡沫成型工艺</h3><h4 id="模塑发泡"><a href="#模塑发泡" class="headerlink" title="模塑发泡"></a>模塑发泡</h4><p>&emsp;&emsp;模塑发泡是通过手工配料然后在一定容积的模具中封闭发泡的一种成型工艺。通过这种工艺可以对制品的形状和密度进行控制。首先将聚醚与匀泡剂、催化剂和发泡剂等助剂按配比均匀混合（白料），然后将按配比称取的 <strong>PAPI</strong>（黑料）加入聚醚与助剂的混合物中，高速搅拌后将混合均匀的物料倒入模具中发泡，发泡完成并冷却一段时间后在 $100^\circ{\rm C}$ 烘箱中熟化 $$4\ {\rm h}$$。聚醚组分和 PAPI 组分的温度调节为 $24^\circ{\rm C}$，模具温度调节为 $42^\circ{\rm C}$。</p>
<h4 id="自由发泡"><a href="#自由发泡" class="headerlink" title="自由发泡"></a>自由发泡</h4><p>&emsp;&emsp;自由发泡是发泡过程在开放容器中完成的一种合成工艺。制品的密度由发泡剂的用量和反应条件决定。与模塑发泡的配料过程相似，首先将聚醚与匀泡剂、催化剂和发泡剂等助剂按配比在一次性纸杯中混合均匀，再将按配比称取的 <strong>PAPI</strong> 加入纸杯，用搅拌器搅拌 $$1\ {\rm min}$$，发泡过程在纸杯中进行，经充分反应待泡沫自然冷却后制备即告完成。环境温度为室温 $28\sim 31^\circ{\rm C}$。</p>
<h3 id="助剂"><a href="#助剂" class="headerlink" title="助剂"></a>助剂</h3><h4 id="匀泡剂"><a href="#匀泡剂" class="headerlink" title="匀泡剂"></a>匀泡剂</h4><p>&emsp;&emsp;匀泡剂一般是硅表面活性剂（silicone surfactant，或称为硅油），用于稳定液体泡沫，是聚氨酯泡沫合成中的关键因素。匀泡剂对水在体系中的溶解度没有影响，但是当水的用量大于其在体系中的溶解度时，匀泡剂可以显著改善水的分散。另外，匀泡剂的种类和浓度对体系中的各种化学反应动力学没有影响。</p>
<p>&emsp;&emsp;匀泡剂最重要的特性是能够降低制备过程中体系的表面张力，表面张力在泡孔结构的形成过程中占有重要地位。它有利于稳定气泡，使小气泡更稳定的存在，并且还可以改善水或其它发泡剂在体系中的分散，因此匀泡剂的使用有利于降低的孔径及分布。不同种类和用量的匀泡剂对降低表面张力和分散发泡剂所起的作用是不完全相同的，因此将导致不同的泡沫塑料孔径和孔径分布。</p>
<p>&emsp;&emsp;对于所有三种匀泡剂，当用量低于份时，孔径随匀泡剂用量的增大而快速下降；当用量高于份时，孔径随匀泡剂用量的增加不再发生明显变化，维持在一个较低的孔径水平上。三种匀泡剂对孔径的影响规律大体上相同，但是也有一些不同特点硅油降低孔径的能力强于另外两种匀泡剂硅油 JSY1020 的用量在多于份以后孔径有明显增大的趋势，另外两种匀泡剂在此范围基本没有引起孔径的增大。</p>
<p>&emsp;&emsp;当匀泡剂在较低和中间用量范围时，随着匀泡剂用量的增加，发泡过程中的液体泡沫体系表面张力降低，有利于小气泡的稳定存在，并减少泡孔间的合并行为，使得整体泡沫的孔径得到降低。当匀泡剂用量增加到一定程度，体系中的匀泡剂浓度增加到足以使匀泡剂覆盖所有气一液介面，表面张力降到最低而当匀泡剂用量较高时，的整体孔径增大，并且呈现如图所示的局部泡孔粗大深色区域、局部泡孔细密浅色区域的现象。原因是匀泡剂用量大于其在聚醚组分中的溶解度而发生聚集，在发泡过程中不能快速移动到气一液界面，从而不能有效稳定气泡，造成较大泡孔的出现，甚至引起泡沫的塌陷。</p>
<p>&emsp;&emsp;匀泡剂的用量还与的闭开孔率有关,表所列为组样品的闭孔率测试结果,该组采用三乙醇胺作为催化剂,在一份范围内变化匀泡剂的用量制备。由表中的数据可以发现,组样品整体的闭孔率较低,并随匀泡剂用量的增加而提高。</p>
]]></content>
  </entry>
  <entry>
    <title>数字体图像相关（Digital Volume Correlation, DVC）技术</title>
    <url>/archive/Exp006-DVC.html</url>
    <content><![CDATA[<p>&lt;img src&#x3D;”&#x2F;Exp009_image001.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”Digital Volume Correlation&emsp;&emsp;Author: Hai-Wei Chai,  International Journal of Plasticity 102730 (2020).”&gt;</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;高分辨率计算机层析成像技术的发展使获得目标微尺度三维图像成为可能。在目标变形过程的不同时刻拍摄其三维图像，即可使用数字体图像相关（Digital Volume Correlation, DVC）技术[1]测算其位移场及应变场。DVC比较变形前后图像各子区，找到匹配特征进而得到位移场。应变场通常通过计算位移场的梯度得到。要估计位移场，通常需将图像分为许多（可重叠）子区，对于每个子区，在下一时刻图像中寻找一个匹配子集以最小化其差异性或最大化其相关性。所产生的应变场的准确性（mean error）和精确性（standard deviation）很大程度上取决于算法设计与参数选择，如子区尺寸[11]等。</p>
<p>&emsp;&emsp;DVC 技术是数字图像相关（Digital Image Correlation, DIC）技术[2]的三维扩展，然而与DIC技术相比，DVC技术的应用场景对其算法设计工作提出了更加严峻的考验。无论是光学成像或是X射线透射成像，平面图像的采集都非常便捷、快速，而对目标进行三维形貌表征往往需要耗费大量时间，这就导致DIC技术的输入图像序列往往拍摄时间间隔较短，相应的相邻两幅图像间变形幅度较小；而DVC技术的输入体图像序列往往拍摄间隔很大，相邻两幅体图像间变形幅度较大，一定程度上提高了目标追踪的难度。基于同步辐射的动态CT技术允许在亚秒级的时间间隔内连续采集CT图像，能够密切观测目标三维结构演化过程。但与这种表征技术相结合的原位加载手段目前仍然十分有限，且受限于高速相机内存空间往往较小与CT图像极大的存储容量需求间的矛盾，这种技术手段的时间分辨率与连续扫描的时间跨度往往不可兼得，存在一定局限性。面对来自应用场景的挑战，DVC技术仍然存在几个方面有待研究和改进。</p>
<p>&emsp;&emsp;DVC可以应用于任何 micro-CT 图像中提供了足够细节的结构非均匀样品，例如金属[3,4]、木材[5,6]、沙砾[7,8]、骨骼[9,10]等。然而结构精细程度较低的图像是对DVC技术的挑战。骨小梁就是一个典型的例子，它是一种低密度海绵状骨，由于其存在大量极纤细的网状结构，难以对其微细观结构进行精细CT表征[9]，进而DVC技术难以准确追踪并测算其位移场。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://link.springer.com/article/10.1007/BF02323555"><font size = 2px>[1]&nbsp;&nbsp;Bay, B.K. , Smith, T.S. , Fyhrie, D.P. , Saad, M. , 1999. Digital volume correlation: three-dimensional strain mapping using x-ray tomography. Exp. Mech. 39 (3), 217–226.</font></a><br><a href="https://iopscience.iop.org/article/10.1088/0957-0233/20/6/062001/meta"><font size = 2px>[2]&nbsp;&nbsp;Pan, B. , Qian, K. , Xie, H. , Asundi, A. , 2009. Two-dimensional digital image correlation for in-plane displacement and strain measurement: a review. Meas. Sci. Technol. 20 (6), 062001.</font></a><br><a href="https://hal.archives-ouvertes.fr/hal-00848721/document"><font size = 2px>[3]&nbsp;&nbsp;Leclerc, H. , Périé, J.-N. , Hild, F. , Roux, S. , 2012. Digital volume correlation: what are the limits to the spatial resolution? Mech. Ind. 13 (6), 361–371.</font></a><br><a href="https://hal.archives-ouvertes.fr/hal-00848726/file/EXME2013a-ccsd.pdf"><font size = 2px>[4]&nbsp;&nbsp;Morgeneyer, T.F. , Helfen, L. , Mubarak, H. , Hild, F. ,2013. 3D digital volume correla- tion of synchrotron radiation laminography images of ductile crack initiation: an initial feasibility study. Exp. Mech. 53 (4), 543–556.</font></a><br><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-1305.2009.00687.x"><font size = 2px>[5]&nbsp;&nbsp;Forsberg, F. , Sjödahl, M. , Mooser, R. , Hack, E. , Wyss, P. , 2010. Full three-dimensional strain measurements on wood exposed to three-point bending: analysis by use of digital volume correlation applied to synchrotron radiation micro-computed tomography image data. Strain 46 (1), 47–60.</font></a><br><a href="https://link.springer.com/article/10.1007/s10853-012-7100-0"><font size = 2px>[6]&nbsp;&nbsp;Tran, H. , Doumalin, P. , Delisee, C. , Dupre, J.C. , Malvestio, J. , Germaneau, A. , 2013. J. Mater. Sci. 48 (8), 3198–3212.</font></a><br><a href="https://reader.elsevier.com/reader/sd/pii/S0038080613000188?token=360410C7A02B3A281C1F7BF303D28F9DEAA92F606202A37921F16CE0709416B87EA4BFAA169E10C130FE0700ACA1C005"><font size = 2px>[7]&nbsp;&nbsp;Higo, Y. , Oka, F. , Sato, T. , Matsushima, Y. , Kimoto, S. , 2013. Investigation of local- ized deformation in partially saturated sand under triaxial compression using microfocus x-ray ct with digital image correlation. Soils Found. 53 (2), 181–198.</font></a><br><a href="https://link.springer.com/article/10.1007%2Fs11340-014-9915-x"><font size = 2px>[8]&nbsp;&nbsp;Hu, Z. , Du, Y. , Luo, H. , Zhong, B. , Lu, H. , 2014. Internal deformation measurement and force chain characterization of mason sand under confined compression using incremental digital volume correlation. Exp. Mech. 54 (9), 1575–1586.</font></a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S1751616113003159"><font size = 2px>[9]&nbsp;&nbsp;Gillard, F. , Boardman, R. , Mavrogordato, M. , Hollis, D. , Sinclair, I. , Pierron, F. , Browne, M. , 2014. The application of digital volume correlation (DVC) to study the microstructural behaviour of trabecular bone during compression. J. Mech. Behav. Biomed. Mater. 29, 4 80–4 99.</font></a><br><a href="https://www.sciencedirect.com/science/article/abs/pii/S0021929014000037"><font size = 2px>[10]&nbsp;&nbsp;Roberts, B.C. , Perilli, E. , Reynolds, K.J. , 2014. Application of the digital volume corre- lation technique for the measurement of displacement and strain fields in bone: a literature review. J. Biomech. 47 (5), 923–934.</font></a><br><a href="http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC2613834&blobtype=pdf"><font size = 2px>[11]&nbsp;&nbsp;Liu, L. , Morgan, E.F. , 2007. Accuracy and precision of digital volume correlation in quantifying displacements and strains in trabecular bone. J. Biomech. 40 (15), 3516–3520.</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a><br><a href=""><font size = 2px>[1]&nbsp;&nbsp;</font></a></p>
]]></content>
  </entry>
  <entry>
    <title>Non Local Means 图像降噪算法</title>
    <url>/archive/Exp007-NLM.html</url>
    <content><![CDATA[<p>Antoni Buades 提出指标 method noise 对数字图像降噪方法的性能进行了评价和比较。他首先针对几个被广泛使用的降噪算法计算并分析了降噪性能。同时，基于图像中所有像素的非局部平均，提出了全新的数字图像降噪算法 Non Local means Algorithm，并通过实验比较了新算法与常用的平滑滤波方法的性能。</p>
<span id="more"></span>

<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> data, img_as_float</span><br><span class="line"><span class="keyword">from</span> skimage.restoration <span class="keyword">import</span> denoise_nl_means, estimate_sigma</span><br><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"><span class="keyword">from</span> skimage.util <span class="keyword">import</span> random_noise</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">astro = img_as_float(data.astronaut())</span><br><span class="line">astro = astro[<span class="number">30</span>:<span class="number">180</span>, <span class="number">150</span>:<span class="number">300</span>]</span><br><span class="line"></span><br><span class="line">sigma = <span class="number">0.08</span></span><br><span class="line">noisy = random_noise(astro, var=sigma**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># estimate the noise standard deviation from the noisy image</span></span><br><span class="line">sigma_est = np.mean(estimate_sigma(noisy, channel_axis=-<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;estimated noise standard deviation = <span class="subst">&#123;sigma_est&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">patch_kw = <span class="built_in">dict</span>(patch_size=<span class="number">5</span>,      <span class="comment"># 5x5 patches</span></span><br><span class="line">                patch_distance=<span class="number">6</span>,  <span class="comment"># 13x13 search area</span></span><br><span class="line">                channel_axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm</span></span><br><span class="line">denoise = denoise_nl_means(noisy, h=<span class="number">1.15</span> * sigma_est, fast_mode=<span class="literal">False</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slow algorithm, sigma provided</span></span><br><span class="line">denoise2 = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">False</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm</span></span><br><span class="line">denoise_fast = denoise_nl_means(noisy, h=<span class="number">0.8</span> * sigma_est, fast_mode=<span class="literal">True</span>,**patch_kw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast algorithm, sigma provided</span></span><br><span class="line">denoise2_fast = denoise_nl_means(noisy, h=<span class="number">0.6</span> * sigma_est, sigma=sigma_est,fast_mode=<span class="literal">True</span>, **patch_kw)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">3</span>, figsize=(<span class="number">8</span>, <span class="number">6</span>),sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].imshow(noisy)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;noisy&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].imshow(denoise)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(slow)&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].imshow(denoise2)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">0</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(slow, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].imshow(astro)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">0</span>].set_title(<span class="string">&#x27;original\n(noise free)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].imshow(denoise_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">1</span>].set_title(<span class="string">&#x27;non-local means\n(fast)&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].imshow(denoise2_fast)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">ax[<span class="number">1</span>, <span class="number">2</span>].set_title(<span class="string">&#x27;non-local means\n(fast, using $\\sigma_&#123;est&#125;$)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print PSNR metric for each case</span></span><br><span class="line">psnr_noisy = peak_signal_noise_ratio(astro, noisy)</span><br><span class="line">psnr = peak_signal_noise_ratio(astro, denoise)</span><br><span class="line">psnr2 = peak_signal_noise_ratio(astro, denoise2)</span><br><span class="line">psnr_fast = peak_signal_noise_ratio(astro, denoise_fast)</span><br><span class="line">psnr2_fast = peak_signal_noise_ratio(astro, denoise2_fast)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (noisy) = <span class="subst">&#123;psnr_noisy:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow) = <span class="subst">&#123;psnr:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (slow, using sigma) = <span class="subst">&#123;psnr2:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast) = <span class="subst">&#123;psnr_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;PSNR (fast, using sigma) = <span class="subst">&#123;psnr2_fast:<span class="number">0.2</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="数字图像噪声"><a href="#数字图像噪声" class="headerlink" title="数字图像噪声"></a>数字图像噪声</h3><p>&emsp;&emsp;数字图像的两个主要限制是模糊及噪声（blur &amp; noise）。模糊是图像采集系统的固有性质，同时数字图像对连续信号离散采样的形式必须遵循 Shannon-Nyquist 采样定律。另一种主要的干扰形式是噪声。数字图像中每个像素点的值 $u(i)$ 都是对局部光强测量的结果，通常通过 CCD 及光学聚焦元件实现。CCD 中每个方形探测单元（captor）都将记录曝光时间内探测区域的入射光子数。在光源强度恒定的情况下，每个探测单元每个曝光周期内采集的光子数的概率分布将遵循中心极限定理，在光强均值周围震荡。另外，如果 CCD 没有经过充分冷却就会接收热光子（heat spurious photons），由此产生的扰动通常称为 obscurity noise。</p>
<p>&emsp;&emsp;数字图像降噪方法的目标是从观测到的噪声图像中还原出原始信号，</p>
<p>$$ v(i)&#x3D;u(i)+n(i), \tag{1}\label{1}$$</p>
<p>其中 $v(i)$ 为实测图像，$u(i)$ 为原始信号，$n(i)$ 则是噪声信号。评估图像中噪声水平通常采用信噪比（signal noise ratio (SNR)）：</p>
<p>$$ SNR &#x3D; \frac{\sigma(u)}{\sigma(n)}, \tag{2}\label{2}$$</p>
<p>其中，$\sigma(n)$为噪声信号标准差，$\sigma(u)$表示真实信号的经验标准差，</p>
<p>$$ \sigma(u) &#x3D; \sqrt{\frac{1}{|I|}\sum_i(u(i)- \overline{u} )^2}, \tag{3}\label{3}$$</p>
<p>$ \overline{u}&#x3D;\frac{1}{|I|}\sum_{i\in I} u(i)$ 为图像的平均灰度值，$|I|$指全图像素数。当噪声模型和参数已知时，噪声的标准差也可以用经验测量法或形式化方法得到。</p>
<p>&emsp;&emsp;迄今为止，图像处理领域已经提出了诸多抑制噪声、还原真实信号的算法。即便它们通常拥有截然不同的数学形式，但都拥有一个共性：平均。这种平均可以在局部进行：高斯滤波器(<a href="https://freddy.cs.technion.ac.il/wp-content/uploads/2018/01/on-gabors-contribution-to-image-enhancement.pdf">Gabor 1994</a>)，各向异性滤波(<a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona-Malik 1990</a>, <a href="https://accedacris.ulpgc.es/bitstream/10553/52821/1/image_selective_smoothing_edge.pdf">Alvarez et al. 1992</a>)，邻域滤波器(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.554.5808&rep=rep1&type=pdf">Smith et al. 1997</a>)；也可以通过计算variations实现：TV滤波(<a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin-Osher-Fatemi 1992</a>)；或是在频域进行：经验维纳滤波(<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky 1985</a>)，小波阈值方法(<a href="https://pdfs.semanticscholar.org/78a5/90a8ac92f02fb48e4e488b6eb00dc7b931eb.pdf">Coiffman-Donoho 1995</a>)。</p>
<h3 id="Method-noise"><a href="#Method-noise" class="headerlink" title="Method noise"></a>Method noise</h3><p>&emsp;&emsp;不妨令 $u$ 表示实测图像，$D_hu$ 表示降噪方法的输出结果，$h$ 为滤波参数。Antoni Buades 定义 method noise 为降噪前后图像之差：</p>
<p>$$ u-D_hu. \tag{4}\label{4}$$</p>
<p>&emsp;&emsp;完美的降噪算法在应用中不应该改变无噪声图像。因此，当图像具有某种规律性时，method noise 理应很小。对理想的降噪算法，Method noise 必须看起来与随机噪声无异，几乎不包含原始信号的结构。因为即便是质量非常高的实测图像，噪声也是不可避免的，计算 method noise 对评估任何降噪算法都是有意义的，而非传统的“添加噪声，再去除噪声”的把戏。</p>
<h2 id="局部平均算法"><a href="#局部平均算法" class="headerlink" title="局部平均算法"></a>局部平均算法</h2><h3 id="高斯滤波-Gaussian-Filtering"><a href="#高斯滤波-Gaussian-Filtering" class="headerlink" title="高斯滤波 (Gaussian Filtering)"></a>高斯滤波 (Gaussian Filtering)</h3><p>&emsp;&emsp;对数字图像进行各向同性过滤，本质上可以归结为图像与各向同性核的卷积。采用数值呈现出高斯分布的卷积核，既是高斯滤波，是图像处理中最常用的操作之一。通俗的讲，高斯滤波就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到（所有的局部平滑滤波方法都是如此）。高斯卷积核：</p>
<p>$$G_h(x)&#x3D;\frac{1}{4\pi h^2}e^{-\frac{|x|^2}{4h^2}}. \tag{5}\label{5}$$</p>
<p><strong>Theorem 1 (Babor 1960):</strong> 当高斯卷积核的特征尺寸 $h$ 极小时，高斯滤波的 method noise 为：</p>
<p>$$ u-G_h* u&#x3D;-h^2\Delta u+o(h^2). \tag{6}\label{6}$$</p>
<p>&emsp;&emsp;高斯滤波的 method noise 在图像谐波部分几乎为零，而在边缘、纹理区域非常大。因此，高斯滤波在图像的平坦区域相对表现优秀，但在边缘、纹理区域较为模糊（blurred）。</p>
<h3 id="各向异性滤波（Anisotropic-Filtering-AF）"><a href="#各向异性滤波（Anisotropic-Filtering-AF）" class="headerlink" title="各向异性滤波（Anisotropic Filtering, AF）"></a>各向异性滤波（Anisotropic Filtering, AF）</h3><p>&emsp;&emsp;各向异性滤波提出之初旨在解决高斯滤波在边缘及纹理区域的模糊问题。该算法通过只在 $Du(\vec x)$ 正交方向上计算图像 $u$ 在 $\vec x$ 处的卷积。这种想法可以追溯到 <a href="https://authors.library.caltech.edu/6498/1/PERieeetpami90.pdf">Perona &amp; Malik</a>。各向异性滤波算法的定义为：</p>
<p>$$ AF_hu(\vec x)&#x3D;\int G_h(t)u(\vec x+t\frac{Du(\vec x)^\perp}{|Du(\vec x)|})dt, \tag{7}\label{7}$$</p>
<p>在 $\vec x$ 处，当 $Du(\vec x)\neq0$ 时成立。$(x,y)^\perp&#x3D;(-y,x)$，且 $G_h$ 代指方差 $h^2$ 的一维高斯函数。假设原始图像 $u$ 在 $\vec x$ 处二次连续可微（twice continuously differentiable ($C^2$)）,将式\eqref{5}二次泰勒展开（second order Taylor expansion）可以推导出：</p>
<p><strong>Theorem 2:</strong> 当 $Du(\vec x)\neq0$ 时，各向异性滤波 $AF_h$ 的 method noise 为：</p>
<p>$$ u(\vec x)-AF_hu(\vec x)&#x3D;-\frac{1}{2}h^2|Du|curv(u)(\vec x)+o(h^2), \tag{8}\label{8}$$</p>
<p>$curv(u)(\vec x)$ 指局部曲率（<font color=Green>此处存疑</font>），即经过 $\vec x$ 点的水平直线上曲率半径的逆（signed inverse）。在图像 $u$ 中局部几乎为一条直线的区域，method noise 几乎为零，而在弯曲的边缘或纹理区域较大。因而，各向异性滤波对直边区域得以保持，而平坦、纹理区域图像精度有所退化。</p>
<h3 id="TV滤波（Total-Variation-Minimization）"><a href="#TV滤波（Total-Variation-Minimization）" class="headerlink" title="TV滤波（Total Variation Minimization）"></a>TV滤波（Total Variation Minimization）</h3><p>&emsp;&emsp;全变分图像去噪算法最早由 <a href="https://www-pequan.lip6.fr/~bereziat/cours/master/vision/papers/rudin92.pdf">Rudin, Osher and Fatemi</a>提出。给定一幅实测图像 $v(\vec x)$，该算法将恢复原始信号 $u(\vec x)$ 的问题转化为式\eqref{7}的最小化问题：</p>
<p>$$TVF_\lambda(v)&#x3D;{\rm arg},\underset{u}{\rm \mathop {min}},TV(u)+\lambda\int|v(\vec x)-u(\vec x)|^2d\vec x, \tag{9}\label{9}$$</p>
<p>其中 $TV(u)$ 为图像 $u$ 的全变分，$\lambda$ 为给定的拉格朗日乘子（Lagrange multiplier）。上述最小化问题的最小值存在且唯一。参数 $\lambda$ 与噪声的统计信息相关，并控制了滤波程度。</p>
<p><strong>Theorem 3:</strong> TV滤波的 method noise 为：</p>
<p>$$ u(\vec x)-TVF_\lambda(u)(\vec x)&#x3D;-\frac{1}{2\lambda}curv(TVF_\lambda(u))(\vec x). \tag{10}\label{10}$$</p>
<p>&emsp;&emsp;在各向异性的情况下，直边由于曲率小而得以保持。但 $\lambda$ 过小时细节及纹理会被过度平滑。</p>
<h3 id="邻域滤波（Neighborhood-Filtering）"><a href="#邻域滤波（Neighborhood-Filtering）" class="headerlink" title="邻域滤波（Neighborhood Filtering）"></a>邻域滤波（Neighborhood Filtering）</h3><p>&emsp;&emsp;我们称邻域滤波为将临近区域内具有相似灰度值的像素取平均以期恢复原始信号的滤波器。<a href="https://books.google.com/books?hl=en&lr=&id=zHPpCAAAQBAJ&oi=fnd&pg=PA2&dq=L.+Yaroslavsky.+Digital+Picture+Processing+-+An+Introduction.+Springer+Verlag,+1985.&ots=kNXsihR5hI&sig=1FSo9cLMzy_GZNZpIwTaGM_nGBw#v=onepage&q&f=false">Yaroslavsky(1985)</a>首次提出的方法通过计算空间邻域 $B_\rho(\vec x)$ 内具有相似灰度值像素的平均来恢复信号：</p>
<p>$$ YNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{B_\rho (\vec x)} u(\vec y)e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{11}\label{11}$$</p>
<p>其中，$\vec x\in\Omega$，$C(\vec x)&#x3D;\int_{B_\rho(\vec x)} e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$h$ 为滤波参数。</p>
<p>&emsp;&emsp;较晚提出的邻域滤波算法相较 Yaroslavsky 滤波要更广为人知一些，既 SUSAN 滤波（1995）及双边滤波（1998）。这些滤波算法都引入到参考像素 $\vec x$ 的距离作为权重因子，而非单纯的考虑一个固定范围的邻域，</p>
<p>$$SNF_{h,\rho}u(\vec x)&#x3D;\frac{1}{C(\vec x)}\int_{\Omega} u(\vec y)e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y, \tag{12}\label{12}$$</p>
<p>这里 $C(\vec x)&#x3D;\int_{\Omega}e^{-\frac{|y-x|^2}{\rho^2}}e^{-\frac{|u(\vec y)-u(\vec x)|^2}{h^2}}d\vec y$ 为归一化常量，$\rho$ 为空间滤波参数（spatial filtering parameter）。事实上，$YNF_{h,\rho}$ 与 $SNF_{h,\rho}$ 之间并没有本质区别（<font color=Green>此处存疑</font>）。如果两个区域的灰度值差异大于 $h$，这些算法都将计算来自于同一区域的像素灰度平均值来恢复参考点的原始信号。因而该算法不会模糊边界区域，这是正是该类算法最核心的用途。</p>
<p>&emsp;&emsp;然而这类算法的问题是，只将单个像素作为参考点，而如若该参考像素恰好被噪声干扰严重，滤波效果将不够鲁棒（robust）。同时，邻域滤波器也会制造人为干扰（artificial shocks），这将会在它的 method noise 中展示出来。</p>
<h2 id="非局部平均算法（Non-Local-Means-Algorithm）"><a href="#非局部平均算法（Non-Local-Means-Algorithm）" class="headerlink" title="非局部平均算法（Non Local Means Algorithm）"></a>非局部平均算法（Non Local Means Algorithm）</h2><p>&emsp;&emsp;Antoni Buades 于 2005 年提出非局部平均数字图像降噪算法（Non Local Algorithm）。给定一幅实测图像 $v&#x3D;\lbrace v(i)|i\in I\rbrace $，像素 $i$ 处的估计值 $NL[v](i)$ 是该图像上所有像素点的加权平均值，</p>
<p>$$ NL<a href="i">v</a>&#x3D;\sum_{j\in I}\omega(i,j)v(j), \tag{13}\label{13}$$</p>
<p>这里的权重系数 $\lbrace\omega (i,j)\rbrace_j$ 取决于像素 $i$ 与 $j$ 之间的相似程度，且始终满足如下标准： $0\leq\omega(i,j)\leq 1$ 且 $\sum_{j} \omega(i,j)&#x3D;1$（等价于上文介绍的滤波算法中归一化常量）。</p>
<p>&emsp;&emsp;俩个像素 $(i,j)$ 之间的相似程度取决于邻域灰度矩阵 $v(N_i)$ 及 $v(N_j)$（intensity gray level vectors），这里 $N_k$ 指以像素 $k$ 为中心，给定尺寸的方形邻域。这种相似性被定义为加权欧式距离的递减函数，$\parallel v(N_i)-v(N_j)\parallel_{2,a}^2$，其中 $a&gt;0$ 是高斯卷积核的标准差。欧式距离对噪声邻域的应用引入了如下等式：</p>
<p>$$ E\parallel v(N_i)-v(N_j)\parallel_{2,a}^2 &#x3D; \parallel u(N_i)-u(N_j) \parallel_{2,a}^2+2\sigma^2. \tag{14}\label{14}$$</p>
<p>&emsp;&emsp;这个等式证明了该算法的鲁棒性（robustness）。因为含噪声的实测图像 $v$ 的欧式距离期望恰恰遵循真正的原始信号之间的相似性。</p>
<p>&emsp;&emsp;与 $v(N_i)$ 具有相似灰度邻域的像素在计算平均时的权重因子更大，</p>
<p>$$ \omega(i,j)&#x3D;\frac{1}{Z(i)}e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{15}\label{15}$$</p>
<p>这里，$Z(i)$ 为归一化常量，</p>
<p>$$ Z(i) &#x3D; \sum_j e^{-\cfrac{\parallel v(N_i)-v(N_j) \parallel_{2,a}^2}{h^2}}, \tag{16}\label{16}$$</p>
<p>参数 $h$ 控制滤波程度，它直接影响了指数函数的衰减趋势，进而控制欧式距离对权重因子衰减速度的影响。</p>
<p>&emsp;&emsp;NL-means 算法不仅仅考虑单个像素的灰度值，而是考虑该像素整个邻域的几何构型，这正是 NL-means 算法比邻域滤波更鲁棒的原因。图$(1)$ 也说明了这个问题，像素 $q3$ 与 $p$ 具有完全一致的灰度值，而邻域的几何构型完全不同，导致 NL-means 中的权重因子 $\omega(p,q3)$ 几乎为零。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image001.jpg” width &#x3D; 30% div align&#x3D;center &#x2F; title&#x3D;”图1.  NL-means 算法方案。相似的像素邻域将提供更大的权重，如 $\omega(p,q1), \omega(p,q2)$，而不相似的邻域提供的权重几乎为零，如 $\omega(p,q3)$。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;NL-means 算法最终的数学形式：</p>
<p>$$ NL<a href="x">v</a>&#x3D;\frac{1}{C(x)} \int_{\Omega} e^{-\cfrac{(G_a * |v(x+.)-v(y+.)|^2)(0)}{h^2}}v(y)dy, \tag{17}\label{17}$$</p>
<p>$x\in\Omega$，$C(x)&#x3D;\int_{\Omega} {\rm exp}\lbrack -\frac{(G_a* |u(x+.)-u(z+.)|^2)(0)}{h^2}\rbrack dz$ 为归一化常量，$G_a$ 为高斯核，$h$ 控制过滤程度。</p>
<p>&emsp;&emsp;NL-means 算法的中心思想是：像素 $x$ 处的信息恢复，是由整幅图像内所有邻域与像素 $x$ 邻域相似的点取平均得到的。与局部滤波算法或频域滤波算法相比，NL-means 算法的主要区别在于可以系统地运用整幅图像中所有可能自预测局部结构的信息。</p>
<h2 id="实验及讨论"><a href="#实验及讨论" class="headerlink" title="实验及讨论"></a>实验及讨论</h2><p>&emsp;&emsp;本节将针对以下三点比较 Non Local Means 算法与局部平滑滤波的性能： method noise，视觉效果，均方差（mean square error）。这里均方差指修复图像与真实图像的欧几里得差异（Euclidean difference）。</p>
<p>&emsp;&emsp;在实现 NL-means 算法时，我们将相似邻域的搜索范围约束在一个较大的 $S\times S$ pixels 区域内。在所有的实验中均固定该搜索范围为 $21\times 21$ pixels，并指定邻域 $N_i$ 范围为 $7\times 7$ pixels。不妨设输入图像的像素数为 $N^2$，那么该算法的时间复杂度约为 $21^2\times 7^2 \times N^2$。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image002.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图2.  NL-means 权重分布。每组中左图中心像素为参考像素点 $x$，每组中右图为权重因子分布，由黑至白对应从0到1。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;$7\times 7$ pixels 的邻域范围已经足够大，能够确保算法对噪声是鲁棒的；也足够小，让细节及纹理得以保持。滤波参数 $h$ 被设置为 $10\sigma$，这里 $\sigma$ 为人工添加高斯白噪声的标准差。由于指数权重的快速衰减，距离中心较远像素的权重几乎为零，这发挥了自动剔除远处像素的作用。Non Local means 算法的权重分布见图$(2)$。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image003.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图3.  对自然图像的降噪实验。从左至右：含噪声的实测图像（噪声标准差 35），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;在前面的段落中，我们明确的计算了各种局部平滑滤波方法的 method noise 理论值。图$(4)$ 的可视化实验证明了前文中公式的正确性。图$(4)$ 对比了数种降噪方法对含噪声lena图像运算的 method noise，噪声为高斯白噪声，标准差 2.5，滤波参数 $h$ 均相同。Method noise 能更好的协助判断降噪算法的性能及局限，因为被移除或改变的纹理、细节将被 method noise 醒目的展示出来。对比图$(4)$ 中数种降噪算法，NL-means 算法的 method noise 几乎无法察觉任何几何纹理。图$(2)$ 可以解释这一现象，因为 NL-means 算法选取的权重因子完全适应图像局部及非局部的几何结构。</p>
<p>&lt;img src&#x3D;”Exp002_image004.jpg” width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图4.  降噪算法的method noise。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。视觉实验验证了第二节的计算公式。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;由于算法本身的性质，纹理及周期性结构是 NL-means 算法最适用的情况。因为对任意像素 $i$，纹理图像或周期性图像中将可以找到大量与该像素具有相似邻域的点，如图$(2.e)$。图$(3)$ 展示了局部平滑滤波器及 NL-means 算法对自然纹理的平滑效果。</p>
<p>&emsp;&emsp;自然图像同样含有足够的信息冗余会被 NL-means 恢复。平坦区域内部将呈现出大量相似的几何结构，见图$(2.a)$。直边界、或弯曲边界将被筛选出一条结构相似的像素线，见图$(2. b)，(2.c)$。并且，NL-means 将会在很远的位置寻找到与参考点相似的结构，如图$(2.f)$。图$(5)$ 展示了一次对自然图像的可视化实验，这组结果与图$(4)$ 是相对应的。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image005.jpg” width &#x3D; 55% div align&#x3D;center &#x2F; title&#x3D;”图5.  对自然图像的降噪实验。从左到右，由上至下：噪声图像（标准差 20），高斯滤波，各向异性滤波，TV滤波，邻域滤波及 NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&emsp;&emsp;最后，表$(1)$ 展示了本文介绍的降噪方法的均方差。这种数值测量方法是最客观的，因为它不依赖于任何肉眼视觉上的解释。然而，这个误差在实际问题中是不可计算的（原始信号是未知的），小的均方误差并不能保证高的视觉质量。因此，以上讨论的标准似乎是比较算法性能的必要条件。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp002_image006.jpg” width &#x3D; 35% div align&#x3D;center &#x2F; title&#x3D;”表1.  均方误差表。均方误差越小，降噪后越接近原始图像。”&gt;</p>
<p>&nbsp;<br>&lt;img src&#x3D;”&#x2F;Exp002_image007.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图6.  多种滤波方法对周期性图像应用结果。从左到右、从上到下：含噪声图像（标准差 35）；高斯滤波；TV滤波；邻域滤波；维纳滤波（ideal filter）；Hard TIWT；DCT 经验维纳滤波；NL-means 算法。”&gt;</p>
<p>&nbsp;<br>&lt;img src&#x3D;”&#x2F;Exp002_image008.jpg” width &#x3D; 40% div align&#x3D;center &#x2F; title &#x3D; “图7.  多种滤波方法对自然图像应用结果。从左到右、从上至下：含噪声图像（标准差 25）；DCT 经验维纳滤波；Hard TIWT；NL-means 算法。”&gt;</p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>&emsp;&emsp;Non-local means 方法 C 语言实现：<a href="http://www.ipol.im/pub/art/2011/bcm_nlm/">http://www.ipol.im/pub/art/2011/bcm_nlm&#x2F;</a></p>
]]></content>
  </entry>
  <entry>
    <title>Windows Server 2019 + Mint OS 搭建 Tomography 数据分析工作站</title>
    <url>/archive/Exp009-WinServerSetup.html</url>
    <content><![CDATA[<p>为实现多用户同时登录 Tomography 数据分析工作站，避免设备冗余浪费，使用 Windows Server 2019 与 Mint OS 虚拟机的组合是个让人满意的方案。 本文记录配置 Tomography 数据分析工作站时的一些常见问题及相应的解决办法。</p>
<p>本文使用的所有 OS 镜像均下载自 <a href="https://msdn.itellyou.cn/">MSDN</a> 镜像资源站，启动盘制作使用 <a href="https://www.ventoy.net/en/index.html">Ventoy</a> 开源工具包，虚拟机平台使用 VMware Workstation 16.0。</p>
<span id="more"></span>

<h1 id="Windows-Server-2019"><a href="#Windows-Server-2019" class="headerlink" title="Windows Server 2019"></a>Windows Server 2019</h1><h2 id="Windows-Server-2019-Standard-激活"><a href="#Windows-Server-2019-Standard-激活" class="headerlink" title="Windows Server 2019 Standard 激活"></a>Windows Server 2019 Standard 激活</h2><p>以管理员权限运行 Windows PowerShell：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ slmgr /upk</span><br><span class="line">$ slmgr /ipk N69G4-B89J2-4G8F4-WWYCC-J464C</span><br><span class="line">$ slmgr /skms kms.03k.org</span><br><span class="line">$ slmgr /ato</span><br></pre></td></tr></table></figure>

<p>是否成功激活，激活码到期时间可输入以下命令查看：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ slmgr /xpr</span><br></pre></td></tr></table></figure>

<h2 id="无法访问共享文件夹的解决办法"><a href="#无法访问共享文件夹的解决办法" class="headerlink" title="无法访问共享文件夹的解决办法"></a>无法访问共享文件夹的解决办法</h2><blockquote>
<ol>
<li>Win+R 快捷键调用 Run，输入 <code>control</code> 调用 Control Panel，Turn Windows features on or off，安装 SMB 1.0&#x2F;CIFS File Sharing Support。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>Win+R 快捷键调用 Run，输入 <code>gpedit.msc</code> 调用 Local Group Policy Editor，Computer Configuration - Administrative Templates - Network - Lanman Workstation - Enable insecure guest logons。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>Windows Defender 防火墙，允许应用或功能通过 Windows Defender 防火墙，允许 SMBDirect 上的文件和打印机共享。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>右键点击 This PC，Add a network location，Choose a custom network location，<code>\\192.168.26.110\APS-data\</code>。</li>
</ol>
</blockquote>
<h2 id="远程桌面连接权限"><a href="#远程桌面连接权限" class="headerlink" title="远程桌面连接权限"></a>远程桌面连接权限</h2><p>与 Windows 10 类似，远程连接权限、防火墙权限、网络共享权限、Remote Desktop Server 权限，共四步骤，此处不做过多介绍。 特别注意每个子账号均需单独开启远程权限。</p>
<h2 id="多用户同时登陆权限"><a href="#多用户同时登陆权限" class="headerlink" title="多用户同时登陆权限"></a>多用户同时登陆权限</h2><p>Windows Server 2019 默认远程桌面连接数上限是 2 位用户，无法容纳更多用户同时登陆，可以通过添加远程桌面授权解决：</p>
<p>参考链接：<a href="https://www.cnblogs.com/laosan007/p/11734283.html">Windows Server 2019 远程桌面服务配置和授权激活</a></p>
<h2 id="Tomography-分析常用软件"><a href="#Tomography-分析常用软件" class="headerlink" title="Tomography 分析常用软件"></a>Tomography 分析常用软件</h2><blockquote>
<ol>
<li>办公类：Chrome浏览器、TIM、Wechat for PC、MobaXterm</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>学术类：Endnote X9、Sublime Text 4、Adobe Acrobat Pro DC</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>工程类：Avizo、OriginPro 9.0、Fiji ImageJ、Matlab、VMware Workstation、Photoshop</li>
</ol>
</blockquote>
<h1 id="VMware-Workstation-Mint-OS"><a href="#VMware-Workstation-Mint-OS" class="headerlink" title="VMware Workstation + Mint OS"></a>VMware Workstation + Mint OS</h1>]]></content>
  </entry>
  <entry>
    <title>人工智能：深度学习超参数调优指南</title>
    <url>/archive/AI-parameter.html</url>
    <content><![CDATA[<p>本文摘录自Google团队公布的深度学习超参数调优指南文档，该文档适用于对最大化深度学习的性能感兴趣的工程师和研究人员。我们假定您具备机器学习和深度学习概念的基本知识。文档的重点是<strong>超参数调优的过程</strong>，但还将涉及深度学习学习的其他方面。例如工作流实施和优化，但这些方面并不详尽。我们假设机器学习问题是监督学习或类似的东西（例如自监督学习）。但是，本文档中描述的技术也可能适用于其他类型的问题。</p>
<p><strong>Reference:</strong> <a href="https://github.com/google-research/tuning_playbook">https://github.com/google-research/tuning_playbook</a></p>
<span id="more"></span>

<h2 id="为什么需要这份调优手册？"><a href="#为什么需要这份调优手册？" class="headerlink" title="为什么需要这份调优手册？"></a>为什么需要这份调优手册？</h2><p>目前，要使深度神经网络在实践中正常运行，需要付出大量的努力和猜测。更糟糕的是，目前很少有人记录下那些深度学习中获得良好结果的实际方法。一方面，通常，论文忽略了导致最终结果的过程，以呈现更清晰的原理。另一方面，处理商业问题的机器学习工程师很少有时间回顾并概括他们的调参过程。教科书也往往回避实用指南，而偏重于基本原理，即使它们的作者具有在应用工作中提供有用建议的经验。在准备创建此文档时，我们找不到任何系统性的资料来解释<em>如何使用深度学习获得良好的结果</em>. 相反，我们看到了博客文章和社交媒体上的建议片段、从研究论文附录中收集的技巧、特定项目或工作流的偶然案例研究，以及很多困惑。在深度学习领域，专家和新手用着表面上类似的方法，但所取得的结果之间存在着巨大的差距。与此同时，这些专家也很乐意承认他们所做的一些事情可能没有充分的理由。随着深度学习的成熟并对世界产生更大的影响，社区需要更多涵盖有用方法的资源，包括对于获得良好结果至关重要的所有实用细节。</p>
<p>我们是一个由五名研究人员和工程师组成的团队，多年来一直致力于深度学习。我们已经将深度学习应用到从语音识别到天文学的方方面面，并在此过程中学到了很多东西。本文档源于我们自己训练神经网络、教授学生以及为我们的同事提供实践建议的经验。虽然深度学习已经从少数学术研究实验室中实践的机器学习方法发展成为为数十亿人使用的产品提供动力的技术，但深度学习在工程领域仍处于起步阶段，我们希望本文档能鼓励其他人也来帮助系统化该领域的实验细节。</p>
<p>这份文件是在我们试图实现我们自己的深度学习方法时产生的，因此它只代表作者在撰写本文时的观点，而不是任何客观事实。它被特别强调是因为我们在调整超参数方面遇到了困难，但它也涵盖了我们在工作中遇到（或看到出错）的其他重要问题。我们希望这项工作成为一份活的文件，能随着我们理解的改变从而成长和演变。例如，一份关于如何调试和如何减少训练失败的文档在两年前是不可能写出来的，因为它这得基于最近的结果和正在进行的研究。不可避免地，我们的在此文档中一些建议也将需要更新以考虑新的结果和改进的工作流程。我们不知道最好的深度学习秘诀，但在大众开始记录它并讨论各个步骤之前，我们不能指望找到它。为此，我们鼓励发现我们的建议存在问题的读者提出替代建议以及令人信服的证据，以便我们更新建议。我们也希望看到可能有不同建议的替代指南和方式，以帮助大众追求最佳方法。最后，任何标有🤖表情符号的地方是我们要进一步调查的地方。只有在尝试编写这本 playbook 之后，我们才完全清楚在深度学习从业者的工作流程中可以找到多少有趣及被忽视的研究问题。</p>
<h2 id="开始新项目的指南"><a href="#开始新项目的指南" class="headerlink" title="开始新项目的指南"></a>开始新项目的指南</h2><p>在调优过程中的许多抉择，我们可以在项目开始时一次性做出决定。只有偶尔在情况发生变化时，才需要重新考虑。</p>
<p>在开始调优之前，请确保您满足以下假设：</p>
<ul>
<li>问题制定、数据清理等基本工作已经完成，花时间在模型架构和训练配置上是有意义的。</li>
<li>已经有一个工作流设置用来进行训练和评估，并且可以很容易地为各种感兴趣的模型执行训练和预测工作。</li>
<li>已选择并实现适当的评估指标。这些指标应该尽可能地代表在部署环境中测量的内容。</li>
</ul>
<h3 id="选择模型架构"><a href="#选择模型架构" class="headerlink" title="选择模型架构"></a>选择模型架构</h3><p><em><strong>总结</strong></em>： <em>在开始一个新项目时，尽量重用有效的模型。</em></p>
<ul>
<li>首先选择一个完善且常用的模型架构来开始工作。这样可以尽早让模型进入工作状态，之后再构建自定义模型也是可行的。</li>
<li>模型架构通常具有各种超参数，用于确定模型的大小和其他细节（例如层数、层宽度、激活函数类型）。<ul>
<li>因此，选择架构实际上意味着选择一整个系列的各种模型（每个模型都有不同的超参数设置）。</li>
</ul>
</li>
<li>如果可以的话，请尝试找到一篇尽可能接近手头问题的相关论文，并将复现该论文中的模型作为起点。</li>
</ul>
<h3 id="选择优化器"><a href="#选择优化器" class="headerlink" title="选择优化器"></a>选择优化器</h3><p><em><strong>总结</strong></em>： <em>从针对手头问题类型的最常用的优化器开始。</em></p>
<ul>
<li><p>没有一个优化器是适用于所有类型的机器学习问题和模型架构的‘最佳’优化器。即使只是 <a href="https://arxiv.org/abs/1910.05446">比较优化器的性能</a>也是一项艰巨的任务。 🤖</p>
</li>
<li><p>我们建议坚持使用成熟、流行的优化器，尤其是在开始新项目时。</p>
<ul>
<li>理想情况下，选择用于同类问题的最常用优化器。</li>
</ul>
</li>
<li><p>做好关注选择的优化器的 <b>*所有*</b> 超参数的准备。</p>
<ul>
<li><p>具有更多超参数的优化器可能需要更多的调优工作才能找到最佳配置。</p>
</li>
<li><p>当我们试图找到各种其他超参数（例如架构超参数）的最佳值时，将优化器超参数视为<a href="#identifying-scientific-nuisance-and-fixed-hyperparameters">冗余参数</a>是有意义的，这在项目的初始阶段尤其重要。</p>
</li>
<li><p>在项目的初始阶段，从更简单的优化器开始会更可取（例如，具有固定动量的 SGD 或具有固定 $\epsilon$、$\beta_{1}$ 和 $\beta_{2}$ 的 Adam ) ，之后可以切换到更通用的优化器。</p>
</li>
</ul>
</li>
<li><p>常用且较为完善的优化器包括（但不限于）：</p>
<ul>
<li><a href="#what-are-the-update-rules-for-all-the-popular-optimization-algorithms">SGD with momentum</a>（Nesterov 变体）</li>
<li><a href="#what-are-the-update-rules-for-all-the-popular-optimization-algorithms">Adam and NAdam</a>，它们比具有动量的 SGD 更通用。请注意，Adam 有 4 个可调超参数，<a href="https://arxiv.org/abs/1910.05446">他们都很重要</a>！<ul>
<li>参见 [Adam 的超参数应该如何调整？](#Adam 的超参数应该如何调整？)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="选择BatchSize"><a href="#选择BatchSize" class="headerlink" title="选择BatchSize"></a>选择BatchSize</h3><p><em><strong>总结</strong></em>： <em>Batch Size决定训练速度，并且不应该被直接用于调整验证集性能。通常来说，可用硬件支持的最大Batch Size是较为理想的数值。</em></p>
<ul>
<li>Batch Size是决定<em>训练时间</em>和<em>计算资源消耗</em>的关键因素。</li>
<li>增加Batch Size通常会减少训练时间。这非常有益，因为它：<ul>
<li>能使固定时间间隔内超参数调整更彻底，最终训练出更好的模型。</li>
<li>减少开发周期的延迟，能更多地测试新想法。</li>
</ul>
</li>
<li>资源消耗和Batch Size之间并没有明确的关系，增加Batch Size让资源消耗增加、减少或是保持不变都有可能。</li>
<li>Batch Size<em>不应该</em>被当作验证集性能的可调超参数。<ul>
<li>只要调整好所有超参数（尤其是学习率和正则化超参数）并且训练步数足够，理论上任意的Batch Size都能获得相同的最终性能（参见 <a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>） .</li>
<li>详见 [为什么不应该调整Batch Size来直接提高验证集性能？](#为什么不应该调整Batch Size来直接提高验证集性能？)</li>
</ul>
</li>
</ul>
<h4 id="确定可行的Batch-Size并估计训练吞吐量"><a href="#确定可行的Batch-Size并估计训练吞吐量" class="headerlink" title="确定可行的Batch Size并估计训练吞吐量"></a>确定可行的Batch Size并估计训练吞吐量</h4><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>对于给定的模型和优化器，可用硬件通常能能够支持一系列Batch Size。限制因素通常是加速器（GPU&#x2F;TPU 等）的内存。</li>
<li>不幸的是，如果不运行或者编译完整的训练程序，就很难计算出适合内存的Batch Size。</li>
<li>最简单的解决方案通常是以不同的批次大小（例如，用 2 的幂来尝试）运行少量的训练实验，直到其中一个实验超过可用内存。</li>
<li>对于每个Batch Size，我们应该训练足够长的时间以准确估计<em>训练吞吐量</em></li>
</ul>
<p align="center">训练吞吐量 =每秒处理的样本数量</p>

<p align="center">或者，我们可以估计<em>每步时间</em> :</p>

<p align="center">每步时间 =（Batch Size）/（训练吞吐量）</p>

<ul>
<li>当加速器内存未饱和时，如果Batch Size加倍，训练吞吐量也应该加倍（或至少接近加倍）。等效地，随着Batch Size的增加，每步的时间应该是恒定的（或至少接近恒定的）。</li>
<li>如果与上述情况不符，那么训练工作流可能存在瓶颈，例如 I&#x2F;O 或计算节点间的同步。有必要在开始下一步前对此进行诊断和矫正。</li>
<li>如果训练吞吐量到某个Batch Size之后就不再增加，那么我们只考虑使用该Batch Size（即使硬件支持更大的Batch Size）<ul>
<li>使用更大Batch Size的所有好处都假定训练吞吐量增加。如果没有，请修复瓶颈或使用较小的Batch Size。</li>
<li>使用<strong>梯度积累</strong>技术可以支持的更大的Batch Size。但其不提供任何训练吞吐量优势，故在应用工作中通常应避免使用它。</li>
</ul>
</li>
<li>每次更改模型或优化器时，可能都需要重复这些步骤（例如，不同的模型架构可能允许更大的Batch Size）。</li>
</ul>
</details>

<h4 id="选择合适的Batch-Size以最小化训练时间"><a href="#选择合适的Batch-Size以最小化训练时间" class="headerlink" title="选择合适的Batch Size以最小化训练时间"></a>选择合适的Batch Size以最小化训练时间</h4><details><summary><em>[点击展开]</em></summary>
<br>

<p align="center">训练时间 =（每步时间）x（总步数）</p>

<ul>
<li>对于所有可行的Batch Size，我们通常可以认为每步的时间近似恒定(实际上，增加Batch Size通常会产生一些开销)。</li>
<li>Batch Size越大，达到某一性能目标所需的步数通常会减少（前提是在更改Batch Size时重新调整所有相关超参数；<a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>）。<ul>
<li>例如，将Batch Size翻倍可能会使训练步数减半。这称为<strong>完美缩放</strong>。</li>
<li>完美缩放适用于Batch Size在临界值之前，超过该临界总步数的减少效果将会下降。</li>
<li>最终，增加Batch Size不会再使训练步数减少（永远不会增加）。</li>
</ul>
</li>
<li>因此，最小化训练时间的Batch Size通常是最大的Batch Size，也同时减少了所需的训练步数。<ul>
<li>Batch Size取决于数据集、模型和优化器，除了通过实验为每个新问题找到它之外，如何计算它是一个悬而未决的问题。🤖</li>
<li>比较Batch Size时，请注意效果(epoch)预算（运行所有实验，固定训练样本的数量达到设定的效果所花的时间）和步数预算（运行设定步数的试验）之间的区别。<ul>
<li>将Batch Size与效果预算进行比较只会涉及到完美缩放的范围，即使更大的Batch Size仍可能通过减少所需的训练步数来提供有意义的加速。</li>
</ul>
</li>
<li>通常，可用硬件支持的最大Batch Size将小于临界Batch Size。因此，一个好的经验法则（不运行任何实验）是使用尽可能大的Batch Size。</li>
</ul>
</li>
<li>如果最终增加了训练时间，那么使用更大的Batch Size就没有意义了。</li>
</ul>
</details>

<h4 id="选择合适的Batch-Size以最小化资源消耗"><a href="#选择合适的Batch-Size以最小化资源消耗" class="headerlink" title="选择合适的Batch Size以最小化资源消耗"></a>选择合适的Batch Size以最小化资源消耗</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>有两种类型的资源成本与增加 batch size有关。<br>1. 前期成本，例如购买新硬件或重写训练工作流以实现多GPU&#x2F;多TPU训练。<br>1. 使用成本，例如，根据团队的资源预算计费，从云供应商处计费，电力&#x2F;维护成本。</li>
</ul>
<p>如果增加 batch size有很大的前期成本，那么直到项目成熟且容易权衡成本效益前，推迟其的增加可能更好。实施多机并行训练程序可能会引入<a href="https://link.zhihu.com/?target=https://github.com/google-research/tuning_playbook%23considerations-for-multi-host-pipelines">错误</a>和<a href="https://link.zhihu.com/?target=https://github.com/google-research/tuning_playbook%23batch-normalization-implementation-details">一些棘手的细节</a>，所以无论如何，一开始最好是用一个比较简单的工作流。(另一方面，当需要进行大量的调优实验时，训练时间的大幅加速可能会在过程的早期非常有利）。</p>
<p>我们把总的使用成本（可能包括多种不同类型的成本）称为 “资源消耗 “。我们可以将资源消耗分解为以下几个部分。</p>
<p>资源消耗 &#x3D; (每步的资源消耗) x (总步数)</p>
<ul>
<li><p>增加 batch size通常可以减少总步骤数。资源消耗是增加还是减少，将取决于每步的消耗如何变化。</p>
</li>
<li><ul>
<li>增加 batch size可能会减少资源消耗。例如，如果大batch size的每一步都可以在与小batch size相同的硬件上运行（每一步只增加少量时间），那么每一步资源消耗的增加可能被步骤数的减少所抵消。</li>
<li>增加 batch size可能不会改变资源消耗。例如，如果将batch size增加一倍，所需的步骤数减少一半，所使用的GPU数量增加一倍，总消耗量（以GPU小时计）将不会改变。</li>
<li>增加 batch size可能会增加资源消耗。例如，如果增加batch size需要升级硬件，那么每步消耗的增加可能超过训练所需步数的减少。</li>
</ul>
</li>
</ul>
</details>

<h4 id="更改Batch-Size需要重新调整大多数超参数"><a href="#更改Batch-Size需要重新调整大多数超参数" class="headerlink" title="更改Batch Size需要重新调整大多数超参数"></a>更改Batch Size需要重新调整大多数超参数</h4><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>大多数超参数的最佳值对Batch Size敏感。因此，更改Batch Size通常需要重新开始调整过程。</li>
<li>与Batch Size交互最强烈的超参数是优化器超参数（学习率、动量等）和正则化超参数，所以有必要对于针对每个Batch Size单独调整它们。</li>
<li>在项目开始时选择Batch Size时请记住，如果您以后需要切换到不同的Batch Size，则为新的Batch Size重新调整所有内容可能会很困难、耗时且成本高昂。</li>
</ul>
</details>

<h4 id="Batch-Norm会对Batch-Size的选择造成什么影响？"><a href="#Batch-Norm会对Batch-Size的选择造成什么影响？" class="headerlink" title="Batch Norm会对Batch Size的选择造成什么影响？"></a>Batch Norm会对Batch Size的选择造成什么影响？</h4><details><summary><em>[点击展开]</em></summary>
<br>

<p>Batch norm 很复杂，一般来说，应该使用与计算梯度不同的 batch size 来计算统计数据(像<a href="https://arxiv.org/abs/1705.08741">Ghost Batch Norm</a>采用固定值的batch size)。有关详细讨论，请参阅<a href="#BatchNorm%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82">BatchNorm的实现细节</a></p>
</details>

<h4 id="选择初始配置"><a href="#选择初始配置" class="headerlink" title="选择初始配置"></a>选择初始配置</h4><ul>
<li>在开始超参数调整之前，我们必须确定起点。这包括指定 (1) 模型配置（例如层数），(2) 优化器超参数（例如学习率），以及 (3) 训练步数。</li>
<li>确定此初始配置将需要一些手动配置的训练运行和反复试验。</li>
<li>我们的指导原则是找到一个简单、相对快速、资源消耗相对较低的配置，以获得“合理”的结果。<ul>
<li>“简单”意味着尽可能避免花里胡哨的东西；这些总是可以在以后添加。即使花里胡哨的东西在未来被证明是有用的，但在初始配置中添加它们可能会浪费时间调整无用的功能和&#x2F;或烘烤不必要的并发症。<ul>
<li>例如，在添加花哨的衰减方案之前以恒定的学习率开始。</li>
</ul>
</li>
<li>选择快速且消耗最少资源的初始配置将使超参数调整更加高效。<ul>
<li>例如，从较小的模型开始。</li>
</ul>
</li>
<li>“合理”性能取决于问题，但至少意味着经过训练的模型在验证集上的性能比随机机会好得多（尽管它可能很糟糕，不值得部署）。</li>
</ul>
</li>
<li>选择训练步数的数量涉及平衡以下方面：<ul>
<li>一方面，训练更多的步数可以提高性能并使超参数调整更容易（参见 <a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>）。</li>
<li>另一方面，更少步数的训练意味着每次训练运行得更快并且使用更少的资源，通过减少周期之间的时间并允许并行运行更多实验来提高调整效率。此外，如果一开始选择了一个不必要的大训练步数，那么以后可能很难改变它，例如，已经将学习率针对该步数进行了调整。</li>
</ul>
</li>
</ul>
<h2 id="提高模型性能的科学方法"><a href="#提高模型性能的科学方法" class="headerlink" title="提高模型性能的科学方法"></a>提高模型性能的科学方法</h2><p>机器学习开发的最终目标是最大化模型的效用。尽管不同应用场景的开发流程有所不同（例如时间长度、可用计算资源、模型类型等），基本步骤和原则都是相似的。</p>
<p>接下来的指南中我们做出了这些假设：</p>
<ul>
<li>已有能运行且得到不错结果的训练工作流。</li>
<li>有足够的计算资源来进行调参实验，至少能够并行发起数个训练流程。</li>
</ul>
<h3 id="增量调整策略"><a href="#增量调整策略" class="headerlink" title="增量调整策略"></a>增量调整策略</h3><p><em><strong>总结</strong></em>： <em>从简单的配置开始，循序渐进，同时进一步了解问题。确保任何改进都有据可循，以避免增加不必要的复杂度。</em></p>
<ul>
<li>我们的最终目标是找到一种训练配置来最大化我们模型的性能。<ul>
<li>在某些情况下，我们的目标是在固定截止日期（例如提交给竞赛）之前最大限度地改进模型。</li>
<li>在其他情况下，我们希望无限期地改进模型（例如，不断改进生产中使用的模型）。</li>
</ul>
</li>
<li>原则上，我们可以使用算法自动搜索整个配置空间来最大化性能，但实践中这往往不实际。<ul>
<li>配置空间可能非常大，目前还没有任何算法可以在没有人工指导的情况下有效地搜索这个空间。</li>
</ul>
</li>
<li>大多数自动搜索算法依赖于人工设计的<em>搜索空间</em>，这些搜索空间往往非常重要。</li>
<li>更有效的方法是从简单的配置开始，逐步添加功能并进行改进，同时深化对问题的理解。<ul>
<li>我们在每一轮调整中都使用自动搜索算法，并随着我们理解的深度不断更新我们的搜索空间。</li>
</ul>
</li>
<li>随着我们的探索，我们自然会找到越来越好的配置，因此我们的“最佳”模型将不断改进。<ul>
<li>当我们更新我们的最佳配置时，我们称之为<em>上线</em>（这不一定对应线上模型的实际上线）。</li>
<li>对于每次上线，我们必须确保更改是有据可循的——而不仅仅是碰运气找到的配置——以避免给训练工作流增加不必要的复杂性。</li>
</ul>
</li>
</ul>
<p>综上所述，我们的增量调优策略需要重复以下四个步骤：</p>
<ol>
<li>为下一轮实验确定适当的目标。</li>
<li>设计并展开实验，朝着这个目标取得进展。</li>
<li>从实验结果中获取经验。</li>
<li>考虑是否上线新的最佳配置。</li>
</ol>
<p>本节的其余部分将更详细地讲解增量调优策略。</p>
<h3 id="探索与利用"><a href="#探索与利用" class="headerlink" title="探索与利用"></a>探索与利用</h3><p><em><strong>总结</strong></em>： <em>大多数时候，我们的目标是更深入地理解问题。</em></p>
<ul>
<li>尽管有些人认为我们会花大部分时间来提升验证集的指标，实际上我们把重心放在进一步理解问题上，而不是降低验证集错误率。<ul>
<li>也就是说，我们大部分时间都花在了“探索”上，只有一小部分时间花在了“利用”上。</li>
</ul>
</li>
<li>从长远来看，如果我们想最大化我们的最终效果，深入理解问题是至关重要的。将深化理解置于短期收益之上可以帮助我们：<ul>
<li>避免仅因历史原因而表现良好的不必要更改。</li>
<li>确定验证集效果对哪些超参数最敏感，哪些超参数交互最多，因此需要一起重新调整，以及哪些超参数对其他变化相对不敏感，因此可以在未来的实验中固定住。</li>
<li>发现潜在的新方向，例如在出现过拟合问题时使用新的正则化器。</li>
<li>确定无效的方向并将其删除，从而降低后续实验的复杂度。</li>
<li>判断超参数的优化空间是否已经饱和。</li>
<li>围绕最佳值缩小我们的搜索空间，以提高调整效率。</li>
</ul>
</li>
<li>最终，我们可以集中提升验证集效果，即便我们无法从新的实验中进一步了解问题的结构了。</li>
</ul>
<h3 id="选择下一轮实验的目标"><a href="#选择下一轮实验的目标" class="headerlink" title="选择下一轮实验的目标"></a>选择下一轮实验的目标</h3><p><em><strong>总结</strong></em>： <em>每轮实验都应该有一个明确的目标，并且范围要足够小，这样实验才能真正朝着目标取得进展。</em></p>
<ul>
<li>每轮实验都应该有一个明确的目标，并且范围要足够小，这样实验才能真正朝着目标取得进展：如果我们试图一次添加多个特征或回答多个问题，我们可能无法理清各自的影响。</li>
<li>举个例子，目标可以包括：<ul>
<li>尝试对训练流程进行改进（例如，新的正则化器、预处理方法等）。</li>
<li>了解特定模型超参数（例如激活函数）的影响</li>
<li>最大化验证集指标。</li>
</ul>
</li>
</ul>
<h3 id="设计下一轮实验"><a href="#设计下一轮实验" class="headerlink" title="设计下一轮实验"></a>设计下一轮实验</h3><p><em><strong>总结</strong></em>： <em>根据实验目标，将超参数分为三类：目标超参数、冗余超参数和固定超参数。创建一系列研究以比较目标超参数的不同值，同时优化冗余超参数。注意选择冗余超参数的搜索空间，以平衡资源成本与科学价值。</em></p>
<h4 id="识别目标超参数、冗余超参数和固定超参数"><a href="#识别目标超参数、冗余超参数和固定超参数" class="headerlink" title="识别目标超参数、冗余超参数和固定超参数"></a>识别目标超参数、冗余超参数和固定超参数</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>对于给定的目标，所有超参数都将是<strong>目标超参数</strong>、<strong>冗余超参数</strong>或<strong>固定超参数</strong>。<ul>
<li>目标超参数是指，我们希望测量出其对于模型由何种影响的参数。</li>
<li>冗余超参数是指，必须优化才能公平比较不同目标超参数值的参数。类似于统计中的<a href="https://en.wikipedia.org/wiki/Nuisance_parameter">冗余参数</a>。</li>
<li>固定超参数是指，在当前轮次实验中取固定值的参数。在比较目标超参数的不同值时，固定超参数的值不需要（或者我们不希望它们）改变。<ul>
<li>因为实验固定了某些超参数，从实验得出的结论可能对固定超参数的其他值无效。换句话说，固定的超参数对我们的实验结论做了限定。</li>
</ul>
</li>
</ul>
</li>
<li>举个例子，如果我们的目标是“确定更深的模型是否会减少验证集错误”，那么模型层数就是目标超参数。<ul>
<li>学习率是一个冗余超参数，如果我们要公平对比不同深度的模型，我们必须分别调整学习率（通常情况下最优学习率和模型结构有关）。</li>
<li>激活函数是一个固定超参数。我们可能通过过去的实验发现最优激活函数和模型深度无关。或者我们接受实验得到的最优深度的仅在某个激活函数上有效。或者我们也可以将激活函数作为一个冗余超参数和深度一起调优。</li>
</ul>
</li>
<li>一个超参数是目标超参数、冗余超参数还是固定超参数是根据实验目标来决定的。<ul>
<li>比如，激活函数的选择可以是一个目标超参数（对于当前问题，ReLU 或 tanh 是更好的选择吗？），一个冗余超参数（允许使用不同的激活函数，最好的 5 层模型是否优于最好的 6 层模型？），或一个固定超参数（对于一个由 ReLU 构成的网络，在特定位置添加批标准化是否有帮助？）。</li>
</ul>
</li>
<li>在设计新一轮实验时，我们根据实验目的确定目标超参数。<ul>
<li>在此阶段，我们将所有其他超参数视为冗余超参数。</li>
</ul>
</li>
<li>接下来，我们将一些冗余超参数转作为固定超参数。<ul>
<li>如果有无限的计算资源，我们会将所有非目标超参数保留为冗余超参数，这样我们从实验中得出的结论就不会受到固定超参数的限定。</li>
<li>然而，冗余超参数越多，我们没能充分针对每个目标超参数调优冗余超参数的风险就越高，从而我们从实验中得出错误结论的风险也越高。<ul>
<li>如<a href="#%E5%B9%B3%E8%A1%A1%E5%AE%9E%E9%AA%8C%E7%9A%84%E4%BF%A1%E6%81%AF%E9%87%8F%E5%92%8C%E6%88%90%E6%9C%AC">下文</a>所述，我们可以通过增加计算资源来应对这种风险，但通常我们的最大资源预算低于调整所有非目标超参数所需的计算资源。</li>
</ul>
</li>
<li>当我们判断将一个冗余超参数转换为固定超参数所带来的限制少于调优它所需的计算资源时，我们可以进行这种转换。<ul>
<li>一个冗余超参数和目标超参数的相互影响越多，固定这个参数所带来的限制就越多。例如，权重衰减强度的最佳值通常取决于模型大小，因此固定权重衰减的强度来比较不同的模型大小，往往得不出有效的结论。</li>
</ul>
</li>
</ul>
</li>
<li>尽管超参数的类型取决于实验目标，但对于某些类别的超参数，我们有以下经验法则：<ul>
<li>在各种优化器超参数（例如学习率、动量、学习率调度参数、Adam优化器的beta等）中，至少有一些是冗余超参数，因为它们往往与其他变化相互影响。<ul>
<li>它们很少是目标超参数，因为像“训练流程的最佳学习率是多少？”这样的目标没有什么意义——最优学习率很容易随着下一次训练流程的改变而改变。</li>
<li>尽管当资源有限或有强力的证据表明它们不影响目标超参数时，我们可能固定其中一些参数，但通常应该假设优化器超参数必须单独调整，以在不同设置之间进行公平比较目标超参数。<ul>
<li>此外，我们没有优化器超参数值的<em>先验</em>倾向（例如，它们通常不会以任何方式影响前向传递或梯度的计算成本）。</li>
</ul>
</li>
</ul>
</li>
<li>相比之下，优化器的<em>选择</em>通常是一个目标超参数或固定超参数。<ul>
<li>如果我们的实验目标涉及在两个或多个不同的优化器之间进行公平比较（例如“确定哪个优化器在给定的步数中产生最低的验证错误”），那么它就是一个目标超参数。</li>
<li>或者，我们可能出于各种原因将其设为固定超参数，包括（1）先前的实验表明最好的优化器和当前的目标超参数无关；（2）当前优化器的训练曲线更容易理解 (3) 当前优化器比其他优化器使用更少的内存。</li>
</ul>
</li>
<li>正则化技术引入的超参数通常是冗余超参数，但是否使用正则化技术往往是目标或固定超参数。<ul>
<li>例如，dropout 增加了代码的复杂性，因此在决定是否包含它时，我们会将“no dropout”与“dropout”作为一个目标超参数，而将 dropout 率作为一个冗余超参数。<ul>
<li>如果我们决定根据这个实验将 dropout 添加到我们的训练流程中，那么在未来的实验中，dropout 率将是一个冗余超参数。</li>
</ul>
</li>
</ul>
</li>
<li>模型结构超参数通常是目标或固定超参数，因为模型结构变化会影响服务和训练成本、延迟和内存需求。<ul>
<li>例如，网络层数通常是一个目标或固定的超参数，因为它往往会对训练速度和内存使用产生巨大影响。</li>
</ul>
</li>
</ul>
</li>
<li>在某些情况下，一个超参数是冗余还是固定超参数将取决于目标超参数的值。<ul>
<li>例如，假设我们想知道 Nesterov momentum 和 Adam 中哪个优化器的验证错误率更低。目标超参数是 <code>optimizer</code>，它的值是 <code>&#123;&quot;Nesterov_momentum&quot;, &quot;Adam&quot;&#125;</code>。值 <code>optimizer=&quot;Nesterov_momentum&quot;</code> 引入了冗余&#x2F;固定超参数 <code>&#123;learning_rate, momentum&#125;</code>，但值 <code>optimizer=&quot;Adam&quot;</code> 引入了冗余&#x2F;固定超参数 <code>&#123;learning_rate, beta1, beta2, epsilon&#125;</code>。</li>
<li>仅针对目标超参数的某些值存在的超参数称为<strong>条件超参数</strong>。</li>
<li>我们不应该仅仅因为两个条件超参数具有相同的名称就认为它们是相同的！在上面的示例中， <code>learning_rate</code> 对于 <code>optimizer=&quot;Nesterov_momentum&quot;</code> 与 <code>optimizer=&quot;Adam&quot;</code> 是<em>不同的</em>条件超参数. 它在两种算法中的作用相似（尽管不完全相同），但在每个优化器中运行良好的值范围通常相差几个数量级。</li>
</ul>
</li>
</ul>
</details>

<h4 id="创建一组研究"><a href="#创建一组研究" class="headerlink" title="创建一组研究"></a>创建一组研究</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>确定了目标和冗余超参数之后，我们会设计一个“研究”或一系列研究，以朝着实验目标取得进展。<ul>
<li>一项研究指定了一组要运行的超参数配置以供后续分析。每个配置称为“试验”。</li>
<li>创建研究通常涉及几个方面：选择试验所需的超参数变量，选择这些超参数的取值范围（“搜索空间”），选择试验次数，以及选择自动搜索算法。或者，我们可以通过手动指定一组超参数配置来创建研究。</li>
</ul>
</li>
<li>研究的目的是使用目标超参数的不同值运行训练流程，同时 <strong>“优化掉”</strong>（或“优化”）冗余超参数，以便公平的比较不同的目标超参数值。</li>
<li>在最简单的情况下，我们将对目标超参数的每个配置进行单独研究，其中每个研究都会调整冗余超参数。<ul>
<li>例如，如果我们的目标是从 Nesterov、momentum 和 Adam 中选择最佳优化器，我们可以创建一个研究，并设置 <code>optimizer=&quot;Nesterov_momentum&quot;</code> 和冗余超参数为 <code>&#123;learning_rate, momentum&#125;</code>。然后创建另一项研究，并设置 <code>optimizer=&quot;Adam&quot;</code> 和冗余超参数为 <code>&#123;learning_rate, beta1, beta2, epsilon&#125;</code>。最后通过比较两个研究中的最优试验来比较这两个优化器。</li>
<li>我们可以使用任何无梯度优化算法，包括贝叶斯优化或进化算法等方法，来优化冗余超参数。但是，在<a href="#%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8">探索阶段</a>，<a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9C%A8%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8Quasi-Random-Search%E8%80%8C%E4%B8%8D%E6%98%AF%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E9%BB%91%E7%9B%92%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%9F">我们更偏向</a>使用准随机算法，因为这些方法在探索阶段有多种优势。在<a href="#%E6%8E%A2%E7%B4%A2%E7%BB%93%E6%9D%9F%E5%90%8E">探索结束后</a>，我们会优先选择最先进的贝叶斯优化方法。</li>
</ul>
</li>
<li>在更复杂的情况下，我们想要比较大量目标超参数的值，并且我们无法进行大量相对独立的研究，我们可以将目标超参数与冗余超参数放在相同的搜索空间中，并使用搜索算法在单个研究中对<em>两种超参数</em>的值进行采样。<ul>
<li>采用这种方法时，条件超参数可能会是一个问题，因为很难指定对应的搜索空间，除非所有目标超参数值都有相同的冗余超参数集。</li>
<li>在这种情况下，<a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9C%A8%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8Quasi-Random-Search%E8%80%8C%E4%B8%8D%E6%98%AF%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E9%BB%91%E7%9B%92%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%9F">我们更加偏好</a>使用Quasi-Random-Search算法，因为它确保我们能相对均匀的采样目标超参数值。无论搜索算法如何，我们都需要确保它均匀搜索目标超参数。</li>
</ul>
</li>
</ul>
</details>

<h4 id="平衡实验的信息量和成本"><a href="#平衡实验的信息量和成本" class="headerlink" title="平衡实验的信息量和成本"></a>平衡实验的信息量和成本</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>在设计一项研究或一系列研究时，我们需要分配有限的预算，以充分满足以下三个要求：<ol>
<li>比较足够多目标超参数的不同值。</li>
<li>在足够大的搜索空间上调整冗余超参数。</li>
<li>对冗余超参数的搜索空间进行足够密集的采样。</li>
</ol>
</li>
<li>这三个必要条件，确保我们能从实验中获得足够多的经验。<ul>
<li>尽可能多地比较目标超参数的值可以拓宽我们从实验中获得的经验的范围。</li>
<li>包括尽可能多的有冗余超参数，并允许每个冗余超参数有尽可能大的值域。这样我们更有信心相信，对于一个目标超参数配置，在当前搜索空间中，<strong>存在</strong>“好的”冗余参数。<ul>
<li>否则，我们可能因为没有搜索某些冗余超参数空间，而对不同目标超参数值进行了不公平的比较。</li>
</ul>
</li>
<li>尽可能密集地对冗余超参数采样，也能让我们更加有信心相信搜索流程能够找到好的冗余超参数配置。<ul>
<li>否则，我们可能对不同目标超参数值进行了不公平的比较。因为某些值恰好有更好的冗余超参数配置。</li>
</ul>
</li>
</ul>
</li>
<li>不幸的是，对这三个要求的<em>任何</em>一个进行改进都需要增加试验次数，从而增加资源成本。或者，我们只能从其他要求中想办法节约资源。<ul>
<li>每个问题都有自己的特性和计算资源限制，因此如何在这三个需求之间分配资源需要一定程度的领域专业知识。</li>
<li>在进行一项研究后，我们都会总结该研究是否将冗余超参数调整得足够好（即充分搜索了足够大的空间）以公平地比较目标超参数（更详细的描述<a href="#%E4%BB%8E%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E4%B8%AD%E8%8E%B7%E5%8F%96%E7%BB%8F%E9%AA%8C">如下</a>）。</li>
</ul>
</li>
</ul>
</details>

<h3 id="从实验结果中获取经验"><a href="#从实验结果中获取经验" class="headerlink" title="从实验结果中获取经验"></a>从实验结果中获取经验</h3><p><em><strong>总结</strong></em>： <em>除了尝试实现每组实验的原始科学目标之外，还要检查其他问题的清单，如果发现问题，请修改实验并重新运行。</em></p>
<ul>
<li>最终，每组实验都有一个特定的目标，我们想要评估实验为该目标提供的证据。<ul>
<li>然而，如果我们提出正确的问题，我们通常会发现在一组给定的实验能够朝着最初的目标取得很大进展之前需要纠正的问题。<ul>
<li>如果我们不问这些问题，我们可能会得出不正确的结论。</li>
</ul>
</li>
<li>由于运行实验的成本很高，我们还希望借此机会从每组实验中提取其他有用的见解，即使这些见解与当前目标并不直接相关。</li>
</ul>
</li>
<li>在分析一组给定的实验以朝着最初的目标取得进展之前，我们应该问自己以下额外的问题：<ul>
<li><a href="#identifying-bad-search-space-boundaries">搜索空间够大吗？</a><ul>
<li>如果研究的最佳点在一维或多维搜索空间的边界附近，则搜索可能不够广泛。在这种情况下，我们应该进行另一项具有扩展搜索空间的研究。</li>
</ul>
</li>
<li><a href="#not-sampling-enough-points-in-the-search-space">我们是否从搜索空间中采样了足够多的点？</a><ul>
<li>如果不是，则在调整目标中运行更多点或不那么雄心勃勃。</li>
</ul>
</li>
<li>每项研究中有多少试验是<strong>不可行</strong>（即出现分歧的试验、得到非常糟糕的损失值，或者因为违反某些隐式约束而根本无法运行）？<ul>
<li>当研究中很大一部分点是<strong>不可行</strong>时，我们应该尝试调整搜索空间以避免对这些点进行采样，这有时需要重新参数化搜索空间。</li>
<li>在某些情况下，大量不可行点可能表示训练代码中存在错误。</li>
</ul>
</li>
<li><a href="#how-can-optimization-failures-be-debugged-and-mitigated">模型是否存在优化问题？</a></li>
<li><a href="#examining-the-training-curves">我们可以从最佳试验的训练曲线中学到什么？</a><ul>
<li>例如，最好的试验是否具有与有问题的过度拟合一致的训练曲线？</li>
</ul>
</li>
</ul>
</li>
<li>如有必要，根据上述问题的答案，改进最近的研究（或研究组）以改进搜索空间和&#x2F;或抽样更多试验，或采取其他一些纠正措施。</li>
<li>一旦我们回答了上述问题，我们就可以继续评估实验为我们最初的目标提供的证据（例如，<a href="#detecting-whether-a-change-is-useful-with-isolation-plots">评估改变是否有用</a>）。</li>
</ul>
<h4 id="识别错误的搜索空间边界"><a href="#识别错误的搜索空间边界" class="headerlink" title="识别错误的搜索空间边界"></a>识别错误的搜索空间边界</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>如果从搜索空间中采样的最佳点靠近其边界，那么这个搜索空间就有可疑之处。如果我们将搜索范围朝着这个方向扩大，我们可能会找到更优秀的点。</li>
<li>为了检查搜索空间边界，我们喜欢在被我们称之为<strong>基本超参数轴图</strong>的图表绘制已完成的试验，我们在其中绘制验证目标值与其中一个超参数（例如学习率）的关系。图中的每个点都对应于一次试验。<ul>
<li>每次试验的验证目标值通常应该是它在训练期间达到的最佳值。</li>
</ul>
</li>
</ul>
<p align="center" id="figure-1">
<img src="assets/bad_search_space.png" width="49%" alt="Example of bad search space boundaries">
<img src="assets/good_search_space.png" width="49%" alt="Example of good search space boundaries">
</p>

<p align="center"><b>图 1：</b>不良的搜索空间边界和可接受的搜索空间边界示例。</p>

<ul>
<li><a href="#figure-1">Figure 1</a>中的图表显示错误率（越低越好）与初始学习率的关系。</li>
<li>如果最佳点聚集在搜索空间的边缘（在某个维度上），则可能需要扩展搜索空间边界，直到最佳观察点不再靠近边界。</li>
<li>通常，一项研究将包括“不可行”的试验，这些试验会产生分歧或得到非常糟糕的结果（在上图中用红色 X 标记）。<ul>
<li>如果所有试验对于大于某个阈值的学习率都是不可行的，并且如果表现最好的试验在该区域的边缘具有学习率，则模型<a href="#how-can-optimization-failures-be-debugged-and-mitigated">可能遇到了稳定性问题，从而无法获得更高的学习率</a>。</li>
</ul>
</li>
</ul>
</details>

<h4 id="没有在搜索空间中采样足够的点"><a href="#没有在搜索空间中采样足够的点" class="headerlink" title="没有在搜索空间中采样足够的点"></a>没有在搜索空间中采样足够的点</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>一般来说，<a href="#how-many-trials-are-needed-to-get-good-results-with-quasi-random-search">可能很难知道</a>是否搜索空间已经被足够密集地采样。🤖</li>
<li>运行更多的试验当然更好，但代价是显而易见的。</li>
<li>由于很难知道我们什么时候采样足够，我们通常会采样我们可以负担得起的代价，并尝试通过反复查看各种超参数轴图来校准我们的直觉，并试图了解有多少点位于搜索空间的“好”区域。</li>
</ul>
</details>

<h4 id="检查训练曲线"><a href="#检查训练曲线" class="headerlink" title="检查训练曲线"></a>检查训练曲线</h4><details><summary><em>[点击展开]</em></summary>

<br>

<p><em><strong>总结</strong></em>： <em>检查训练曲线是识别常见故障的一种简单方法，也可以帮助我们优先考虑下一步采取什么行动。</em></p>
<ul>
<li>虽然在许多情况下，我们实验的主要目标只需要考虑每次试验的验证误差，但在试验中将验证误差减少到固定数字时我们必须小心，因为它可以隐藏表面下发生的事情的重要细节。</li>
<li>对于每一项研究，我们总是查看至少是最好的几项试验的<strong>训练曲线</strong>（绘制的训练误差和验证误差与训练期间训练步数的关系图）。</li>
<li>即使这对于解决主要的实验目标不是必要的，但检查训练曲线是识别常见故障模式的简单方法，也可以帮助我们优先考虑下一步采取什么行动。</li>
<li>在检查训练曲线时，我们对以下问题感兴趣。</li>
<li>是否有任何试验显示<strong>过拟合</strong>？<ul>
<li>当验证误差在训练期间的某个时刻开始<em>增加</em>时，就会发生过度拟合。</li>
<li>在试验中(我们对目标超参数的不同设置选取最佳试验效果的试验[这实际上优化了冗余超参数])，我们应该<em>至少</em>在目标超参数的每个设置相对应的最佳试验中检查是否有过拟合问题。<ul>
<li>如果任何最佳试验出现过拟合问题，我们通常会在比较目标超参数的不同值之前使用额外的正则化技术重新运行实验和&#x2F;或更好地调整现有的正则化参数(防止因固定超参数的设置漏掉可能的优解？)。<ul>
<li>如果目标超参数包括正则化参数，这可能不适用，因为如果这些正则化参数的低强度设置导致有问题的过拟合是不足为奇的。</li>
</ul>
</li>
<li>使用常见的正则化技术减少过度拟合通常很简单，这些技术增加了代码复杂性的下届或额外的计算（例如，dropout、标签平滑化、权重衰减），因此在下一轮实验中添加一个或多个这些通常问题不大。</li>
<li>举个例子，如果目标超参数是“隐藏层数”，当使用最大隐藏层数的最佳试验表现出过拟合问题，那么我们通常更愿意使用额外的正则化再次尝试，而不是立即选择较小数量的隐藏层。</li>
<li>即使“最佳”试验都没有表现出有过拟合，但它发生在<em>所有</em>试验中时，这就可能存在问题。<ul>
<li>选择最佳试验会抑制出现过拟合问题的配置，并偏向那些不会出现过拟合问题的配置。换句话说，它对具有更多正则化的配置更偏爱。</li>
<li>然而，任何让训练变得更糟的事情都可以作为正则化器，即使它不是故意的。例如，选择较小的学习率可以通过阻碍优化过程来规范训练，但我们通常不希望以这种方式选择学习率。</li>
<li>因此，我们必须意识到，目标超参数的每个设置的“最佳”试验是否会以有利于某些目标或冗余超参数像“坏”值的方式选择。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>在训练后期，训练或验证误差是否存在较高的步与步之间的<a href="https://math.stackexchange.com/questions/3604607/can-i-work-out-the-variance-in-batches">方差</a>？<ul>
<li>如果是这样，这可能会干扰我们比较目标超参数的不同值的能力（因为每个试验都随机地在 “幸运 “或 “不幸运 “的一步上结束），以及我们在生产中重现最佳试验结果的能力（因为生产模型可能不会像研究中那样在 “幸运 “一步上结束）。</li>
<li>导致步间方差的最大可能的是Batch的方差（应当从训练集中随机抽取样本），过小的验证集，以及在训练后期使用过高的学习率。 </li>
<li>可能的补救措施包括增加Batch Size，使用更多的验证数据，使用学习率衰减，或使用Polyak平均法。</li>
</ul>
</li>
<li>训练结束时试验是否仍能改进？<ul>
<li>如果是这样，这表明我们在<a href="#determining-the-number-of-steps-for-each-training-run">“计算限制”</a>制度中，我们可能会受益于<a href="#Deciding-how-long-to-train-when-training-is-compute-bound">增加训练步数</a>或更改学习率计划。</li>
</ul>
</li>
<li>训练集和验证集的性能在最后的训练步骤之前很久就饱和了吗？<ul>
<li>如果是这样，这表明我们处于<a href="#determining-the-number-of-steps-for-each-training-run">“不受计算限制”</a>制度中，我们可能能够<a href="#deciding-how-long-to-train-when-training-is-not-compute-bound">减少训练步数</a>。</li>
</ul>
</li>
<li>虽然我们不能一一列举，但还有许多其他的行为可以通过检查训练曲线而变得明显（例如，训练误差在训练过程中增加，通常表明训练工作流中存在错误）。</li>
</ul>
</details>

<h4 id="使用isolation图检测更改是否有用"><a href="#使用isolation图检测更改是否有用" class="headerlink" title="使用isolation图检测更改是否有用"></a>使用isolation图检测更改是否有用</h4><details><summary><em>[点击展开]</em></summary>

<br>


<p align="center" id="figure-2">
<img src="assets/isolation_plot.png" width="49%" alt="Isolation plot that investigates the best value of weight decay for ResNet-50 trained on ImageNet.">
</p>




<p align="center"><b>图 2：</b>研究在 ImageNet 上训练的 ResNet-50 的最佳权重衰减值的isolation图。</p>

<ul>
<li>通常，一组实验的目标是比较目标超参数的不同值。<ul>
<li>例如，我们可能想要确定导致最佳验证误差的权重衰减值。</li>
</ul>
</li>
<li><strong>isolation图</strong>是基本超参数轴图的特例。isolation图上的每个点对应着在优化某些（或全部）冗余超参数上最佳试验的性能。<ul>
<li>换句话说，我们绘制了在”优化掉”冗余超参数后模型的性能。</li>
</ul>
</li>
<li>isolation图可以更轻松地在目标超参数的不同值之间进行同类比较。</li>
<li>例如，<a href="#%E5%9B%BE2">图2</a>显示了在ImageNet上训练的ResNet-50的特定配置(学习率)下产生最佳验证性能的权重衰减值。<ul>
<li>如果我们的目标是确定是否要加入权重衰减，那么我们会将此图中的最佳点与没有权重衰减的Baseline进行比较。为了公平比较，Baseline的学习率也应该同样得到很好的调整。</li>
</ul>
</li>
<li>当我们正在考虑为一个连续的超参数来绘制isolation图时，并且我们是使用Quasi-Random-Search(近似随机搜索)产生的超参数的不同值时，我们可以通过对基本超参数轴图的X轴值进行分桶，并在分桶定义的每个垂直切片中取最佳试验来近似绘制隔离图。</li>
</ul>
</details>

<h4 id="自动化常用的绘图"><a href="#自动化常用的绘图" class="headerlink" title="自动化常用的绘图"></a>自动化常用的绘图</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>当第一次生成此类图表花费的努力越多，您查看这类图表的频率就越低。因此，最好将您的基础策略设为自动生成尽可能多的图表。</li>
<li>至少，我们会为我们在实验中变化的所有超参数自动生成基本超参数轴图。</li>
<li>此外，我们会自动为所有试验生成训练曲线，并尽可能轻松地找到每项研究中最好的几次试验并检查它们的训练曲线。</li>
<li>我们可以也添加许多其他有用的潜在图表和可视化。尽管上面的例子的是一个很好的起点，但套用杰弗里 · 辛顿 (Geoffrey Hinton) 的话，“每次设计新事物时，您都会学到新事物。”</li>
</ul>
</details>

<h3 id="确定是否采用此训练工作流更改或超参数配置"><a href="#确定是否采用此训练工作流更改或超参数配置" class="headerlink" title="确定是否采用此训练工作流更改或超参数配置"></a>确定是否采用此训练工作流更改或超参数配置</h3><p><em><strong>总结</strong></em>： <em>当决定是否对我们的模型或训练程序进行改变或采用新的超参数配置时，我们需要理解导致我们结果中不同的变化的来源。</em></p>
<ul>
<li>当我们试图改进我们的模型时，我们可能会观察到，与我们现有的配置相比，一个特定的候选变化最初取得了更好的验证误差，但在重复实验后发现，没有发现一致的优势。非正式地，我们可以把可能导致这种不一致结果的最重要的变化来源分为以下几大类。<ul>
<li><strong>训练程序方差</strong>、<strong>再训练方差</strong>或<strong>试验方差</strong>：我们在使用相同的超参数但不同的随机种子的训练运行之间看到的差异。<ul>
<li>例如，不同的随机初始化、训练数据的shuffles、dropout掩码、数据增强操作的模式和并行运算的顺序，都是试验方差的潜在来源。</li>
</ul>
</li>
<li><strong>超参数搜索方差</strong>或<strong>学习方差</strong>：由我们选择超参数的程序引起的结果变化。<ul>
<li>例如，我们可能会在特定搜索空间运行相同的实验，但使用两个不同的种子进行Quasi-Random-Search搜索，并最终选择不同的超参数值。</li>
</ul>
</li>
<li><strong>数据收集和抽样方差</strong>：训练数据、验证数据和测试数据的任何一种随机分割所产生的方差，或者更普遍的由于训练数据生成过程而产生的方差。</li>
</ul>
</li>
<li>使用严格的统计测试对有限验证集上估计的验证错误率进行比较是很好的，但往往仅试验方差就能在使用相同超参数设置的两个不同的训练模型之间产生统计上的显著差异。</li>
<li>当我们试图得出超出超参数空间中单个点水平的结论时，我们最关心的是学习方差。<ul>
<li>学习方差取决于试验次数和搜索空间，我们已经看到它大于试验方差的情况以及它小得多的情况。</li>
</ul>
</li>
<li>因此，在采用一个候选变化之前，考虑运行最佳试验N次，以估计训练方差。<ul>
<li>通常情况下，我们可以只在工作流发生重大变化后重新对试验方差进行估计，但在某些应用中，我们可能需要使用更新鲜的估计。 </li>
<li>在其他应用中，估计试验方差的成本太高，不值得这样做。</li>
</ul>
</li>
<li>归根结底，虽然我们只想采用能够产生真正改进的更改（包括新的超参数配置），但要求完全相信某些东西会有所帮助也不是正确的要求。</li>
<li>因此，如果一个新的超参数点（或其他变化）得到比Baseline更好的结果（尽可能考虑新点和Baseline的再训练方差），那么我们可能应该采用它作为新的Baseline为以后的比较。<ul>
<li>但是，我们应该只采用产生的改进超过它们增加的复杂性的更改。</li>
</ul>
</li>
</ul>
<h3 id="探索结束后"><a href="#探索结束后" class="headerlink" title="探索结束后"></a>探索结束后</h3><p><em><strong>总结</strong></em>： <em>一旦我们完成了对“好”的搜索空间的探索，并决定了哪些超参数甚至应该被调整，贝叶斯优化工具就是一个值得考虑的选择。</em></p>
<ul>
<li>在这个时候，我们的优先事项将从学习更多优化经验转向产生一个最佳配置来启动或以其他方式使用。</li>
<li>在这一点上，我们应该有一个精确的搜索空间，可以舒适地包含最佳观察试验周围的局部区域，并且已经过充分采样。</li>
<li>我们的探索工作应该已经揭示了最重要的要调整的超参数（以及它们的合理范围），我们可以使用这些超参数来构建搜索空间，以使用尽可能大的调整预算进行最终的自动调整研究。</li>
<li>由于我们不再关心最大化我们对优化问题的经验，<a href="#why-use-quasi-random-search-instead-of-more-sophisticated-black-box-optimization-algorithms-during-the-exploration-phase-of-tuning">Quasi-Random-Search的优化方式</a>不再适用，这时应该使用贝叶斯优化工具来自动找到最佳超参数配置。<ul>
<li>如果搜索空间包含大量发散点（获得 NaN 训练损失或比平均值差很多标准差的训练误差的点），使用黑盒优化工具来正确处理发散试验很重要（请参阅<a href="https://arxiv.org/abs/1403.5607">具有未知约束的贝叶斯优化</a>是处理此问题的绝佳方法）。</li>
</ul>
</li>
<li>此时，我们还应该考虑检查测试集上的性能。<ul>
<li>原则上，我们甚至可以将验证集折叠到训练集中，并重新训练通过贝叶斯优化找到的最佳配置。但是，这只适用于未来不会有这种特定工作需求的情况（例如，单次 Kaggle 竞赛）。</li>
</ul>
</li>
</ul>
<h2 id="确定每次训练运行的步数"><a href="#确定每次训练运行的步数" class="headerlink" title="确定每次训练运行的步数"></a>确定每次训练运行的步数</h2><ul>
<li>有两种类型的工作模式：受计算限制的和不受计算限制的。</li>
<li>当训练为<strong>受计算限制</strong>时，训练受限于我们愿意等待的时间，而不是受我们拥有多少训练数据或其他因素的限制。<ul>
<li>在这种情况下，如果我们能以某种方式延长训练时间或提高训练效率，我们应该看到较低的训练损失，并且通过适当的调整，改善验证损失。</li>
<li>换句话说，加快训练速度就等于改善训练效果，而 “最佳 “训练时间总是 “我们愿意等待的时间”范围内。</li>
<li>然而，当工作模式受计算限制时，并不意味我们只能通过更长&#x2F;更快的训练来改善结果。</li>
</ul>
</li>
<li>当训练为<strong>不受计算限制</strong>时，我们可以负担得起训练的时间，只要我们愿意。或在某些时候，训练更长的时间并没有多大帮助（甚至会导致过拟合）。<ul>
<li>在这种情况下，我们应该期望能够训练到非常低的训练误差，训练时间更长可能会略微减少训练误差，但不会显着减少验证误差。</li>
<li>当训练不受计算限制时，慷慨的训练时间预算可以使调整更容易，特别是在调整学习率衰减计划时，因为它们与训练预算有特别强的相互作用。<ul>
<li>换句话说，吝啬的训练时间预算可能需要将学习率衰减计划调整到完美，以实现良好的训练效果。</li>
</ul>
</li>
</ul>
</li>
<li>不管一个给定的工作负载是否是计算约束，使用增加梯度方差（跨Batch）的方法通常会导致较慢的训练进度，从而可能增加达到特定验证损失所需的训练步骤。高梯度方差可能是由以下原因造成的。<ul>
<li>使用了较小的Batch Size</li>
<li>使用了数据增强技术</li>
<li>添加了一些类型的正则化（例如 dropout）</li>
</ul>
</li>
</ul>
<h3 id="当训练不受计算限制时如何决定该训练多久"><a href="#当训练不受计算限制时如何决定该训练多久" class="headerlink" title="当训练不受计算限制时如何决定该训练多久"></a>当训练不受计算限制时如何决定该训练多久</h3><ul>
<li>我们的主要目标是确保我们训练的时间足够长，以使模型达到最佳效果，同时避免在训练步数的数量上过度浪费。</li>
<li>在有疑问的时候，请偏向于选择延长训练时间。假设回顾性（最佳）检查点选择使用得当，并且检查点足够频繁，那么训练时间越长，性能就越不会下降。</li>
<li>不要在训练中调整 <code>max_train_steps</code> 以获得更好的效果。我们只需要选择一个值并将其用于所有试验。从这些试验中，绘制回顾检查点选择发现的训练steps，以优化<code>max_train_steps</code>的数值。<ul>
<li>例如，如果最佳step总是出现在训练过程的前10%，那么最大训练step数就太高了。</li>
<li>或者，如果最好的step总是出现在训练过程的最后的25%中，我们可能可以在增加训练时间和重新调整学习率衰减策略中受益(都与max_train_steps相关)。</li>
</ul>
</li>
<li>当模型架构或数据发生变化时(例如添加数据增强)，理想的训练的step数也会发生变化。</li>
<li>下面我们将描述如何根据使用恒定学习率“完全拟合”训练集所需的step数，为<code>max_train_steps</code>选择初始候选值。<ul>
<li>注意，我们并没有以精确或数学定义良好的方式使用短语“完美拟合训练集”。<br>它只是一个非正式的描述语，表示非常低的训练损失。<ul>
<li>例如，当训练损失为log loss且没有正则化项时，我们可能会看到训练损失会一直在缓慢减小(这与log loss的特性有关)，直到达到浮点极限（floating point limits），因为网络权重可以无限制地增长，模型会对训练集的预测变得越来越自信。在这种情况下，我们可能会说，当训练集中的错误分类为0时，模型“完全拟合”训练集。</li>
</ul>
</li>
<li>如果训练过程中 gradient noise(译注：可参考Umut Simsekl et al) 增大时，则<code>max_train_steps</code>可能需要增加起始值。<ul>
<li>例如，如果在模型中引入数据增强或dropout等正则化方法。</li>
</ul>
</li>
<li>如果训练过程以某种方式改进，可能会减少<code>max_train_steps</code>。<ul>
<li>例如，使用更好的优化器或更好的学习率更新策略。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="使用学习率搜索算法来确定-max-train-steps-的初始值"><a href="#使用学习率搜索算法来确定-max-train-steps-的初始值" class="headerlink" title="使用学习率搜索算法来确定 max_train_steps 的初始值"></a>使用学习率搜索算法来确定 max_train_steps 的初始值</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>此过程假设不仅可以“完美”地拟合训练集，而且可以使用恒定的学习率更新策略来实现。</li>
<li>如果可以完美地拟合整个训练集，那么<code>max_train_steps</code>应该有一个确定的值可以完美地拟合训练集；找到这个值作为<code>max_train_stepsd</code>的起点<code>N</code></li>
<li>在没有数据增强和正则化的情况下运行恒定的学习率搜索（即网格搜索学习率），其中每个试验训练 <code>N</code> 步骤。</li>
<li>在搜索中最快达到完美训练的实验所需的步数就是我们对 <code>max_train_steps</code> 的初步猜测。</li>
<li><strong>注意：</strong> 错误的搜索空间可能会导致自欺欺人。<ul>
<li>例如，如果一项研究中的所有学习率都太小，我们可能会错误地得出结论，认为一个非常大的<code>max_train_steps</code>的值是必要的。</li>
<li>至少，我们应该检查研究中的最佳学习率是否在搜索空间的边界(基本超参数轴图)。</li>
</ul>
</li>
</ul>
</details>

<h3 id="当训练受计算限制时如何决定该训练多久"><a href="#当训练受计算限制时如何决定该训练多久" class="headerlink" title="当训练受计算限制时如何决定该训练多久"></a>当训练受计算限制时如何决定该训练多久</h3><ul>
<li>在某些情况下，训练误差会无限地改善，而我们的耐心和计算资源就成为了限制因素。</li>
<li>如果训练误差（或甚至验证误差）可以无限地改善，我们是否应该在我们能接受的情况下一直训练？答案是不必要。<ul>
<li>通过运行更多的短时间的实验，我们可以更快地找到最佳的模型和优化器超参数，而不必浪费大量的计算资源和时间在不优秀的超参数上。最后，我们可能会运行少量的长时间(“production length” 指模型在生产环境中运行的时间,也就是预期的长时间训练)的实验来在最佳超参数点上获得最终模型。这样，我们就可以更有效地使用我们的资源来调整最有可能在生产环境中表现良好的模型。</li>
<li>我们的训练时间越长，我们对模型的理解就会越深入，这样我们就可以更好的了解模型的性能和限制，因此我们可以更确定哪些参数是最有可能在生产环境中表现良好的参数。但是，当我们的训练时间越长，我们能完成的实验就会越少，因为我们的耐心和计算资源有限。</li>
<li>当我们只训练 ~10% 的production length时，我们可能能够回答很多问题，但是在这个时间限制下的结论不一定适用于20%的production length的实验，更不用说100%了。这是因为训练模型的时间越长，模型就会越来越接近其最佳性能，而在较短的训练时间内得出的结论可能不能完全适用于长时间训练后的模型。</li>
</ul>
</li>
<li>因此我们建议在每轮调整中逐渐增加训练步数限制，以在有限的资源和耐心内获得最大的理解，并在最终长时间训练后再进行验证和确认。<ul>
<li>我们可以想做多少轮就做多少轮，但通常 1-3 轮是最实用的。</li>
<li>从本质上讲，在进行调整时要在两个方面进行平衡：相关性和彻底性。相关性指的是调整结果与最终长时间运行之间的相似性，而彻底性则指调整结果的详尽程度。因此，在进行调整时，我们应该尽量使用快速转换时间的试验来获得尽可能多的问题理解，同时保证这些结论与最终长时间运行相关。这样可以在有限的时间和资源内获得最大的理解，并尽可能地减少对最终长时间运行的影响。</li>
<li>一旦给定的每次试验时间限制中产生了有用的见解，我们就可以增加训练时间并继续调整，以确保它们在长时间运行中仍然适用。</li>
</ul>
</li>
<li>作为起点，我们建议进行两轮调整：<ul>
<li>第一轮：进行短时间的训练来找到较佳的模型和优化器超参数</li>
<li>第二轮：在较佳的超参数上进行少量长时间的训练来得到最终模型</li>
</ul>
</li>
<li>从 <code>Round i</code> → <code>Round i+1</code> 的最大问题是如何调整学习率衰减计划。<ul>
<li>在进行调整时，最大的问题是如何调整学习率衰减计划。在调整学习率衰减计划时的一个常见问题是使用了太小的学习率，如果学习率过小，模型的收敛速度会变慢，可能会需要更多的训练步骤才能达到最优状态。这可能会增加训练时间并增加计算资源的需求。</li>
</ul>
</li>
</ul>
<h4 id="第一轮"><a href="#第一轮" class="headerlink" title="第一轮"></a>第一轮</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>遗憾的是，在短时间和不完整训练中找到的超参数在增加训练长度后仍然是好选择的保证是没有的。但是，对于某些类型的超参数，它们通常具有足够的相关性，因此第一轮非常有用。</li>
<li>我们期望在短运行中找到的哪些超参数值会转移到更长的训练运行中？对于这一切，我们需要更多的研究。但是根据已有的结论我们可以提出一些猜测，以下是作者的猜测，按转移概率的降序排列：<ul>
<li>极有可能转移<ul>
<li>在第一轮调参中，使用较少的训练步数可以解决早期训练的不稳定性。也许这些超参数是最能保证转移的选择。<ul>
<li>Warmup时长</li>
<li>模型参数初始值</li>
</ul>
</li>
</ul>
</li>
<li>可能转移<ul>
<li>模型架构 - 模型架构上的显著胜利通常会转移，但可能有很多例外。</li>
</ul>
</li>
<li>可能会转移<ul>
<li>优化算法&#x2F;优化器超参数——我们认为这将”松散”转移。它明显比上面的东西弱。</li>
<li>数据增强方法</li>
<li>正则化<ul>
<li>如果不可能完美地拟合训练集，则模型可能处于正则化不太可能有太大的帮助。</li>
</ul>
</li>
</ul>
</li>
<li>不太可能转移<ul>
<li>学习率衰减计划：不太可能完美迁移。<ul>
<li><a href="https://arxiv.org/abs/2203.15556">This paper</a>说学习率衰减计划也能转移。但我们不相信这在通常情况下是正确的。例如：在较少的训练步骤上调整开根号衰减，然后扩展到大量训练步骤将导致在过小的步骤上进行大部分训练。<ul>
<li>在极端训练预算限制下，可能可以用大多数计划做到“足够好”，但如果进行了调整，可能会看到明显的性能改进。</li>
</ul>
</li>
<li><a href="https://arxiv.org/abs/1803.02021">了解随机元优化中的短期偏差</a>描述了选择学习率的短视危险。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>

<h4 id="第二轮"><a href="#第二轮" class="headerlink" title="第二轮"></a>第二轮</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>运行第一轮中最佳的超参数配置。</li>
<li><strong>（推测）</strong> 🤖使用额外的步骤来延长高学习率的训练时间。<ul>
<li>例如，如果是线性计划，则保持第一轮中衰减大小的固定值，并在开始时延长恒定的lr期。</li>
<li>对于余弦衰减，只需保留第一轮的基础 lr 并像<a href="https://arxiv.org/abs/2203.15556"> Chinchilla 论文 </a>一样增大 <code>max_train_steps</code>。</li>
</ul>
</li>
<li>对于具有非常成熟建模和调整的工作流以及非常长且昂贵的生产训练运行的团队来说，更多回合可能更有意义，但它们通常会过于复杂。<ul>
<li>我们已经描述了如何从第一轮  → 第二轮 进行转换。如果我们不关心分析时间，并且计算效率是关键因素，那么理想情况是在许多不同的调整轮次中逐渐增加训练运行的长度(从而增加完成研究的总体时间)。<ul>
<li>在每一轮中，我们都系统地确保我们的选择仍然是正确的。</li>
<li>新的想法经过一个完整的工作，越来越长时间的实验逐渐降低了它不可用的风险。</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>

<h2 id="关于训练管道的额外补充"><a href="#关于训练管道的额外补充" class="headerlink" title="关于训练管道的额外补充"></a>关于训练管道的额外补充</h2><h3 id="优化输入管道"><a href="#优化输入管道" class="headerlink" title="优化输入管道"></a>优化输入管道</h3><p><em><strong>总结</strong></em>： <em>输入管道性能受限的原因及干预措施与具体任务高度相关，使用性能分析工具并注意常见的一些问题。</em></p>
<ul>
<li>使用适当的性能分析工具来诊性能受限的输入管道，例如，用于 JAX 的 <a href="https://jax.readthedocs.io/en/latest/profiling.html">Perfetto</a> 或用于 TensorFlow 的 <a href="https://www.tensorflow.org/guide/profiler">TensorFlow profiler</a>。</li>
<li>归根结底，具体原因和干预措施将高度依赖于任务。更广泛的工程考虑(如减少磁盘空间占用)可能会导致较差的输入管道性能。</li>
<li>常见问题：<ul>
<li>数据未与训练进程存放在同一位置，从而导致I&#x2F;O延迟(通过网络读取训练数据时可能会发生这种情况)。</li>
<li>昂贵的在线数据预处理(考虑进行一次性离线预处理并保存)。</li>
<li>无意间的同步屏障干扰数据管道预读取。例如，在 CommonLoopUtils(<a href="https://github.com/google/CommonLoopUtils/blob/fea2518ada8814a78e1492023fd9f00edb0b0568/clu/metrics.py#L291">link</a>) 中同步设备和主机之间的数据时。</li>
</ul>
</li>
<li>常见技巧：<ul>
<li>例如使用 <a href="https://www.tensorflow.org/guide/data_performance#prefetching">tf.data.Dataset.prefetch</a> 之类的工具对输入管道预读取数据。</li>
<li>尽可能早地在管道中删除不必要的特征和元数据。</li>
<li>通过使用 <a href="https://www.tensorflow.org/api_docs/python/tf/data/experimental/service">tf.data service</a> 来增加输入管道生成数据的进程的数量。</li>
</ul>
</li>
</ul>
<h3 id="评估模型性能"><a href="#评估模型性能" class="headerlink" title="评估模型性能"></a>评估模型性能</h3><p><em><strong>总结</strong></em>： <em>使用比训练时更大的 batch size 进行评估。在固定步长间隔进行评估，而不是固定的时间间隔。（注：如100个epoch评估一次，而不是10分钟评估一次）。</em></p>
<h4 id="评估设置"><a href="#评估设置" class="headerlink" title="评估设置"></a>评估设置</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>我们可以通过多种方式来评估模型的性能。<ul>
<li>在线评估-当模型在生产环境中提供预测时收集指标。</li>
<li>离线评估-当模型在代表生产环境的离线训练&#x2F;验证&#x2F;测试集上运行时，收集指标。</li>
<li>定期评估-在模型训练期间收集的指标可能是离线评估的代理，和(或)离线评估中使用的数据的子集。</li>
</ul>
</li>
<li>在线评估是最佳标准，但在模型开发阶段往往是不切实际的。</li>
<li>根据问题的不同，离线评估可能会相当复杂，并且计算成本很高。</li>
<li>定期评估是最实际和最经济的选择，但可能不能完全代表生产环境。<ul>
<li>我们在定期评估时的目标是在训练期间获得可靠信号，使同时尽可能缩短评估时间。</li>
</ul>
</li>
</ul>
</details>

<h4 id="设置定期评估"><a href="#设置定期评估" class="headerlink" title="设置定期评估"></a>设置定期评估</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>我们在训练期间定期进行评估，以实时监控其进度，以便于<a href="https://github.com/google-research/tuning_playbook#:~:text=facilitate%20retrospective%20model%20checkpoint%20selection">追溯模型检查点选择</a>，以便我们可以在<a href="https://github.com/google-research/tuning_playbook#:~:text=examine%20the%20training%20curves%20at%20the%20end%20of%20training">训练结束时检查训练曲线</a>。</li>
<li>其中最简单的配置是在同一计算实例中执行训练和定期评估，并定期在训练和评估之间交替。(注：比如固定步长间隔评估一次）</li>
<li>在这种情况下，用于执行评估的 batch size 大小应该至少与用于训练的 batch size 大小一样大，因为在评估期间不需要保持模型运行（注：如不用计算梯度之类的），从而降低了每个示例的计算要求。</li>
<li>定期评估应在固定步长间隔进行，而不是按时间间隔进行。<ul>
<li>基于时间间隔进行评估可能会使解释训练曲线变得更加困难，尤其是在培训可能受到训练作业抢占、网络延迟问题等影响的情况下。</li>
<li>有效&#x2F;测试度量中的周期性(当使用打乱后的训练&#x2F;确认&#x2F;测试分割时)可以指出某些实现错误，例如测试数据与训练数据重叠，或者训练数据没有被适当地打乱。这些问题可以通过在固定步长间隔进行评估来更容易地检测到。</li>
<li>当评估集不能被 batch size 整除时，会出现部分 batch 的情况。确保填充的数据被正确地加权，以防止损失函数产生偏向。通常，这些填充的数据可以被赋予零的权重。</li>
<li>最后，保存每次评估的足够信息，以支持离线分析。理想情况下，我们将保存一些单个示例的预测，因为它们对于调试来说非常有价值。<ul>
<li>生成像 <a href="https://www.tensorflow.org/guide/saved_model">SavedModels</a> 这样的构件可以轻松地在评估完成后进行即时模型检查。</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>

<h4 id="选择样本进行定期评估"><a href="#选择样本进行定期评估" class="headerlink" title="选择样本进行定期评估"></a>选择样本进行定期评估</h4><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>定期评估作业的运行速度可能不够快，无法在合理的时间内计算完整离线评估集的指标。这通常需要对数据进行抽样以进行定期评估。</li>
<li>在构建采样数据集时，我们会考虑以下因素：<ul>
<li><u>样本量</u><ul>
<li>确保定期作业使用的采样数据集的性能与整个离线评估集的性能相似，确保采样集与完整数据集之间没有偏差。</li>
</ul>
<ul>
<li>用于定期评估的数据集应该足够小，以便很容易生成整个模型的预测，但也应该足够大，以便可以准确地测量模型的改进(即不被大量标签噪声影响)。</li>
</ul>
<ul>
<li>它应该足够大，以适应顺序试验中的多个这样的评估，并仍然产生准确的估计。也就是说，避免在多轮评估中对验证集过度适应，从而影响模型对留出集的表现。然而，这种考虑很少是一个实际的问题。</li>
</ul>
</li>
<li><u>不平衡的数据集</u><ul>
<li>对于不平衡的数据集，在稀有类别样本上的表现往往会有噪音。</li>
<li>对于每个类别只有少量样本的数据集，记录正确预测样本的数量，可以更深入地了解准确性改进(.05灵敏度改进听起来很令人兴奋，但它只是因为更多的样本被正确预测了吗？)</li>
</ul>
</li>
</ul>
</li>
</ul>
</details>

<h3 id="保存检查点并追溯选择最佳检查点"><a href="#保存检查点并追溯选择最佳检查点" class="headerlink" title="保存检查点并追溯选择最佳检查点"></a>保存检查点并追溯选择最佳检查点</h3><p><em><strong>总结</strong></em>：<em>运行固定步长的训练，并回顾性地从中选择最佳检查点。</em></p>
<ul>
<li>大多数深度学习框架都支持<a href="https://flax.readthedocs.io/en/latest/api_reference/flax.training.html">模型检查点</a>。模型的当前状态会定期保存在磁盘上。这允许训练作业对计算实例中断具有弹性。</li>
<li>最佳检查点并不一定是最后一个检查点，尤其是当验证集性能不会随时间持续增加而是围绕特定值波动时。</li>
<li>设置管道以跟踪到目前为止在训练期间看到的 N 个最佳检查点。在训练结束时，模型选择就是选择训练期间看到的最佳检查点。我们将此称为 <strong>回顾性最佳检查点选择</strong>。</li>
<li>因为预先指定了试验预算并保留了迄今为止看到的 N 个最佳检查点，所以通常不必要支持预期提前停止。</li>
</ul>
<h3 id="设置实验跟踪"><a href="#设置实验跟踪" class="headerlink" title="设置实验跟踪"></a>设置实验跟踪</h3><p><em><strong>总结</strong></em>：<em>在跟踪不同的实验时，一定要注意一些要点，比如研究中检查点的最佳性能，以及对研究的简短描述。</em></p>
<ul>
<li>我们发现，在电子表格中跟踪实验结果有助于我们解决各种建模问题。它通常有以下列：<ul>
<li>实验名称</li>
<li>实验配置存储位置的链接</li>
<li>实验的注释或简短描述</li>
<li>运行次数</li>
<li>最佳模型在验证集上的表现</li>
<li>训练所需的配置和运行命令</li>
</ul>
</li>
<li>选择一种跟踪系统，能够满足上述信息的记录要求并且对使用者友好易用是非常重要的，未经记录的实验可能不会得到重视。</li>
</ul>
<h3 id="BatchNorm的实现细节"><a href="#BatchNorm的实现细节" class="headerlink" title="BatchNorm的实现细节"></a>BatchNorm的实现细节</h3><p><em><strong>总结</strong></em>：<em>目前Batch Norm通常可以用Layer Norm代替，但在不能替换的情况下，在更改批大小或主机数量时会有一些棘手的细节。</em></p>
<ul>
<li>Batch norm 使用当前批次的均值和方差对激活值进行归一化，但在多设备设置中，除非明确同步处理，否则这些统计数据在每个设备上都是不同的。</li>
<li>据说（主要在ImageNet上）仅使用约 64 个样本计算这些归一化统计数据在实际应用中效果更好（请参阅 <a href="https://arxiv.org/abs/1705.08741">Ghost Batch Norm</a>）。</li>
<li>将总批大小与用于计算批归一化统计数据的样本数量分离对于批次大小的比较特别有用。</li>
<li>Ghost batch norm 实现并不总能正确处理每台设备的批次大小 &gt; 虚拟批次大小的情况。在这种情况下，我们实际上需要在每个设备上对批次进行二次抽样，以获得适当数量的批归一化统计样本。</li>
<li>在测试模式中使用的指数移动平均(EMA）仅仅是训练统计数据的线性组合，因此这些 EMA 只需要在将它们保存在检查点之前进行同步。然而一些常见的批归一化实现不同步这些EMA，并只保存第一个设备的EMA。</li>
</ul>
<h3 id="多主机管道的考虑因素"><a href="#多主机管道的考虑因素" class="headerlink" title="多主机管道的考虑因素"></a>多主机管道的考虑因素</h3><p><em><strong>总结</strong></em>： <em>在日志记录、评估、RNG(随机数生成器)、检查点和数据分片方面，多主机训练非常容易引入错误！</em></p>
<ul>
<li>保证管道只在一台主机上进行日志记录和检查点</li>
<li>确保在运行评估或检查点之前，批处理规范统计信息在主机之间同步</li>
<li>保证在多主机之间使用相同的随机数生成器种子(用于模型初始化)和不同的种子(用于数据混洗和预处理)是非常重要的，因此请确保合适地标记它们</li>
<li>为了提升性能，通常建议将数据文件在多台主机之间进行分片</li>
</ul>
<h2 id="常见问题的回答"><a href="#常见问题的回答" class="headerlink" title="常见问题的回答"></a>常见问题的回答</h2><h3 id="最好的学习率衰减方案是什么"><a href="#最好的学习率衰减方案是什么" class="headerlink" title="最好的学习率衰减方案是什么"></a>最好的学习率衰减方案是什么</h3><details><summary><em>[点击展开]</em></summary>

<br>

<ul>
<li>这是一个开放性问题。目前尚不清楚如何构建一组严格的实验来自信地回答最佳的LR 衰减方案是什么。</li>
<li>虽然我们不知道最好的方案是什么，但我们相信尝试一些（非恒定的）方案很重要并且调整它很重要。</li>
<li>在优化过程中，不同的学习率在不同的时间效果最好。 有某种衰减方案可以使模型更有可能达到良好的学习率。</li>
</ul>
</details>

<h3 id="我应该使用哪种学习率衰减方案作为默认值？"><a href="#我应该使用哪种学习率衰减方案作为默认值？" class="headerlink" title="我应该使用哪种学习率衰减方案作为默认值？"></a>我应该使用哪种学习率衰减方案作为默认值？</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>我们的偏好是linear decay或cosine decay，其他一些方案可能也不错。</li>
</ul>
</details>

<h3 id="为什么有些论文有复杂的学习率衰减方案？"><a href="#为什么有些论文有复杂的学习率衰减方案？" class="headerlink" title="为什么有些论文有复杂的学习率衰减方案？"></a>为什么有些论文有复杂的学习率衰减方案？</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>具有复杂分段学习率 (LR) 衰减方案的论文并不少见。</li>
<li>读者常常想知道作者是如何得出如此复杂的研究结果的。</li>
<li>许多复杂的 LR 衰减方案是根据验证集性能以临时方式调整衰减方案的结果：<ol>
<li>使用一些简单的 LR 衰减（或恒定学习率）开始执行单次训练。</li>
<li>继续训练，直到性能提升似乎停滞为止。如果发生这种情况，请暂停训练。 从此时开始，使用可能更陡峭的 LR 衰减方案（或更小的恒定学习率）恢复它。 重复此过程，直到会议&#x2F;发布截止日期。</li>
</ol>
</li>
<li>随意复制生成的衰减方案通常不是一个好主意，因为最佳的特定衰减方案将对许多其他超参数选择敏感。<ul>
<li>最好复制生成衰减方案的算法，尽管在人为判断生成的衰减方案时这几乎不可能。</li>
</ul>
</li>
<li>如果这种类型的验证错误敏感计划可以完全自动化，则可以很好地使用，但作为验证错误函数的人在循环计划是脆弱的并且不容易重现，因此我们建议避免使用它们。<ul>
<li>在发布使用此类衰减方案的结果之前，请尽量确保其可重现性。</li>
</ul>
</li>
</ul>
</details>

<h3 id="Adam-的超参数应该如何调整？"><a href="#Adam-的超参数应该如何调整？" class="headerlink" title="Adam 的超参数应该如何调整？"></a>Adam 的超参数应该如何调整？</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>正如之前讨论的那样, 对搜索空间以及应该从搜索空间中采样数量做出概括性陈述是非常困难的。 请注意，并非 Adam 中的所有超参数都一样重要。 以下经验法则对应于研究中试验次数的不同“预算”。<ul>
<li>如果在一次研究中，训练次数试验次数小于10，那么只需要对基本学习率进行调整。</li>
<li>如果试验次数在10到25次之间， 那么需要对学习率以及 $\beta_1$ 进行调整。</li>
<li>如果试验次数在25次以上，那么需要对学习率、 $\beta_1$ 以及 $\epsilon$ 进行调整。</li>
<li>如果可以运行的试验次数大于25次，还需要额外调整$\beta_2$。</li>
</ul>
</li>
</ul>
</details>


<h3 id="为什么在优化的探索阶段使用Quasi-Random-Search而不是更复杂的黑盒优化算法？"><a href="#为什么在优化的探索阶段使用Quasi-Random-Search而不是更复杂的黑盒优化算法？" class="headerlink" title="为什么在优化的探索阶段使用Quasi-Random-Search而不是更复杂的黑盒优化算法？"></a>为什么在优化的探索阶段使用Quasi-Random-Search而不是更复杂的黑盒优化算法？</h3><details><summary><em>[点击展开]</em></summary>

<ul>
<li>Quasi-Random-Search（基于<a href="https://en.wikipedia.org/wiki/Low-discrepancy_sequence">低差异序列</a>）<br>是我们在用作迭代调优过程的一部分时优于更高级的黑盒优化工具，旨在最大限度地洞察调优问题（我们称之为“探索阶段”）。贝叶斯优化和与其类似的工具更适合开发阶段。</li>
<li>基于随机移动的低差异序列的Quasi-Random-Search可以被认为是“抖动的、打乱的网格搜索”，因为它统一但随机地探索给定的搜索空间，并且搜索点更为分散。</li>
<li>与更复杂的黑盒优化工具（例如贝叶斯优化、遗传算法）相比，Quasi-Random-Search的优势包括：<ol>
<li>非自适应地采样搜索空间可以在不重新运行实验的情况下更改性能指标。<ul>
<li>例如，我们通常希望根据任何训练点上达到的验证误差来找到最佳试验。但是Quasi-Random-Search的非自适应性质使得我们可以基于最终验证误差、训练误差或某些替代评估指标来找到最佳试验，而不需要重新运行任何实验。(译注：假设你正在训练一个深度学习模型，并使用随机搜索来调整超参数。在第一次实验中，你使用随机搜索来寻找最优的超参数组合，并使用验证误差作为评估指标。你找到了一组超参数，使得验证误差最小。现在，你想要更改评估指标，而不是使用验证误差，而是使用训练误差(可能你在解决某种模型需求)。由于你使用的是非自适应随机搜索，因此你可以在不重新运行实验的情况下，使用已经运行的实验中的数据来评估每一组超参数的训练误差。这样你就可以找到最优的超参数组合，并且可以使用训练误差作为评估指标。这样的好处在于，你可以在不重新运行实验的情况下，使用不同的评估指标来评估这些结果，从而找到最优的实验。相比之下，如果我们使用自适应随机搜索来调参，我们会根据之前实验的结果来动态调整采样策略这导致我们不能随意的更换目标，因为采样空间已经变化)</li>
</ul>
</li>
<li>Quasi-Random-Search以一致且数据上可重现的方式运行。<ul>
<li>即使在搜索算法实现发生变化的情况下，只要它保持相同的均匀性，就应该可以重现六个月前的研究。 如果使用复杂的贝叶斯优化软件，实现可能会在版本之间发生重大变化，从而使旧搜索更难重现。 并非总是可以回滚到旧的实现（例如，如果优化工具作为服务运行）。</li>
</ul>
</li>
<li>它对搜索空间的统一探索使得对结果以及它们可能对搜索空间提出的建议的推理变得更容易。<ul>
<li>例如，如果Quasi-Random-Search遍历中的最佳点位于搜索空间的边界，这是一个很好的（但不是万无一失的）信号，这表明应该更改搜索空间边界。我们在<a href="#%E8%AF%86%E5%88%AB%E9%94%99%E8%AF%AF%E7%9A%84%E6%90%9C%E7%B4%A2%E7%A9%BA%E9%97%B4%E8%BE%B9%E7%95%8C">这一节</a>会对此进行进一步探讨。 然而，自适应黑盒优化算法可能会因为一些不幸的早期试验而忽略了搜索空间的中间部分，尽管它包含相同优秀的点。因为正是这种不均匀性才是一个好的优化算法所需要的，它能加快搜索。</li>
</ul>
</li>
<li>与自适应算法相比，在使用Quasi-Random-Search（或其他非自适应搜索算法）时，并行运行与顺序运行不同数量的试验不会产生统计上不同的结果(这种误差会造成优化效果变差)。</li>
<li>更复杂的搜索算法可能并不总能正确处理不可行的点，特别是如果它们在设计时未考虑神经网络超参数调整。</li>
<li>Quasi-Random-Search很简单，在许多调优试验并行运行时特别高效。<ul>
<li>实际上 [^3]，自适应算法很难击败预算是其两倍的Quasi-Random-Search，尤其是当许多试验需要并行运行时（因此当启动新试验时，很难利用先前的试验结果）。</li>
<li>如果没有贝叶斯优化和其他高级黑盒优化方法方面的专业知识，我们可能无法获得它们理论上能够提供的优势。 在实际的深度学习超参数调优条件下，很难对高级黑盒优化算法进行benchmark测试。 它们是当前研究中非常活跃的领域，对于没有经验的用户来说，更复杂的算法也有其自身的缺陷。 这些方法的专家能够获得良好的结果，但在高并行条件下，搜索空间和预算往往更为重要。</li>
</ul>
</li>
</ol>
</li>
<li>这也就是说，如果我们的计算资源只允许少量试验并行运行，但我们能够按顺序运行许多试验。那么对我们来说，贝叶斯优化就会显得更具吸引力，尽管这会让我们更难解释我们的调优结果。</li>
</ul>
<p>[^3]: Ben Recht 和 Kevin Jamieson<br><a href="http://www.argmin.net/2016/06/20/hypertuning/">指出</a> 使用2倍预算随机搜索作为Baseline有多强大（<a href="https://jmlr.org/papers/volume18/16-558/16-558.pdf">Hyperband的论文</a>也有类似的观点），但肯定有可能找到最先进的贝叶斯优化技术可以击败两倍预算随机搜索的搜索空间和问题。然而，根据我们的经验，在高并行机制中击败 2 倍预算的随机搜索变得更加困难，因为贝叶斯优化没有机会观察先前试验的结果。</p>
</details>

<h3 id="在哪里可以找到Quasi-Random-Search的实现？"><a href="#在哪里可以找到Quasi-Random-Search的实现？" class="headerlink" title="在哪里可以找到Quasi-Random-Search的实现？"></a>在哪里可以找到Quasi-Random-Search的实现？</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>我们可以使用<a href="https://github.com/mlcommons/algorithmic-efficiency/blob/main/algorithmic_efficiency/halton.py">这个实现</a>。它能够在给定搜索空间内生成（旨在按照<a href="https://arxiv.org/abs/1706.03200%E4%B8%AD%E5%BB%BA%E8%AE%AE%E6%9D%A5%E5%AE%9E%E7%8E%B0%E7%A7%BB%E4%BD%8D%E7%9A%84%E3%80%81%E5%8A%A0%E6%89%B0%E7%9A%84">https://arxiv.org/abs/1706.03200中建议来实现移位的、加扰的</a> Halton 序列）。</li>
<li>如果基于低差异序列的Quasi-Random-Search算法不可用，则可以换成伪随机均匀搜索，虽然这可能效率稍低。<ul>
<li>在 1-2 维中，网格搜索也是可以接受的，尽管在更高的维度中不行（详见<a href="https://www.jmlr.org/papers/v13/bergstra12a.html">Bergstra &amp; Bengio, 2012</a>）。</li>
</ul>
</li>
</ul>
</details>

<h3 id="需要多少次试验才能通过Quasi-Random-Search获得较好的结果？"><a href="#需要多少次试验才能通过Quasi-Random-Search获得较好的结果？" class="headerlink" title="需要多少次试验才能通过Quasi-Random-Search获得较好的结果？"></a>需要多少次试验才能通过Quasi-Random-Search获得较好的结果？</h3><details><summary><em>[点击展开]</em></summary>
<br>

<p align="center">
<img src="assets/have_we_sampled_enough.png" width="49%" alt="A box plot showing the importance of sampling enough">
</p>

<p align="center"><b>Figure 3:</b> ResNet-50 在 ImageNet 上进行了 100 次试验调整。 通过自举，模拟了不同数量的调整预算。 上面绘制了每个试验预算的最佳性能的箱线图。

<ul>
<li>这个问题没有办法笼统地回答，但是我们可以看具体的例子。</li>
<li>正如Figure 3所示那样, 研究中的试验次数会对结果产生重大影响。<ul>
<li>请注意，当对6个试验进行抽样时，与对20个试验进行抽样时的四分位间距有多大的区别。</li>
<li>即使进行了20次试验，运气特别好和运气特别差的研究之间的差异也可能大于使用固定超参数在不同随机种子上重新训练该模型之间的典型差异，对于此工作量可能约为 +&#x2F;- 0.1% 的验证误差的概率约为 23%。</li>
</ul>
</li>
</ul>
</details>

<h3 id="如何调试和缓解优化失败"><a href="#如何调试和缓解优化失败" class="headerlink" title="如何调试和缓解优化失败"></a>如何调试和缓解优化失败</h3><details><summary><em>[点击展开]</em></summary>
<br>
***总结***： *如果在优化模型时遇到困难，那么在尝试其他东西之前解决这些问题很重要。 诊断和纠正训练失败是一个活跃的研究领域。*

<p align="center">
<img src="assets/stride_instability.png" width="80%" alt="Changing the strides in a single residual block in a WideResnet results in training instability.">
</p>


<p align="center"><b>Figure 4:</b> 在 WideResnet 中更改单个残差块 (2x2 -> 1x1) 中的步幅会导致训练不稳定。 这不会降低在低学习率下的性能，但由于不稳定的影响，高学习率不再能很好地进行训练。 使用1000步的学习率预热可以解决这种特殊的不稳定情况，允许以 0.1 的最大学习率进行稳定训练。</p>

<h4 id="识别不稳定的训练任务"><a href="#识别不稳定的训练任务" class="headerlink" title="识别不稳定的训练任务"></a>识别不稳定的训练任务</h4><ul>
<li>当学习率过大时，任何训练任务都会变得不稳定，但当不稳定迫使我们使用太小的学习率时，这才会是问题</li>
<li>这里至少有两种类型的不稳定的训练任务值得需要进行区分：<ol>
<li>初始化&#x2F;训练早期中存在的不稳定。</li>
<li>训练中期突然出现的不稳定。</li>
</ol>
</li>
<li>我们可以采用系统的方法来找出训练任务中存在的稳定性问题.<ol>
<li>进行一次学习率扫描(不考虑学习率衰减的固定学习率)，并找到最佳的学习率 lr*.</li>
<li>绘制学习率略高于 lr* 的训练损失曲线。</li>
<li>如果学习率大于 lr* 的训练损失曲线显示不稳定（误差在训练期间上升而不下降），那么修复不稳定性可能会得到更好的训练结果(说明我们最佳的学习率比较临界)。</li>
</ol>
</li>
<li>在训练过程中记录全损失梯度的 L2 范数的变化(全损失梯度的 L2 范数是指在深度学习中，对于每个参数的梯度进行平方并相加后再取平方根的过程，反映了损失函数在当前状态下沿着梯度方向的变化程度。当前状态下的梯度向量越大，说明当前状态下的模型参数需要更大的更新量才能更好的逼近最优解)，如果我们发现全损失梯度的 L2 范数异常值非常大，这可能表明模型参数在某一时刻发生了非常大的变化，导致训练过程中出现不稳定性（例如误差上升而不下降）。 这可以告诉我们该如何选择梯度&#x2F;更新剪辑。</li>
</ul>
<p><strong>注意：</strong> 某些模型会在非常早期的阶段显示出不稳定的情况，随后出现恢复，这会导致出现缓慢但稳定的训练(这可能会成为问题)。 <strong>常见的评估方法可能会因为评估不够频繁而错过这些问题！</strong></p>
<p>为了检查出这一问题，我们可以使用 <code>lr = 2 * current best</code> 来进行一次仅包含500次训练的计划，但每执行一次训练都要进行一次评估。</p>
<p align="center">
<img src="assets/more_frequent_evals.png" width="80%" alt="Illustration of the value of more frequent evaluations at the start of
training.">
</p>

<p align="center"><b>Figure 5:</b> 该图展示的是训练开始时频繁更新评估的结果。如果怀疑模型受到早期训练不稳定的影响，则很有用。</p>

<h4 id="常见不稳定模式的潜在修复方式"><a href="#常见不稳定模式的潜在修复方式" class="headerlink" title="常见不稳定模式的潜在修复方式"></a>常见不稳定模式的潜在修复方式</h4><ul>
<li>使用学习率预热<ul>
<li>最适合用于早期训练不稳定的情况。</li>
</ul>
</li>
<li>使用梯度截断<ul>
<li>对于早期和中期训练中不稳定情况都有好处，可能会解决一些学习率预热无法解决的问题。</li>
</ul>
</li>
<li>尝试使用新的优化器<ul>
<li>Adam 有时可以处理一些 Momentum 无法处理的不稳定影响。这也是该领域的一个活跃研究领域。</li>
</ul>
</li>
<li>确保使用最佳实践&#x2F;初始化：<ul>
<li>例如，如果模型中尚未包含残差连接和归一化，则添加它们。</li>
</ul>
</li>
<li>归一化应该是残差之前的最后一个操作。例如， x +Norm(f(x))。</li>
<li>众所周知，Norm(x + f(x)) 会引起问题。(译注：Norm相当于白化，意在降低层参数的训练敏感性，而残差大大增加了训练参的敏感性，所有在残差前的f(x)归一化有助于降低不稳定性)</li>
<li>尝试将残差调控因子初始化为 0 （例如，<a href="https://arxiv.org/abs/2003.04887">ReZero init所示</a>）$\boldsymbol{x}_{i+1}&#x3D;\boldsymbol{x}_i+\alpha_i F\left(\boldsymbol{x}_i\right)$.</li>
<li>降低学习率<ul>
<li>这是最终手段。</li>
</ul>
</li>
</ul>
<h4 id="学习率预热"><a href="#学习率预热" class="headerlink" title="学习率预热"></a>学习率预热</h4><p align="center">
<img src="assets/instability_during_warmup.png" width="80%" alt="An example of instability during a warmup period (note the horizontal axis log
scale).">
</p>
<p align="center"><b>Figure 6:</b> 预热期间不稳定的示例（注意横轴的刻度是以对数的形式展示）。 在这种情况下，成功训练需要4万次的预热。</p>


<h5 id="何时对学习率进行预热"><a href="#何时对学习率进行预热" class="headerlink" title="何时对学习率进行预热"></a>何时对学习率进行预热</h5><p align="center">
<img src="assets/axis_model_with_instability.png" width="49%" alt="Axis plot for model with instability">
</p>

<p align="center"><b>Figure 7a:</b> 表现出训练不稳定性的模型的超参数轴图示例。 最佳学习率处于可行的边缘。 “不可行”试验被定义为产生 NaN 或异常高的损失值的试验。</p>

<p align="center">
<img src="assets/loss_model_with_instability.png" width="49%" alt="Loss curve for model with instability">
</p>

<p align="center"><b>Figure 7b:</b> 模型训练损失中不稳定的学习率</p>

<ul>
<li>Figure 7a 展示的是一个超参数轴图，该图表明模型正在经历训练不稳定，因为最佳学习率恰好位于可行的边缘。</li>
<li>Figure 7b展示了以5-10倍的峰值学习率来训练模型中产生的训练损失是如何通过双重检查的。如果该图展示的训练损失在稳步下降后突然上升（例如，如图中10000步处展示的那样），那么该模型可能存在着优化不稳定性的情况。</li>
</ul>
<h5 id="如何对学习率进行预热"><a href="#如何对学习率进行预热" class="headerlink" title="如何对学习率进行预热"></a>如何对学习率进行预热</h5><p align="center">
<img src="assets/beneficial_effect_warmup.png" width="80%" alt="Beneficial effect of warmup on training instabilities">
</p>

<p align="center"><b>Figure 8:</b> 学习率预热对解决训练不稳定性的有益影响</p>

<ul>
<li>在上面的内容中，我们假设从业者已经确定了让模型变得不稳定的学习率。也就是 <code>unstable_base_learning_rate</code>。</li>
<li>预热的过程涉及了预先安排一个学习率计划，这个计划会将学习率从0提升到某个稳定的 <code>base_learning_rate</code>，这至少比 <code>unstable_base_learning_rate</code>要大一个数量级。<br>默认设置是尝试使用 <code>unstable_base_learning_rate</code> 10倍大小的 <code>base_learning_rate</code>。值得注意的是，对于使用例如100倍<br><code>unstable_base_learning_rate</code>这样的数值，那么可能需要重新运行整个过程。具体安排如下：<ul>
<li>在<code>warmup_steps</code>的过程中，将数值从0提升到 <code>base_learning_rate</code>。</li>
<li><code>post_warmup_steps</code>的过程中，以一个恒定的速率进行训练。</li>
</ul>
</li>
<li>我们的目标是找到最少的 <code>warmup_steps</code>，以此来让我们获得远高于<code>unstable_base_learning_rate</code>的峰值学习率。</li>
<li>因此，对于，每个 <code>base_learning_rate</code>来说， 我们需要对 <code>warmup_steps</code> 以及<code>post_warmup_steps</code>进行调优。 通常将 <code>post_warmup_steps</code> 设定为<code>warmup_steps</code>的两倍就可以了。</li>
<li>预热可以独立于现有的衰减计划进行调整。<br><code>warmup_steps</code> 应该以几个不同的数量级进行扫描。例如，在样本学习中可以以[10, 10<sup>3</sup>, 10<sup>4</sup>,10<sup>5</sup>]这样的数量级进行尝试。最大的搜索值不应超过<code>max_train_steps</code>的10%。</li>
<li>一旦建立了不会破坏以 <code>base_learning_rate</code> 进行训练的<code>warmup_steps</code>，就应该将其应用于Baseline模型。<br>本质上，我们将这个安排添加到现有安排上，并使用上面讨论中选择的最佳检查点来将这个实验与Baseline进行比较。例如，如果我们一开始的<code>max_train_steps</code>的值是10000，<br>并进行了1000次<code>warmup_steps</code>。那么，新的训练过程总共应当进行了11000次。</li>
<li>如果稳定训练需要较长的<code>warmup_steps</code>（大于<code>max_train_steps</code>的5%），则可能需要增加<code>max_train_steps</code>来解决这个问题。</li>
<li>在整个工作量的范围中并不存在真正意义上的<code>标准</code>值。有些模型可能只需要100次训练，然而有些模型则可能需要4万次以上的训练，尤其是Transformer类。</li>
</ul>
<h4 id="梯度截断"><a href="#梯度截断" class="headerlink" title="梯度截断"></a>梯度截断</h4><p align="center">
<img src="assets/gradient_clipping.png" width="80%" alt="Gradient clipping on early training instabilities">
</p>

<p align="center"><b>Figure 9:</b> 梯度截断纠正早期训练不稳定性的图示。</p>

<ul>
<li>当出现较大或离群的梯度问题时，梯度截断会变得非常有用。</li>
<li>梯度截断可以修复早期训练中出现的不稳定性（早期较大的梯度范数），或中期训练中出现的不稳定性（训练中期突然出现的梯度尖峰）。</li>
<li>有时，较长的预热时间可以纠正梯度截断无法纠正的不稳定性: 请查看<a href="#%E5%A6%82%E4%BD%95%E5%AF%B9%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%BF%9B%E8%A1%8C%E9%A2%84%E7%83%AD">之前的章节</a>。<ul>
<li>🤖 在预热的时候，进行梯度截断会发生什么？</li>
</ul>
</li>
<li>理想的截断阈值要刚好高于“典型的”梯度范数。</li>
<li>下面是一个关于如何进行梯度截断的案例：<ul>
<li>如果梯度范数 $\left | g \right |$ 大于梯度截断的阈值 $\lambda$，那么就需要进行 ${g}’&#x3D; \lambda \times \frac{g}{\left | g \right |}$。此处的 ${g}’$是新的梯度。</li>
</ul>
</li>
<li>在训练期间记录下未截断梯度范数。 默认情况下会生成:<ul>
<li>梯度范数与步骤数量的关系图</li>
<li>聚合所有步数的梯度范数直方图</li>
</ul>
</li>
<li>根据梯度范数的第90百分位数选择梯度截断阈值。<ul>
<li>这个阈值的大小与工作量有关。但90%是一个很好的选择。但如果这个奏效，那么可以对其进行调优。</li>
<li>🤖 那么，某种适应性策略会怎么样呢?</li>
</ul>
</li>
<li>如果我们尝试梯度截断并且不稳定问题仍然存在，那么我们可以更努力地尝试（例如，阈值更小）。</li>
<li>极端激进的梯度截断本质上是一种降低学习率的奇怪方式。 如果我们发现自己使用了非常激进的截断，那么我们可能应该只降低学习率。</li>
<li>我们通常会认为以某种方式将超过 50% 的更新剪裁为“极其激进”。</li>
<li>如果我们需要进行极其激进的梯度截断来处理我们的不稳定问题，那么我们不妨降低学习率。</li>
</ul>
</details>

<h3 id="为什么将学习率和其他优化参数称为超参数？-它们不是任何先验分布的参数。"><a href="#为什么将学习率和其他优化参数称为超参数？-它们不是任何先验分布的参数。" class="headerlink" title="为什么将学习率和其他优化参数称为超参数？ 它们不是任何先验分布的参数。"></a>为什么将学习率和其他优化参数称为超参数？ 它们不是任何先验分布的参数。</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li>确实，在贝叶斯机器学习中，“超参数”这一术语拥有一种更加精确的<a href="https://en.wikipedia.org/wiki/Hyperparameter">含义</a>，我们在深度学习中调优的学习率和大部分其他被叫做“超参数”的参数都是对术语的一种滥用。</li>
<li>我们更愿意使用“元参数”这个术语来表示学习率、架构参数以及我们在深度学习中调整的所有其他参数， 因为它避免了因滥用“超参数”一词而引起的潜在混淆（例如，可能在讨论贝叶斯优化时，概率响应曲面模型拥有它自己的真实超参数，此时使用超参数一词是不合适的。）</li>
<li>不幸的是，尽管可能会造成混淆，但超参数这个术语在深度学习社区中已经变得极为通俗。</li>
<li>因此，对于一份文档而言，例如本文。为了面向普通大众，我们决定为该领域的一个混乱来源做出贡献，希望避免产生另一个混淆。</li>
<li>也就是说，在发布一篇研究论文的时候，我们可能采取了一种不同的说法。并且，在大多数情况下，我们推荐其他人使用“元参数”这个说法。</li>
</ul>
</details>

<h3 id="为什么不应该调整Batch-Size来直接提高验证集性能"><a href="#为什么不应该调整Batch-Size来直接提高验证集性能" class="headerlink" title="为什么不应该调整Batch Size来直接提高验证集性能?"></a>为什么不应该调整Batch Size来直接提高验证集性能?</h3><details><summary><em>[点击展开]</em></summary>
<br>

<ul>
<li><em>在不更改训练工作流其他细节的情况下</em>， 修改batch size 通常会影响验证集的性能。</li>
<li>但是，如果针对每个batch size单独调优，则两个batch size之间的验证集性能差异通常会消失。</li>
<li>受batch size影响最强烈的那些超参数，即优化器超参数（例如：学习率、动量）和正则化超参数，这些东西对于每个batch size进行单独调优的时候是最重要的。<ul>
<li>由于样本方差的原因，较小的batch size会在训练算法中引入更多的不确定性，并且这些不确定性可能存在着正则化效果。因此，较大的batch size可能更容易过度拟合。并且，这可能需要更强的正则化和&#x2F;或额外的正则化技术。</li>
</ul>
</li>
<li>此外， 当修改batch size的大小时，<a href="#choosing-the-batch-size-to-minimize-training-time">训练步骤的数量可能也需要进行调整</a>。</li>
<li>一旦考虑了所有这些因素带来的影响，目前还没有任何能够令人信服的证据表明batch size会影响最大可实现的验证性能（具体请阅读 <a href="https://arxiv.org/abs/1811.03600">Shallue et al. 2018</a>）。</details></li>
</ul>
<h3 id="所有流行的优化算法的更新规则是什么？"><a href="#所有流行的优化算法的更新规则是什么？" class="headerlink" title="所有流行的优化算法的更新规则是什么？"></a>所有流行的优化算法的更新规则是什么？</h3><details><summary><em>[点击展开]</em></summary>

<br>

<h4 id="Stochastic-gradient-descent-SGD"><a href="#Stochastic-gradient-descent-SGD" class="headerlink" title="Stochastic gradient descent (SGD)"></a>Stochastic gradient descent (SGD)</h4><p>$$\theta_{t+1} &#x3D; \theta_{t} - \eta_t \nabla \mathcal{l}(\theta_t)$$</p>
<h4 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h4><p>$$v_0 &#x3D; 0$$</p>
<p>$$v_{t+1} &#x3D; \gamma v_{t} + \nabla \mathcal{l}(\theta_t)$$</p>
<p>$$\theta_{t+1} &#x3D; \theta_{t} - \eta_t v_{t+1}$$</p>
<h4 id="Nesterov"><a href="#Nesterov" class="headerlink" title="Nesterov"></a>Nesterov</h4><p>$$v_0 &#x3D; 0$$</p>
<p>$$v_{t+1} &#x3D; \gamma v_{t} + \nabla \mathcal{l}(\theta_t)$$</p>
<p>$$\theta_{t+1} &#x3D; \theta_{t} - \eta_t( \gamma v_{t+1} + \nabla \mathcal{l}(\theta_{t})$$</p>
<h4 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h4><p>$$v_0 &#x3D; 1 \text{,} m_0 &#x3D; 0$$</p>
<p>$$v_{t+1} &#x3D; \rho v_{t} + (1 - \rho) \nabla \mathcal{l}(\theta_t)^2$$</p>
<p>$$m_{t+1} &#x3D; \gamma m_{t} + \frac{\eta_t}{\sqrt{v_{t+1} + \epsilon}}\nabla \mathcal{l}(\theta_t)$$</p>
<p>$$\theta_{t+1} &#x3D; \theta_{t} - m_{t+1}$$</p>
<h4 id="ADAM"><a href="#ADAM" class="headerlink" title="ADAM"></a>ADAM</h4><p>$$m_0 &#x3D; 0 \text{,} v_0 &#x3D; 0$$</p>
<p>$$m_{t+1} &#x3D; \beta_1 m_{t} + (1 - \beta_1) \nabla \mathcal{l} (\theta_t)$$</p>
<p>$$v_{t+1} &#x3D; \beta_2 v_{t} + (1 - \beta_2) \nabla \mathcal{l}(\theta_t)^2$$</p>
<p>$$b_{t+1} &#x3D; \frac{\sqrt{1 - \beta_2^{t+1}}}{1 - \beta_1^{t+1}}$$</p>
<p>$$\theta_{t+1} &#x3D; \theta_{t} - \alpha_t \frac{m_{t+1}}{\sqrt{v_{t+1}} + \epsilon} b_{t+1}$$</p>
<h4 id="NADAM"><a href="#NADAM" class="headerlink" title="NADAM"></a>NADAM</h4><p>$$m_0 &#x3D; 0 \text{,} v_0 &#x3D; 0$$</p>
<p>$$m_{t+1} &#x3D; \beta_1 m_{t} + (1 - \beta_1) \nabla \mathcal{l} (\theta_t)$$</p>
<p>$$v_{t+1} &#x3D; \beta_2 v_{t} + (1 - \beta_2) \nabla \mathcal{l} (\theta_t)^2$$</p>
<p>$$b_{t+1} &#x3D; \frac{\sqrt{1 - \beta_2^{t+1}}}{1 - \beta_1^{t+1}}$$</p>
<p>$$\theta_{t+1} &#x3D; \theta_{t} - \alpha_t \frac{\beta_1 m_{t+1} + (1 - \beta_1) \nabla \mathcal{l} (\theta_t)}{\sqrt{v_{t+1}} + \epsilon} b_{t+1}$$</p>
</details>
]]></content>
  </entry>
  <entry>
    <title>Scale Invariant Feature Transform 算法</title>
    <url>/archive/Exp012-SIFT.html</url>
    <content><![CDATA[<p>尺度不变特征变换匹配（Scale Invariant Feature Transform, SIFT）算法，是David G. Lowe[1]在1999年提出的高效区域检测算法，2004年[2]完善。SIFT算法将图像中检测到的特征点用128维的特征向量进行描述。其本质是在不同的空间尺度上查找特征点，并计算特征点方向。SIFT算法所查找到的特征点是一些十分突出的局部结构，对旋转、尺度缩放、亮度变化等保持不变性，对于光照、仿射和投影变换也有一定的不变性，是目前领域内非常成熟稳定的局部特征检测算法。</p>
<span id="more"></span>

<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><ul>
<li><a href="https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html">OpenCV: Introduction to SIFT (Scale-Invariant Feature Transform)</a></li>
</ul>
<figure class="highlight python"><figcaption><span>sift.py, For feature keypoints extraction</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># reading the image</span></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert to greyscale</span></span><br><span class="line">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT feature extractor</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect features from the image</span></span><br><span class="line">keypoints, descriptors = sift.detectAndCompute(img, <span class="literal">None</span>)</span><br><span class="line"><span class="comment"># draw the detected key points</span></span><br><span class="line">sift_image = cv2.drawKeypoints(gray, keypoints, img)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, sift_image)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;table-sift.jpg&quot;</span>, sift_image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><figcaption><span>feature_match.py, For feature matching</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="comment"># read the images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">&#x27;book.jpg&#x27;</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">&#x27;table.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># convert images to grayscale</span></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># create SIFT object</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"><span class="comment"># detect SIFT features in both images</span></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># create feature matcher</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># match descriptors of both images</span></span><br><span class="line">matches = bf.<span class="keyword">match</span>(descriptors_1,descriptors_2)</span><br><span class="line"><span class="comment"># sort matches by distance</span></span><br><span class="line">matches = <span class="built_in">sorted</span>(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"><span class="comment"># draw first 50 matches</span></span><br><span class="line">matched_img = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:<span class="number">50</span>], img2, flags=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># show the image</span></span><br><span class="line">cv2.imshow(<span class="string">&#x27;image&#x27;</span>, matched_img)</span><br><span class="line"><span class="comment"># save the image</span></span><br><span class="line">cv2.imwrite(<span class="string">&quot;matched_images.jpg&quot;</span>, matched_img)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>




<h1 id="逻辑框架"><a href="#逻辑框架" class="headerlink" title="逻辑框架"></a>逻辑框架</h1><p>Lowe教授将SIFT算法分解为如下四步：</p>
<blockquote>
<ol>
<li><strong>尺度空间极值检测</strong>：搜索所有尺度上的图像位置。通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li><strong>特征点精确定位</strong>：在每个候选的位置上，通过精细拟合模型确定位置和尺度。特征点的选择依赖它们的稳定程度。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li><strong>方向确定</strong>：基于图像局部梯度方向，分配给每个特征点位置一个或多个方向。所有后面的对图像数据的操作都相对于关键点的方向、尺度和位置进行变换，从而提供对于这些变换的不变性。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li><strong>特征点描述</strong>：在每个关键点周围的邻域内，在选定的尺度上测量图像局部的梯度。这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变化。</li>
</ol>
</blockquote>
<h1 id="SIFT算法原理"><a href="#SIFT算法原理" class="headerlink" title="SIFT算法原理"></a>SIFT算法原理</h1><h2 id="尺度空间极值检测"><a href="#尺度空间极值检测" class="headerlink" title="尺度空间极值检测"></a>尺度空间极值检测</h2><h3 id="尺度空间理论"><a href="#尺度空间理论" class="headerlink" title="尺度空间理论"></a>尺度空间理论</h3><p>尺度越大图像越模糊。用机器视觉系统分析未知场景时，计算机并不预先知道图像中物体的尺度。我们需要同时考虑图像在多尺度下的描述，获知感兴趣物体的最佳尺度。另外如果不同的尺度下都有同样的关键点，那么在不同的尺度的输入图像下就都可以检测出来关键点匹配，也就是尺度不变性。 图像的尺度空间表达就是图像在所有尺度下的描述。</p>
<h3 id="高斯模糊"><a href="#高斯模糊" class="headerlink" title="高斯模糊"></a>高斯模糊</h3><p>高斯核是唯一可以产生多尺度空间的核。一个图像的尺度空间$L(x,y,\sigma)$，定义为原始图像$I(x,y)$与一个可变尺度的2维高斯函数$G(x,y,\sigma)$的卷积运算。二维空间高斯函数：</p>
<p>\begin{equation}<br>G(x_i,y_i,\sigma)&#x3D;\frac{1}{2\pi\sigma^2}{\rm exp}\left[-\frac{(x-x_i)^2+(y-y_i)^2}{2\sigma^2}\right]<br>\end{equation}</p>
<p>尺度空间为：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;G(x,y,\sigma)*I(x,y)<br>\end{equation}</p>
<p>在二维空间中，这个公式生成的曲面的等高线是从中心开始呈正态分布的同心圆。分布不为零的像素组成的卷积矩阵与原始图像做变换。每个像素的值都是周围相邻像素值的高斯加权平均。中心像素的值有最大的高斯分布值，所以有最大的权重，相邻像素随着距离中心像素越来越远，其权重也越来越小。这样进行模糊处理比其它的均衡模糊滤波器更高地保留了边缘效果。$\sigma$越大，中心像素的权重与周围像素就会相对越小，加权平均后就会越模糊；反之，$\sigma$越小，中心像素权重相对越大，当$\sigma&#x3D;0$时，就是原图的样子，相当于周围像素对新图没有贡献。换句话说，大尺度对应于图像的概貌特征，小尺度对应于图像的细节特征。理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大约$3\sigma$距离之外的像素都可以看作不起作用，这些像素的计算也就可以忽略。通常，图像处理程序只需要计算$(6\sigma+1)^2$的矩阵就可以保证相关像素影响。</p>
<h3 id="金字塔多分辨率"><a href="#金字塔多分辨率" class="headerlink" title="金字塔多分辨率"></a>金字塔多分辨率</h3><p>与多尺度空间相对的，金字塔是早期图像多尺度的表示方式。图像金字塔化一般两个步骤：</p>
<blockquote>
<ol>
<li>使用低通滤波器（LPF）平滑图像；</li>
<li>平滑图像降采样（通常</li>
</ol>
</blockquote>
<p> 该方式能得到系列尺寸缩小的图片。尺度空间表达和金字塔分辨率表达的明显区别有：</p>
<blockquote>
<ol>
<li>尺度空间表达是由不同高斯核平滑卷积得到的，在所有尺度上分辨率相同；</li>
<li>金字塔多分辨率表达每层分辨率减少固定比率。</li>
</ol>
</blockquote>
<p>因此，金字塔多分辨率生成快，空间少，但局部特征描述单一；多尺度空间的图片局部特征可以在不同尺度描述，但随尺度参数增加会增加冗余信息。</p>
<h3 id="高斯金字塔"><a href="#高斯金字塔" class="headerlink" title="高斯金字塔"></a>高斯金字塔</h3><p>高斯金字塔是最基本的图像塔。原理：首先将原图像作为最底层图像 level0（高斯金字塔的第0层），利用高斯核（5$*$5）对其进行卷积，然后对卷积后的图像进行下采样（去除偶数行和列）得到上一层图像G1，将此图像作为输入，重复卷积和下采样操作得到更上一层的图像，反复迭代多次，形成一个金字塔形的图像数据结构，即高斯金字塔。高斯金字塔是在sift算子中提出来的概念，首先高斯金字塔并不是一个金字塔，而是由很多组（Octave）金字塔构成，并且每组金字塔都包含若干层（Interval），即在同一组的金字塔中，使用不同$\sigma$进行高斯模糊，然后再不同组的金字塔中，使用下采样，获得不同分辨率的图像。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xox4Te.png" width="90%" alt="Fig.1 高斯金字塔与高斯差分金字塔。" align=center /></p>
<p>高斯金字塔的构建过程：</p>
<blockquote>
<ol>
<li>先将原图像扩大一倍之后作为高斯金字塔的第1组第1层，将第1组第1层图像经高斯卷积（高斯平滑或称高斯滤波）之后作为第1组金字塔的第2层。对于参数$\sigma$，在SIFT算子中取的是固定值 1.6；</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>将$\sigma$乘以一个比例系数$k$，得到新的平滑因子$\sigma&#x3D;k*\sigma_{old}$，用它来平滑第1组第2层图像，结果图像作为第3层。</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>如此重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>将第1组倒数第三层图像作为比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像作平滑因子为$\sigma$的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：$0，\sigma，k\sigma，k^2\sigma，k^3\sigma……k^{(L-2)}\sigma$。但是在尺寸方面第2组是第1组图像的一半。这样反复执行，就可以得到一共$O$组，每组$L$层，共计$O*L$个图像，这些图像一起就构成了高斯金字塔。在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子是前一层图像平滑因子的$k$倍；在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半。</li>
</ol>
</blockquote>
<h3 id="高斯拉普拉斯金字塔"><a href="#高斯拉普拉斯金字塔" class="headerlink" title="高斯拉普拉斯金字塔"></a>高斯拉普拉斯金字塔</h3><p>LoG（Laplace of Gaussian）是对高斯函数进行拉普拉斯变换：</p>
<p>\begin{equation}<br>L(x,y,\sigma)&#x3D;\frac{\partial^2G}{\partial x^2} + \frac{\partial^2G}{\partial y^2}<br>\end{equation}</p>
<p>拉普拉斯金字塔用于重建图形，也就是预测残差，对图像进行最大程度的还原。比如一幅小图像重建为一幅大图。原理：用高斯金字塔的每一层图像减去其上一层图像上采样并高斯卷积之后的预测图像，得到一系列的差值图像，即为Laplacian分解图像。<br>LoG第$i$层的数学定义：</p>
<p>\begin{align}<br>L_i &amp;&#x3D; G_i-Up(G_{i+1})\otimes g \<br>&amp;&#x3D;G_i - PyrUp(G_{i+1}) \<br>\end{align}</p>
<p>式中，$G_i$表示高斯金字塔中第层图像。也就是说，拉普拉斯金字塔是通过高斯金字塔图像减去先缩小（即上一层图像）后再放大（即上采样操作）并高斯卷积后的图像的一系列图像构成的。</p>
<h3 id="高斯差分金字塔"><a href="#高斯差分金字塔" class="headerlink" title="高斯差分金字塔"></a>高斯差分金字塔</h3><p>LoG的主要缺点是需要求二阶导，计算较复杂，因此我们就想用别的算子去近似它。DoG（Difference of Gaussian），相当于对LoG的近似计算，SIFT算法中建议某一尺度的特征检测，可以通过两个相邻高斯尺度空间的图像相减，得到DoG的响应值图像。DoG和LoG的关系如下述所示：</p>
<p>\begin{equation}<br>\sigma\nabla^2G &#x3D; \frac{\partial G}{\partial\sigma} \approx \frac{G(x,y,k\sigma) - G(x,y,\sigma)}{k\sigma - \sigma}<br>\end{equation}</p>
<p>因此，有：</p>
<p>\begin{equation}<br>G(x,y,k\sigma) - G(x,y,\sigma) \approx (k-1)\sigma^2\nabla^2G<br>\end{equation}</p>
<p>而$\sigma^2\nabla^2G$正是尺度归一化算子的表达形式。在所有的尺度中$k-1$是一个常数，当$k$趋近于1的时候误差趋近于0，但实际上这种误差对于极值的位置检测并没有什么影响（不过前人的实验证明LoG提取的特征稳定性最强）。</p>
<h3 id="空间极值点检测"><a href="#空间极值点检测" class="headerlink" title="空间极值点检测"></a>空间极值点检测</h3><p>SIFT关键点是由DOG空间的局部极值点组成的，关键点的初步探查是通过同一组内各DoG相邻两层图像之间比较完成的。极值点定义：每一个像素点与它所有相邻点比较，当其大于（或小于）它的图像域和尺度域的所有相邻点时，即为极值点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoxIFH.png" width="40%" alt="Fig.2 空间极值点检测。" align=center /></p>
<p>由于要在相邻尺度进行比较，那么对于高斯差分金子塔中的每一组的所有层，只能在中间两层中进行两个尺度的极值点检测，其它尺度则只能在不同组中进行。为了在每组中检测$S$个尺度的极值点，则DOG金字塔每组需$S+2$层图像，而DOG金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需$S+3$层图像，实际计算时$S$在3到5之间。当然这样产生的极值点并不全都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。</p>
<p>到这里，总结一下，构建DOG尺度空间金字塔的三个重要参数是：尺度$\sigma$、组(octave)数$O$和组内层数$S$。</p>
<h2 id="特征点精确定位"><a href="#特征点精确定位" class="headerlink" title="特征点精确定位"></a>特征点精确定位</h2><p>计算机中存储的图像数据是离散的，而我们之前找到的极值点也就是离散空间中的极值点，但是离散空间中的极值点并不是真实的连续空间中的极值点。所以需要对DoG空间进行拟合处理，以找到极值点的精确位置和尺度。另外，我们还需要去除那些在边缘位置的极值点，以提高关键点的稳定性。</p>
<h3 id="精确定位"><a href="#精确定位" class="headerlink" title="精确定位"></a>精确定位</h3><p>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xoz3nK.png" width="60%" alt=" " align=center /></p>
<p>利用已知的离散空间点插值得到连续空间极值点的方法叫做子像元插值。<br>在Lowe的论文中，使用的是泰勒展开式作为拟合函数。<br>通过上步的极值点检测，我们得到的极值点是一个三维向量，包括它所在的尺度$\sigma$以及所在尺度图像中的位置坐标$(x,y)$。设$X_0 &#x3D; (x_0,y_0,\sigma_0)$，则泰勒展开的矩阵表示为：</p>
<p>\begin{equation}<br>f(\left[\begin{matrix}x\y\\sigma\end{matrix}\right]) \approx f(\left[\begin{matrix}x_0\y_0\\sigma_0\end{matrix}\right]) + \left[\frac{\partial f}{\partial x}    \frac{\partial f}{\partial y} \frac{\partial f}{\partial \sigma}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right] + \frac{1}{2}\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]^{\rm T}\left[\begin{matrix}<br>\frac{\partial^2 f}{\partial x^2}               &amp; \frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial x \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial y}      &amp; \frac{\partial^2 f}{\partial y^2}               &amp; \frac{\partial^2 f}{\partial y \partial \sigma} \<br>\frac{\partial^2 f}{\partial x \partial \sigma} &amp; \frac{\partial^2 f}{\partial y \partial \sigma} &amp; \frac{\partial^2 f}{\partial \sigma^2}          \<br>\end{matrix}\right]\left[\begin{matrix}x-x_0\y-y_0\\sigma-\sigma_0\end{matrix}\right]<br>\end{equation}</p>
<p>若写成矢量形式，则为：</p>
<p>\begin{equation}<br>f(X) &#x3D; f(X_0）+\frac{\partial f^{\rm T}}{\partial X}(X- X_0)+\frac{1}{2}(X-X_0)^{\rm T}\frac{\partial^2 f}{\partial X^2}(X-X_0)<br>\end{equation}</p>
<p>在这里$X_0$表示离散的插值中心，$X$表示拟合后连续空间的插值点坐标，则设$\hat{X}&#x3D;X-X_0$，表示偏移量，带入上式，另求得的导数为0（求一阶导等于0得到的点就是极值点），则有：</p>
<p>\begin{equation}<br>\hat{X} &#x3D; -\frac{\partial^2 f^{-1}}{\partial X^2}\frac{\partial f}{\partial X}<br>\end{equation}</p>
<p>只要上式中得到的偏移量大于0.5，则认为偏移量过大，需要把位置移动到拟合后的新位置，继续进行迭代求偏移量，若迭代过一定次数后偏移量仍然大于0.5，则抛弃该点。如果迭代过程中有偏移量小于0.5，则停止迭代。</p>
<p>把该极值点带入到原公式中，则得到极值点所在的函数值：</p>
<p>\begin{equation}<br>f(\hat{X}) &#x3D; f(X_0) + \frac{1}{2}\frac{\partial f^{\rm T}}{\partial X} \hat{X}<br>\end{equation}</p>
<p>如果上式中得到的$f(\hat{X})$过小，即其响应值过小，这样的点易受噪声的干扰而变得不稳定，所以也要被删除，Lowe论文中阈值为0.03（设灰度值为0~1）。</p>
<h3 id="消除边缘响应"><a href="#消除边缘响应" class="headerlink" title="消除边缘响应"></a>消除边缘响应</h3><p>有些极值点的位置是在图像的边缘位置的，因为图像的边缘点很难定位，同时也容易受到噪声的干扰，我们把这些点看做是不稳定的极值点，需要进行去除。<br>由于图像中的物体的边缘位置的点的主曲率一般会比较高，因此我们可以通过主曲率来判断该点是否在物体的边缘位置。<br>某像素点位置处的主曲率可以由二维的Hessian矩阵计算得到：</p>
<p>\begin{equation}<br>H &#x3D; \left[\begin{matrix}D_{xx}(x,y)&amp;D_{xy}(x,y)\D_{xy}(x,y)&amp;D_{yy}(x,y)\end{matrix}\right]<br>\end{equation}</p>
<p>设该矩阵的两个特征值分别为$\alpha$和$\beta$，其中$\alpha &#x3D; \gamma\beta$，有如下公式：</p>
<p>\begin{align}<br>{\rm Tr}(H) &#x3D; \alpha +\beta\<br>{\rm Det}(H) &#x3D; \alpha\beta<br>\end{align}</p>
<p>其中${\rm Tr}(H)$表示矩阵的迹，${\rm Det}(H)$表示的矩阵的行列式。首先需要去除行列式为负的点。接下来需要去掉主曲率比较大的点，Lowe中使用如下判断规则：<br>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &#x3D; \frac{(\gamma\beta+\beta)^2}{\gamma\beta^2} &#x3D; \frac{(\gamma+1)^2}{\gamma}<br>\end{equation}</p>
<p>这里$\gamma$越大，则表示该点越有可能在边缘，因此要检查主曲率是否超过一定的阈值$\gamma_0$，只需要判断：</p>
<p>\begin{equation}<br>\frac{ {\rm Tr}(H)^2}{ {\rm Det}(H)} &lt; \frac{(\gamma_0+1)^2}{\gamma_0}<br>\end{equation}</p>
<p>Lowe论文中阈值为10。</p>
<h2 id="特征点方向确定"><a href="#特征点方向确定" class="headerlink" title="特征点方向确定"></a>特征点方向确定</h2><p>上面我们已经找到了特征点。为了实现图像旋转不变性，需要根据检测到的特征点局部图像结构为特征点方向赋值。我们使用图像的梯度直方图法求特征点局部结构的稳定方向。</p>
<h3 id="梯度方向和幅值"><a href="#梯度方向和幅值" class="headerlink" title="梯度方向和幅值"></a>梯度方向和幅值</h3><p>在前文中，精确定位关键点后也找到特征点的尺度值$\sigma$，根据这一尺度值，得到最接近这一尺度值的高斯图像：</p>
<p>\begin{equation}<br>L(x,y) &#x3D; G(x,y,\sigma)\otimes I(x,y)<br>\end{equation}</p>
<p>使用有限差分，计算以特征点为中心，以$3\times1.5\sigma$为半径的区域内图像梯度的幅值$m(x,y)$和幅角$\theta(x,y)$，公式如下：</p>
<p>\begin{align}<br>m(x,y)      &amp;&#x3D; \sqrt{(L(x+1, y) - L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2} \<br>\theta(x,y) &amp;&#x3D; {\rm arctan}\left[\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right]<br>\end{align}</p>
<h3 id="梯度直方图"><a href="#梯度直方图" class="headerlink" title="梯度直方图"></a>梯度直方图</h3><p>在完成特征点邻域内高斯图像梯度计算后，使用直方图统计邻域内像素对应的梯度方向和幅值。<br>梯度方向直方图的横轴是梯度方向角，纵轴是梯度方向角对应的梯度幅值累加值（(为简化，图中只画了八个方向的直方图)）。梯度方向直方图将0°~360°的范围分为36个柱，每10°为一个柱。可看作一定区域内的图像像素点对特征点方向生成所作的贡献。</p>
<p>在计算直方图时，每个加入直方图的采样点都使用圆形高斯函数函数进行了加权处理，也就是进行高斯平滑。Lowe建议子区域的像素的梯度大小$\sigma&#x3D;0.5d$的高斯加权计算。这主要是因为SIFT算法只考虑了尺度和旋转不变形，没有考虑仿射不变性。通过高斯平滑，可以使关键点附近的梯度幅值有较大权重，从而部分弥补没考虑仿射不变形产生的特征点不稳定。通常离散的梯度直方图要进行插值拟合处理，以求取更精确的方向角度值。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSeDf.png" width="60%" alt=" " align=center /></p>
<h3 id="特征点方向"><a href="#特征点方向" class="headerlink" title="特征点方向"></a>特征点方向</h3><p>直方图峰值代表该特征点处邻域内图像梯度的主方向，也就是该特征点的主方向。在梯度方向直方图中，当存在另一个相当于主峰值80%能量的峰值时，则将这个方向认为是该特征点的辅方向。所以一个特征点可能检测得到多个方向，这可以增强匹配的鲁棒性。Lowe的论文指出大概有15%特征点具有多方向，但这些点对匹配的稳定性至为关键。获得图像特征点主方向后，每个特征点有三个信息$(x,y,\sigma,\theta)$：位置、尺度、方向。由此我们可以确定一个SIFT特征区域。通常使用一个带箭头的圆或直接使用箭头表示SIFT区域的三个值：中心表示特征点位置，半径表示特征点尺度（$r&#x3D;2.5\sigma$），箭头表示主方向。具有多个方向的特征点可以复制成多份，然后将方向值分别赋给复制后的特征点。如下图：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/10/31/xTSYrV.png" width="60%" alt=" " align=center /></p>
<h2 id="特征点描述"><a href="#特征点描述" class="headerlink" title="特征点描述"></a>特征点描述</h2><p>上文找到的SIFT特征点包含位置、尺度和方向的信息。接下来的步骤是特征点描述，即用一组向量将这个特征点描述出来，这个描述子不但包括特征点，也包括特征点周围对其有贡献的像素点，用来作为目标匹配的依据（所以描述子应该有较高的独特性，以保证匹配率），也可使特征点具有更多的不变特性，如光照变化、3D视点变化等。<br>SIFT描述子$h(x,y,\theta)$是对特征点附近邻域内高斯图像梯度统计的结果，是一个三维矩阵，但通常用一个矢量来表示。特征向量通过对三维矩阵按一定规律排列得到。</p>
<h3 id="描述子采样区域"><a href="#描述子采样区域" class="headerlink" title="描述子采样区域"></a>描述子采样区域</h3><p>特征描述子与特征点所在尺度有关，因此对梯度的求取应在特征点对应的高斯图像上进行。<br>将特征点附近划分成$d^2$个子区域，每个子区域尺寸为$m\sigma$个像元（$d&#x3D;4$，$m&#x3D;3$，$\sigma$为特征点的尺度值）。考虑到实际计算时需要双线性插值，故计算的图像区域为$m\sigma(d+1)$，再考虑旋转，则实际计算的图像区域为$\sqrt{2}m\sigma(d+1)&#x2F;2$，如下图所示：<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTco9A.png" width="35%" alt=" " align=center /></p>
<h3 id="区域坐标轴旋转"><a href="#区域坐标轴旋转" class="headerlink" title="区域坐标轴旋转"></a>区域坐标轴旋转</h3><p>为了保证特征矢量具有旋转不变性，要以特征点为中心，在附近邻域内旋转角，即旋转为特征点的方向。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTc7ct.png" width="60%" alt=" " align=center /></p>
<p>旋转后区域内采样点新的坐标为：</p>
<p>\begin{equation}<br>\begin{pmatrix} x’ \ y’\end{pmatrix} &#x3D; \begin{pmatrix} cos\theta &amp; -sin\theta \ sin\theta &amp; cos\theta\end{pmatrix} \begin{pmatrix} x \ y\end{pmatrix}<br>\end{equation}</p>
<h3 id="计算采样区域梯度直方图"><a href="#计算采样区域梯度直方图" class="headerlink" title="计算采样区域梯度直方图"></a>计算采样区域梯度直方图</h3><p>将旋转后区域划分为$d^2$个子区域（每个区域间隔为$m\sigma$像元），在子区域内计算8个方向的梯度直方图，绘制每个方向梯度方向的累加值，形成一个种子点。 与求主方向不同的是，此时，每个子区域梯度方向直方图将0°~360°划分为8个方向区间，每个区间为45°。即每个种子点有8个方向区间的梯度强度信息。由于存在$d^2$，即16个子区域，所以最终共有128个数据（Lowe建议的数据），形成128维SIFT特征矢量。<br>&emsp;<br><img src="https://s1.ax1x.com/2022/11/01/xTcqnf.png" width="60%" alt=" " align=center /></p>
<p>对特征矢量需要加权处理，加权采用$m\sigma d&#x2F;2$的标准高斯函数。为了除去光照变化影响，还有进一步归一化处理。</p>
<p>至此SIFT描述子生成，SIFT算法也基本完成了。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Lowe, David G. “Object recognition from local scale-invariant features.” Proceedings of the seventh IEEE international conference on computer vision. Vol. 2. Ieee, 1999.<br>[2] Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.</p>
]]></content>
  </entry>
  <entry>
    <title>X-ray micro-CT 中消除环状伪影的高级技巧</title>
    <url>/archive/Exp008-stripe-remove.html</url>
    <content><![CDATA[<p>同步辐射 X 射线显微 CT 系统的重建图像经常遭受严重的环状伪影（ring artifacts）干扰。在正弦图中这种干扰通常呈直线或条纹状分布。它们往往来自于探测系统的不规则响应，按结构又分为如下几类：全条纹；局部条纹；震荡条纹；无响应条纹。CT 投影图像的预处理算法如变形矫正、相位恢复等都会更进一步的模糊、放大这些干扰条纹。然而目前还没有一种算法能够同时移除上述所有种类的干扰条纹。本文将介绍三种针对性解决这些干扰的算法，所有的步骤都是易于复刻的；不会带来额外的干扰；在实际应用中的效果比其他算法更好。</p>
<p>本文所有工作均由 <a href="https://scholar.google.com/citations?hl=en&user=ob0Q9skAAAAJ">Nghia T. Vo</a> 博士依托 Diamond Light Source, <a href="https://www.diamond.ac.uk/Instruments/Imaging-and-Microscopy/I12/Beamline-Characteristics.html">I12-JEEP线站</a>完成。</p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>&emsp;&emsp;在同步辐射层析成像系统中X射线平行光穿透试样构成的二维投影图像在 180$^\circ$ 范围内多个角度下被二维X射线探测系统所采集。将所有投影图像的第n行按角度顺序组合在一起就形成了第n行的正弦图像。对该正弦图像进行重构，即可得到样品第n层处的切片图像。探测系统任何无法被白背底校正所消除的缺陷都将在正弦图像中形成竖条纹，进而在其重构出的切片图中产生环状伪影（图(1)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image001.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图1. 探测系统缺陷的影响：(a)正弦图中的条纹伪影；(b)切片图中的环状伪影。”&gt;</p>
<p>&emsp;&emsp;缺陷可能来自于传感器芯片的非线性响应、光学元件污渍（尤其是闪烁体）等等。适用于同步辐射的高质量、高分辨率、耐辐射闪烁体制造始终具有一定的挑战性。长时间高通量的X射线会破坏闪烁体的微观结构，这是因为X射线照射将促使光学元件（镜子、阳极化膜等）表面不断释放粒子并沉积在闪烁体表面，进而影响闪烁体成像质量（图(2)）。虽然在慢速实验中频繁的更换与清洗可以暂时解决这个问题，但在不能中断的时间分辨成像实验中闪烁体仍然可能发生损坏。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image002.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图2. 实验过程中闪烁体的退化：(a)实验开始时；(b)使用数日后。”&gt;</p>
<p>&emsp;&emsp;目前已有许多去环状伪影算法问世。然而，面对同步辐射上采集的海量数据，只有少数低计算成本的算法被集成到层析成像重建软件包中[1-6]。这些算法按原理又可分为两类：实空间方法和频域空间方法。规范化方法（normalization-based methods）[7]及正则化方法（regularization-based methods）[8]非常易用，但只适用于抑制某些特定类型的条纹。傅里叶变换方法（FFT-based methods）[9]及小波傅里叶变换方法（wavelet-FFT-based methods）[10]可以解决更多种类的条纹，但需要调整许多参数以达到最佳效果，较难使用。此外，如果参数选择不合适，该算法还会对图像质量产生很大影响。并且，所有上面提到的算法都有两个共同的缺点：如果图像中存在高频边缘，则会带来额外的条纹伪影；提高滤波强度将会抹去切片图中心区域的原本纹理（void-center artifacts）。其他作用于切片图上的算法[11]在此不做介绍。</p>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="典型环状伪影分类"><a href="#典型环状伪影分类" class="headerlink" title="典型环状伪影分类"></a>典型环状伪影分类</h3><p>&emsp;&emsp;比较缺陷像素与邻近完好像素的强度分布特征，可将典型伪影分为如下四类。这里的强度分布指缺陷像素强度值随样品旋转角度变化的分布函数。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_table001.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; &gt;</p>
<p>&emsp;&emsp;无响应条纹S1可能来自于传感器芯片的坏点、遮光的粉尘（黑色块）或闪烁体损伤（白色块）。这些区域对X射线入射强度的变化都无法做出响应，导致正弦图像中出现恒定强度的竖条纹，进而将在切片图中产生醒目的半环。重建算法中的 ramp filter 将更进一步的加强这类条纹的高频边缘（图(1.b)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image003.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图3. 缺陷像素的典型强度分布（红色）与邻近完好像素强度分布（蓝色）对比：(a)无响应条纹S1；(b)全条纹S2；(c)局部条纹S3；(d)震荡条纹S4。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image004.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图4. (a)全条纹S2、局部条纹S3以及震荡条纹S4的实物示范；(b)蓝色子区的放大视图；(c)，(d)，(e) 分别由全条纹、局部条纹、震荡条纹引起的环状伪影。”&gt;</p>
<p>&emsp;&emsp;全条纹S2、局部条纹S3以及震荡条纹S4则来自于探测器的不完美区域，然而这些区域难以通过肉眼从投影图像中分辨出来。图(4.c-e)展示了这三类条纹所造成的重建图像中的环状伪影。图(5.a)展示了长时间使用并发生明显退化的闪烁体所采集的白背景图像。缺陷区域（defective regions, called blobs）从图中可以清晰分辨。经过平场校正的高衬度目标投影图像中，视觉上已经无法明显察觉这些缺陷区域（图(5.b)）。然而更深入的分析表明，认为投影图像与白背景图像间符合简单的线性关系是不严谨的。Nghia T. Vo提出了一种易于实现的技术来分析每个像素的响应系数分布，这有助于迅速的检测探测器隐藏的缺陷区域。以旋转范围为[0$^\circ$,90$^\circ$]的匀质玻璃板作为X射线衰减器，连续采集其在不同角度下时的投影图像，而后对所有像素的测量强度的对数与该角度下X射线穿透厚度进行线性拟合。计算得到各个像素的线性拟合偏差，即可得到如图(5.c)所示的响应系数偏差分布。对于理想探测器，应当得到一幅完全平整的响应系数偏差分布图像。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image005.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图5. 平场校正图与响应系数偏差分布图对比：(a) 白背景图像；(b) 平场校正后投影图像；(c) 响应系数偏差分布；(d,e,f) 分别对应前三幅图像中方框区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;这个简易的方法对检测探测系统的非均匀响应非常有效。令人遗憾的是，所得到的响应系数偏差不能直接用于校正。在实践中，缺陷像素的响应系数取决于信号强度的动态范围和相邻区域（即闪烁体的光散射）的信号强度，而这是由样品的形状和吸收特性决定的，在不同情况下通常存在差异。图(6)展示了在相同条件下扫描的两个样品在同一行探测器上的切片图像，其中样品一（图(6.a)）产生的透射强度动态范围比样品二低得多。图(6)中可见在样本二中存在样本一中没有出现的环状伪影。样品二中的强吸收物质在闪烁体中产生了极暗弱的阴影区域，在某些角度下，阴影覆盖在闪烁体缺陷处，缺陷像素的响应系数与临近正常像素的响应系数偏差变得非常突出，进而产生了局部条纹S3。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image006.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”图6. 局部条纹S3存在与否取决于投影强度的动态范围。 (a) 低动态范围投影强度试样的重建切片；(b) 高动态范围投影强度试样的重建切片。”&gt;</p>
<h3 id="移除小型、中型局部条纹及全条纹"><a href="#移除小型、中型局部条纹及全条纹" class="headerlink" title="移除小型、中型局部条纹及全条纹"></a>移除小型、中型局部条纹及全条纹</h3><p>&emsp;&emsp;从全条纹S2及局部条纹S3的典型强度分布中我们不难发现，相邻像素间强度分布的低频分量差异是这两类环状伪影的主要成因。基于这种差异消除条纹是此处介绍方法的关键。为了使相邻像素的响应系数一致，我们可以沿着正弦图像的水平方向进行平滑滤波变换。然而，这种方法将会引入空心伪影（void-center artifacts），损失重建图像中心区域的细节，顶峰多尺度科学研究所早期的CT分析工作常常遭受此干扰。为避免空心伪影，我们需要测算探测器的响应系数分布及其分布差异，而后才能对其进行平滑滤波变换或使用其他校正方法。表(2)列出了三种从正弦图像中测算响应系数分布并校准图像的方法。</p>
<img src="/Exp005_table002.jpg" width = 100% div align=center />

<p>&emsp;&emsp;虽然实现的方法不同，但是算法1与算法2的思想内核是一致的，它们的核心目标都是均衡相邻像素强度分布的低通分量。算法1的多项式阶数和算法2的窗口大小、类型的选择都是灵活的，最佳参数取决于正弦图特征的复杂程度。我们发现算法1更适用于低通分量可以用五阶以下多项式拟合的正弦图像。步骤2中平滑滤波器的强度应该在移除干扰条纹和损失真实信号间权衡。在算法1和2中有许多滤波方法及参数集的选择，本文将不再赘述此处细节。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image007.jpg” width &#x3D; 95% div align&#x3D;center &#x2F; title&#x3D;”图7. 算法3在示例正弦图像上的应用：(a) 原始正弦图像；(b) 对各列排序后的正弦图像；(c) 横向平滑后的正弦图像；(d) 重新构建的正弦图像；(e) 图(7.a)与图(7.d)的差异。”&gt;</p>
<p>&emsp;&emsp;令人惊讶的是，算法3虽然是最简单的方法，但却非常有效，它特别适用于处理局部条纹S3，而其他公开的方法都提及了处理局部条纹S3的挑战性。图(7)展示了算法3在一幅示例正弦图像上的应用，移除局部条纹后的重建图像上几乎无法察觉任何残留，如图(8)所示。算法3的原理可以通过近似假设来理解：由于透射强度随样品转动角度不断变化，探测系统内相邻区域对相近的入射通量范围进行采样；与样品中代表性的细节尺度相比，探测系统的反常区域（图(5.f)）很小。如果探测系统是理想的，那么相邻像素所探测到的投影强度在一次完整的CT扫描中的动态范围理应是几乎相同的。这意味着，如果将各像素处投影强度分布排序，相邻像素理应呈现一致的分布。在不规则区域较小的假设下，完全可以利用投影强度排序值对不规则区域进行识别、比较和校正，从而实现移除小型条纹。使用平滑滤波器是最简单的校正方法，但是在样品内锐利的边缘处将会产生伪影（图(7.e)）。边界处的artifacts将会导致重建图像中样品边缘处的环状伪影，然而，这相较于其他去环状伪影算法的副作用已经小得多了。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image008.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图8. 使用算法3前后重构图像对比：(a) 图(7.a)对应重建图像;(b) 根据图(7.d)对应重建图像;(c) (a) 中红色框放大视图;(d) (b)中红色框放大视图。”&gt;</p>
<p>&emsp;&emsp;算法3不仅在移除中小型局部条纹时非常有效，还可以替代算法1、2步骤2中的平滑滤波器。由于平滑滤波器而带来的额外风险，算法1、2只能用于移除中小型条纹。下一节将介绍针对大型条纹的处理方法，其中算法3仍然发挥着关键作用。</p>
<h3 id="移除大型条纹"><a href="#移除大型条纹" class="headerlink" title="移除大型条纹"></a>移除大型条纹</h3><p>&emsp;&emsp;上节介绍的算法能够在不显著影响其他区域的情况下校正中小型条纹。实际上，它甚至可以有选择地只应用于有缺陷的像素处。但在实践中，当使用低强度平滑滤波器时，对正常区域的影响微乎其微，而有选择地应用则极大的提升了工作复杂度，面对同步辐射上采集的海量数据集时很不实用。然而，当面对鲜见的大尺度缺陷区域（宽度大于20像素）时，我们不得不使用高强度平滑滤波器，而对整幅图像应用高强度平滑滤波器又将显著降低图像清晰度，得不偿失。在这种情况下，对缺陷区域选择性的应用强滤波器就显得尤为重要。那么额外的缺陷检测定位方法就必不可少。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image009.jpg” width &#x3D; 90% div align&#x3D;center &#x2F; title&#x3D;”图9. 大型条纹产生的原因及影响。(a) 大尺度缺陷（垂直箭头）及过曝斑点（水平箭头）；(b) 正弦图像中的大型条纹；(c) 重构图像中的环状伪影。”&gt;</p>
<p>&emsp;&emsp;探测器的大尺度缺陷鲜少出现，它们往往会引起全条纹S2及局部条纹S3的出现。这类大尺度缺陷可能来自于闪烁体的受损的大片区域，这些区域受损后将会反射额外的散射光（halo effect）从而形成亮斑（图(9)）。为了准确地从正弦图像中检测这类缺陷，Nghia T. Vo提出了一种一维数组分割算法以分离正缺陷（亮斑）与负缺陷（暗斑），如表(3)所示。</p>
<img src="/Exp005_table003.jpg" width = 100% div align=center />

<p>&emsp;&emsp;$I_0$、$I_1$为一维数组中的最小值与最大值，$F_0$、$F_1$为数组头尾处的拟合值，如图(10.b)所示。结合可调参数$R$，计算下阀值$T_L$与上阀值$T_U$：</p>
<p>$$T_L&#x3D;F_0-(F_1-F_0)\times R&#x2F;2, {\ \rm if\ } (F_0-I_0)&#x2F;(F_1-F_0)&gt;R.　\tag{1}\label{1}$$</p>
<p>$$T_U&#x3D;F_1+(F_1-F_0)\times R&#x2F;2, {\ \rm if\ } (I_1-F_1)&#x2F;(F_1-F_0)&gt;R.　\tag{2}\label{2}$$</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image010.jpg” width &#x3D; 50% div align&#x3D;center &#x2F; title&#x3D;”图10. 算法4演示。(a) 背景校正后的一维数组。(b) 排序后的一维数组及其中段的线性拟合。”&gt;</p>
<p>&emsp;&emsp;$R$可以理解为缺陷与背景的比值，用户可以修改$R$值来调整算法的灵敏度。通常情况下，$R$的取值在3.0以上。算法4在某些情况下也可作为二值化方法使用。算法4即为大型缺陷的检测、定位步骤，以算法4为基础构造移除大型条纹的算法5，如表(4)所示。</p>
<img src="/Exp005_table004.jpg" width = 100% div align=center />

<p>&emsp;&emsp;在算法5的步骤2中，必须去除正弦图像顶部及底部少量像素，这可以避免高频边缘引起的条纹误检测，如图(11)所示。步骤1、2和3有助于抑制部分大型条纹及小的全条纹（图(12.a)）。原理层面上，算法5是一种完全不同于正则化方法的算法。图(12.b)展示了通过算法5的后三步去除剩余局部条纹的效果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image011.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图11. 算法5中步骤2的演示。(a) 排序后的正弦图像，其中高频边缘（箭头所示）将会导致条纹误检测；(b) 对图(11.a)应用水平方向的中值滤波。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image012.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图12. 对图(9.c)应用算法5移除大型条纹的结果。(a) 应用步骤1、2和3后的重建切片图像，其中仍存在少量局部条纹（箭头所示）；(b) 完整应用算法5后的重建切片图像；(c) 最终校正后切片图像（图(12.b)）与初始切片图像（图(9.c)）的差异（difference）。”&gt;</p>
<h3 id="移除无响应条纹及震荡条纹"><a href="#移除无响应条纹及震荡条纹" class="headerlink" title="移除无响应条纹及震荡条纹"></a>移除无响应条纹及震荡条纹</h3><p>&emsp;&emsp;无响应条纹S1及震荡条纹S4同样会在重构图像中产生环状伪影及条纹伪影（图(13)）。令人遗憾的是，这些条纹无法通过上文介绍的方法移除。因为这类条纹内的像素值和条纹外像素之间的灰度差异很大，几乎没有相关性。无响应条纹S1及震荡条纹S4间的特征强度分布也不同，无响应条纹S1的低通分量几乎保持不变（图(3.a)），而震荡条纹变化较大（图(3.d)）。这种强度分布的特点可以帮助我们通过如下信息检测此类条纹：正弦图像中横向强度分布与其低通分量间的绝对差的纵向平均（图(14.a)）；规范化上述结果（图(14.b)）；并应用算法4定位条纹。检测到条纹位置后，通过插值方法填充条纹所在位置各像素值，进而移除无响应条纹S1及震荡条纹S4。表(5)展示了移除无响应条纹S1及震荡条纹S4的步骤，即算法6。</p>
<img src="/Exp005_table005.jpg" width = 100% div align=center />

<p>&lt;img src&#x3D;”&#x2F;Exp005_image013.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图13. 无响应条纹S1及震荡条纹S4的影响。(a) 既存在无响应条纹S1（箭头）也存在震荡条纹S4（方框）的正弦图像；(b) 无响应条纹S1及震荡条纹S4导致的环状伪影；(c) 探测系统中导致无响应条纹S1的过曝斑点；(d) 图(13.a)中红色方框的放大视图；(e) 图(13.b)中红色方框的放大视图。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image014.jpg” width &#x3D; 70% div align&#x3D;center &#x2F; title&#x3D;”图14. 算法6中步骤1及步骤2的说明。(a)正弦图横向强度分布的纵向平均与其低通分量间的绝对差值（蓝色曲线）；及其中值滤波后的结果（红色曲线）;(b) 图(14.a)中两条曲线相除的结果。”&gt;</p>
<p>&emsp;&emsp;图(15)展示了对图(13.a)中正弦图应用算法6的结果。过曝斑点可能会在其周围产生非线性的边缘效应，从而产生图(15.a)中的残余大型条纹。因此，算法5必须在算法6之后使用（图(15.c)）。此外，算法6的检测方法对于类似于无响应条纹S1的真实信号（例如呈圆柱形的单一材料样品）可能产生错误判断。在这种情况下，算法5是必不可少的。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image015.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图15. 校正无响应条纹S1及震荡条纹S4的结果。(a) 对图(13.a)应用算法6的结果，仍然存在未完全去除的条纹；(b) 由图(15.a)中正弦图重构所得切片图像；(c) 应用算法5后的重构切片图像；(d) 图(13.b)与图(15.c)的差异。”&gt;</p>
<h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><h3 id="去除局部条纹与全条纹方法的比较"><a href="#去除局部条纹与全条纹方法的比较" class="headerlink" title="去除局部条纹与全条纹方法的比较"></a>去除局部条纹与全条纹方法的比较</h3><p>&emsp;&emsp;下文将比较算法1、2、3与四种广泛使用的算法在消除了中小型全条纹S2及局部条纹S3时的表现。用于比较的四种算法分别为：规范化方法（normalization-based method）[7]，正则化方法（regularization-based method）[8]，傅里叶变换方法（FFT-based method）[9]，小波傅里叶变换方法（wavelet-FFT-based method）[10]。下文中为了精简描述，将这四种算法分别称作M1、M2、M3和M4。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image016.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图16. (a) 样品一的正弦图像，拥有高频边缘及低动态范围；(b) 样品二的正弦图像，拥有高频边缘及高动态范围，其中存在强吸收区域（椭圆区域）”&gt;</p>
<p>&emsp;&emsp;在第一组对比测试中，我们对相同条件下扫描两个样品所得的正弦图像应用算法M1、M2、M3、M4以及算法3。这两个样品具有相似的结构和物质组成（嵌入化石的石灰岩），但在探测器的各层中它们的结构不尽相同。样品结构差异也将导致透射强度的动态范围不同（图(16)），高动态范围可能诱发正弦图像中出现局部条纹S3。此外，还需特别注意各去环状伪影算法在相衬成像[12]引起的高频边缘（图(16.a)）处的负面影响。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image017.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图17. 对图(16.a)中正弦图应用不同的算法后的重建结果，箭头标识典型的环状伪影：(a) 平场校正后；(b) M1；(c) M2；(d) M3；(e) M4；(f) 算法3。”&gt;</p>
<p>&emsp;&emsp;对于形状大致近圆的样品一，所有去环状伪影算法的表现都较好（图(17,18)）。各个方法所用的参数如下：M1)高斯滤波，$$\sigma$$&#x3D;11；M2) $$\alpha$$&#x3D;0.005；M3) u&#x3D;30，v&#x3D;0，n&#x3D;10；M4) Daubechies wavelet, order&#x3D;10，level&#x3D;5，$$\sigma$$&#x3D;1；A3)中值滤波，size&#x3D;31。图(17.b-e)中可见其他方法在实际应用中产生了额外的局部环状伪影，而本文介绍的算法3没有在目标内部造成额外的环状伪影，不过还是在边界处产生了一些无关紧要的artifacts（图(17.f)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image018.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图18. 图(17)中重建图像中心区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;对于高长宽比的样品二，即便使用与样品一中完全相同的参数，M1-M4方法仍然表现不佳（图(19.b-e)）。它们不仅无法完美地清除原有的环状伪影，留下了许多局部条纹（图(20)），甚至产生了许多强环状伪影（图(19)中的箭头所示）。使用不同的参数集，可能可以稍稍改善计算结果。然而，这对于在同步辐射上处理海量数据集的需求而言非常低效。对比图(19.f)与图(17.f)可以看出，本文介绍的算法3应用于高动态范围的正弦图时仍然表现良好。然而，在重建图像（图(18,20)）中仍然存在由震荡条纹S4引起的环状伪影。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image019.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图19. 图(16.b)中正弦图应用不同的算法后的重建结果，箭头标识典型的环状伪影：(a) 平场校正后；(b) M1；(c) M2；(d) M3；(e) M4；(f) 算法3。”&gt;</p>
<p>&emsp;&emsp;第一组对比测试的结果表明，对于传统的M1-M4方法，需对不同样品甚至同一样品的不同层使用不同的参数集才能达到最佳效果，然而这在实际应用中极其低效，本文介绍的方法即便使用相同的参数仍然可以得到理想的去环状伪影效果，从而使得高效处理海量数据集成为可能。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image020.jpg” width &#x3D; 60% div align&#x3D;center &#x2F; title&#x3D;”图20. 图(19)中重建图像中心区域的放大视图。”&gt;</p>
<p>&emsp;&emsp;在第二组对比测试中，我们测试了这些算法去除局部条纹S3时的性能。所用样品呈高长宽比的矩形，且长边略微超出视场。这导致光路近似平行于样品长边时样品呈极强的吸收进而形成暗区，产生高动态范围。这直接引起正弦图像中出现局部条纹S3（图(21.a-c)），并在重建图像中产生局部环状伪影（图(21.d-e)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image021.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图21. 高动态范围的入射强度引起的局部条纹S3。 (a) 高长宽比矩形试样的正弦图；(b) 图(21.a)中顶部方框的放大试图；(c) 图(21.a)中底部方框的放大试图；(d) 由图(21.a)中正弦图重建所得切片图像；(e) 图(21.d)中方框的放大视图。”&gt;</p>
<p>&emsp;&emsp;应用M1-M4方法时，使用与第一次测试相同的参数对局部环形伪影几乎没有作用（图(22.a.1-d.1)）。适当的调整参数以达到更强的去环状伪影效果：M1) $$\sigma$$&#x3D;17，c&#x3D;30；M2) $$\alpha$$&#x3D;0.001，c&#x3D;30；M3) u&#x3D;30，v&#x3D;10，n&#x3D;10；M4) order&#x3D;10，level&#x3D;5，$$\sigma$$&#x3D;10。其中，<font color = #ff7f00>使用参数c（chunk）将正弦图划分为多个行块[13]</font>，从而增加算法M1及M2的强度。增强算法M1-M4的强度后均能清除局部环状伪影，但也抹去了重建图像中心区域的细节（void-center artifacts），如图(22.a.2-d.2)所示。然而，本文介绍的算法3在使用窗口大小分别为31和51的中值过滤器时都返回了没有额外干扰的干净图像（图(22.e.1，22.e.2)）。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image022.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图22. 应用不同参数集的算法M1-M4和算法3后的重建图像。 (a.1) M1；(b.1) M2；(c.1) M3；(d.1) M4；(e.1) A3；(a.2) M1；(b.2) M2；(c.2) M3；(d.2) M4；(e.2) A3。”&gt;</p>
<p>&emsp;&emsp;在第三组对比测试中，我们尝试比较了这些算法应用在一组极具挑战性的数据上时的性能。图(23.a)展示了其对比度极低的正弦图像，<font color = #ff7f00>我们不得不对其使用强低通滤波器[14]以提高其对比度</font>。然而，这种方法不可避免的模糊并扩大了原先存在的条纹（图(23.b)）。面对这一极具挑战性的数据时，我们发现与算法2、算法3相比，算法1提供了最好的结果。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image023.jpg” width &#x3D; 62% div align&#x3D;center &#x2F; title&#x3D;”图23. 预处理方法引起的条纹扩大，及应用算法1后的结果。(a,b) 应用预处理方法前后探测器同一排的正弦图像；(c) 由图(23.b)中正弦图重建所得切片图像；(d) 应用算法1中步骤1后的结果，采用三阶多项式；(e) 依靠强二维低通滤波器校正后的正弦图像；(f) 由图(23.e)中正弦图重建所得切片图像。”&gt;</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image024.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图24. 应用M1-M4方法校正环状伪影，箭头标识典型的残余环状伪影。(a) M1（$\sigma$&#x3D;121）；(b) M2（$\alpha$&#x3D;0.00001）；(c) M3（u&#x3D;2，v&#x3D;1，n&#x3D;10）；(d) M4（order&#x3D;11，level&#x3D;3，$\sigma$&#x3D;10）。”&gt;</p>
<h3 id="去除各类条纹的方法组合"><a href="#去除各类条纹的方法组合" class="headerlink" title="去除各类条纹的方法组合"></a>去除各类条纹的方法组合</h3><p>&emsp;&emsp;前面的示例中，只使用了几组带有特定类型条纹的正弦图像用于演示方法的性能。在实践中，我们需要同时处理三维数据集中所有的正弦图像，各种类型的条纹可能出现在各个位置，甚至可能同时存在于同一位置。然而，单一的算法无法同时移除所有种类的条纹。例如，算法3及方法M1-M4无法去除图(18，20)所示的震荡条纹，也无法移除无响应条纹，这类条纹必须使用某种插值方法以填充缺失信息。并且，算法6不能单独使用，必须组合算法5以清理残余条纹。一般情况下，我们需要结合算法6，算法5以及表(2)中某种算法，既确保移除所有种类条纹，又极大抑制了算法导致的额外干扰。本文中介绍各个算法的顺序是基于它们之间相互依赖的顺序。然而，在实践中实际使用它们的顺序应该与文中顺序相反（[6 5 1]，[6 5 2]，或[6 5 3]）。算法1、2、3应在算法5之后使用，否则可能反而放大大型条纹。</p>
<p>&emsp;&emsp;图(25)展示了运用算法[6 5 3]组合处理完整层析数据集的结果。不使用去环状伪影方法的重构结果和使用小波傅里叶变换方法（wavelet-FFT-based method）[10]的重构结果也被展示出来以进行对照。图(25.c)中可见，各类环状伪影被清除殆尽。少量非常大但对比度很低的环状伪影仍然存在，它们来自于探测器中被晕轮效应（halo effect）影响的区域，在实际应用中很难准确检测到这类干扰。算法6中步骤1使用半径30的均值滤波器重建原始信号的低通分量，步骤2中使用尺寸为81的中值滤波器，步骤3中使用的R为3，步骤4中使用线性插值方法；算法5中中值滤波的尺寸与R的取值与算法6完全相同，步骤2中两侧5%的像素被舍弃；算法3中使用尺寸为31的中值滤波器。</p>
<p>&lt;img src&#x3D;”&#x2F;Exp005_image025.jpg” width &#x3D; 100% div align&#x3D;center &#x2F; title&#x3D;”图25. (a) 原始重构图像；(b) 应用小波傅里叶变换方法后的重构切片，参数与图(17.e)相同；(c) 应用算法[6 5 3]组合后的重构图像。”&gt;</p>
<p>&emsp;&emsp;组合算法似乎允许非常宽泛的参数集取值选择。然而，所有的可调参数很大程度上是由探测系统缺陷的尺寸和亮度差异直接决定的，它们分别与平滑滤波器的尺寸和R值相关。这是在同步辐射束线长期实验总结的经验结论，Nghia T. Vo证明此参数集选取标准适用于I12-JEEP线站长期以来采集的大多数层析成像数据[15]。其他参数，如算法6步骤1中均值滤波器的尺寸或算法5步骤2中舍弃边界的百分比，都是非敏感参数，对结果影响较小。算法5和算法6可以使用一致的参数集。总之，只有三个关键参数需要调整：算法5与算法6所用的平滑滤波器尺寸及R值；以及算法3中平滑滤波器的尺寸。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>&emsp;&emsp;根据探测系统缺陷像素的特征强度分布，本文将X-ray micro-CT中常见的条纹伪影分为四类：局部条纹、全条纹、震荡条纹和无响应条纹。它们分别需要利用不同的算法针对性解决，本文建议将文中介绍的三种算法组合使用，不仅可以移除各类条纹，还可以极大降低算法带来的负面影响。这些算法根据两项核心思想发展而来：（一）基于均衡或平滑相邻像素相应系数的校正方法；（二）基于排序、拟合、阈值的探测器缺陷区域检测方法。</p>
<p>&emsp;&emsp;本文所有方法都是易于学习理解、实现并使用的。在具有高动态范围、难以处理的局部条纹和模糊条纹的数据上，证明了其优于主流方法的性能。对照实验的结果表明，本文介绍的方法在不同样本间应用时无需修改参数，使用方便。</p>
<h2 id="Code-and-Data"><a href="#Code-and-Data" class="headerlink" title="Code and Data"></a>Code and Data</h2><p>本文介绍的算法与M1-M4方法的Python实现：<a href="https://github.com/nghia-vo/sarepy">https://github.com/nghia-vo/sarepy</a>。</p>
<p>本文使用的示例投影图像及重建图像数据集：<a href="https://doi.org/10.5281/zenodo.1443568">https://doi.org/10.5281/zenodo.1443568</a>。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://arxiv.org/ftp/arxiv/papers/1610/1610.08015.pdf"><font size = 2px>[1]&nbsp;&nbsp;N. Wadeson and M. Basham, “Savu: a Python-based, MPI framework for simultaneous processing of multiple, N-dimensional, large tomography datasets,” (2016)</font></a><br><a href="http://journals.iucr.org/s/issues/2014/05/00/pp5049/pp5049.pdf"><font size = 2px>[2]&nbsp;&nbsp;D. Gürsoy, F. De Carlo, X. Xiao, and C. Jacobsen, “Tomopy: a framework for the analysis of synchrotron tomographic data,” J. Synchrotron Radiat. 21(Pt 5), 1188–1193 (2014).</font></a><br><a href="https://ascimaging.springeropen.com/track/pdf/10.1186/s40679-016-0036-8"><font size = 2px>[3]&nbsp;&nbsp;F. Brun, L. Massimi, M. Fratini, D. Dreossi, F. Billé, A. Accardo, R. Pugliese, and A. Cedola, “SYRMEP Tomo Project: a graphical user interface for customizing CT reconstruction workflows,” Adv. Struct. Chem. Imaging 3(1), 4 (2017).</font></a><br><a href="http://sci-hub.tw/https://doi.org/10.1117/12.893252"><font size = 2px>[4]&nbsp;&nbsp;T. E. Gureyev, Y. Nesterets, D. Ternovski, D. Thompson, S. Wilkins, A. Stevenson, A. Sakellariou, and J. A. Taylor, “Toolbox for advanced X-ray image processing,” Proc. SPIE 8141, 81410B (2011).</font></a><br><a href="https://arxiv.org/pdf/1306.1392"><font size = 2px>[5]&nbsp;&nbsp;A. Mirone, E. Brun, E. Gouillart, P. Tafforeau, and J. Kieffer, “The PyHST2 hybrid distributed code for high speed tomographic reconstruction with iterative reconstruction and a priori knowledge capabilities,” Nucl. Instrum. Methods Phys. Res. B 324, 41–48 (2014).</font></a><br><a href="http://sci-hub.tw/10.1109/HPCC.2012.116"><font size = 2px>[6]&nbsp;&nbsp;M. Vogelgesang, S. Chilingaryan, T. d. Rolo, and A. Kopmann, “UFO: a scalable GPU-based image processing framework for on-line monitoring,” in IEEE International Conference on High Performance Computing and Communication &amp; Embedded Software and Systems (2012) pp. 824–829.</font></a><br><a href="https://www.mcs.anl.gov/research/projects/X-ray-cmt/rivers/tutorial.html"><font size = 2px>[7]&nbsp;&nbsp;M. Rivers, “Tutorial Introduction to X-ray Computed Microtomography Data Processing,”</font></a><br><a href="https://reader.elsevier.com/reader/sd/pii/S089396591000282X?token=8B0E798EF5FAD6E02787BF0198E9AE875C06C7210B90414AFE0F8C9C77E247F5231A50F10F7F85643E2B558522256429"><font size = 2px>[8]&nbsp;&nbsp;S. Titarenko, P. J. Withers, and A. Yagola, “An analytical formula for ring artefact suppression in X-ray tomography,” Appl. Math. Lett. 23(12), 1489–1495 (2010).</font></a><br><a href="http://qmxmt.com/scans/dave/other/papers/xmt%20artefacts/numerical%20removal%20of%20ring%20artifacts%20in%20microtomography.pdf"><font size = 2px>[9]&nbsp;&nbsp;C. Raven, “Numerical Removal of Ring Artifacts in Microtomography,” Rev. Sci. Instrum. 69(8), 2978–2980 (1998).</font></a><br><a href="https://www.osapublishing.org/DirectPDFAccess/48AC7ECE-D00F-B398-27185C39BD3B35FB_179485/oe-17-10-8567.pdf?da=1&id=179485&seq=0&mobile=no"><font size = 2px>[10]&nbsp;&nbsp;B. Münch, P. Trtik, F. Marone, and M. Stampanoni, “Stripe and ring artifact removal with combined wavelet-Fourier filtering,” Opt. Express 17(10), 8567–8591 (2009).</font></a><br><a href="https://pdfs.semanticscholar.org/4aee/d2da8e4a8bf7d25e5a777bf4b240ac7efd53.pdf"><font size = 2px>[11]&nbsp;&nbsp;J. Sijbers and A. Postnov, “Reduction of ring artefacts in high resolution micro-CT reconstructions,” Phys. Med. Biol. 49(14), N247–N253 (2004).</font></a><br><a href="https://pdfs.semanticscholar.org/1378/e0d19965c975086be524bb7903090e874d3c.pdf"><font size = 2px>[12]&nbsp;&nbsp;A. Snigirev, I. Snigireva, V. Kohn, S. Kuznetsov, and I. Schelokov, “On the possibilities of x-ray phase contrast microimaging by coherent high-energy synchrotron radiation,” Rev. Sci. Instrum. 66(12), 5486–5492 (1995).</font></a><br><a href="https://www.researchgate.net/profile/Valeriy_Titarenko/publication/51082293_Suppression_of_ring_artefacts_when_tomographing_anisotropically_attenuating_samples/links/0deec524021cc213f7000000.pdf"><font size = 2px>[13]&nbsp;&nbsp;S. Titarenko, V. Titarenko, A. Kyrieleis, P. J. Withers, and F. De Carlo, “Suppression of ring artefacts when tomographing anisotropically attenuating samples,” J. Synchrotron Radiat. 18(3), 427–435 (2011).</font></a><br><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1046/j.1365-2818.2002.01010.x"><font size = 2px>[14]&nbsp;&nbsp;D. Paganin, S. C. Mayo, T. E. Gureyev, P. R. Miller, and S. W. Wilkins, “Simultaneous phase and amplitude extraction from a single defocused image of a homogeneous object,” J. Microsc. 206(1), 33–40 (2002).</font></a><br><a href="https://www.nature.com/articles/s41598-018-26644-6.pdf"><font size = 2px>[15]&nbsp;&nbsp;M. Polacci, F. Arzilli, G. La Spina, N. Le Gall, B. Cai, M. E. Hartley, D. Di Genova, N. T. Vo, S. Nonni, R. C. Atwood, E. W. Llewellin, P. D. Lee, and M. R. Burton, “Crystallisation in basaltic magmas revealed via in-situ 4D synchrotron X-ray microtomography,” Sci. Rep. 8(1), 8377 (2018).</font></a></p>
]]></content>
  </entry>
  <entry>
    <title>Kaggle竞赛：基于PyTorch/U-Net算法的表面缺陷检测</title>
    <url>/archive/Exp013-Kaggle01.html</url>
    <content><![CDATA[<p>Kaggle成立于2010年，是进行数据挖掘和预测算法研发的在线平台。除平台功能外，Kaggle官方每年会举办一次大规模竞赛，奖金一百万美元，吸引了广大Data Science爱好者参与其中。从某种角度上，可以把它理解为众包平台。但不同于传统的低层次劳动力需求，Kaggle致力于解决业界难题，不再以学历和工作经验作为唯一的人才评判标准，旨在任用最聪明的人解决世界上最棘手的问题，为顶尖人才和企业之间搭建了一座桥梁。</p>
<p>Kaggle曾公开举办一次<a href="https://www.kaggle.com/c/severstal-steel-defect-detection/overview">钢材表面缺陷检测竞赛</a>，是将深度学习应用于传统目标检测很好的例子。对该赛题和解法的剖析，可以辅助理解深度学习的流程，及其应用于具体问题的套路。</p>
<span id="more"></span>

<h2 id="获取云端Kaggle数据集"><a href="#获取云端Kaggle数据集" class="headerlink" title="获取云端Kaggle数据集"></a>获取云端Kaggle数据集</h2><p>此处引用：<a href="https://github.com/Kaggle/kaggle-api">Kaggle API User Guide</a></p>
<p>To use the Kaggle API, sign up for a Kaggle account at <a href="https://www.kaggle.com/">https://www.kaggle.com</a>. Then go to the ‘Account’ tab of your user profile (<a href="https://www.kaggle.com/%22username%22/account">https://www.kaggle.com/&quot;username&quot;/account</a>) and select ‘Create API Token’. This will trigger the download of kaggle.json, a file containing your API credentials. Place this file in the location ~&#x2F;.kaggle&#x2F;kaggle.json (on Windows in the location C:\Users&quot;Windows-username”\.kaggle\kaggle.json - you can check the exact location, sans drive, with echo %HOMEPATH%). You can define a shell environment variable KAGGLE_CONFIG_DIR to change this location to $KAGGLE_CONFIG_DIR&#x2F;kaggle.json (on Windows it will be %KAGGLE_CONFIG_DIR%\kaggle.json).</p>
<p>For your security, ensure that other users of your computer do not have read access to your credentials. On Unix-based systems you can do this with the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chmod 600 ~/.kaggle/kaggle.json</span><br></pre></td></tr></table></figure>

<p>在本地计算机环境已经安装Python 3及pip环境后，<code>windows+X</code>打开Windows PowerShell (Administrator)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install kaggle</span><br></pre></td></tr></table></figure>

<p>下载数据集至<code>C:\Windows\system32\</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">kaggle competitions download -c severstal-steel-defect-detection</span><br></pre></td></tr></table></figure>

<p>可以发现该数据集包含了赛题中完整的数据集信息：</p>
<ul>
<li>train_images：训练集图像</li>
<li>test_images：测试集图像</li>
<li>train.csv：训练集图像的缺陷标注，有4类缺陷，ClassId &#x3D; [1, 2, 3, 4]</li>
<li>sample_submission.csv：上传文件样例，每个ImageID要有4排，每一排对应一类缺陷</li>
</ul>
<h2 id="Clear-mask-visualization-and-simple-eda"><a href="#Clear-mask-visualization-and-simple-eda" class="headerlink" title="Clear mask visualization and simple eda"></a>Clear mask visualization and simple eda</h2><p>Import modules and define models:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.set_option(<span class="string">&quot;display.max_rows&quot;</span>, <span class="number">101</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># print(os.listdir(&quot;D:/Code/Kaggle/Steel Defect Detection/Data Base/&quot;))</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># matplotlib inline</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.size&quot;</span>] = <span class="number">15</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">input_dir = <span class="string">&quot;D:/Code/Kaggle/Steel Defect Detection/Data Base/severstal-steel-defect-detection/&quot;</span></span><br></pre></td></tr></table></figure>

<p>如检测到有宏包未安装，则使用pip安装，如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>

<p>Read all text data:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_df = pd.read_csv(os.path.join(input_dir,<span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">sample_df = pd.read_csv(os.path.join(input_dir,<span class="string">&quot;sample_submission.csv&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_df.head())</span><br><span class="line"><span class="built_in">print</span>(sample_df.head())</span><br></pre></td></tr></table></figure>

<p>First, check the number of each class.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">class_dict = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">kind_class_dict = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">no_defects_num = <span class="number">0</span></span><br><span class="line">defects_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(train_df), <span class="number">4</span>):</span><br><span class="line">    img_names = [<span class="built_in">str</span>(i).split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> train_df.iloc[col:col+<span class="number">4</span>, <span class="number">0</span>].values]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (img_names[<span class="number">0</span>] == img_names[<span class="number">1</span>] == img_names[<span class="number">2</span>] == img_names[<span class="number">3</span>]):</span><br><span class="line">        <span class="keyword">raise</span> ValueError</span><br><span class="line">        </span><br><span class="line">    labels = train_df.iloc[col:col+<span class="number">4</span>, <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> labels.isna().<span class="built_in">all</span>():</span><br><span class="line">        no_defects_num += <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        defects_num += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    kind_class_dict[<span class="built_in">sum</span>(labels.isna().values == <span class="literal">False</span>)] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> idx, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(labels.isna().values.tolist()):</span><br><span class="line">        <span class="keyword">if</span> label == <span class="literal">False</span>:</span><br><span class="line">            class_dict[idx+<span class="number">1</span>] += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the number of images with no defects: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(no_defects_num))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the number of images with defects: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(defects_num))</span><br></pre></td></tr></table></figure>

<p>the number of images with no defects: 5902<br>the number of images with defects: 6666</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">sns.barplot(x=<span class="built_in">list</span>(class_dict.keys()), y=<span class="built_in">list</span>(class_dict.values()), ax=ax)</span><br><span class="line">ax.set_title(<span class="string">&quot;the number of images for each class&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;class&quot;</span>)</span><br><span class="line">class_dict</span><br></pre></td></tr></table></figure>

<p>defaultdict(int, {1: 897, 3: 5150, 4: 801, 2: 247})</p>
<ul>
<li>There are similar numbers of images with and without defects.</li>
<li>class is imbalanced</li>
</ul>
<h2 id="install-segmentation-models-pytorch"><a href="#install-segmentation-models-pytorch" class="headerlink" title="install segmentation_models_pytorch"></a>install segmentation_models_pytorch</h2><h3 id="install-PyTorch"><a href="#install-PyTorch" class="headerlink" title="install PyTorch"></a>install PyTorch</h3><p>查看CUDA版本，在Windows PowerShell中运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p>在<a href="https://pytorch.org/">PyTorch官网</a>下载对应版本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117</span><br></pre></td></tr></table></figure>

<h3 id="install-segmentation-models-pytorch-1"><a href="#install-segmentation-models-pytorch-1" class="headerlink" title="install segmentation_models_pytorch"></a>install segmentation_models_pytorch</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install segmentation-models-pytorch</span><br></pre></td></tr></table></figure>

<p>or install latest version from source:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install git+https://github.com/qubvel/segmentation_models.pytorch</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>复杂网络中的节点相似度</title>
    <url>/archive/NetSimu.html</url>
    <content><![CDATA[<p><figure><img src="https://s21.ax1x.com/2024/10/22/pAdGFBt.png" alt="Network Science, Albert-László Barabási, Section 3.6, Page 16"><figcaption aria-hidden="true">Network Science, Albert-László Barabási, Section 3.6, Page 16</figcaption></figure></p>
<p>笔者在去年发表的论文 <a href="/download/2023_hwchai_Acta_Mater..pdf">“Deformation dynamics of a neutron-irradiated aluminum alloy: an in-situ synchrotron tomography study”, Acta Mater., 243, 118493 (2023).</a> 中公开了一种对三维结构中复数个目标的追踪方法（Appendix A. Particle tracking analysis, PTA）。该方法摒弃了基于三维矩阵卷积的图像配准方法，而依赖具体对象的结构参数信息，实现目标追踪时计算效率的质变以及目标对目标的映射追踪。然而该方法仍有两点不足：</p>
<ol>
<li>依赖目标自身结构特征及近邻目标位移矢量的相似程度，但未充分利用复数个目标组成的局部网络结构相似程度</li>
<li>目标结构信息依赖前序步骤，如三维数字图像降噪、二值化等。应融合自适应局部结构特征识别算法</li>
</ol>
<p>与上述第一点不谋而合的是，深度学习领域往往需要衡量两个对象的相似性，特别是在信息检索，模式匹配等方向上。本文将介绍深度学习领域衡量复杂网络中节点相似程度的工作，并简要构思 PTA 方法的后续改进计划。</p>
<span id="more"></span>

<h2 id="相似性与距离"><a href="#相似性与距离" class="headerlink" title="相似性与距离"></a>相似性与距离</h2><h2 id="Reference-Link"><a href="#Reference-Link" class="headerlink" title="Reference Link:"></a>Reference Link:</h2><p><a href="https://zr9558.com/2020/12/22/nodesimilarity/">https://zr9558.com/2020/12/22/nodesimilarity/</a></p>
]]></content>
  </entry>
  <entry>
    <title>《Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow, Third Edition》 全书第三章：分类</title>
    <url>/archive/Hands-On_ML_Sec3.html</url>
    <content><![CDATA[<p>Geron教授所著的该书第一章中已经简要介绍了监督学习任务是回归（预测数值）和分类（预测类别）。在第二章中探索了一个预测加州地区房价的回归任务，并测试了如线性回归、决策树和随机森林等算法。现在我们将注意力转向分类系统。</p>
<span id="more"></span>

<h2 id="MNIST-数据集"><a href="#MNIST-数据集" class="headerlink" title="MNIST 数据集"></a>MNIST 数据集</h2><p>MNIST 数据集是一组美国高中生及人口普查局员工手写的70,000个数字图像。每个图像都标有它代表的数字。这个集合已经在机器学习领域被大量研究以至于通常称之为机器学习的“hello world”。以下代码为使用 Scikit-Learn 获取 MNIST 数据集的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_openml</span><br><span class="line">mnist = fetch_openml(<span class="string">&#x27;mnist_784&#x27;</span>,as_frame=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>sklearn.datasets 包主要包含三种类型的函数：fetch_*函数（例如fetch_openml()）用来下载现实生活中的数据集；load_*函数用来加载与Scikit-Learn捆绑的本地微型数据集；make_*函数用于生成测试数据集。生成的数据集通常包含输入数据和目标分类的元组(X,y),两者均为NumPy数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X, y = mnist.data, mnist.target</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X</span><br><span class="line">array([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       ...,</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">       [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X.shape</span><br><span class="line">(<span class="number">70000</span>, <span class="number">784</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, ..., <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;6&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y.shape</span><br><span class="line">(<span class="number">70000</span>,)</span><br></pre></td></tr></table></figure>

<p>共70000张图片，每张图片有784&#x3D;28*28个像素。使用 Matplotlib 的 imshow() 函数，令 cmap&#x3D;“binary” 来获取灰度颜色图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_digit</span>(<span class="params">image_data</span>):</span><br><span class="line">    image = image_data.reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">    plt.imshow(image,cmap=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">some_digit = X[<span class="number">0</span>]</span><br><span class="line">plot_digit(some_digit)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>这看起来像一个5，实际上标签的结果也印证了这一点：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y[<span class="number">0</span>]</span><br><span class="line"><span class="string">&#x27;5&#x27;</span></span><br></pre></td></tr></table></figure>

<p>分离训练集与测试集：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]</span><br></pre></td></tr></table></figure>

<h2 id="训练二元分类器"><a href="#训练二元分类器" class="headerlink" title="训练二元分类器"></a>训练二元分类器</h2><p>现在让我们简化这个问题，只尝试识别一个数字——例如，数字5。这个“5检测器”将是二元分类器的一个例子，能够区分两个类别，5和非5。首先，我们将为这个分类任务创建目标向量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_train_5 = (y_train == <span class="string">&#x27;5&#x27;</span>)</span><br><span class="line">y_test_5 = (y_test == <span class="string">&#x27;5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>现在让我们选择一个分类器并训练它。一个好的起点是使用ScikitLearn的随机梯度下降（Stochastic Gradient Descent, SGD）分类器，SGDClassifier类。这个分类器能够有效地处理非常大的数据集。这部分是因为SGD独立地处理训练实例，每次处理一个，这也使得SGD非常适合在线学习。让我们创建一个SGDClassifier并在整个训练集上训练它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">sgd_clf.fit(X_train, y_train_5)</span><br></pre></td></tr></table></figure>

<p>现在我们可以用它来检测数字5的图像：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.predict([some_digit])</span><br><span class="line">array([ <span class="literal">True</span>])</span><br></pre></td></tr></table></figure>

<p>分类器猜测该图像代表5（True）。看起来它在这个特殊情况下猜对了！现在，我们来评估一下这个模型的性能。</p>
<h2 id="模型性能评估"><a href="#模型性能评估" class="headerlink" title="模型性能评估"></a>模型性能评估</h2><p>评估分类器通常比评估回归器要棘手得多，所以我们将在本章的大部分时间里讨论这个话题。有许多可用的绩效衡量标准：</p>
<h3 id="使用交叉验证测量精度"><a href="#使用交叉验证测量精度" class="headerlink" title="使用交叉验证测量精度"></a>使用交叉验证测量精度</h3><p>评估模型的一个好方法是使用交叉验证函数 cross_val_score() 来评估我们的 SGDClassifier 模型，使用三次的 k-fold 交叉验证。k-fold 交叉验证意味着将训练集分成k个折叠（在本例中为3个），然后训练模型 k 次，每次进行不同的折叠进行评估：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.95035</span>, <span class="number">0.96035</span>, <span class="number">0.9604</span>])</span><br></pre></td></tr></table></figure>

<p>所有交叉验证的准确率（预测正确的比率）都在95%以上？这看起来很神奇，不是吗？好吧，在你太兴奋之前，让我们看看一个虚拟分类器，它只对最常见的类中的每个图像进行分类，在这种情况下是负类（即非5）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.dummy <span class="keyword">import</span> DummyClassifier</span><br><span class="line">dummy_clf = DummyClassifier()</span><br><span class="line">dummy_clf.fit(X_train, y_train_5)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">any</span>(dummy_clf.predict(X_train))) <span class="comment"># prints False: no 5s detected_</span></span><br></pre></td></tr></table></figure>

<p>你能猜出这个模型的精度吗？让我们来看看：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(dummy_clf, X_train, y_train_5, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.90965</span>, <span class="number">0.90965</span>, <span class="number">0.90965</span>])</span><br></pre></td></tr></table></figure>

<p>没错，准确率超过90%！这很简单，因为只有大约10%的图像是5，所以如果你总是猜测图像不是5，你将有90%的时间是正确的。这说明了为什么准确率通常不是分类器的首选性能度量，特别是当您处理倾斜的数据集。评估分类器性能的更好方法是查看混淆矩阵。</p>
<h3 id="混淆矩阵（Confusion-Matrix-CM）"><a href="#混淆矩阵（Confusion-Matrix-CM）" class="headerlink" title="混淆矩阵（Confusion Matrix, CM）"></a>混淆矩阵（Confusion Matrix, CM）</h3><p>混淆矩阵的一般思想是对于所有A&#x2F;B对计算A类实例被分类为B类的次数。例如，要知道分类器混淆8和0图像的次数，您可以查看混淆矩阵的第8行第0列。要计算混淆矩阵，首先需要有一组预测，以便将它们与实际目标进行比较。您可以对测试集进行预测，但是现在最好不要碰它（请记住，您只希望在项目的最后使用测试集，一旦您有了准备启动的分类器）。相反，你可以使用 cross_val_predict() 函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line">y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<p>就像 cross_val_score（）函数一样，cross_val_predict（）执行k-fold交叉验证，但它不是返回评估分数，而是返回对每个测试 fold 所做的预测。这意味着您可以对训练集中的每个实例进行干净的预测（这里的“干净”是指“样本外”：模型对训练期间从未见过的数据进行预测）。现在可以使用 confusion_matrix() 函数获得混淆矩阵了。只需将目标类 y_train_5 和预测类 y_train_pred 传递给它：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix </span><br><span class="line">&gt;&gt;&gt;cm = confusion_matrix(y_train_5, y_train_pred) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cm</span><br><span class="line">array([[<span class="number">53892</span>, <span class="number">687</span>],</span><br><span class="line">	[<span class="number">1891</span>, <span class="number">3530</span>]])</span><br></pre></td></tr></table></figure>

<p>混淆矩阵中的每一行表示一个实际的类，而每一列表示一个预测的类。该矩阵的第一行考虑非5图像（阴性类）：其中53,892张被正确分类为非5（称为真阴性），而其余687张被错误分类为5（假阳性，也称为I型错误）。第二行考虑5的图像（阳性类）：1,891被错误地分类为非5（假阴性，也称为II型错误），而其余3,530被正确分类为5（真阳性）。一个完美的分类器只会有真正和真负，所以它的混淆矩阵只会在它的主对角线上（从左上到右下）有非零值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_perfect_predictions = y_train_5 <span class="comment"># pretend we reached perfection </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>confusion_matrix(y_train_5, y_train_perfect_predictions) </span><br><span class="line">array([[<span class="number">54579</span>, <span class="number">0</span>],</span><br><span class="line">	[ <span class="number">0</span>, <span class="number">5421</span>]])</span><br></pre></td></tr></table></figure>

<h3 id="准确率和召回率"><a href="#准确率和召回率" class="headerlink" title="准确率和召回率"></a>准确率和召回率</h3><p>混淆矩阵为您提供了大量信息，但有时您可能更喜欢更简洁的度量。一个有趣的问题是阳性预测的准确性；这被称为分类器的准确率（Precision）。</p>
<p>$$ {\rm Precision} &#x3D; \frac{\rm TP}{\rm TP+FP} \tag{3-1}\label{3-1}$$</p>
<p>其中，TP 表示真阳性数，FP 表示假阳性数。</p>
<p>获得完美准确率的一个简单方法是创建一个分类器，它总是做出负面预测，除了对它最自信的实例进行一个单一的正面预测。如果这一个预测是正确的，那么分类器有100%的精度（精度&#x3D; 1&#x2F;1 &#x3D; 100%）。显然，这样的分类器不是很有用，因为它会忽略除一个阳性实例外的所有实例。因此，精度通常与另一个名为召回率的指标一起使用，也称为灵敏度或真阳性率（True Position Rate, TPR）：这是分类器正确检测到的阳性实例的比率。</p>
<p>$$ {\rm Recall} &#x3D; \frac{\rm TP}{\rm TP+FN} \tag{3-2}\label{3-2}$$</p>
<p>其中，FN 是假阴性的数量。</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPnQhV.jpg" alt="图 3-3: 图示的混淆矩阵显示了真阴性（左上）、假阳性（右上）、假阴性（左下）和真阳性（右下）的示例。
"><figcaption aria-hidden="true">图 3-3: 图示的混淆矩阵显示了真阴性（左上）、假阳性（右上）、假阴性（左下）和真阳性（右下）的示例。
</figcaption></figure></p>
<blockquote class="blockquote-center">
<p>简单的说，准确率代表用户得到模型判断为真的样本中确实是真的比率，召回率代表确实为真的样本被模型判断为真的比率。准确率与召回率均较高代表模型达到了优秀的性能，只有单一指标优秀不代表模型性能好。 </p>

</blockquote>

<p>Scikit-Learn 提供了几个函数来计算分类器指标，包括准确率和召回率：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score, recall_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>precision_score(y_train_5, y_train_pred) <span class="comment"># == 3530/ (687 + 3530)</span></span><br><span class="line"><span class="number">0.8370879772350012</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>recall_score(y_train_5, y_train_pred) <span class="comment"># == 3530 /(1891 + 3530)</span></span><br><span class="line"><span class="number">0.6511713705958311</span></span><br></pre></td></tr></table></figure>

<p>现在我们的5检测器看起来不像我们在考虑它的准确率时那么闪亮了。当它声称图像代表5时，正确率只有83.7%。此外，它只能检测到65.1%的5。将准确率和召回率组合成一个称为 ${\rm F}_1$ 分数的指标通常很方便，特别是当您需要一个指标来比较两个分类器时。F1分数是准确率和召回率的调和平均值。常规均值对所有值一视同仁，而调和均值对低值给予更多的权重。因此，只有在召回率和准确率都很高的情况下，分类器才会得到很高的${\rm F}_1$分数。</p>
<p>$$ {\rm F}_1 &#x3D; \frac{2}{\frac{1}{\rm Precision}+\frac{1}{\rm Recall}} &#x3D; \frac{\rm TP}{\rm TP+\frac{FN+FP}{2}} \tag{3-3}\label{3-3} $$</p>
<p>要计算 ${\rm F}_1$分数只需调用 f1_score() 函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_train_pred)</span><br><span class="line"><span class="number">0.7325171197343846</span></span><br></pre></td></tr></table></figure>

<p>F1分数倾向于具有相似精度和召回率的分类器。这并不总是你想要的：在某些情况下，你最关心的是准确性，而在其他情况下，你真正关心的是召回率。例如，如果你训练一个分类器来检测对孩子安全的视频，你可能更喜欢一个分类器，它会拒绝许多好的视频（低召回率），但只保留安全的视频（高精度），而不是一个具有更高召回率的分类器，但会让一些非常糟糕的视频出现在你的产品中（在这种情况下，你甚至可能想要添加一个人工管道来检查分类器的视频选择）。另一方面，假设你训练一个分类器来检测监视图像中的商店扒手：如果你的分类器只有30%的准确率，只要它有99%的召回率，这可能是好的（当然，保安会得到一些错误的警报，但几乎所有的商店扒手都会被抓住）。不幸的是，你不能两全其美：提高精确度会降低召回率，反之亦然。这被称为精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）。</p>
<h3 id="精确度-召回率权衡（precision-recall-trade-off）"><a href="#精确度-召回率权衡（precision-recall-trade-off）" class="headerlink" title="精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）"></a>精确度&#x2F;召回率权衡（precision&#x2F;recall trade-off）</h3><p>为了理解这种权衡，让我们看看 SGDClassifier 是如何做出分类决策的。对于每个实例，它根据决策函数计算一个分数。如果该分数大于阈值，则将实例分配给正类；否则它会把它赋值给负类。图 3-4 给出了分数从左边最低到右边最高的几个数字。假设决策阈值位于中间的箭头（在两个5之间）：你会发现在该值的右边有4个真阳性，和1个假阳性。但在6个真实的5中,分类器只检测到4个。如果你提高阈值,假阳性（6）成为一个真正的阴性，从而增加的精度(在本例中高达100%)，但一个真正的5的成为假阴性，召回率降低到50%。相反，降低阈值会增加召回率，降低准确率。</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPMB90.jpg" alt="图 3-4: 精度&#x2F;召回权衡：图像根据分类器得分进行排序，高于所选决策阈值的图像被认为是正面的；阈值越高，召回率越低，但（通常）精度越高"><figcaption aria-hidden="true">图 3-4: 精度/召回权衡：图像根据分类器得分进行排序，高于所选决策阈值的图像被认为是正面的；阈值越高，召回率越低，但（通常）精度越高</figcaption></figure></p>
<p>Scikit-Learn 不能让你直接设置阈值，但它可以让你访问它用来做出预测的决策分数。你可以调用分类器的predict() 方法，而不是调用它的 decision_function() 方法，它会为每个实例返回一个分数，然后使用你想要基于这些分数进行预测的任何阈值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;y_scores = sgd_clf.decision_function([some_digit])</span><br><span class="line">&gt;&gt;&gt;y_scores</span><br><span class="line">array([<span class="number">2164.22030239</span>])</span><br><span class="line">&gt;&gt;&gt;threshold = <span class="number">0</span></span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred = (y_scores &gt; threshold) </span><br><span class="line">array([<span class="literal">True</span>])</span><br></pre></td></tr></table></figure>

<p>SGDClassifier 使用 0 为阈值，因此前面的代码返回与predict() 方法相同的结果。让我们提高阈值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;threshold = <span class="number">3000</span> </span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred = (y_scores &gt; threshold) </span><br><span class="line">&gt;&gt;&gt;y_some_digit_pred </span><br><span class="line">array([<span class="literal">False</span>])</span><br></pre></td></tr></table></figure>

<p>这证实了提高阈值会降低召回。图像实际上代表一个5，当阈值为0时，分类器会检测到它，但当阈值增加到3000时，它会错过它。如何决定使用哪个阈值？首先，使用cross_val_predict() 函数获取训练集中所有实例的分数，但这次指定要返回决策分数而不是预测分类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=<span class="number">3</span>，method=<span class="string">&quot;decision_function&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>有了这些分数，使用 precision_recall_curve() 函数来计算所有可能阈值的精度和召回率（该函数添加的最后精度为0，最后召回率为1，对应于无限阈值），最后，使用Matplotlib绘制精度和召回率作为阈值的函数（图3-5）。让我们显示我们选择的阈值3000：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve</span><br><span class="line"></span><br><span class="line">precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)</span><br><span class="line"></span><br><span class="line">plt.plot(thresholds, precisions[:-<span class="number">1</span>], <span class="string">&quot;b--&quot;</span>, label=<span class="string">&quot;Precision&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.plot(thresholds, recalls[:-<span class="number">1</span>], <span class="string">&quot;g-&quot;</span>, label=<span class="string">&quot;Recall&quot;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">plt.vlines(thresholds, <span class="number">0</span>, <span class="number">1.0</span>, <span class="string">&quot;k&quot;</span>, <span class="string">&quot;dotted&quot;</span>, label=<span class="string">&quot;threshold&quot;</span>)</span><br><span class="line">[...] <span class="comment"># beautify the figure: add grid, legend, axis, labels, and circles </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPQPbQ.jpg" alt="图 3-5：精确率和召回率对决策阈值的影响"><figcaption aria-hidden="true">图 3-5：精确率和召回率对决策阈值的影响</figcaption></figure></p>
<p>此外该图还呈现了一个有趣的现象，当阈值提高时，准确率偶尔会下降，而召回率一定随阈值提高而单调下降。</p>
<p>在3000这个阈值下，准确率接近90%，召回率约为50%。另一种选择良好的精度&#x2F;召回率权衡的方法是直接绘制精度与召回率的关系，如图3-6所示：</p>
<p><figure><img src="https://s21.ax1x.com/2025/01/11/pEPQkUs.jpg" alt="图 3-6：准确率 vs 召回率"><figcaption aria-hidden="true">图 3-6：准确率 vs 召回率</figcaption></figure></p>
<p>你可以看到，准确度在 80% 的召回率左右开始急剧下降。您可能希望在下降之前选择一个准确率&#x2F;召回率权衡-例如，在60% 左右召回。当然，选择取决于您的项目。假设你的目标是90% 的准确率，你可以用第一张图找到你需要使用的阈值，但这不是很精确。或者，您可以搜索至少提供90%精度的最低阈值。为此，您可以使用 NumPy 数组的 argmax() 方法。这将返回最大值的第一个索引，在本例中意味着第一个 True 值。</p>
<h3 id="受试者操作特征（ROC）曲线"><a href="#受试者操作特征（ROC）曲线" class="headerlink" title="受试者操作特征（ROC）曲线"></a>受试者操作特征（ROC）曲线</h3><p>受试者操作特征（Receiver Operating Characteristic, ROC）曲线是二值分类器的另一个常用工具。它与精确率&#x2F;召回率曲线非常相似，但ROC曲线不是绘制精确率与召回率的关系，而是绘制真阳性率（召回率的另一个名称）与假阳性率（False Positive Rate, FPR）的关系。FPR（也称为fall-out）是指False事件被错误地归类为True事件的比率。它等于1-真阴性率（True Negative Rate, TNR），即正确归类为阴性的阴性实例的比率。TNR也被称为特异性。因此，ROC曲线绘制敏感性（召回率）与1-特异性。为了绘制ROC曲线，首先使用roc_curve() 函数计算各种阈值的 TPR 和 FPR：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve</span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)</span><br></pre></td></tr></table></figure>

<p>然后，您可以使用 Matplotlib 绘制FPR与TPR的关系。下面的代码生成图3-7中的图。为了找到对应于90%精度的点，我们需要查找所需阈值的索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">idx_for_threshold_at_90 = (thresholds &lt;= threshold_for_90_precision).argmax()</span><br><span class="line">tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]</span><br><span class="line"></span><br><span class="line">plt.plot(fpr, tpr, linewidth=<span class="number">2</span>, label=<span class="string">&quot;ROC curve&quot;</span>) </span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;k:&#x27;</span>, label=<span class="string">&quot;Random classifier&#x27;s ROC curve&quot;</span>) </span><br><span class="line">plt.plot([fpr_90], [tpr_90], <span class="string">&quot;ko&quot;</span>, label=<span class="string">&quot;Threshold for 90% precision&quot;</span>) </span><br><span class="line">[...] <span class="comment"># beautify the figure: add labels, grid, legend, arrow, and text </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/13/pEPbgLd.png" alt="图3-7  在所有可能的阈值下绘制假阳性率与真阳性率的ROC曲线；黑色圆圈突出了所选择的比例（90%的准确率和48%的召回率）。"><figcaption aria-hidden="true">图3-7  在所有可能的阈值下绘制假阳性率与真阳性率的ROC曲线；黑色圆圈突出了所选择的比例（90%的准确率和48%的召回率）。</figcaption></figure></p>
<p>这里存在一个权衡：召回率（TPR）越高，分类器产生的假阳性（FPR）越多。虚线表示纯随机分类器的ROC曲线；一个好的分类器会尽可能远离那条线（朝向左上角）。比较分类器的一种方法是测量曲线下面积（Area Under the Curve, AUC）。一个完美的分类器的ROC AUC等于1，而一个纯粹随机的分类器的ROC AUC等于0.5。Scikit-Learn 提供了一个函数来估计ROC AUC：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores)</span><br><span class="line"><span class="number">0.9604938554008616</span></span><br></pre></td></tr></table></figure>

<p>现在让我们创建一个 RandomForestClassifier，我们可以将其PR曲线和${\rm F}_1$分数与 SGDClassifier 进行比较：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier </span><br><span class="line">forest_clf = RandomForestClassifier(random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>

<p>precision_recall_curve() 函数需要每个实例的标签和分数，因此我们需要训练随机森林分类器并使其为每个实例分配分数。但是 RandomForestClassifier 类没有 decision_function() 方法，因为它的工作方式（我们将在第7章中介绍）。幸运的是，它有一个 predict_proba() 方法，返回每个实例的类概率，我们可以只使用正类的概率作为分数，所以它会工作得很好。我们可以调用 cross_val_predict() 函数来使用交叉验证训练 RandomForestClassifier，并使其预测每个图像的类别概率，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=<span class="number">3</span>, method=<span class="string">&quot;predict_proba&quot;</span>)</span><br><span class="line">&gt;&gt;&gt;y_probas_forest[:<span class="number">2</span>] </span><br><span class="line">array([[<span class="number">0.11</span>, <span class="number">0.89</span>],</span><br><span class="line">    [<span class="number">0.99</span>, <span class="number">0.01</span>]])</span><br></pre></td></tr></table></figure>

<p>让我们看看训练集中前两张图像的类概率。该模型预测第一张图像为正的概率为89%，预测第二张图像为负的概率为99%。因为每个图像要么是正的，要么是负的，每一行的概率加起来是100%。</p>
<p>这些是估计的概率，不是实际的概率。例如，如果你看一下所有被模型分类为阳性的图像，估计概率在50%到60%之间，大约94%的图像实际上是阳性的。因此，在这种情况下，模型估计的概率太低了——但模型也可能过于自信。sklearn calibration package 包含工具来校准估计的概率，使它们更接近实际概率。请参阅本章笔记本中的额外材料部分了解更多细节。</p>
<p>第二列包含正类的估计概率，因此让我们将它们传递给precision_recall_curve()函数，并绘制PR曲线（图3-8）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y_scores_forest = y_probas_forest[:, <span class="number">1</span>] </span><br><span class="line">precisions_forest, recalls_forest, thresholds_forest = precision_recall_curve( y_train_5, y_scores_forest)</span><br><span class="line"></span><br><span class="line">plt.plot(recalls_forest, precisions_forest, <span class="string">&quot;b-&quot;</span>, linewidth=<span class="number">2</span>, label=<span class="string">&quot;Random Forest&quot;</span>)</span><br><span class="line">plt.plot(recalls, precisions, <span class="string">&quot;--&quot;</span>, linewidth=<span class="number">2</span>, label=<span class="string">&quot;SGD&quot;</span>) </span><br><span class="line">[...] <span class="comment"># beautify the figure: add labels, grid, and legend </span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><figure><img src="https://s21.ax1x.com/2025/01/16/pEFyTEQ.png" alt="图 3-8：PR曲线比较：随机森林分类器优于SGD分类器，因为它的PR曲线更接近右上角，并且具有更大的AUC"><figcaption aria-hidden="true">图 3-8：PR曲线比较：随机森林分类器优于SGD分类器，因为它的PR曲线更接近右上角，并且具有更大的AUC</figcaption></figure></p>
<p>如图3-8所示，RandomForestClassifier的PR曲线看起来比SGDClassifier的要好得多：它更接近右上角。其Fi评分和ROC AUC评分也明显较好：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>y_train_pred_forest =y_probas_forest[:, <span class="number">1</span>]&gt;= <span class="number">0.5</span> <span class="comment"># positive proba 2 50% </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f1_score(y_train_5, y_pred_forest)</span><br><span class="line"><span class="number">0.9242275142688446</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>roc_auc_score(y_train_5, y_scores_forest)</span><br><span class="line"><span class="number">0.9983436731328145</span></span><br></pre></td></tr></table></figure>

<p>试着测量准确率和召回率得分：你应该发现99.1%的准确率和86.6%的召回率。还不错！现在您知道了如何训练二元分类器、为您的任务选择适当的指标、使用交叉验证评估分类器、选择适合您需要的精度&#x2F;召回率权衡，以及使用几个指标和曲线来比较不同的模型。</p>
<h2 id="多元分类"><a href="#多元分类" class="headerlink" title="多元分类"></a>多元分类</h2><p>二元分类器区分两个类，而多类分类器（也称为多项分类器）可以区分两个以上的类。一些 Scikit-Learn 分类器（例如 LogisticRegression，RandomForestClassifier 和 GaussianNB）能够本地处理多个类。其他的则是严格的二元分类器（例如 SGDClassifier 和 SVC）。但是，您可以使用各种策略来使用多个二进制分类器执行多类分类。</p>
<p>OvR策略：创建可以将数字图像分类为10类（从0到9）的系统的一种方法是训练10个二进制分类器，每个数字一个（0检测器、1检测器、2检测器等等）。然后，当你想对图像进行分类时，你从该图像的每个分类器中获得决策分数，然后<strong>选择分类器输出最高分数的类</strong>。这被称为一对其余（one-versus-the-rest, OvR）策略，有时也称为一对所有（one-versus-all, OvA）策略。</p>
<p>OvO策略：另一种策略是为每一对数字训练一个二元分类器：一个用于区分0和1，另一个用于区分0和2，另一个用于区分1和2，以此类推。这被称为1对1（one-versus-one, OvO）策略。如果有N个类，你需要训练 Nx(N-1)&#x2F;2 个分类器。对于 MNIST 问题，这意味着要训练 45 个二元分类器！当您想要对图像进行分类时，您必须在所有 45 个分类器中运行图像，并<strong>查看哪个类赢得最多的决斗</strong>。OvO 的主要优点是每个分类器只需要在包含它必须区分的两个类的训练集部分进行训练。</p>
<p>一些算法（如支持向量机分类器）随着训练集的大小缩放得很差。对于这些算法，OvO是首选，因为在小的训练集上训练许多分类器比在大的训练集上训练很少的分类器要快。然而，对于大多数二进制分类算法，OvR 是首选。当您尝试使用二进制分类算法时，Scikit-Learn 会检测一个多类分类任务，它会根据算法自动运行 OvR 或 OvO。让我们使用 sklearn.svm.SVC 类（参见第5章）来尝试使用支持向量机分类器。我们只训练前 2000 张图像，否则将花费很长时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"></span><br><span class="line">svm_clf = SVC(random_state=<span class="number">42</span>) </span><br><span class="line">svm_clf.fit(X_train[:<span class="number">2000</span>], y_train[:<span class="number">2000</span>]) <span class="comment"># y_train, not y_train_5</span></span><br></pre></td></tr></table></figure>

<p>这很简单！我们使用从0到9的原始目标类（y_train）来训练SVC，而不是使用5对其余目标类（y_train_5）。由于有10个类（即超过2个），Scikit-Learn使用OvO策略并训练了45个二元分类器。现在让我们对图像做一个预测：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;svm_clf.predict([some_digit]) </span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>], dtype=<span class="built_in">object</span>)</span><br></pre></td></tr></table></figure>

<p>这是正确的!这段代码实际上做了45个预测，每对类一个，它选择了赢得最多决斗的类。如果调用decision_function() 方法，您将看到它为每个实例返回10个分数：每个类一个。每个类的得分等于赢得决斗的次数，加上或减去一个小调整（最大±0.33），以打破平局，基于分类器得分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;some_digit_scores=svm_clf.decision_function([some_digit])</span><br><span class="line">&gt;&gt;&gt;some_digit_scores.<span class="built_in">round</span>(<span class="number">2</span>)</span><br><span class="line">array([[ <span class="number">3.79</span>, <span class="number">0.73</span>, <span class="number">6.06</span>, <span class="number">8.3</span>,-<span class="number">0.29</span>, <span class="number">9.3</span>, <span class="number">1.75</span>, <span class="number">2.77</span>, <span class="number">7.21</span>, <span class="number">4.82</span>]])</span><br></pre></td></tr></table></figure>

<p>最高分9.3分，确实是类别5所对应的分数。</p>
<p>当一个分类器被训练时，它将目标类的列表存储在其classes属性中，按值排序。在MNIST的情况下，classes_ 数组中每个类的索引方便地匹配类本身（例如，索引5处的类恰好是类‘5’），但通常你不会那么幸运；你需要像这样查找类标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>svm_clf.classes_</span><br><span class="line">array(ГO<span class="string">&#x27;, &#x27;</span><span class="number">1</span><span class="string">&#x27;, &#x27;</span><span class="number">2</span><span class="string">&#x27;, &#x27;</span><span class="number">3</span><span class="string">&#x27;, &#x27;</span><span class="number">4</span><span class="string">&#x27;, &#x27;</span><span class="number">5</span><span class="string">&#x27;, &#x27;</span><span class="number">6</span><span class="string">&#x27;, &#x27;</span><span class="number">7</span><span class="string">&#x27;, &#x27;</span><span class="number">8</span><span class="string">&#x27;, &#x27;</span><span class="number">9</span><span class="string">&#x27;], dtype=object)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; svm_clf.classes_[class_id] </span></span><br><span class="line"><span class="string">&#x27;</span><span class="number">5</span><span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>

<p>如果你想强迫 Scikit-Learn 使用OvO或OvR的测试，你可以使用 onevsonecclassifier 或 OneVsRestClassifier 类。只需创建一个实例并将一个分类器传递给它的构造函数（它甚至不必是二进制分类器）。例如，以下代码使用基于 SVC 的 OvR 策略创建了一个多类分类器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.multiclass <span class="keyword">import</span> OneVsRestClassifier</span><br><span class="line"></span><br><span class="line">ovr_clf = OneVsRestClassifier(SVC(random_state=<span class="number">42</span>)) </span><br><span class="line">ovr_clf.fit(X_train[:<span class="number">2000</span>], y_train[:<span class="number">2000</span>])</span><br></pre></td></tr></table></figure>

<p>让我们做一个预测，并检查训练的分类器的数量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>ovr_clf.predict([some_digit]) </span><br><span class="line">array([<span class="string">&#x27;5&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">len</span>(ovr_clf.estimators_)</span><br><span class="line"><span class="number">10</span></span><br></pre></td></tr></table></figure>

<p>在多类数据集上训练 SGDClassifier 并使用它进行预测也同样简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;sgd_clf = SGDClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">&gt;&gt;&gt;sgd_clf.fit(X_train, y_train)</span><br><span class="line">&gt;&gt;&gt;sgd_clf.predict([some_digit])</span><br><span class="line">array([<span class="string">&#x27;3&#x27;</span>], dtype=<span class="string">&#x27;&lt;U1&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>哎呀，这是不正确的。预测错误确实会发生！这次 Scikit-Learn 在底层使用了OvR策略：因为有10个类，所以它训练了10个二元分类器。decision_function()方法现在每个类返回一个值。让我们看看 SGD 分类器分配给每个类的分数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sgd_clf.decision_function([some_digit]).<span class="built_in">round</span>()</span><br><span class="line">array([[-<span class="number">31893.</span>, -<span class="number">34420.</span>, -<span class="number">9531.</span>, <span class="number">1824.</span>, -<span class="number">22320.</span>, -<span class="number">1386.</span>, -<span class="number">26189.</span>,-<span class="number">16148.</span>, -<span class="number">4604.</span>,-<span class="number">12051.</span>]])</span><br></pre></td></tr></table></figure>

<p>你可以看到分类器对它的预测不是很有信心：几乎所有的分数都是非常负的，而类3的分数是+1824，类5的分数是-1386，并没有落后太多。当然，您需要在多个图像上评估这个分类器。由于每个类中有大致相同数量的图像，因此精度度量很好。像往常一样，你可以使用 cross_val_score() 函数来评估模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train, y_train, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">array([<span class="number">0.87365</span>, <span class="number">0.85835</span>, <span class="number">0.8689</span> ])</span><br></pre></td></tr></table></figure>

<p>它在所有测试折叠中都超过了85.8%。如果你使用随机分类器，你会得到10%的准确率，所以这不是一个糟糕的分数，但你仍然可以做得更好。简单地缩放输入（如第2章所述）将精度提高到89.1%以上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>scaler = StandardScaler()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X_train_scaled = scaler.fit_transform(X_train.astype(<span class="string">&quot;float64&quot;</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cross_val_score(sgd_clf, X_train_scaled, y_train, cv=<span class="number">3</span>, scoring=<span class="string">&quot;accuracy&quot;</span>) </span><br><span class="line">array([<span class="number">0.8983</span>, <span class="number">0.891</span> , <span class="number">0.9018</span>])</span><br></pre></td></tr></table></figure>

<h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2>]]></content>
  </entry>
  <entry>
    <title>数据科学：t-SNE 的原理与应用</title>
    <url>/archive/Tsne.html</url>
    <content><![CDATA[<p><img src="https://upload.wikimedia.org/wikipedia/commons/9/94/T-SNE_visualisation_of_word_embeddings_generated_using_19th_century_literature.png"></p>
<div align="center">使用 19 世纪文献生成的词嵌入的 T-SNE 可视化</div>

<p>t 分布随机邻域嵌入(t-SNE) 是一种统计方法，通过为每个数据点在二维或三维地图中赋予一个位置来可视化高维数据。它是一种非线性降维技术，用于在二维或三维低维空间中嵌入高维数据以进行可视化。具体而言，它通过二维或三维点对每个高维对象进行建模，这样相似的对象由附近的点建模，而不同的对象则以高概率由远处的点建模。<br>t-SNE 算法包括两个主要阶段。首先，t-SNE 在高维对象对上构建一个概率分布，这样相似的对象被分配更高的概率，而不同的点被分配更低的概率。其次，t-SNE 在低维图中的点上定义一个相似的概率分布，并最小化两个分布之间关于图中点位置的Kullback-Leibler 散度（<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL 散度</a>）。<br>对于包含n 个元素的数据集，t-SNE 的运行时间为$O(n^2)$，空间为$O( n^2)$。</p>
<span id="more"></span>

<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>给定一组高维数据对象$x_i$,…,$x_N$,t-SNE计算$x_i$与$x_j$的相似度成正比的概率</p>
<p>$$<br>p_{i|j} &#x3D; \frac{\exp\left(-|x_i - x_j|^2 &#x2F; 2 \sigma_i^2\right)}{\sum_{k \neq i} \exp\left(-|x_i - x_k|^2 &#x2F; 2 \sigma_i^2\right)}( i\neq j)<br>$$</p>
<p>其中$\sigma_i$是以数据点$x_i$为中心的高斯方差,$|x_i - x_j|$表示数据$x_i$与$x_j$的<a href="https://en.wikipedia.org/wiki/Euclidean_distance">欧式距离</a>,且定义$p_{i|i}$&#x3D;0;$p_{i|j}$表示$x_i$按照其概率密度的比例并以$x_i$为高斯中心选择$x_j$作为邻居的条件概率;<br>且有定义$p_{ij} &#x3D; \frac{p_{j|i} + p_{i|j}}{2N}$。<br>t-SNE旨在学习一个映射,通过该映射,高维数据$x_i$,…,$x_N$将映射为对应的低维数据$y_i$,…,$y_N$(维数一般为2或者3),该低维数据之间计算所得相似度$q_{ij}$尽可能接近$p_{ij}$。$q_{ij}$定义如下:</p>
<p>$$<br>q_{ij} &#x3D; \frac{(1+|y_i - y_j|^2 )^{-1}}{\sum_{k}\sum_{l \neq k}(1+|y_k - y_l|^2 )^{-1}}( i\neq j)<br>$$</p>
<p>为了得到逼近高维数据之间计算得到相似度的低维数据，我们需要通过梯度下降（当前采用的主流方法为Barnes-Hut算法）的方法最小化P分布与Q分布的KL散度：</p>
<p>$$<br>KL(P||Q) &#x3D; \sum_{i \neq j}p_{ij}\log \frac{p_{ij}}{q_{ij}}<br>$$</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>案例选取一个长度为3072随机生成的二维信号，通过t-SNE计算并使用matplotlib库进行绘制,使用python进行t-SNE计算的库主要有sklearn.manifold.TSNE、<a href="https://github.com/KlugerLab/pyFIt-SNE/tree/master">fitsne</a>、<a href="https://github.com/CannyLab/tsne-cuda">tsnecuda</a>三个。<br>测试算法时笔者的测试平台的相关配置信息如下：<br><img src="https://i.postimg.cc/DZyT1pwM/cpuinfo.png"><br>上述命令得到的信息依次是：CPU逻辑核数与型号信息、CPU物理个数、每个物理CPU的核数、总CPU逻辑个数（总CPU逻辑个数 &#x3D; 物理CPU个数 x 每个物理CPU的核数 x 超线程数）。<br>GPU信息如下所示：<br><img src="https://i.postimg.cc/W3Ww4zyH/gpuinfo.png"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> set_seed</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> fitsne <span class="keyword">import</span> FItSNE</span><br><span class="line"><span class="keyword">from</span> tsnecuda <span class="keyword">import</span> TSNE <span class="keyword">as</span> CudaTSNE</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quzheng</span>(<span class="params">num:<span class="built_in">float</span></span>):</span><br><span class="line">    <span class="keyword">if</span> num&lt;<span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> math.floor(num)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> math.ceil(num)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment">#sure result can repeat</span></span><br><span class="line">    seed = <span class="number">1234</span></span><br><span class="line">    setup_seed(seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#gen random 2d data</span></span><br><span class="line">    m = <span class="number">2</span></span><br><span class="line">    n = <span class="number">3072</span> </span><br><span class="line">    data1 = np.random.uniform(-<span class="number">100</span>, <span class="number">100</span>, size=(n, <span class="number">1</span>)).astype(np.float32) <span class="comment">#random data range (-100,100),type is float32</span></span><br><span class="line">    data2 = np.random.uniform(-<span class="number">100</span>, <span class="number">100</span>, size=(n, <span class="number">1</span>)).astype(np.float32) <span class="comment">#random data range (-100,100),type is float32</span></span><br><span class="line">  </span><br><span class="line">    data = np.column_stack((data1, data2))</span><br><span class="line">    origin_data = data.copy()</span><br><span class="line">  </span><br><span class="line">    data_dict = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    tsne = TSNE(n_components = <span class="number">2</span>,perplexity=<span class="number">30</span>,verbose=<span class="number">1</span>,max_iter=<span class="number">2000</span>,random_state=seed,init=<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    tsne_data = tsne.fit_transform(data)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;tsne&#x27;</span>] = tsne_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    fit_tsne_data = FItSNE(data.astype(np.float64), perplexity=<span class="number">30</span>, max_iter=<span class="number">2000</span>,fft_not_bh=<span class="literal">True</span>,rand_seed=seed,initialization=<span class="string">&#x27;random&#x27;</span>)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;fit-tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;fit-tsne&#x27;</span>] = fit_tsne_data</span><br><span class="line"></span><br><span class="line">    cuda_tsne = CudaTSNE(n_iter=<span class="number">2000</span>, verbose=<span class="number">1</span>, perplexity=<span class="number">30</span>,random_seed=seed)</span><br><span class="line">    start_time = time.perf_counter()</span><br><span class="line">    cuda_tsne_data = cuda_tsne.fit_transform(data)</span><br><span class="line">    end_time = time.perf_counter()</span><br><span class="line">    execution_time = end_time-start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;cuda-tsne excute cost &quot;</span>,execution_time)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> np.array_equal(data,origin_data):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;data change!&quot;</span>)</span><br><span class="line">        exit(<span class="number">0</span>)</span><br><span class="line">    data_dict[<span class="string">&#x27;cuda-tsne&#x27;</span>] = cuda_tsne_data</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">    xy_min_max_list =  <span class="built_in">list</span>(<span class="built_in">map</span>(quzheng,reduce(<span class="keyword">lambda</span> x,y:[<span class="built_in">min</span>(x[<span class="number">0</span>],y[<span class="number">0</span>]),<span class="built_in">min</span>(x[<span class="number">1</span>],y[<span class="number">1</span>]),<span class="built_in">max</span>(x[<span class="number">2</span>],y[<span class="number">2</span>]),<span class="built_in">max</span>(x[<span class="number">3</span>],y[<span class="number">3</span>])],<span class="built_in">map</span>(<span class="keyword">lambda</span> x:[np.<span class="built_in">min</span>(x[:,<span class="number">0</span>]),np.<span class="built_in">min</span>(x[:,<span class="number">1</span>]),np.<span class="built_in">max</span>(x[:,<span class="number">0</span>]),np.<span class="built_in">max</span>(x[:,<span class="number">1</span>])],data_dict.values()))))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;get xy_range is &quot;</span>,xy_min_max_list)</span><br><span class="line">    x_min = xy_min_max_list[<span class="number">0</span>]</span><br><span class="line">    y_min = xy_min_max_list[<span class="number">1</span>]</span><br><span class="line">    x_max = xy_min_max_list[<span class="number">2</span>]</span><br><span class="line">    y_max = xy_min_max_list[<span class="number">3</span>]</span><br><span class="line">  </span><br><span class="line">    plt.figure(figsize=(<span class="number">32</span>, <span class="number">24</span>))</span><br><span class="line">    plt.suptitle(<span class="string">f&quot;Tsne Test&quot;</span>,fontsize=<span class="number">40</span>,    <span class="comment"># 字体大小</span></span><br><span class="line">                fontweight=<span class="string">&#x27;bold&#x27;</span>,  <span class="comment"># 字体粗细</span></span><br><span class="line">                fontstyle=<span class="string">&#x27;italic&#x27;</span>,  <span class="comment"># 字体风格（斜体）</span></span><br><span class="line">                color=<span class="string">&#x27;blue&#x27;</span>   <span class="comment"># 字体颜色</span></span><br><span class="line">            )</span><br><span class="line">    keys_list = <span class="built_in">list</span>(data_dict.keys())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(keys_list)):</span><br><span class="line">        sample = data_dict[keys_list[i]]</span><br><span class="line">        ax = plt.subplot(<span class="number">1</span>,<span class="built_in">len</span>(keys_list),i+<span class="number">1</span>)</span><br><span class="line">        ax.xaxis.set_major_locator(MultipleLocator(<span class="number">25</span>))  <span class="comment"># x轴主刻度间隔为25</span></span><br><span class="line">        ax.yaxis.set_major_locator(MultipleLocator(<span class="number">25</span>))  <span class="comment"># y轴主刻度间隔为25</span></span><br><span class="line">        ax.scatter(sample[:, <span class="number">0</span>], sample[:, <span class="number">1</span>], s=<span class="number">5</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line">        ax.set_title(<span class="string">f&#x27;<span class="subst">&#123;keys_list[i]&#125;</span>&#x27;</span>)</span><br><span class="line">        ax.set_ylim(y_min,y_max)</span><br><span class="line">        ax.set_xlim(x_min,x_max)</span><br><span class="line">        ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>, <span class="string">&#x27;box&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    save_file_path = <span class="string">&quot;./tsne&quot;</span></span><br><span class="line">    plt.savefig(save_file_path,dpi=<span class="number">300</span>)</span><br><span class="line">    plt.close()</span><br></pre></td></tr></table></figure>
<p>运行得到上述三种算法时间的花销如下：<br><img src="https://i.postimg.cc/BZxNfZZ4/tsne-cost.png"><br><strong>由于tsnecuda底层实现并未采用随机数种子，而是基于当前时间生成的种子,详情参见<a href="https://github.com/CannyLab/tsne-cuda/issues/44">issue</a>所以对于同一数据重复运行也无法得到相同结果</strong><br>上述运行结果可视化如下:<br><img src="https://www.helloimg.com/i/2025/01/13/6784c614828bf.png"></p>
]]></content>
  </entry>
  <entry>
    <title>部分开放基因数据库</title>
    <url>/archive/Exp013-GeneDataset.html</url>
    <content><![CDATA[<p><img src="https://i0.wp.com/sangerinstitute.blog/wp-content/uploads/2023/08/what-is-a-gene-1440-540-1.jpg?fit=1440,540&ssl=1"></p>
<p>基因是编码蛋白质的DNA碱基对序列，蛋白质是细胞和身体的基石。基因编码蛋白质结构。很简单，是吗？但是，深入到分子的细节，很快就会变得复杂起来。在二十一世纪初的机器学习时代，学界已经充分挖掘了短基因序列内的片段间的关联关系及其与宏观性状表达间的映射；2017年兴起的人工智能序列大模型依赖 Transformer 架构实现的超长上下文关联分析能力让人类对更长尺度的生命密码解读提供了可能。</p>
<p>人工智能大模型效能与模型参数规模和喂养的数据量强相关。笔者曾先后向湖南农业大学、深圳大学、重庆医科大学等数位基因组学方向的学者请教学界开放的海量基因数据的获取途径，并查阅了一些书籍及互联网资料，本文对部分开放基因数据库做简单的归纳整理。</p>
<span id="more"></span>

<h2 id="NCBI-GenBank-综合性基因数据库"><a href="#NCBI-GenBank-综合性基因数据库" class="headerlink" title="NCBI GenBank 综合性基因数据库"></a>NCBI GenBank 综合性基因数据库</h2><p>GenBank <a href="https://ftp.ncbi.nlm.nih.gov/"><font color="#80b1d3">[Link]</font></a> 是由美国国家生物技术信息中心（National Center for Biotechnology Information, NCBI）维护的全球最大、最权威的公开核酸序列数据库，与欧洲分子生物学实验室（EMBL’s European Bioinformatics Institute, EMBL-EBI）和日本DNA数据库（DNA Data Bank of Japan, DDBJ）共同组成国际核酸序列数据库合作联盟（International Nucleotide Sequence Database Collaboration, INSDC），三方数据每日同步更新。</p>
<p>GenBank 存储DNA、RNA和蛋白质序列，包括基因组、转录组、EST（表达序列标签）、专利序列等。数据来自全球科研机构、测序中心、个人研究者的提交，所有数据可免费下载和分析。新提交的序列会快速纳入数据库并每日公开更新。GenBank 的数据按类别组织，主要包括以下子数据库：</p>
<p><strong>（一）核心核酸序列数据库</strong>：</p>
<blockquote>
<p>标准序列记录：包含基因、mRNA、非编码RNA等。</p>
<p>全基因组测序（WGS）：存储未完全组装的基因组数据。</p>
<p>转录组 shotgun 组装（TSA）：基于RNA测序的转录本数据。</p>
</blockquote>
<p><strong>（二）特殊子数据库</strong>：</p>
<blockquote>
<p><a href="https://www.ncbi.nlm.nih.gov/refseq/">RefSeq参考序列数据库</a>：高质量、非冗余的基因组、转录本和蛋白质参考序列，由NCBI人工或自动注释。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/snp/">dbSNP单核苷酸多态性数据库</a>：存储SNP（单核苷酸多态性）、INDEL（插入缺失）等遗传变异数据。</p>
<p>dbEST表达序列标签数据库：存储cDNA测序得到的短片段（EST），用于基因发现和表达研究。</p>
<p><a href="https://www.ncbi.nlm.nih.gov/sra">Sequence Read Archive, SRA</a>：存储高通量测序（如Illumina、PacBio）的原始数据（FASTQ&#x2F;BAM格式）。</p>
</blockquote>
<p>每条GenBank记录包含以下关键信息：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       (序列名称、长度、类型)  </span><br><span class="line">DEFINITION  (简要描述)  </span><br><span class="line">ACCESSION   (唯一标识号，如KM123456)  </span><br><span class="line">VERSION    (版本号，如KM123456<span class="number">.1</span>)  </span><br><span class="line">KEYWORDS   (关键词)  </span><br><span class="line">SOURCE     (物种来源)  </span><br><span class="line">  ORGANISM (分类学信息)  </span><br><span class="line">REFERENCE  (参考文献)  </span><br><span class="line">FEATURES   (注释信息，如基因、CDS、启动子等)  </span><br><span class="line">ORIGIN     (实际序列)</span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       NM_001301717           <span class="number">2372</span> bp    mRNA    linear   PRI <span class="number">05</span>-JUN<span class="number">-2018</span></span><br><span class="line">DEFINITION  Homo sapiens zinc finger protein <span class="number">717</span> (ZNF717)<span class="punctuation">,</span> mRNA.</span><br><span class="line">ACCESSION   NM_001301717</span><br><span class="line">VERSION     NM_001301717<span class="number">.1</span></span><br><span class="line">KEYWORDS    RefSeq.</span><br><span class="line">SOURCE      Homo sapiens (human)</span><br><span class="line">  ORGANISM  Homo sapiens</span><br><span class="line">            Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi;</span><br><span class="line">            Mammalia; Eutheria; Euarchontoglires; Primates; Haplorrhini;</span><br><span class="line">            Catarrhini; Hominidae; Homo.</span><br><span class="line">FEATURES             Location/Qualifiers</span><br><span class="line">     source          <span class="number">1.</span><span class="number">.2372</span></span><br><span class="line">                     /organism=<span class="string">&quot;Homo sapiens&quot;</span></span><br><span class="line">                     /mol_type=<span class="string">&quot;mRNA&quot;</span></span><br><span class="line">                     /db_xref=<span class="string">&quot;taxon:9606&quot;</span></span><br><span class="line">     gene            <span class="number">1.</span><span class="number">.2372</span></span><br><span class="line">                     /gene=<span class="string">&quot;ZNF717&quot;</span></span><br><span class="line">     CDS             <span class="number">123.</span><span class="number">.1505</span></span><br><span class="line">                     /gene=<span class="string">&quot;ZNF717&quot;</span></span><br><span class="line">                     /protein_id=<span class="string">&quot;NP_001288646.1&quot;</span></span><br><span class="line">                     /translation=<span class="string">&quot;MESKVILF...&quot;</span></span><br><span class="line">ORIGIN</span><br><span class="line">        <span class="number">1</span> gatcctgcag gacaggatgc attggctgta aactctggag gacaggtgtg ggaggggggt...</span><br></pre></td></tr></table></figure>

<p><strong>GenBank 数据库的访问方法</strong></p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ncbi.nlm.nih.gov/nuccore">NCBI 网站搜索</a>，支持按Accession号（如KM123456）、基因名称、物种、关键词等搜索。</p>
</li>
<li><p>使用 <a href="https://blast.ncbi.nlm.nih.gov/">BLAST 进行序列比对</a>，可上传FASTA序列，比对相似序列。</p>
</li>
<li><p>通过 <a href="https://ftp.ncbi.nlm.nih.gov/genbank/">GenBank FTP</a>批量下载，可下载完整的GenBank数据（按物种或日期分类）。</p>
</li>
<li><p>使用 API 或编程工具，如 Entrez Programming Utilities (E-Utilities)，适用于Python、R等语言的自动化数据获取。或者 Biopython，Python库，支持GenBank数据解析。</p>
</li>
</ol>
</blockquote>
<blockquote class="blockquote-center">
<p>GenBank 的局限性包括：数据冗余：同一基因可能有多个提交版本；注释质量不一：部分记录依赖自动注释，可能有误；非参考基因组：许多测序数据未完成高质量组装。建议的解决方案是使用RefSeq（精选的高质量参考序列），并结合Ensembl、UCSC Genome Browser等工具交叉验证。 </p>

</blockquote>


<h2 id="EMBL-EBI-欧洲分子生物学实验室核苷酸序列数据库"><a href="#EMBL-EBI-欧洲分子生物学实验室核苷酸序列数据库" class="headerlink" title="EMBL-EBI 欧洲分子生物学实验室核苷酸序列数据库"></a>EMBL-EBI 欧洲分子生物学实验室核苷酸序列数据库</h2><p>欧洲分子生物学实验室核苷酸序列数据库（European Molecular Biology Laboratory Nucleotide Sequence Database）<a href="https://www.ebi.ac.uk/"><font color="#80b1d3">[Link]</font></a>是由欧洲生物信息学研究所 EMBL-EBI 维护的全球三大公共核酸序列数据库之一，与美国NCBI GenBank和日本DDBJ共同组成国际核酸序列数据库联盟INSDC，三方数据每日同步更新。</p>
<p>EMBL数据库所有数据免费公开，支持科研和商业用途（部分数据需遵循特定条款）；存储DNA、RNA、基因组、转录组、宏基因组等序列数据；部分记录经过人工或自动化功能的高级注释（如基因、蛋白质编码区）。EMBL-EBI 维护多个相关数据库，EMBL 核心数据库包含以下内容：</p>
<p>（一）**EMBL-Bank（核心核酸序列数据库）**存储原始提交的DNA&#x2F;RNA序列，包括：</p>
<blockquote>
<p>基因组测序（如人类、小鼠、细菌等）</p>
<p>转录组数据（如mRNA、ncRNA）</p>
<p>克隆序列、合成生物学数据</p>
</blockquote>
<p>（二）<a href="https://www.ebi.ac.uk/ena"><strong>欧洲核苷酸档案库（European Nucleotide Archive, ENA）</strong></a>，EMBL 的扩展数据库，包含：</p>
<blockquote>
<p>原始测序数据（SRA）（如Illumina、PacBio、Nanopore的FASTQ文件）</p>
<p>组装基因组（如细菌、真核生物参考基因组）</p>
<p>注释信息（如基因、CDS、调控元件）</p>
</blockquote>
<p>（三）<strong>其他相关EMBL-EBI数据库</strong>：</p>
<blockquote>
<p><a href="https://www.ensembl.org/">Ensembl</a>，基因组注释、比较基因组学</p>
<p><a href="https://www.uniprot.org/">UniProt</a>，蛋白质序列与功能</p>
<p><a href="https://www.ebi.ac.uk/arrayexpress">ArrayExpress</a>，基因表达数据（微阵列、RNA-seq）</p>
<p><a href="https://www.ebi.ac.uk/pdbe/">Protein Data Bank Europe, PDBe</a>，蛋白质3D结构</p>
</blockquote>
<p>EMBL 采用标准平面文件格式（flatfile），每条记录包含：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">ID   (序列标识符)  </span><br><span class="line">AC   (Accession编号，如 LT960628)  </span><br><span class="line">DT   (提交/更新日期)  </span><br><span class="line">DE   (描述)  </span><br><span class="line">KW   (关键词)  </span><br><span class="line">OS   (物种来源)  </span><br><span class="line">OC   (分类学信息)  </span><br><span class="line">RN   (参考文献)  </span><br><span class="line">RP   (参考文献位置)  </span><br><span class="line">RX   (PubMed/DOI链接)  </span><br><span class="line">FT   (特征注释，如基因、启动子、突变位点)  </span><br><span class="line">SQ   (序列数据)  </span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">ID   LT960628; SV <span class="number">1</span>; linear; genomic DNA; STD; PRO; <span class="number">243</span> BP.</span><br><span class="line">AC   LT960628;</span><br><span class="line">DT   <span class="number">12</span>-JUL<span class="number">-2016</span> (Rel. <span class="number">118</span><span class="punctuation">,</span> Created)</span><br><span class="line">DT   <span class="number">12</span>-JUL<span class="number">-2016</span> (Rel. <span class="number">118</span><span class="punctuation">,</span> Last updated<span class="punctuation">,</span> Version <span class="number">1</span>)</span><br><span class="line">DE   Synthetic construct DNA<span class="punctuation">,</span> clone<span class="punctuation">:</span> pEX-A2J2-EGFP.</span><br><span class="line">KW   synthetic construct; EGFP; reporter gene.</span><br><span class="line">OS   synthetic construct</span><br><span class="line">OC   .</span><br><span class="line">RN   <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span></span><br><span class="line">RP   <span class="number">1</span><span class="number">-243</span></span><br><span class="line">RX   DOI; <span class="number">10.1016</span>/j.plasmid<span class="number">.2016</span><span class="number">.03</span><span class="number">.002</span>.</span><br><span class="line">FT   source          <span class="number">1.</span><span class="number">.243</span></span><br><span class="line">FT                  /organism=<span class="string">&quot;synthetic construct&quot;</span></span><br><span class="line">FT                  /mol_type=<span class="string">&quot;other DNA&quot;</span></span><br><span class="line">FT   gene            <span class="number">1.</span><span class="number">.243</span></span><br><span class="line">FT                  /gene=<span class="string">&quot;EGFP&quot;</span></span><br><span class="line">FT   CDS             <span class="number">30.</span><span class="number">.740</span></span><br><span class="line">FT                  /gene=<span class="string">&quot;EGFP&quot;</span></span><br><span class="line">FT                  /protein_id=<span class="string">&quot;CCD12345.1&quot;</span></span><br><span class="line">SQ   Sequence <span class="number">243</span> BP;</span><br><span class="line">     agctagctag ctagctagct agctagctag ctagctagct agctagctag ctagctagct agctagctag</span><br><span class="line">     ctaggatccg gtaccgagct cgaattcgag ctcgagatct ggtacccggg gatcctctag agtcgacctg</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure>

<p><strong>EMBL 数据库的访问方法</strong></p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ebi.ac.uk/ena">ENA 浏览器</a>搜索，可按 Accession号（如LT960628）、基因名、物种、测序项目 搜索。</p>
</li>
<li><p>使用 ENA API 批量获取，支持编程访问（Python&#x2F;R），示例：</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl <span class="string">&quot;https://www.ebi.ac.uk/ena/portal/api/filereport?accession=PRJEB12345&amp;result=read_run&amp;fields=fastq_ftp&quot;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>ENA FTP：<a href="https://ftp.ebi.ac.uk/pub/databases/ena/">https://ftp.ebi.ac.uk/pub/databases/ena/</a>，可下载FASTA、FASTQ、SAM&#x2F;BAM等格式数据。</p>
</li>
<li><p>工具整合：Galaxy、Bioconductor 等生物信息学平台支持直接调用EMBL数据。</p>
</li>
</ol>
</blockquote>
<p>EMBL 数据库的典型应用包括：<strong>基因组组装</strong>：获取参考序列或原始测序数据（如细菌基因组）；<strong>基因功能注释</strong>：通过FT字段查看CDS、启动子等特征；<strong>宏基因组分析</strong>：从ENA下载环境样本的16S rRNA数据；<strong>合成生物学</strong>：查询质粒、载体序列（如EGFP、Cas9）。</p>
<h2 id="DDBJ-日本DNA数据库"><a href="#DDBJ-日本DNA数据库" class="headerlink" title="DDBJ 日本DNA数据库"></a>DDBJ 日本DNA数据库</h2><p>DDBJ 是由日本国立遗传学研究所（National Institute of Genetics, NIG）维护的全球三大公共核酸序列数据库之一，与美国NCBI GenBank和欧洲EMBL-EBI共同组成国际核酸序列数据库联盟INSDC，三方数据每日同步，确保全球数据一致性。</p>
<p>DDBJ 为亚洲核心数据库，由日本主导，服务亚太地区研究机构；所有数据免费公开，支持科研与商业用途（需遵守数据使用政策）。特色数据包括日本本土物种基因组（如水稻、珊瑚、深海生物）；亚洲人群基因组变异数据（如JGAS、3.5KJPN项目）；微生物与极端环境生物测序数据。DDBJ 提供多个子数据库，涵盖不同数据类型：</p>
<p>（一）<strong>DDBJ Nucleotide Sequence Database 核心核酸数据库</strong>，存储DNA&#x2F;RNA序列，包括：</p>
<blockquote>
<p>基因组（全基因组、质粒、病毒）</p>
<p>转录组（mRNA、ncRNA）</p>
<p>人工合成序列</p>
</blockquote>
<p>（二）<a href="https://www.ddbj.nig.ac.jp/dra/index.html"><strong>DDBJ Sequence Read Archive, DRA</strong></a>：</p>
<blockquote>
<p>存储高通量测序原始数据（如Illumina、PacBio的FASTQ文件）。</p>
</blockquote>
<p>（三）<a href="https://www.ddbj.nig.ac.jp/jga/index.html"><strong>Japanese Genotype-phenotype Archive, JGA</strong></a>：</p>
<blockquote>
<p>存储日本人群基因组与表型关联数据（需申请访问权限）。</p>
</blockquote>
<p>（四）<strong>BioProject&#x2F;BioSample</strong></p>
<blockquote>
<p>管理测序项目（BioProject）和样本元数据（BioSample）。</p>
</blockquote>
<p>（五）<strong>其他相关数据库</strong></p>
<blockquote>
<p><a href="https://humandbs.biosciencedbc.jp/">NBDC Human Database</a>，日本人群体数据</p>
<p><a href="https://togotv.dbcls.jp/">TogoTV</a>，生物医学视频资源</p>
</blockquote>
<p>DDBJ 采用与GenBank、EMBL一致的INSDC标准格式，每条记录包含：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       (序列ID、长度、类型)  </span><br><span class="line">DEFINITION  (描述)  </span><br><span class="line">ACCESSION   (唯一编号，如LC000001)  </span><br><span class="line">VERSION    (版本号)  </span><br><span class="line">KEYWORDS   (关键词)  </span><br><span class="line">SOURCE     (物种来源)  </span><br><span class="line">  ORGANISM (分类学信息)  </span><br><span class="line">REFERENCE  (参考文献)  </span><br><span class="line">FEATURES   (基因、CDS、突变等注释)  </span><br><span class="line">ORIGIN     (序列数据)</span><br></pre></td></tr></table></figure>

<p>示例（部分记录）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">LOCUS       LC000001                <span class="number">502</span> bp    DNA     linear   PLN <span class="number">01</span>-JAN<span class="number">-2020</span></span><br><span class="line">DEFINITION  Oryza sativa Japonica Group mRNA for actin.</span><br><span class="line">ACCESSION   LC000001</span><br><span class="line">VERSION     LC000001<span class="number">.1</span></span><br><span class="line">KEYWORDS    actin; cytoskeleton.</span><br><span class="line">SOURCE      Oryza sativa (rice)</span><br><span class="line">  ORGANISM  Oryza sativa</span><br><span class="line">            Eukaryota; Viridiplantae; Streptophyta; Embryophyta; Tracheophyta;</span><br><span class="line">            Spermatophyta; Magnoliopsida; Poales; Poaceae; Oryza.</span><br><span class="line">FEATURES             Location/Qualifiers</span><br><span class="line">     source          <span class="number">1.</span><span class="number">.502</span></span><br><span class="line">                     /organism=<span class="string">&quot;Oryza sativa&quot;</span></span><br><span class="line">                     /mol_type=<span class="string">&quot;mRNA&quot;</span></span><br><span class="line">     gene            <span class="number">1.</span><span class="number">.502</span></span><br><span class="line">                     /gene=<span class="string">&quot;act1&quot;</span></span><br><span class="line">     CDS             <span class="number">50.</span><span class="number">.450</span></span><br><span class="line">                     /gene=<span class="string">&quot;act1&quot;</span></span><br><span class="line">                     /protein_id=<span class="string">&quot;BAA12345.1&quot;</span></span><br><span class="line">ORIGIN</span><br><span class="line">        <span class="number">1</span> atggtgaggc atgtcgtcca tccgcgcttc tcccgctcgt cgctcgtcgt cgtcgacggt</span><br><span class="line">       <span class="number">61</span> gacgatattc gcgctctcgt cgttcgagaa gctgctgctg ctgctgctgc tgctgctgct</span><br><span class="line">       ...</span><br></pre></td></tr></table></figure>

<p><strong>DDBJ 数据库的访问方法</strong>：</p>
<blockquote>
<ol>
<li><p>通过 <a href="https://www.ddbj.nig.ac.jp/">DDBJ 网站</a>搜索，支持按 Accession号（如LC000001）、基因名、物种、关键词 搜索。</p>
</li>
<li><p>通过 getentry 快速检索，工具链接：<a href="https://getentry.ddbj.nig.ac.jp/">https://getentry.ddbj.nig.ac.jp/</a>，输入Accession号直接获取FASTA或GenBank格式数据。</p>
</li>
<li><p>FTP 批量下载，DDBJ FTP：<a href="https://ftp.ddbj.nig.ac.jp/">https://ftp.ddbj.nig.ac.jp/</a>，可下载完整数据库或按物种分类的数据。</p>
</li>
<li><p>提交数据至 DDBJ，提交系统：<a href="https://www.ddbj.nig.ac.jp/sub/index.html">https://www.ddbj.nig.ac.jp/sub/index.html</a>，支持基因组、转录组、变异数据提交。</p>
</li>
</ol>
</blockquote>
<p>DDBJ 的典型应用包括<strong>作物基因组研究</strong>：如水稻、大豆的基因变异分析；<strong>微生物多样性</strong>：日本本土极端环境微生物测序数据；<strong>人群遗传学</strong>：亚洲人群基因组项目（如3.5KJPN）；<strong>生物信息学工具开发</strong>：提供API和数据集用于算法测试。</p>
<h2 id="植物与微生物基因组数据库"><a href="#植物与微生物基因组数据库" class="headerlink" title="植物与微生物基因组数据库"></a>植物与微生物基因组数据库</h2><ul>
<li><a href="https://phytozome-next.jgi.doe.gov/"><strong>Phytozome 植物基因组数据库</strong></a>：植物基因组比较平台，包含多种作物基因组数据。Phytozome的基因组数据通常经过人工校正，质量较高，但要注意的是该网站上有些基因组数据是提前释放的，有使用限制，它的说明里会明确给出使用限制：可以自由使用个别或少量基因的信息，但不能完整使用全部基因组的信息。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETCYKH.png" alt="Phytozome 植物基因组数据库"><figcaption aria-hidden="true">Phytozome 植物基因组数据库</figcaption></figure></p>
<ul>
<li><a href="http://plants.ensembl.org/index.html"><strong>Ensembl Genomes 植物基因组数据库</strong></a>：Ensembl Genomes 植物基因组数据库的数据质量相对较高，好处是全部可以自由使用，但物种数量较少。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETCtrd.png" alt="Ensembl Genomes 数据库"><figcaption aria-hidden="true">Ensembl Genomes 数据库</figcaption></figure></p>
<ul>
<li><a href="https://ftp.ncbi.nlm.nih.gov/"><strong>NCBI 基因数据库</strong></a>：NCBI 基因数据库涵盖大量基因组数据，典型的子链接包括：<a href="https://ftp.ncbi.nlm.nih.gov/genomes/refseq/plant/">*&#x2F;genomes&#x2F;refseq&#x2F;plant&#x2F;</a>，这里的基因组质量也还行，物种数量较多。<a href="https://ftp.ncbi.nlm.nih.gov/genomes/genbank/plant/">*&#x2F;genomes&#x2F;genbank&#x2F;plant&#x2F;</a>，这里的基因组物种数量最全，囊括了至少95%以上的已发表的植物基因组数据，但质量参差不齐，有些只拼接到contig水平，甚至没有拼接。<a href="https://www.ncbi.nlm.nih.gov/refseq/">*&#x2F;refseq&#x2F;</a>，NCBI RefSeq 提供高质量参考基因组序列。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETPles.png" alt="NCBI 基因数据库"><figcaption aria-hidden="true">NCBI 基因数据库</figcaption></figure></p>
<ul>
<li><a href="https://genome.jgi.doe.gov/"><strong>JGI Genome Portal</strong></a>：由美国能源部联合基因组研究所维护，涵盖微生物、真菌和植物基因组。</li>
</ul>
<p><figure><img src="https://s21.ax1x.com/2025/04/26/pETPdOJ.png" alt="JGI Genome Portal"><figcaption aria-hidden="true">JGI Genome Portal</figcaption></figure></p>
<h2 id="人类基因组数据库"><a href="#人类基因组数据库" class="headerlink" title="人类基因组数据库"></a>人类基因组数据库</h2><h3 id="UCSC-Genome-Browser"><a href="#UCSC-Genome-Browser" class="headerlink" title="UCSC Genome Browser"></a>UCSC Genome Browser</h3><p>网址: <a href="https://genome.ucsc.edu/">https://genome.ucsc.edu/</a></p>
<p>提供人类和其他物种基因组的可视化工具和原始数据下载。</p>
<h3 id="1000-Genomes-Project"><a href="#1000-Genomes-Project" class="headerlink" title="1000 Genomes Project"></a>1000 Genomes Project</h3><p>网址: <a href="https://www.internationalgenome.org/">https://www.internationalgenome.org/</a></p>
<p>包含全球多个人类群体的基因组变异数据。</p>
<h3 id="gnomAD（基因组聚合数据库）"><a href="#gnomAD（基因组聚合数据库）" class="headerlink" title="gnomAD（基因组聚合数据库）"></a>gnomAD（基因组聚合数据库）</h3><p>网址: <a href="https://gnomad.broadinstitute.org/">https://gnomad.broadinstitute.org/</a></p>
<p>提供大规模人群的基因组变异频率数据。</p>
<h2 id="癌症基因组数据库"><a href="#癌症基因组数据库" class="headerlink" title="癌症基因组数据库"></a>癌症基因组数据库</h2><h3 id="TCGA（癌症基因组图谱）"><a href="#TCGA（癌症基因组图谱）" class="headerlink" title="TCGA（癌症基因组图谱）"></a>TCGA（癌症基因组图谱）</h3><p>网址: <a href="https://www.cancer.gov/tcga">https://www.cancer.gov/tcga</a></p>
<p>包含多种癌症的基因组、转录组和表观组数据。</p>
<h3 id="ICGC（国际癌症基因组联盟）"><a href="#ICGC（国际癌症基因组联盟）" class="headerlink" title="ICGC（国际癌症基因组联盟）"></a>ICGC（国际癌症基因组联盟）</h3><p>网址: <a href="https://dcc.icgc.org/">https://dcc.icgc.org/</a></p>
<p>全球合作的癌症基因组数据平台。</p>
<h3 id="COSMIC（癌症体细胞突变数据库）"><a href="#COSMIC（癌症体细胞突变数据库）" class="headerlink" title="COSMIC（癌症体细胞突变数据库）"></a>COSMIC（癌症体细胞突变数据库）</h3><p>网址: <a href="https://cancer.sanger.ac.uk/cosmic">https://cancer.sanger.ac.uk/cosmic</a></p>
<p>收录癌症相关基因突变信息。</p>
<h2 id="表观基因组与功能基因组"><a href="#表观基因组与功能基因组" class="headerlink" title="表观基因组与功能基因组"></a>表观基因组与功能基因组</h2><h3 id="ENCODE（ENCyclopedia-Of-DNA-Elements）"><a href="#ENCODE（ENCyclopedia-Of-DNA-Elements）" class="headerlink" title="ENCODE（ENCyclopedia Of DNA Elements）"></a>ENCODE（ENCyclopedia Of DNA Elements）</h3><p>网址: <a href="https://www.encodeproject.org/">https://www.encodeproject.org/</a></p>
<p>人类和小鼠基因组功能元件数据库（如启动子、增强子等）。</p>
<h3 id="Roadmap-Epigenomics"><a href="#Roadmap-Epigenomics" class="headerlink" title="Roadmap Epigenomics"></a>Roadmap Epigenomics</h3><p>网址: <a href="https://www.roadmapepigenomics.org/">https://www.roadmapepigenomics.org/</a></p>
<p>人类不同细胞类型的表观基因组数据。</p>
<h2 id="宏基因组与环境DNA"><a href="#宏基因组与环境DNA" class="headerlink" title="宏基因组与环境DNA"></a>宏基因组与环境DNA</h2><h3 id="MG-RAST"><a href="#MG-RAST" class="headerlink" title="MG-RAST"></a>MG-RAST</h3><p>网址: <a href="https://www.mg-rast.org/">https://www.mg-rast.org/</a></p>
<p>微生物群落宏基因组数据分析平台。</p>
<h3 id="NCBI-SRA（Sequence-Read-Archive）"><a href="#NCBI-SRA（Sequence-Read-Archive）" class="headerlink" title="NCBI SRA（Sequence Read Archive）"></a>NCBI SRA（Sequence Read Archive）</h3><p>网址: <a href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</a></p>
<p>存储高通量测序原始数据。</p>
<h2 id="中国主导的数据库"><a href="#中国主导的数据库" class="headerlink" title="中国主导的数据库"></a>中国主导的数据库</h2><h3 id="CNGB（中国国家基因库）"><a href="#CNGB（中国国家基因库）" class="headerlink" title="CNGB（中国国家基因库）"></a>CNGB（中国国家基因库）</h3><p>网址: <a href="https://www.cngb.org/">https://www.cngb.org/</a></p>
<p>中国深圳建立的综合性基因数据库。</p>
<h3 id="GSA（组学原始数据归档库）"><a href="#GSA（组学原始数据归档库）" class="headerlink" title="GSA（组学原始数据归档库）"></a>GSA（组学原始数据归档库）</h3><p>网址: <a href="https://ngdc.cncb.ac.cn/gsa/">https://ngdc.cncb.ac.cn/gsa/</a></p>
<p>由中国科学院北京基因组研究所维护。</p>
]]></content>
  </entry>
  <entry>
    <title>Support</title>
    <url>/support/index.html</url>
    <content><![CDATA[<h2 id="Tools-for-scholar"><a href="#Tools-for-scholar" class="headerlink" title="Tools for scholar"></a>Tools for scholar</h2><ul>
<li><a href="https://www.overleaf.com/"><font color="#80b1d3">[Link]</font></a>                    &emsp; Overleaf 全球共享的在线LaTeX写作平台</li>
<li><a href="https://colorbrewer2.org/"><font color="#80b1d3">[Link]</font></a>                    &emsp; ColorBrewer 配色方案优化</li>
<li><a href="http://www.mohu.org/info/symbols/symbols.htm"><font color="#80b1d3">[Link]</font></a> &emsp; LaTeX 常用数学符号表示方法</li>
<li><a href="https://www.tablesgenerator.com/"><font color="#80b1d3">[Link]</font></a>             &emsp; LaTeX 表格在线自动生成</li>
</ul>
<h2 id="Tools-for-Vision"><a href="#Tools-for-Vision" class="headerlink" title="Tools for Vision"></a>Tools for Vision</h2><ul>
<li><a href="https://processing.org/"><font color="#80b1d3">[Link]</font></a>                      &emsp; Processing 视觉软件开发开源工具</li>
<li><a href="https://github.com/smartgeometry-ucl/dl4g"><font color="#80b1d3">[Link]</font></a>    &emsp; CreativeAI: Deep Learning for Graphics Tutorial Code</li>
<li><a href="http://lightfield.stanford.edu/lfs.html"><font color="#80b1d3">[Link]</font></a>      &emsp; 斯坦福大学计算机图形实验室光场数据库，提供光场采集设备资料，相机标定以及可视化工具</li>
<li><a href="https://graphics.stanford.edu/courses/cs178/applets/applets.html"><font color="#80b1d3">[Link]</font></a>      &emsp; 斯坦福大学计算机图形实验室的Marc Levoy教授制作的动画仿真，详细介绍了相机参数变化对应的光路变化</li>
<li><a href="https://lightfield-analysis.uni-konstanz.de/"><font color="#80b1d3">[Link]</font></a>      &emsp; HCI光场数据集及解码工具</li>
</ul>
<h2 id="The-big-guys’-website"><a href="#The-big-guys’-website" class="headerlink" title="The big guys’ website"></a>The big guys’ website</h2><ul>
<li><a href="https://cseweb.ucsd.edu//~ravir/"><font color="#80b1d3">[Link]</font></a>             &emsp; Ravi Ramamoorthi 教授，加州大学圣地亚哥分校视觉计算中心主任，计算机视觉领域的大牛</li>
<li><a href="https://cseweb.ucsd.edu//~viscomp/projects/LF/"><font color="#80b1d3">[Link]</font></a>             &emsp; 光场实验室，隶属Ravi Ramamoorthi教授，研究光场领域深度图像获取，三维重建及去除高光等</li>
<li><a href="https://imechanica.org/"><font color="#80b1d3">[Link]</font></a>                      &emsp; iMechanica - web of mechanics and mechanicians</li>
</ul>
<h2 id="Tools-for-Hexo-NexT"><a href="#Tools-for-Hexo-NexT" class="headerlink" title="Tools for Hexo|NexT"></a>Tools for Hexo|NexT</h2><ul>
<li><a href="http://www.ehcoo.com/seo.html"><font color="#80b1d3">[Link]</font></a>                &emsp; Hexo|NexT 搜索引擎SEO检索优化</li>
<li><a href="https://imgse.com/"><font color="#80b1d3">[Link]</font></a>                           &emsp; Imgse 图床与外链服务，全球CDN加速</li>
<li><a href="https://fontawesome.com/start"><font color="#80b1d3">[Link]</font></a>                &emsp; Font Awesome 互联网最受欢迎的开源图标集</li>
<li><a href="http://yearito.cn/posts/hexo-writing-skills.html"><font color="#80b1d3">[Link]</font></a>    &emsp; Markdown 写作技巧</li>
<li><a href="https://serverless-page-bucket-rtsw4b6p-1300965131.cos-website.ap-hongkong.myqcloud.com/"><font color="#80b1d3">[Link]</font></a>    &emsp; Haiwei Chai’s Blog Beta Version</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>Tags</title>
    <url>/tags/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>人工智能：attn_implementation 在性能、显存与可复现性之间做出选择</title>
    <url>/archive/flashattention.html</url>
    <content><![CDATA[<p>当您在使用 Hugging Face <code>transformers</code> 库加载模型时，可以通过 <code>attn_implementation</code> 参数来指定底层的注意力（Attention）计算方式。这是一个至关重要的参数，直接影响了模型的训练和推理速度、显存占用以及计算结果的可复现性。</p>
<p>您在调试中发现 <code>flash_attention_2</code> 是随机性的来源，这是一个非常典型的例子，说明了前沿的性能优化有时会以牺牲一些可预测性为代价。理解不同选项的优缺点，可以帮助您根据具体需求（高性能、低显存、严格复现等）做出最优决策。</p>
<span id="more"></span>
<hr>
<h2 id="可选项对比分析"><a href="#可选项对比分析" class="headerlink" title="可选项对比分析"></a>可选项对比分析</h2><p>以下是 <code>attn_implementation</code> 的主要可选项及其详细的优缺点对比：</p>
<table>
<thead>
<tr>
<th>选项 (Option)</th>
<th>优点 (Pros)</th>
<th>缺点 (Cons)</th>
<th>适用场景 (Best For)</th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>flash_attention_2</code></strong></td>
<td><strong>极致的速度和显存优化</strong>：通过分块计算避免生成完整的 N x N 注意力矩阵，是目前公认最快的实现。</td>
<td><strong>硬件要求高</strong> (NVIDIA Ampere&#x2F;Hopper 架构，如 A100&#x2F;H100)。<strong>需要额外安装</strong> (<code>pip install flash-attn</code>)。<strong>潜在的可复现性问题</strong> (其自定义CUDA内核可能引入细微的数值不确定性)。</td>
<td><strong>生产环境中的高性能训练和推理</strong>。当追求极致性能且硬件支持时是首选。</td>
</tr>
<tr>
<td><strong><code>sdpa</code></strong></td>
<td><strong>PyTorch 原生集成</strong> (无需额外安装，需要 <code>torch&gt;=2.0</code>)。<strong>非常好的性能和显存效率</strong>，性能通常非常接近 Flash Attention。<strong>官方支持，未来趋势</strong>。</td>
<td><strong>需要较新版本的 PyTorch</strong> (<code>&gt;=2.0</code>)。在顶级硬件上，性能可能微弱于专门优化的 <code>flash_attention_2</code>。</td>
<td><strong>现代 PyTorch 环境下的通用选择</strong>。这是目前<strong>最佳的平衡点</strong>，也是最被推荐的默认选项。</td>
</tr>
<tr>
<td><strong><code>eager</code></strong></td>
<td><strong>最高的兼容性和可复现性</strong>：这是 PyTorch 的标准、原始实现，行为最可预测。<strong>无需任何特殊软硬件</strong>。<strong>是理解算法和调试的基准</strong>。</td>
<td><strong>速度最慢，显存占用最大</strong>：因为它会完整地实例化一个巨大的注意力分数矩阵，对于长序列很容易导致显存溢出 (OOM)。</td>
<td><strong>调试、教学、确保严格的比特级可复现性</strong>，或在不支持优化的旧硬件上运行。</td>
</tr>
<tr>
<td><strong><code>bettertransformer</code></strong></td>
<td>在 <code>sdpa</code> 出现之前的原生优化方案，利用了 PyTorch 的 <code>nn.TransformerEncoderLayer</code> 内核。比 <code>eager</code> 更快、更省显存。</td>
<td><strong>已被 <code>sdpa</code> 全面取代</strong>。功能、性能和未来的支持都不如 <code>sdpa</code>。在某些模型或 <code>transformers</code> 新版本中可能不再被支持。</td>
<td><strong>遗留选项</strong>。主要用于无法使用 <code>torch&gt;=2.0</code> 的旧项目，用于获得一些基础优化。</td>
</tr>
</tbody></table>
<hr>
<h2 id="为什么-Flash-Attention-会引入不确定性？"><a href="#为什么-Flash-Attention-会引入不确定性？" class="headerlink" title="为什么 Flash Attention 会引入不确定性？"></a>为什么 Flash Attention 会引入不确定性？</h2><p><code>flash-attn</code> 库的实现依赖于高度优化的、由开发者手写的 CUDA 内核。为了压榨出每一分性能，这些内核在计算方式上（例如浮点数的累加顺序、并行计算的划分等细节）可能与 PyTorch 的标准实现 (<code>eager</code>) 有所不同。</p>
<p>虽然这些算法在数学上是等价的，但在精度有限的计算机上，这些微小的实现差异会导致浮点数计算结果的细微偏差。当这些偏差在深度神经网络的多层传播中不断累积时，最终就会导致输出结果产生肉眼可见的不同。您遇到的情况很可能是某个特定的 PyTorch &#x2F; CUDA &#x2F; <code>flash-attn</code> 版本组合触发了这种行为。</p>
<hr>
<h2 id="我现在应该用哪个？——-最佳实践推荐"><a href="#我现在应该用哪个？——-最佳实践推荐" class="headerlink" title="我现在应该用哪个？—— 最佳实践推荐"></a>我现在应该用哪个？—— 最佳实践推荐</h2><p>对于目前的情况，<strong><code>sdpa</code> (Scaled Dot Product Attention) 是最佳选择。</strong></p>
<p>它完美地平衡了性能和可复现性的需求：</p>
<ul>
<li><strong>性能</strong>: <code>sdpa</code> 利用了 PyTorch 内置的、高度优化的注意力后端。它底层也可能调用类似 Flash Attention 的内核，但由 PyTorch 团队维护和保证其行为，性能与 <code>flash_attention_2</code> 非常接近，远超 <code>eager</code> 模式。</li>
<li><strong>易用性</strong>: 它是 PyTorch 2.0+ 的一部分，您<strong>无需安装任何额外依赖</strong>。</li>
<li><strong>可复现性</strong>: 作为 PyTorch 的原生组件，它的行为通常比外部的自定义库更加稳定和可预测。在配置了确定性算法的环境下，它的可复现性通常要比 <code>flash_attention_2</code> 好得多。</li>
</ul>
<h3 id="如何应用-sdpa"><a href="#如何应用-sdpa" class="headerlink" title="如何应用 sdpa"></a>如何应用 <code>sdpa</code></h3><p>您只需要在加载模型的代码中修改 <code>attn_implementation</code> 参数即可：</p>
<pre><code class="language-python">model = AutoModelForCausalLM.from_config(
    config,
    torch_dtype=torch.bfloat16,
    # 将 &quot;eager&quot; 或 &quot;flash_attention_2&quot; 替换为 &quot;sdpa&quot;
    attn_implementation=&quot;sdpa&quot; 
)
</code></pre>
]]></content>
  </entry>
  <entry>
    <title>人工智能：KL散度与交叉熵</title>
    <url>/archive/kldivergence.html</url>
    <content><![CDATA[<p>KL散度（Kullback-Leibler Divergence）与交叉熵（Cross-Entropy）是信息论中两个非常重要的概念，在机器学习，特别是深度学习领域，它们被广泛用作损失函数，以衡量两个概率分布之间的差异。两者在数学上紧密相关，在某些特定场景下（如分类任务的损失函数），最小化交叉熵等价于最小化KL散度。交叉熵衡量使用“错误的”分布Q来表示来自“正确的”分布P的样本所需要的平均信息量（比特数）。而KL散度衡量使用“错误的”分布Q来表示分布P的样本，相对于使用“正确的”分布P自己来表示时，所产生的额外信息量。</p>
<span id="more"></span>

<h2 id="一、交叉熵-Cross-Entropy"><a href="#一、交叉熵-Cross-Entropy" class="headerlink" title="一、交叉熵 (Cross-Entropy)"></a>一、交叉熵 (Cross-Entropy)</h2><h3 id="1-概念与直觉"><a href="#1-概念与直觉" class="headerlink" title="1. 概念与直觉"></a>1. 概念与直觉</h3><p>想象一下，你需要设计一套编码系统来传输一个地区（分布P）的天气信息（晴、阴、雨）。如果你的编码系统是根据另一个地区（分布Q）的天气历史设计的，那么用这套编码系统来传输P地区的天气信息时，平均每个信息所需要的编码长度就是<strong>交叉熵</strong>。</p>
<ul>
<li>如果分布Q与分布P非常相似，那么这套编码会非常高效，交叉熵就很低。</li>
<li>如果分布Q与分布P差异很大，编码效率就会很低，交叉熵就很高。</li>
</ul>
<p>在机器学习中，我们通常将：</p>
<ul>
<li><strong>P (真实分布)</strong>：看作是数据的真实标签，通常是独热编码（One-Hot Encoding）形式，例如 <code>[0, 1, 0]</code> 表示样本真实属于第2类。</li>
<li><strong>Q (预测分布)</strong>：看作是模型（如通过Softmax层）输出的预测概率，例如 <code>[0.1, 0.7, 0.2]</code>。</li>
</ul>
<p>交叉熵损失函数的目标就是让模型的预测分布Q尽可能地接近真实分布P。</p>
<h3 id="2-数学公式"><a href="#2-数学公式" class="headerlink" title="2. 数学公式"></a>2. 数学公式</h3><p>对于两个离散的概率分布 P 和 Q，其交叉熵定义为：</p>
<p>$$H(P, Q) &#x3D; - \sum_{i} P(i) \log_b Q(i)$$</p>
<p>其中：</p>
<ul>
<li><code>i</code> 代表所有可能的事件（或类别）。</li>
<li><code>P(i)</code> 是事件 <code>i</code> 在真实分布 P 中的概率。</li>
<li><code>Q(i)</code> 是事件 <code>i</code> 在预测分布 Q 中的概率。</li>
<li><code>b</code> 是对数的底，在机器学习中通常使用自然对数 <code>e</code> (即 <code>ln</code>)。</li>
</ul>
<h3 id="3-计算过程-以分类任务为例"><a href="#3-计算过程-以分类任务为例" class="headerlink" title="3. 计算过程 (以分类任务为例)"></a>3. 计算过程 (以分类任务为例)</h3><p>假设我们有一个3分类问题，一个样本的真实标签是“狗”。</p>
<p><strong>步骤 1: 定义 P 和 Q</strong></p>
<ul>
<li><p><strong>真实分布 P (One-Hot)</strong>:</p>
<ul>
<li><code>P = [P(猫), P(狗), P(鱼)] = [0, 1, 0]</code></li>
</ul>
</li>
<li><p><strong>模型预测分布 Q (Softmax输出)</strong>:</p>
<ul>
<li><code>Q = [Q(猫), Q(狗), Q(鱼)] = [0.2, 0.7, 0.1]</code></li>
</ul>
</li>
</ul>
<p><strong>步骤 2: 应用交叉熵公式</strong></p>
<p>$$H(P, Q) &#x3D; - \left( P(猫)\ln Q(猫) + P(狗)\ln Q(狗) + P(鱼)\ln Q(鱼) \right)$$</p>
<p><strong>步骤 3: 代入数值计算</strong></p>
<p>$$H(P, Q) &#x3D; - \left( 0 \cdot \ln(0.2) + 1 \cdot \ln(0.7) + 0 \cdot \ln(0.1) \right)$$</p>
<p>由于真实分布P是独热编码，只有真实标签那一项的 <code>P(i)</code> 是1，其余都是0。这极大地简化了计算：</p>
<p>$$H(P, Q) &#x3D; - \ln(0.7) \approx -(-0.3567) \approx 0.3567$$</p>
<p><strong>重要结论</strong>：在机器学习分类任务中，当真实标签是One-Hot形式时，<strong>交叉熵损失函数简化为对“正确类别”的预测概率取负对数</strong>。</p>
<hr>
<h2 id="二、KL散度-Kullback-Leibler-Divergence"><a href="#二、KL散度-Kullback-Leibler-Divergence" class="headerlink" title="二、KL散度 (Kullback-Leibler Divergence)"></a>二、KL散度 (Kullback-Leibler Divergence)</h2><h3 id="1-概念与直觉-1"><a href="#1-概念与直觉-1" class="headerlink" title="1. 概念与直觉"></a>1. 概念与直觉</h3><p>KL散度，又称<strong>相对熵 (Relative Entropy)</strong>，衡量的是两个概率分布之间的“距离”或“差异”。它量化了当我们用一个近似分布Q来代替真实分布P时，会损失多少信息。</p>
<p>与交叉熵不同，KL散度衡量的是<strong>额外</strong>的编码长度。</p>
<ul>
<li>如果P和Q完全相同，KL散度为0，表示没有信息损失。</li>
<li>P和Q差异越大，KL散度越大。</li>
<li><strong>不对称性</strong>：KL散度一个非常重要的特性是它不具有对称性，即 $D_{KL}(P || Q) \neq D_{KL}(Q || P)$。因此，它不是一个严格意义上的“距离度量”。</li>
</ul>
<h3 id="2-数学公式-1"><a href="#2-数学公式-1" class="headerlink" title="2. 数学公式"></a>2. 数学公式</h3><p>KL散度的定义如下：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log_b \frac{P(i)}{Q(i)}$$</p>
<h3 id="3-计算过程-使用相同例子"><a href="#3-计算过程-使用相同例子" class="headerlink" title="3. 计算过程 (使用相同例子)"></a>3. 计算过程 (使用相同例子)</h3><p><strong>步骤 1: 定义 P 和 Q</strong></p>
<ul>
<li><strong>真实分布 P</strong>: <code>[0, 1, 0]</code></li>
<li><strong>模型预测分布 Q</strong>: <code>[0.2, 0.7, 0.1]</code></li>
</ul>
<p><strong>步骤 2: 应用KL散度公式</strong></p>
<p>$$D_{KL}(P || Q) &#x3D; P(猫)\ln\frac{P(猫)}{Q(猫)} + P(狗)\ln\frac{P(狗)}{Q(狗)} + P(鱼)\ln\frac{P(鱼)}{Q(鱼)}$$</p>
<p><strong>步骤 3: 代入数值计算</strong></p>
<p>由于 <code>P(猫)</code> 和 <code>P(鱼)</code> 为0，这些项对总和的贡献也是0。我们只需计算 <code>P(狗)=1</code> 的那一项。</p>
<blockquote>
<p>注意: 当 <code>P(i)=0</code> 时，<code>P(i) * log(...)</code> 项为0。当 <code>Q(i)=0</code> 而 <code>P(i)≠0</code> 时，KL散度为无穷大。</p>
</blockquote>
<p>$$D_{KL}(P || Q) &#x3D; 1 \cdot \ln\frac{1}{0.7} &#x3D; \ln(1) - \ln(0.7) &#x3D; 0 - \ln(0.7) \approx 0.3567$$</p>
<p>你会发现，在这个特定的例子中，计算出的KL散度值与交叉熵的值完全相同。这并非偶然。</p>
<hr>
<h2 id="三、KL散度与交叉熵的关系"><a href="#三、KL散度与交叉熵的关系" class="headerlink" title="三、KL散度与交叉熵的关系"></a>三、KL散度与交叉熵的关系</h2><p>我们可以通过简单的数学变换揭示两者的深刻联系。</p>
<p>从KL散度的公式开始：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log \frac{P(i)}{Q(i)}$$</p>
<p>使用对数运算法则 $\log(a&#x2F;b) &#x3D; \log(a) - \log(b)$:</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) (\log P(i) - \log Q(i))$$</p>
<p>将求和拆开：</p>
<p>$$D_{KL}(P || Q) &#x3D; \sum_{i} P(i) \log P(i) - \sum_{i} P(i) \log Q(i)$$</p>
<p>我们发现，这个公式由两部分组成：</p>
<ol>
<li>$- \sum_{i} P(i) \log P(i)$：这是<strong>信息熵 (Entropy)</strong> 的定义，记为 $H(P)$。它衡量的是分布P自身的不确定性。</li>
<li>$- \sum_{i} P(i) \log Q(i)$：这正是<strong>交叉熵 (Cross-Entropy)</strong> 的定义，记为 $H(P, Q)$。</li>
</ol>
<p>于是，我们得到了它们之间的关系式：</p>
<p>$$D_{KL}(P || Q) &#x3D; -H(P) + H(P, Q)$$</p>
<p>移项后得到更清晰的形式：</p>
<p>$$H(P, Q) &#x3D; H(P) + D_{KL}(P || Q)$$</p>
<p><strong>交叉熵 &#x3D; 熵 + KL散度</strong></p>
<h3 id="在机器学习中的意义"><a href="#在机器学习中的意义" class="headerlink" title="在机器学习中的意义"></a>在机器学习中的意义</h3><p>在监督学习中，真实分布P（即数据标签）是固定的，因此它的熵 $H(P)$ 是一个<strong>常数</strong>。</p>
<p>当我们训练模型时，我们的目标是调整模型的参数来最小化损失函数。因为 $H(P)$ 是一个常数，所以<strong>最小化交叉熵 $H(P, Q)$ 就等价于最小化KL散度 $D_{KL}(P || Q)$</strong>。</p>
<p>由于交叉熵的计算比KL散度更简单（它不需要计算 $H(P)$），所以在实践中，分类模型的损失函数几乎总是使用交叉熵。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table>
<thead>
<tr>
<th align="left">特性</th>
<th align="left">交叉熵 (Cross-Entropy)</th>
<th align="left">KL散度 (KL Divergence)</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>全称</strong></td>
<td align="left">Cross-Entropy</td>
<td align="left">Kullback-Leibler Divergence &#x2F; Relative Entropy</td>
</tr>
<tr>
<td align="left"><strong>公式</strong></td>
<td align="left">$H(P, Q) &#x3D; - \sum P(i) \log Q(i)$</td>
<td align="left">$D_{KL}(P</td>
</tr>
<tr>
<td align="left"><strong>直观意义</strong></td>
<td align="left">用Q的编码方案来编码P的平均成本</td>
<td align="left">用Q的编码方案代替P的方案所带来的额外成本</td>
</tr>
<tr>
<td align="left"><strong>对称性</strong></td>
<td align="left">不对称</td>
<td align="left"><strong>不对称</strong> ($D_{KL}(P|Q) \neq D_{KL}(Q|P)$)</td>
</tr>
<tr>
<td align="left"><strong>与熵的关系</strong></td>
<td align="left">$H(P,Q) &#x3D; H(P) + D_{KL}(P|Q)$</td>
<td align="left">$D_{KL}(P|Q) &#x3D; H(P,Q) - H(P)$</td>
</tr>
<tr>
<td align="left"><strong>主要用途</strong></td>
<td align="left">在分类任务中作为<strong>损失函数</strong>。</td>
<td align="left">衡量分布差异，用于变分自编码器(VAE)、策略梯度等。</td>
</tr>
</tbody></table>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/download/Waline.css</url>
    <content><![CDATA[:root{--waline-font-size: 1rem;--waline-white: #fff;--waline-light-grey: #999;--waline-dark-grey: #666;--waline-theme-color: #FFD5CF;--waline-active-color: #FFD5CF;--waline-color: #444;--waline-bgcolor: #fff;--waline-bgcolor-light: #f8f8f8;--waline-bgcolor-hover: #f0f0f0;--waline-border-color: #ddd;--waline-disable-bgcolor: #f8f8f8;--waline-disable-color: #000;--waline-code-bgcolor: #282c34;--waline-bq-color: #f0f0f0;--waline-avatar-size: 3.25rem;--waline-m-avatar-size: calc(var(--waline-avatar-size) * 9 / 13);--waline-badge-color: #3498db;--waline-badge-font-size: 0.75em;--waline-info-bgcolor: #f8f8f8;--waline-info-color: #999;--waline-info-font-size: 0.625em;--waline-border: 1px solid var(--waline-border-color);--waline-avatar-radius: 50%;--waline-box-shadow: none}[data-waline]{font-size:var(--waline-font-size);text-align:start}[dir=rtl] [data-waline]{direction:rtl}[data-waline] *{box-sizing:content-box;line-height:1.75}[data-waline] p{color:var(--waline-color)}[data-waline] a{position:relative;display:inline-block;color:var(--waline-theme-color);text-decoration:none;word-break:break-word;cursor:pointer}[data-waline] a:hover{color:var(--waline-active-color)}[data-waline] img{max-width:100%;max-height:400px;border:none}[data-waline] hr{margin:.825em 0;border-style:dashed;border-color:var(--waline-bgcolor-light)}[data-waline] code,[data-waline] pre{margin:0;padding:.2em .4em;border-radius:3px;background:var(--waline-bgcolor-light);font-size:85%}[data-waline] pre{overflow:auto;padding:10px;line-height:1.45}[data-waline] pre::-webkit-scrollbar{width:6px;height:6px}[data-waline] pre::-webkit-scrollbar-track-piece:horizontal{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}[data-waline] pre::-webkit-scrollbar-thumb:horizontal{width:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}[data-waline] pre code{padding:0;background:rgba(0,0,0,0);color:var(--waline-color);white-space:pre-wrap;word-break:keep-all}[data-waline] blockquote{margin:.5em 0;padding:.5em 0 .5em 1em;border-inline-start:8px solid var(--waline-bq-color);color:var(--waline-dark-grey)}[data-waline] blockquote>p{margin:0}[data-waline] ol,[data-waline] ul{margin-inline-start:1.25em;padding:0}[data-waline] input[type=checkbox],[data-waline] input[type=radio]{display:inline-block;vertical-align:middle;margin-top:-2px}.wl-btn{display:inline-block;vertical-align:middle;min-width:2.5em;margin-bottom:0;padding:.5em 1em;border:1px solid var(--waline-border-color);border-radius:.5em;background:rgba(0,0,0,0);color:var(--waline-color);font-weight:400;font-size:.75em;line-height:1.5;text-align:center;white-space:nowrap;cursor:pointer;user-select:none;transition-duration:.4s;touch-action:manipulation}.wl-btn:hover,.wl-btn:active{border-color:var(--waline-theme-color);color:var(--waline-theme-color)}.wl-btn:disabled{border-color:var(--waline-border-color);background:var(--waline-disable-bgcolor);color:var(--waline-disable-color);cursor:not-allowed}.wl-btn.primary{border-color:var(--waline-theme-color);background:var(--waline-theme-color);color:var(--waline-white)}.wl-btn.primary:hover,.wl-btn.primary:active{border-color:var(--waline-active-color);background:var(--waline-active-color);color:var(--waline-white)}.wl-btn.primary:disabled{border-color:var(--waline-border-color);background:var(--waline-disable-bgcolor);color:var(--waline-disable-color);cursor:not-allowed}.wl-loading{text-align:center}.wl-loading svg{margin:0 auto}.wl-comment{position:relative;display:flex;margin-bottom:.75em}.wl-close{position:absolute;top:-4px;inset-inline-end:-4px;padding:0;border:none;background:rgba(0,0,0,0);line-height:1;cursor:pointer}.wl-login-info{max-width:80px;margin-top:.75em;text-align:center}.wl-logout-btn{position:absolute;top:-10px;inset-inline-end:-10px;padding:3px;border:none;background:rgba(0,0,0,0);line-height:0;cursor:pointer}.wl-avatar{position:relative;width:var(--waline-avatar-size);height:var(--waline-avatar-size);margin:0 auto;border:var(--waline-border);border-radius:var(--waline-avatar-radius)}@media(max-width: 720px){.wl-avatar{width:var(--waline-m-avatar-size);height:var(--waline-m-avatar-size)}}.wl-avatar img{width:100%;height:100%;border-radius:var(--waline-avatar-radius)}.wl-login-nick{display:block;color:var(--waline-theme-color);font-size:.75em;word-break:break-all}.wl-panel{position:relative;flex-shrink:1;width:100%;margin:.5em;border:var(--waline-border);border-radius:.75em;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow)}.wl-header{display:flex;overflow:hidden;padding:0 4px;border-bottom:2px dashed var(--waline-border-color);border-top-left-radius:.75em;border-top-right-radius:.75em}@media(max-width: 580px){.wl-header{display:block}}.wl-header label{min-width:40px;padding:.75em .5em;color:var(--waline-color);font-size:.75em;text-align:center}.wl-header input{flex:1;width:0;padding:.5em;background:rgba(0,0,0,0);font-size:.625em;resize:none}.wl-header-item{display:flex;flex:1}@media(max-width: 580px){.wl-header-item:not(:last-child){border-bottom:2px dashed var(--waline-border-color)}}.wl-header-1 .wl-header-item{width:100%}.wl-header-2 .wl-header-item{width:50%}@media(max-width: 580px){.wl-header-2 .wl-header-item{flex:0;width:100%}}.wl-header-3 .wl-header-item{width:33.33%}@media(max-width: 580px){.wl-header-3 .wl-header-item{width:100%}}.wl-editor{position:relative;width:calc(100% - 1em);min-height:8.75em;margin:.75em .5em;border-radius:.5em;background:rgba(0,0,0,0);font-size:.875em;resize:vertical}.wl-editor,.wl-input{max-width:100%;border:none;color:var(--waline-color);outline:none;transition:all .25s ease}.wl-editor:focus,.wl-input:focus{background:var(--waline-bgcolor-light)}.wl-preview{padding:0 .5em .5em}.wl-preview h4{margin:.25em;font-weight:bold;font-size:.9375em}.wl-preview .wl-content{min-height:1.25em;padding:.25em;word-break:break-word;hyphens:auto}.wl-preview .wl-content>*:first-child{margin-top:0}.wl-preview .wl-content>*:last-child{margin-bottom:0}.wl-footer{position:relative;display:flex;flex-wrap:wrap;margin:.5em .75em}.wl-actions{display:flex;flex:2;align-items:center}.wl-action{display:inline-flex;align-items:center;justify-content:center;width:1.5em;height:1.5em;margin:2px;padding:0;border:none;background:rgba(0,0,0,0);color:var(--waline-color);font-size:16px;cursor:pointer}.wl-action:hover{color:var(--waline-theme-color)}.wl-action.active{color:var(--waline-active-color)}#wl-image-upload{display:none}#wl-image-upload:focus+label{color:var(--waline-color)}#wl-image-upload:focus-visible+label{outline:-webkit-focus-ring-color auto 1px}.wl-info{display:flex;flex:3;align-items:center;justify-content:flex-end}.wl-info .wl-text-number{color:var(--waline-info-color);font-size:.75em}.wl-info .wl-text-number .illegal{color:red}.wl-info button{margin-inline-start:.75em}.wl-info button svg{display:block;margin:0 auto;line-height:18px}.wl-emoji-popup{position:absolute;top:100%;inset-inline-start:1.25em;z-index:10;max-width:526px;border:var(--waline-border);border-radius:6px;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow);opacity:0;visibility:hidden;transition:transform .2s ease-out,opacity .2s ease-out;transform:scale(0.9, 0.9);transform-origin:0 0}.wl-emoji-popup.display{opacity:1;visibility:visible;transform:none}.wl-emoji-popup button{display:inline-block;vertical-align:middle;width:2em;margin:.125em;padding:0;border-width:0;background:rgba(0,0,0,0);font-size:inherit;line-height:2;text-align:center;cursor:pointer}.wl-emoji-popup button:hover{background:var(--waline-bgcolor-hover)}.wl-emoji-popup .wl-emoji{display:inline-block;vertical-align:middle;max-width:1.5em;max-height:1.5em}.wl-emoji-popup .wl-tab-wrapper{overflow-y:auto;max-height:145px;padding:.5em}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar{width:6px;height:6px}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar-track-piece:vertical{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}.wl-emoji-popup .wl-tab-wrapper::-webkit-scrollbar-thumb:vertical{width:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}.wl-emoji-popup .wl-tabs{position:relative;overflow-x:auto;padding:0 6px;white-space:nowrap}.wl-emoji-popup .wl-tabs::before{content:" ";position:absolute;top:0;right:0;left:0;z-index:2;height:1px;background:var(--waline-border-color)}.wl-emoji-popup .wl-tabs::-webkit-scrollbar{width:6px;height:6px}.wl-emoji-popup .wl-tabs::-webkit-scrollbar-track-piece:horizontal{-webkit-border-radius:6px;border-radius:6px;background:rgba(0,0,0,.1)}.wl-emoji-popup .wl-tabs::-webkit-scrollbar-thumb:horizontal{height:6px;-webkit-border-radius:6px;border-radius:6px;background:var(--waline-theme-color)}.wl-emoji-popup .wl-tab{position:relative;margin:0;padding:0 .5em}.wl-emoji-popup .wl-tab.active{z-index:3;border:1px solid var(--waline-border-color);border-top-width:0;border-bottom-right-radius:6px;border-bottom-left-radius:6px;background:var(--waline-bgcolor)}.wl-gif-popup{position:absolute;top:100%;inset-inline-start:1.25em;z-index:10;width:calc(100% - 3em);padding:.75em .75em .25em;border:var(--waline-border);border-radius:6px;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow);opacity:0;visibility:hidden;transition:transform .2s ease-out,opacity .2s ease-out;transform:scale(0.9, 0.9);transform-origin:0 0}.wl-gif-popup.display{opacity:1;visibility:visible;transform:none}.wl-gif-popup input{box-sizing:border-box;width:100%;margin-bottom:10px;padding:3px 5px;border:var(--waline-border)}.wl-gif-popup img{display:block;box-sizing:border-box;width:100%;border-width:2px;border-style:solid;border-color:#fff;cursor:pointer}.wl-gif-popup img:hover{border-color:var(--waline-theme-color);border-radius:2px}.wl-gallery{display:flex;overflow-y:auto;max-height:80vh}.wl-gallery-column{display:flex;flex:1;flex-direction:column;height:-webkit-max-content;height:-moz-max-content;height:max-content}.wl-cards .wl-user{--avatar-size: var(--waline-avatar-size);position:relative;margin-inline-end:.75em}@media(max-width: 720px){.wl-cards .wl-user{--avatar-size: var(--waline-m-avatar-size)}}.wl-cards .wl-user img{width:var(--avatar-size);height:var(--avatar-size);border-radius:var(--waline-avatar-radius);box-shadow:var(--waline-box-shadow)}.wl-cards .wl-user .verified-icon{position:absolute;top:calc(var(--avatar-size)*3/4);inset-inline-start:calc(var(--avatar-size)*3/4);border-radius:50%;background:var(--waline-bgcolor);box-shadow:var(--waline-box-shadow)}.wl-card-item{position:relative;display:flex;padding:.5em}.wl-card-item .wl-card-item{padding-inline-end:0}.wl-card{flex:1;width:0;padding-bottom:.5em;border-bottom:1px dashed var(--waline-border-color)}.wl-card:first-child{margin-inline-start:1em}.wl-card-item:last-child>.wl-card{border-bottom:none}.wl-card .wl-nick svg{position:relative;bottom:-0.125em;line-height:1}.wl-card .wl-head{overflow:hidden;line-height:1.5}.wl-card .wl-head .wl-nick{position:relative;display:inline-block;margin-inline-end:.5em;font-weight:bold;font-size:.875em;line-height:1;text-decoration:none}.wl-card span.wl-nick{color:var(--waline-dark-grey)}.wl-card .wl-badge{display:inline-block;margin-inline-end:1em;padding:0 .3em;border:1px solid var(--waline-badge-color);border-radius:4px;color:var(--waline-badge-color);font-size:var(--waline-badge-font-size)}.wl-card .wl-time{margin-inline-end:.875em;color:var(--waline-info-color);font-size:.75em}.wl-card .wl-meta{position:relative;line-height:1}.wl-card .wl-meta>span{display:inline-block;margin-inline-end:.25em;padding:2px 4px;border-radius:.2em;background:var(--waline-info-bgcolor);color:var(--waline-info-color);font-size:var(--waline-info-font-size);line-height:1.5}.wl-card .wl-meta>span:empty{display:none}.wl-card .wl-comment-actions{float:right;line-height:1}[dir=rtl] .wl-card .wl-comment-actions{float:left}.wl-card .wl-delete,.wl-card .wl-like,.wl-card .wl-reply,.wl-card .wl-edit{display:inline-flex;align-items:center;border:none;background:rgba(0,0,0,0);color:var(--waline-color);line-height:1;cursor:pointer;transition:color .2s ease}.wl-card .wl-delete:hover,.wl-card .wl-like:hover,.wl-card .wl-reply:hover,.wl-card .wl-edit:hover{color:var(--waline-theme-color)}.wl-card .wl-delete.active,.wl-card .wl-like.active,.wl-card .wl-reply.active,.wl-card .wl-edit.active{color:var(--waline-active-color)}.wl-card .wl-content{position:relative;margin-bottom:.75em;padding-top:.625em;font-size:.875em;line-height:2;word-wrap:break-word}.wl-card .wl-content.expand{overflow:hidden;max-height:8em;cursor:pointer}.wl-card .wl-content.expand::before{content:"";position:absolute;top:0;bottom:3.15em;inset-inline-start:0;z-index:999;display:block;width:100%;background:linear-gradient(180deg, #000, rgba(255, 255, 255, 0.9))}.wl-card .wl-content.expand::after{content:attr(data-expand);position:absolute;bottom:0;inset-inline-start:0;z-index:999;display:block;width:100%;height:3.15em;background:rgba(255,255,255,.9);color:#828586;line-height:3.15em;text-align:center}.wl-card .wl-content>*:first-child{margin-top:0}.wl-card .wl-content>*:last-child{margin-bottom:0}.wl-card .wl-admin-actions{margin:8px 0;font-size:12px;text-align:right}.wl-card .wl-comment-status{margin:0 8px}.wl-card .wl-comment-status .wl-btn{border-radius:0}.wl-card .wl-comment-status .wl-btn:first-child{border-inline-end:0;border-radius:.5em 0 0 .5em}.wl-card .wl-comment-status .wl-btn:last-child{border-inline-start:0;border-radius:0 .5em .5em 0}.wl-card .wl-quote{border-inline-start:1px dashed rgba(237,237,237,.5)}.wl-card .wl-quote .wl-user{--avatar-size: var(--waline-m-avatar-size)}.wl-close-icon{color:var(--waline-border-color)}.wl-content .vemoji,.wl-content .wl-emoji{display:inline-block;vertical-align:baseline;height:1.25em;margin:-0.125em .25em}.wl-content .wl-tex{background:var(--waline-info-bgcolor);color:var(--waline-info-color)}.wl-content span.wl-tex{display:inline-block;margin-inline-end:.25em;padding:2px 4px;border-radius:.2em;font-size:var(--waline-info-font-size);line-height:1.5}.wl-content p.wl-tex{text-align:center}.wl-content .katex-display{overflow:auto hidden;-webkit-overflow-scrolling:touch;padding-top:.2em;padding-bottom:.2em}.wl-content .katex-display::-webkit-scrollbar{height:3px}.wl-content .katex-error{color:red}.wl-count{flex:1;font-weight:bold;font-size:1.25em}.wl-empty{overflow:auto;padding:1.25em;color:var(--waline-color);text-align:center}.wl-operation{text-align:center}.wl-operation button{margin:1em 0}.wl-power{padding:.5em 0;color:var(--waline-light-grey);font-size:var(--waline-info-font-size);text-align:end}.wl-meta-head{display:flex;flex-direction:row;align-items:center;padding:.375em}.wl-sort{margin:0;list-style-type:none}.wl-sort li{display:inline-block;color:var(--waline-info-color);font-size:.75em;cursor:pointer}.wl-sort li.active{color:var(--waline-theme-color)}.wl-sort li+li{margin-inline-start:1em}.wl-reaction{overflow:auto hidden;margin-bottom:1.75em;text-align:center}.wl-reaction img{width:100%;height:100%;transition:all 250ms ease-in-out}.wl-reaction-title{margin:16px auto;font-weight:bold;font-size:18px}.wl-reaction-list{display:flex;flex-direction:row;gap:16px;justify-content:center;margin:0;padding:8px;list-style-type:none}@media(max-width: 580px){.wl-reaction-list{gap:12px}}[data-waline] .wl-reaction-list{margin-inline-start:0}.wl-reaction-item{display:flex;flex-direction:column;align-items:center;cursor:pointer}.wl-reaction-item:hover img,.wl-reaction-item.active img{transform:scale(1.15)}.wl-reaction-img{position:relative;width:42px;height:42px}@media(max-width: 580px){.wl-reaction-img{width:32px;height:32px}}.wl-reaction-loading{position:absolute;top:-4px;inset-inline-end:-5px;width:18px;height:18px;color:var(--waline-theme-color)}.wl-reaction-votes{position:absolute;top:-9px;inset-inline-end:-9px;min-width:1em;padding:2px;border:1px solid var(--waline-theme-color);border-radius:1em;background:var(--waline-bgcolor);color:var(--waline-theme-color);font-weight:700;font-size:.75em;line-height:1}.wl-reaction-item.active .wl-reaction-votes{background:var(--waline-theme-color);color:var(--waline-bgcolor)}.wl-reaction-text{font-size:.875em}.wl-reaction-item.active .wl-reaction-text{color:var(--waline-theme-color)}.wl-content pre,.wl-content pre[class*=language-]{overflow:auto;margin:.75rem 0;padding:1rem 1.25rem;border-radius:6px;background:var(--waline-code-bgcolor);line-height:1.4}.wl-content pre code,.wl-content pre[class*=language-] code{padding:0;border-radius:0;background:rgba(0,0,0,0) !important;color:#bbb;direction:ltr}.wl-content code[class*=language-],.wl-content pre[class*=language-]{background:none;color:#ccc;font-size:1em;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;text-align:left;white-space:pre;word-spacing:normal;word-wrap:normal;word-break:normal;tab-size:4;hyphens:none}.wl-content pre[class*=language-]{overflow:auto}.wl-content :not(pre)>code[class*=language-],.wl-content pre[class*=language-]{background:#2d2d2d}.wl-content :not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.wl-content .token.comment,.wl-content .token.block-comment,.wl-content .token.prolog,.wl-content .token.doctype,.wl-content .token.cdata{color:#999}.wl-content .token.punctuation{color:#ccc}.wl-content .token.tag,.wl-content .token.attr-name,.wl-content .token.namespace,.wl-content .token.deleted{color:#e2777a}.wl-content .token.function-name{color:#6196cc}.wl-content .token.boolean,.wl-content .token.number,.wl-content .token.function{color:#f08d49}.wl-content .token.property,.wl-content .token.class-name,.wl-content .token.constant,.wl-content .token.symbol{color:#f8c555}.wl-content .token.selector,.wl-content .token.important,.wl-content .token.atrule,.wl-content .token.keyword,.wl-content .token.builtin{color:#cc99cd}.wl-content .token.string,.wl-content .token.char,.wl-content .token.attr-value,.wl-content .token.regex,.wl-content .token.variable{color:#7ec699}.wl-content .token.operator,.wl-content .token.entity,.wl-content .token.url{color:#67cdcc}.wl-content .token.important,.wl-content .token.bold{font-weight:bold}.wl-content .token.italic{font-style:italic}.wl-content .token.entity{cursor:help}.wl-content .token.inserted{color:green}.wl-recent-item p{display:inline}.wl-user-list{padding:0;list-style:none}.wl-user-list a,.wl-user-list a:hover,.wl-user-list a:visited{color:var(--waline-color);text-decoration:none}.wl-user-list .wl-user-avatar{position:relative;display:inline-block;overflow:hidden;margin-inline-end:10px;border-radius:4px;line-height:0}.wl-user-list .wl-user-avatar>img{width:var(--waline-user-avatar-size, 48px);height:var(--waline-user-avatar-size, 48px)}.wl-user-list .wl-user-badge{position:absolute;bottom:0;inset-inline-end:0;min-width:.7em;height:1.5em;padding:0 .4em;border-radius:4px;background:var(--waline-info-bgcolor);color:var(--waline-info-color);font-weight:bold;font-size:10px;line-height:1.5em;text-align:center}.wl-user-list .wl-user-item{margin:10px 0}.wl-user-list .wl-user-item:nth-child(1) .wl-user-badge{background:var(--waline-rank-gold-bgcolor, #fa3939);color:var(--waline-white);font-weight:bold}.wl-user-list .wl-user-item:nth-child(2) .wl-user-badge{background:var(--waline-rank-silver-bgcolor, #fb811c);color:var(--waline-white);font-weight:bold}.wl-user-list .wl-user-item:nth-child(3) .wl-user-badge{background:var(--waline-rank-copper-bgcolor, #feb207);color:var(--waline-white)}.wl-user-list .wl-user-meta{display:inline-block;vertical-align:top}.wl-user-list .wl-badge{display:inline-block;vertical-align:text-top;margin-inline-start:.5em;padding:0 .3em;border:1px solid var(--waline-badge-color);border-radius:4px;color:var(--waline-badge-color);font-size:var(--waline-badge-font-size)}.wl-user-wall{padding:0;list-style:none}.wl-user-wall .wl-user-badge,.wl-user-wall .wl-user-meta{display:none}.wl-user-wall .wl-user-item{position:relative;display:inline-block;transition:transform ease-in-out .2s}.wl-user-wall .wl-user-item::before,.wl-user-wall .wl-user-item::after{position:absolute;bottom:100%;left:50%;z-index:10;opacity:0;pointer-events:none;transition:all .18s ease-out .18s;transform:translate(-50%, 4px);transform-origin:top}.wl-user-wall .wl-user-item::before{content:"";width:0;height:0;border:5px solid rgba(0,0,0,0);border-top-color:rgba(16,16,16,.95)}.wl-user-wall .wl-user-item::after{content:attr(aria-label);margin-bottom:10px;padding:.5em 1em;border-radius:2px;background:rgba(16,16,16,.95);color:#fff;font-size:12px;white-space:nowrap}.wl-user-wall .wl-user-item:hover{transform:scale(1.1)}.wl-user-wall .wl-user-item:hover::before,.wl-user-wall .wl-user-item:hover::after{opacity:1;pointer-events:none;transform:translate(-50%, 0)}.wl-user-wall .wl-user-item img{width:var(--waline-user-avatar-size, 48px);height:var(--waline-user-avatar-size, 48px)}/*# sourceMappingURL=waline.css.map */]]></content>
  </entry>
</search>
