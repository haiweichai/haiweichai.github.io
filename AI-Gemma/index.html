<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Times+New+Roman:300,300italic,400,400italic,700,700italic%7CGeorgia:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hwchai.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Gemini是Google开发的一款多模态大模型，能够处理文本、图像、音频、视频和代码等信息。目前推出的Gemini模型分为Nano、Pro、Ultra以及1.5Pro，这些模型都可以在谷歌网站上进行访问：https:&#x2F;&#x2F;gemini.google.com 。此外，谷歌还提供了Gemini模型的API，可在代码中调用模型，输入文本和图片然后，输出文本回复，以及一款开源大语言模型gemma，该模型">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能：语言大模型训练与部署流程">
<meta property="og:url" content="https://hwchai.com/AI-Gemma/index.html">
<meta property="og:site_name" content="Hai-Wei Chai&#39;s Blog">
<meta property="og:description" content="Gemini是Google开发的一款多模态大模型，能够处理文本、图像、音频、视频和代码等信息。目前推出的Gemini模型分为Nano、Pro、Ultra以及1.5Pro，这些模型都可以在谷歌网站上进行访问：https:&#x2F;&#x2F;gemini.google.com 。此外，谷歌还提供了Gemini模型的API，可在代码中调用模型，输入文本和图片然后，输出文本回复，以及一款开源大语言模型gemma，该模型">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/17/pAUAupF.png">
<meta property="og:image" content="https://s21.ax1x.com/2024/07/12/pk4n7AP.png">
<meta property="article:published_time" content="2024-07-11T16:27:43.000Z">
<meta property="article:modified_time" content="2024-07-11T13:58:01.000Z">
<meta property="article:author" content="Hai-Wei Chai (柴海伟)">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="Gemini">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s21.ax1x.com/2024/10/17/pAUAupF.png">


<link rel="canonical" href="https://hwchai.com/AI-Gemma/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://hwchai.com/AI-Gemma/","path":"AI-Gemma/","title":"人工智能：语言大模型训练与部署流程"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>人工智能：语言大模型训练与部署流程 | Hai-Wei Chai's Blog</title>
  







<link rel="dns-prefetch" href="https://vercel.hwchai.com/">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hai-Wei Chai's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-house-chimney fa-fw"></i>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-list fa-fw"></i>Archives</a></li><li class="menu-item menu-item-support"><a href="/support/" rel="section"><i class="fa fa-screwdriver-wrench fa-fw"></i>Support</a></li><li class="menu-item menu-item-books"><a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i>Books</a></li><li class="menu-item menu-item-scholar"><a href="/scholar/" rel="section"><i class="fa fa-chart-column fa-fw"></i>Scholar</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="nav-number">1.</span> <span class="nav-text">环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-CentOS-Stream-10"><span class="nav-number">1.1.</span> <span class="nav-text">配置 CentOS Stream 10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Nvidia-Driver-CUDA-%E5%8F%8A-cuDNN-%E7%8E%AF%E5%A2%83"><span class="nav-number">1.2.</span> <span class="nav-text">安装 Nvidia Driver, CUDA 及 cuDNN 环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85-Pytorch-%E5%8F%8A-Transformers-%E7%AD%89%E7%8E%AF%E5%A2%83"><span class="nav-number">1.3.</span> <span class="nav-text">安装 Pytorch 及 Transformers 等环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%83%A8%E7%BD%B2-Gemma-%E8%AE%AD%E7%BB%83%E7%8E%AF%E5%A2%83%E5%8F%8A%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.</span> <span class="nav-text">部署 Gemma 训练环境及预训练模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gemma%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%85%A5%E4%B8%8E%E9%85%8D%E7%BD%AE"><span class="nav-number">2.</span> <span class="nav-text">Gemma模型导入与配置</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hai-Wei Chai (柴海伟)"
      src="/images/gamersky.gif">
  <p class="site-author-name" itemprop="name">Hai-Wei Chai (柴海伟)</p>
  <div class="site-description" itemprop="description">I am a slow walker, but never backwards!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/haiweichai" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;haiweichai" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chw9402@mail.ustc.edu.com" title="E-Mail → mailto:chw9402@mail.ustc.edu.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hwchai.com/AI-Gemma/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/gamersky.gif">
      <meta itemprop="name" content="Hai-Wei Chai (柴海伟)">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hai-Wei Chai's Blog">
      <meta itemprop="description" content="I am a slow walker, but never backwards!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="人工智能：语言大模型训练与部署流程 | Hai-Wei Chai's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能：语言大模型训练与部署流程
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-07-11 16:27:43" itemprop="dateCreated datePublished" datetime="2024-07-11T16:27:43Z">2024-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-07-11 13:58:01" itemprop="dateModified" datetime="2024-07-11T13:58:01Z">2024-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline: </span>
  
    <a title="waline" href="/AI-Gemma/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/AI-Gemma/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><img src="https://s21.ax1x.com/2024/10/17/pAUAupF.png"></p>
<p>Gemini是Google开发的一款多模态大模型，能够处理文本、图像、音频、视频和代码等信息。目前推出的Gemini模型分为Nano、Pro、Ultra以及1.5Pro，这些模型都可以在谷歌网站上进行访问：<a target="_blank" rel="noopener" href="https://gemini.google.com/">https://gemini.google.com</a> 。此外，谷歌还提供了<a target="_blank" rel="noopener" href="https://ai.google.dev/gemini-api/docs/models/gemini?hl=zh-cn">Gemini模型的API</a>，可在代码中调用模型，输入文本和图片然后，输出文本回复，以及一款<a target="_blank" rel="noopener" href="https://www.kaggle.com/models/google/gemma">开源大语言模型gemma</a>，该模型基于Gemini的研究和技术开发，能处理文本信息。模型有2b和7b两种参数规模以及经过指令调优（2b-it &amp; 7b-it）和未调优的基础模型等版本，可通过多种框架构建：Keras、Pytorch、Transformers、Gemma C++、TensorRT-LLM、TensorFlow Lite、MaxText、Pax、Flax。感谢我过去的学生 Weizheng Wang, Hui Wu 对本文的贡献。</p>
<span id="more"></span>

<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="配置-CentOS-Stream-10"><a href="#配置-CentOS-Stream-10" class="headerlink" title="配置 CentOS Stream 10"></a>配置 CentOS Stream 10</h3><p>本文选用 CentOS Stream 10 操作系统，内核版本 6.12.0，并配置网络环境：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">uname</span> -r                        <span class="comment"># 查看内核版本</span></span></span><br><span class="line">6.12.0-89.el10.x86_64</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum --exclude=kernel* update    <span class="comment"># 禁用 yum update，避免 kernel 更新导致的生产环境不稳定风险</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nmcli connection show</span></span><br><span class="line">NAME       UUID                                  TYPE      DEVICE</span><br><span class="line">enp0s31f6  52eaa752-25be-451f-a8c1-4037030e4cb4  ethernet  enp0s31f6</span><br><span class="line">lo         4d717253-e93b-404c-9487-38d706cb9308  loopback  lo</span><br><span class="line">enp2s0     7ef8d2c6-cd0a-3123-9fef-4218782fcf1b  ethernet  --</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> /etc/NetworkManager/system-connections/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">su vi enp0s31f6.nmconnection    <span class="comment"># 编辑对应网卡的配置文件</span></span></span><br></pre></td></tr></table></figure>

<p>编辑 enp031f6.connection 文件，示例信息如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[connection]</span><br><span class="line">id=enp0s31f6</span><br><span class="line">uuid=52eaa752-25be-451f-a8c1-4037030e4cb4</span><br><span class="line">type=ethernet</span><br><span class="line">autoconnect-priority=-999</span><br><span class="line">interface-name=enp0s31f6</span><br><span class="line">timestamp=1748939249</span><br><span class="line"></span><br><span class="line">[ethernet]</span><br><span class="line"></span><br><span class="line">[ipv4]</span><br><span class="line">address1=192.168.0.125/24</span><br><span class="line">dns=192.168.0.1;</span><br><span class="line">gateway=192.168.0.1</span><br><span class="line">method=manual</span><br><span class="line"></span><br><span class="line">[ipv6]</span><br><span class="line">addr-gen-mode=eui64</span><br><span class="line">method=auto</span><br><span class="line"></span><br><span class="line">[proxy]</span><br></pre></td></tr></table></figure>

<p>修改完成后重新启动网络服务：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart NetworkManager</span><br><span class="line">$ nmcli c reload                           # 重新加载配置文件</span><br><span class="line">$ nmcli c up enp031f6                      # 重启ens33网卡</span><br><span class="line"></span><br><span class="line">$ ping www.baidu.com -c4                   # 验证网络连接</span><br><span class="line">PING www.a.shifen.com (39.156.66.14) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=1 ttl=50 time=38.5 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=2 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=3 ttl=50 time=38.2 ms</span><br><span class="line">64 bytes from 39.156.66.14 (39.156.66.14): icmp_seq=4 ttl=50 time=38.2 ms</span><br></pre></td></tr></table></figure>

<p>配置硬盘分区永久挂载：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsblk   <span class="comment"># 查看磁盘硬件</span></span></span><br><span class="line">NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class="line">sda           8:0    0 21.8T  0 disk /mnt/disk1</span><br><span class="line">sdb           8:16   0 14.6T  0 disk /mnt/disk0</span><br><span class="line">sdc           8:32   0 21.8T  0 disk /mnt/disk2</span><br><span class="line">nvme0n1     259:0    0  1.8T  0 disk</span><br><span class="line">├─nvme0n1p1 259:1    0  600M  0 part /boot/efi</span><br><span class="line">                    ...</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">fdisk /dev/sda                <span class="comment"># 修改该磁盘中的分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mkfs.ext4 /dev/sda            <span class="comment"># 按 ext4 文件系统格式化分区</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> /mnt/mydrive            <span class="comment"># 创建挂载路径</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">mount /dev/sda /mnt/mydrive   <span class="comment"># 临时挂载该分区</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">blkid /dev/sda                <span class="comment"># 查看该磁盘的UUID与文件系统格式</span></span></span><br><span class="line">/dev/sda: UUID=&quot;E600-A571&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;exfat&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/fstab                 <span class="comment"># 修改 /etc/fstab 文件永久挂载磁盘</span></span></span><br><span class="line">UUID=04c21771-726f-42d0-a7d3-34f4b5cd88ab /                 xfs     defaults        0 0</span><br><span class="line">UUID=246017ac-59da-4dd2-9493-dbcba61a2958 /boot             xfs     defaults        0 0</span><br><span class="line">UUID=AD2B-E205                            /boot/efi         vfat    umask=0077,shortname=winnt 0 2</span><br><span class="line">UUID=35b358b4-d3c7-443f-866d-8db5d364a46b /home             xfs     defaults        0 0</span><br><span class="line">UUID=521947e5-c326-4436-9e2d-26a148d8f42f none              swap    defaults        0 0</span><br><span class="line">UUID=40948978-7d0f-4e63-9feb-ffa7ab03f2a4 /mnt/disk0        ext4    defaults        0 0</span><br><span class="line">UUID=E600-A571                            /mnt/disk1        exfat   defaults        0 0</span><br><span class="line">UUID=C839-78EB                            /mnt/disk2        exfat   defaults        0 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">systemctl daemon-reload        <span class="comment"># 修改 fstab 文件后重启 daemon</span></span></span><br></pre></td></tr></table></figure>

<p>为用户名为 hwchai 的普通用户创建 Ed25519 密钥：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ su hwchai                                              # 切换到 hwchai</span><br><span class="line">$ ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519             # 创建 Ed25519 密钥</span><br><span class="line">$ chmod 700 ~/.ssh</span><br><span class="line">$ chmod 600 ~/.ssh/id_ed25519</span><br><span class="line">$ chmod 644 ~/.ssh/id_ed25519.pub                        # 设置正确的权限</span><br><span class="line">$ cat ~/.ssh/id_ed25519.pub &gt;&gt; ~/.ssh/authorized_keys    # 将公钥加入到自己的 authorized_keys 中</span><br><span class="line">$ chmod 600 ~/.ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">$ su vi /etc/ssh/sshd_config                             # 回到 root 账号并编辑 ssh 配置文件</span><br><span class="line">PubkeyAuthentication yes                                 # 启用公钥认证</span><br><span class="line">PasswordAuthentication no                                # 禁用密码登录（提高安全性）</span><br><span class="line">PermitRootLogin prohibit-password                        # root 仅允许密钥登录</span><br><span class="line"></span><br><span class="line">$ systemctl restart sshd</span><br></pre></td></tr></table></figure>

<h3 id="安装-Nvidia-Driver-CUDA-及-cuDNN-环境"><a href="#安装-Nvidia-Driver-CUDA-及-cuDNN-环境" class="headerlink" title="安装 Nvidia Driver, CUDA 及 cuDNN 环境"></a>安装 Nvidia Driver, CUDA 及 cuDNN 环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum update -y</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install pciutils                                <span class="comment"># 使用 yum install pciutils 安装 lspci 工具</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lspci | grep -i nvidia                              <span class="comment"># 检查显卡连接状态</span></span></span><br><span class="line">16:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">34:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ac:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line">ca:00.0 3D controller: NVIDIA Corporation GA100 [A100 PCIe 80GB] (rev a1)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install -y gcc kernel-devel kernel-headers     <span class="comment"># 安装编译环境和内核开发包，确保与当前内核版本相匹配</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">yum install <span class="string">&quot;kernel-devel-uname-r == <span class="subst">$(uname -r)</span>&quot;</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /etc/selinux/config         <span class="comment"># 修改SELINUX=disabled。保存退出</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">setenforce 0                   <span class="comment"># 临时关闭selinux</span></span></span><br></pre></td></tr></table></figure>

<h4 id="安装-Nvidia-driver"><a href="#安装-Nvidia-driver" class="headerlink" title="安装 Nvidia driver"></a>安装 Nvidia driver</h4><p>禁用 Linux 默认的显示驱动 nouveau：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">lsmod | grep nouveau          <span class="comment"># 该命令若无输出，则跳过以下步骤</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vi /lib/modprobe.d/dist-blacklist.conf</span> </span><br></pre></td></tr></table></figure>

<p>编辑 &#x2F;lib&#x2F;modprobe.d&#x2F;dist-blacklist.conf 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># blacklist nvidiafb                 # 注释掉 blacklist nvidiafb</span><br><span class="line">blacklist nouveau                    # 文件末尾添加：blacklist nouveau</span><br><span class="line">options nouveau modeset=0            # 文件末尾添加：options nouveau modeset=0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak</span><br><span class="line">$ dracut /boot/initramfs-$(uname -r).img $(uname -r)             # 重建 initramfs image 镜像</span><br><span class="line">$ systemctl set-default multi-user.target                        # 修改运行模式为文本模式 </span><br><span class="line"></span><br><span class="line">$ reboot</span><br><span class="line">$ lsmod | grep nouveau                                           # 该命令若无输出，表示禁用 nouveau 成功</span><br></pre></td></tr></table></figure>

<p>在<a target="_blank" rel="noopener" href="https://www.nvidia.cn/Download/index.aspx?lang=cn">Nvidia driver download</a>根据GPU型号及操作系统选择相应的驱动程序下载至本地后安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./NVIDIA-Linux-x86_64-版本号.run</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">nvidia-smi                <span class="comment"># 查看 Nvidia GPU 实时信息，验证 Nvidia driver</span></span></span><br><span class="line">Thu Jun  5 22:19:43 2025</span><br><span class="line">+-----------------------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |</span><br><span class="line">|-----------------------------------------+------------------------+----------------------+</span><br><span class="line">| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                                         |                        |               MIG M. |</span><br><span class="line">|=========================================+========================+======================|</span><br><span class="line">|   0  NVIDIA A100 80GB PCIe          Off |   00000000:16:00.0 Off |                    0 |</span><br><span class="line">| N/A   28C    P0             62W /  300W |       0MiB /  81920MiB |      0%      Default |</span><br><span class="line">|                                         |                        |             Disabled |</span><br><span class="line"></span><br><span class="line">                                        ......</span><br></pre></td></tr></table></figure>

<h4 id="安装-CUDA-Toolkit"><a href="#安装-CUDA-Toolkit" class="headerlink" title="安装 CUDA Toolkit"></a>安装 CUDA Toolkit</h4><p>在<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">CUDA Toolkit 12.9 Downloads</a>中下载 CUDA 工具包：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cuda/12.9.0/local_installers/cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ rpm -i cuda-repo-rhel9-12-9-local-12.9.0_575.51.03-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cuda-toolkit-12-9</span><br><span class="line"></span><br><span class="line">$ echo &#x27;export PATH=/usr/local/cuda/bin:$PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ echo &#x27;export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">$ source ~/.bashrc</span><br><span class="line">$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2025 NVIDIA Corporation</span><br><span class="line">Built on Wed_Apr__9_19:24:57_PDT_2025</span><br><span class="line">Cuda compilation tools, release 12.9, V12.9.41</span><br><span class="line">Build cuda_12.9.r12.9/compiler.35813241_0</span><br></pre></td></tr></table></figure>

<h4 id="安装-cuDNN"><a href="#安装-cuDNN" class="headerlink" title="安装 cuDNN"></a>安装 cuDNN</h4><p>在<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cudnn-downloads?target_os=Linux&target_arch=x86_64&Distribution=RHEL&target_version=9&target_type=rpm_local">cuDNN 9.10.1 Downloads</a>中下载 cuDNN 包：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://developer.download.nvidia.com/compute/cudnn/9.10.1/local_installers/cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ rpm -i cudnn-local-repo-rhel9-9.10.1-1.0-1.x86_64.rpm</span><br><span class="line">$ dnf clean all</span><br><span class="line">$ dnf -y install cudnn</span><br></pre></td></tr></table></figure>

<h4 id="安装Miniconda-3"><a href="#安装Miniconda-3" class="headerlink" title="安装Miniconda 3"></a>安装Miniconda 3</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">chmod</span> +x Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">./Miniconda3-latest-Linux-x86_64.sh</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> ~/.bashrc</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda --version</span></span><br><span class="line">conda 24.4.0</span><br></pre></td></tr></table></figure>

<h3 id="安装-Pytorch-及-Transformers-等环境"><a href="#安装-Pytorch-及-Transformers-等环境" class="headerlink" title="安装 Pytorch 及 Transformers 等环境"></a>安装 Pytorch 及 Transformers 等环境</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda create -n hwchai python=3.13        <span class="comment"># 环境创建</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda activate hwchai                     <span class="comment"># 激活环境</span></span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">pip install torch transformers bitsandbytes tensorboard trl datasets peft</span></span><br></pre></td></tr></table></figure>

<p>查看 Pytorch, CUDA 及 cuDNN 版本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(torch.backends.cudnn.version())</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">2.7</span><span class="number">.1</span>+cu126</span><br><span class="line"><span class="number">12.6</span></span><br><span class="line"><span class="number">90501</span></span><br></pre></td></tr></table></figure>

<p>可能还有包未列出，可按照运行提示安装。</p>
<h3 id="部署-Gemma-训练环境及预训练模型"><a href="#部署-Gemma-训练环境及预训练模型" class="headerlink" title="部署 Gemma 训练环境及预训练模型"></a>部署 Gemma 训练环境及预训练模型</h3><p>注册Kaggle账号，在网站 <a target="_blank" rel="noopener" href="https://www.kaggle.com/models/google/gemma">https://www.kaggle.com/models/google/gemma</a> 下载所需模型，配置要求：Python≥3.8，下载模型：</p>
<img src="https://s21.ax1x.com/2024/07/12/pk4n7AP.png" width = 95% div align=center />

<p>官方文档页面： <a target="_blank" rel="noopener" href="https://github.com/google/gemma_pytorch">https://github.com/google/gemma_pytorch</a> ，文档中介绍了在Linux下使用docker配置环境并运行模型的方法，但未说明对模型进行调整的操作和对训练集的要求，使用常规Pytorch对NLP模型的训练方式即可。</p>
<p>下载的预训练模型分别存放在<code>/home/ai/gemma-2b</code>及<code>/home/ai/gemma-7b</code>中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-2b</span><br><span class="line">total 14712812</span><br><span class="line">drwxrwxr-x. 2 ai ai        4096 Jun  6 22:49 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--. 1 ai ai         634 Jun  6 22:49 config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai 10031780672 Jun  6 22:49 gemma-2b.gguf</span><br><span class="line">-rw-rw-r--. 1 ai ai         137 Jun  6 22:18 generation_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1620 Jun  6 22:49 .gitattributes</span><br><span class="line">-rw-rw-r--. 1 ai ai  4945242264 Jun  6 22:18 model-00001-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai    67121608 Jun  6 22:02 model-00002-of-00002.safetensors</span><br><span class="line">-rw-rw-r--. 1 ai ai       13489 Jun  6 22:02 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--. 1 ai ai         555 Jun  6 22:02 special_tokens_map.json</span><br><span class="line">-rw-rw-r--. 1 ai ai        1108 Jun  6 22:02 tokenizer_config.json</span><br><span class="line">-rw-rw-r--. 1 ai ai    17477553 Jun  6 22:02 tokenizer.json</span><br><span class="line">-rw-rw-r--. 1 ai ai     4241003 Jun  6 22:02 tokenizer.model</span><br><span class="line">(base) [root@server01 gemma-2b]# ls -al /home/ai/gemma-7b</span><br><span class="line">total 50054220</span><br><span class="line">drwxrwxr-x  3 ai ai        4096 Jun 29 06:13 .</span><br><span class="line">drwx------. 9 ai ai        4096 Jul  4 07:51 ..</span><br><span class="line">-rw-rw-r--  1 ai ai         636 Jun 29 06:13 config.json</span><br><span class="line">drwxrwxr-x  2 ai ai          88 Jun 29 06:13 examples</span><br><span class="line">-rw-rw-r--  1 ai ai 34158344288 Jun 29 06:13 gemma-7b.gguf</span><br><span class="line">-rw-rw-r--  1 ai ai         137 Jun 29 05:25 generation_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1620 Jun 29 06:13 .gitattributes</span><br><span class="line">-rw-rw-r--  1 ai ai  4995496656 Jun 29 05:25 model-00001-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953168 Jun 29 05:18 model-00002-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  4982953200 Jun 29 05:11 model-00003-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai  2113988336 Jun 29 05:04 model-00004-of-00004.safetensors</span><br><span class="line">-rw-rw-r--  1 ai ai       20920 Jun 29 05:01 model.safetensors.index.json</span><br><span class="line">-rw-rw-r--  1 ai ai         555 Jun 29 05:01 special_tokens_map.json</span><br><span class="line">-rw-rw-r--  1 ai ai        1108 Jun 29 05:01 tokenizer_config.json</span><br><span class="line">-rw-rw-r--  1 ai ai    17477553 Jun 29 05:01 tokenizer.json</span><br><span class="line">-rw-rw-r--  1 ai ai     4241003 Jun 29 05:01 tokenizer.model</span><br></pre></td></tr></table></figure>

<p>测试数据集保存在另一路径，数据形如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@server01 ~]# less /dataset02/dataset/01.ont.seq/train/Exp001_shanzhu.aozhouhuangjin.raw.fastq.txt</span><br><span class="line">TGCTTCGTTCAGTTACGTATTGCTAAGGTTAAACAGACGACTACAAACTGAATCGACAGCACCTCTTTCTATTATGGTGGACTTTATGTATTATAGTTTTGATTTGTGTATTATGGATTATGGTTGGTTGCTTTGATTTAGCTAGATTATGGATTACTTAGCCTCGTAAAGTGGTATCGATCGAAATGAGTGTAATGGTCGTGATG</span><br><span class="line">ACATTTTGGAGGGTAACATCGATGTTTTGTTTAGATTGTAAAGAAGGGTGCCTATGGTATGTATGAGATGGGGTAAGAAGTGATTTTCTTGAATTGTCCATATTCCAATGTTTGGTTACTTAGTGAAATCGTCGGTGTTGATGCTTACTTGTTTTGTAGAATCATAATGGTGGCTAGC</span><br><span class="line">TACTTCAGTTTCGGTTACGTATTGCTAAGGTTAACAGACGACTACAAAACGGAATCGACAGCACCTTTATTTTGTGTTTGTCGTTGGAGAATTGATCTTTCTTCAATGAAATTTATCTCTAGAATTTATTTGTTGATTAATTTCTAGGTTGAAGAACATAAAGAAATTCATAGATTAAATCCTATCTGAATAACTGGGGCCGATCT</span><br><span class="line">ATGCGGCAATAAAAGGTTAATGATTTGTCTTTAATAAAGTTTATTTAAATCATGTATGATTAACCATGATCAATATAAATTTGGATAGGATTAATGTAATTTGATCGTAAGTACATTAATCAATCAAGATCACTATTTGGCTAGTAAAGGCAACAATTCAATTAGCATATCTATAGAAAATTGTCATATCATTACTTGGTTAAATT</span><br><span class="line">······</span><br></pre></td></tr></table></figure>

<h2 id="Gemma模型导入与配置"><a href="#Gemma模型导入与配置" class="headerlink" title="Gemma模型导入与配置"></a>Gemma模型导入与配置</h2><p>编写脚本，使用transformers加载本地模型和分词器：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> LoraConfig, PeftModel, prepare_model_for_kbit_training</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line"> AutoModelForCausalLM,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> BitsAndBytesConfig,</span><br><span class="line"> AutoTokenizer,</span><br><span class="line"> TrainingArguments,</span><br><span class="line"> set_seed</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/data/models/gemma-2b-tf/&quot;</span></span><br><span class="line">set_seed(<span class="number">1234</span>)  <span class="comment"># For reproducibility</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=<span class="literal">True</span>, use_fast=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.pad_token_id =  tokenizer.eos_token_id</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;left&#x27;</span></span><br><span class="line"></span><br><span class="line">data_files = &#123;<span class="string">&quot;train&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/train1.tsv&quot;</span>, <span class="string">&quot;test&quot;</span>: <span class="string">&quot;/data/datasets/WNLI/dev1.tsv&quot;</span>&#125;</span><br><span class="line">ds = load_dataset(<span class="string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line"></span><br><span class="line">compute_dtype = <span class="built_in">getattr</span>(torch, <span class="string">&quot;float16&quot;</span>)</span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">     load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">     bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">     bnb_4bit_compute_dtype=compute_dtype,</span><br><span class="line">     bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">       model_path, quantization_config=bnb_config, device_map=&#123;<span class="string">&quot;&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">)</span><br><span class="line">model = prepare_model_for_kbit_training(model)</span><br><span class="line"><span class="comment"># Configure the pad token in the model</span></span><br><span class="line">model.config.pad_token_id = tokenizer.pad_token_id</span><br><span class="line">model.config.use_cache = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 编辑微调配置</span></span><br><span class="line">peft_config = LoraConfig(</span><br><span class="line">     lora_alpha=<span class="number">16</span>,</span><br><span class="line">     lora_dropout=<span class="number">0.05</span>,</span><br><span class="line">     r=<span class="number">16</span>,</span><br><span class="line">     bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">     task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">     target_modules= [<span class="string">&#x27;k_proj&#x27;</span>, <span class="string">&#x27;q_proj&#x27;</span>, <span class="string">&#x27;v_proj&#x27;</span>, <span class="string">&#x27;o_proj&#x27;</span>, <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 设定训练参数</span></span><br><span class="line">training_arguments = TrainingArguments(</span><br><span class="line">     output_dir=<span class="string">&quot;./results_qlora&quot;</span>,</span><br><span class="line">     evaluation_strategy=<span class="string">&quot;steps&quot;</span>,</span><br><span class="line">     do_eval=<span class="literal">True</span>,</span><br><span class="line">     optim=<span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">     per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">     per_device_eval_batch_size=<span class="number">4</span>,</span><br><span class="line">     log_level=<span class="string">&quot;debug&quot;</span>,</span><br><span class="line">     save_steps=<span class="number">50</span>,</span><br><span class="line">     logging_steps=<span class="number">50</span>,</span><br><span class="line">     learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">     eval_steps=<span class="number">50</span>,</span><br><span class="line">     max_steps=<span class="number">300</span>,</span><br><span class="line">     warmup_steps=<span class="number">30</span>,</span><br><span class="line">     lr_scheduler_type=<span class="string">&quot;linear&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 载入训练配置</span></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">     model=model,</span><br><span class="line">     train_dataset=ds[<span class="string">&#x27;train&#x27;</span>],</span><br><span class="line">     eval_dataset=ds[<span class="string">&#x27;test&#x27;</span>],</span><br><span class="line">     peft_config=peft_config,</span><br><span class="line">     dataset_text_field=<span class="string">&quot;text&quot;</span>,</span><br><span class="line">     max_seq_length=<span class="number">128</span>,</span><br><span class="line">     tokenizer=tokenizer,</span><br><span class="line">     args=training_arguments,</span><br><span class="line">)</span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<p>将脚本保存为gemmatrain.py，命令行运行<code>python gemma.train.py</code> ，即可运行。</p>
<p>在上述脚本中导入了tsv格式的文本作为训练和测试集，实际上原始格式的文本并不能直接作为模型的输入，还需将一整行的文本内容（即单个输入输出对）记在同一标签“text”下。如：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br><span class="line">sentence1：xxxxxxxx.senstence2：xxxxxxxx.label：n</span><br></pre></td></tr></table></figure>

<p>以上格式仅为测试使用，后续会考虑数据集的具体内容和训练需求进行优化。</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Hai-Wei Chai (柴海伟)
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://hwchai.com/AI-Gemma/" title="人工智能：语言大模型训练与部署流程">https://hwchai.com/AI-Gemma/</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
              <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
              <a href="/tags/Gemini/" rel="tag"># Gemini</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/PythonLes14/" rel="prev" title="Python 在科研中的应用 13：课程作业及评分标准">
                  <i class="fa fa-angle-left"></i> Python 在科研中的应用 13：课程作业及评分标准
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/AI-Repeatability/" rel="next" title="人工智能：Pytorch训练可重复性（Reproducibility）">
                  人工智能：Pytorch训练可重复性（Reproducibility） <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-user"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Hai-Wei Chai (柴海伟)</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"https://vercel.hwchai.com/","cssUrl":"https://hwchai.com/download/Waline.css","commentCount":true,"pageview":false,"locale":{"placeholder":"请留下邮箱，若有回复您将收到提醒。QQ邮箱可以自动识别头像喔~"},"pageSize":10,"visitor":false,"comment_count":true,"meta":["nick","mail","link"],"requiredMeta":["nick"],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","emoji":["https://unpkg.com/@waline/emojis@1.0.1/bilibili"],"login":"disable","el":"#waline","comment":true,"path":"/AI-Gemma/"}</script>
<link rel="stylesheet" href="https://hwchai.com/download/Waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
