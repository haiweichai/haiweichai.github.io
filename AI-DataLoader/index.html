<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Times+New+Roman:300,300italic,400,400italic,700,700italic%7CGeorgia:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hwchai.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="PyTorch 数据加载实用程序的核心是 torch.utils.data.DataLoader 类。它表示数据集上的 Python 可迭代对象，支持：映射式和可迭代式数据集；自定义数据加载顺序；自动批处理；单进程和多进程数据加载；自动内存固定。这些选项由 DataLoader 的构造函数参数配置，其签名为： 12345DataLoader(dataset, batch_size&#x3D;1, shuf">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能：Pytorch DataLoader">
<meta property="og:url" content="https://hwchai.com/AI-DataLoader/index.html">
<meta property="og:site_name" content="Hai-Wei Chai&#39;s Blog">
<meta property="og:description" content="PyTorch 数据加载实用程序的核心是 torch.utils.data.DataLoader 类。它表示数据集上的 Python 可迭代对象，支持：映射式和可迭代式数据集；自定义数据加载顺序；自动批处理；单进程和多进程数据加载；自动内存固定。这些选项由 DataLoader 的构造函数参数配置，其签名为： 12345DataLoader(dataset, batch_size&#x3D;1, shuf">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s21.ax1x.com/2024/10/18/pAUyxEQ.png">
<meta property="article:published_time" content="2024-10-18T11:45:09.000Z">
<meta property="article:modified_time" content="2024-10-18T12:03:32.000Z">
<meta property="article:author" content="Hai-Wei Chai (柴海伟)">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="DataLoader">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s21.ax1x.com/2024/10/18/pAUyxEQ.png">


<link rel="canonical" href="https://hwchai.com/AI-DataLoader/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://hwchai.com/AI-DataLoader/","path":"AI-DataLoader/","title":"人工智能：Pytorch DataLoader"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>人工智能：Pytorch DataLoader | Hai-Wei Chai's Blog</title>
  







<link rel="dns-prefetch" href="https://vercel.hwchai.com/">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hai-Wei Chai's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-house-chimney fa-fw"></i>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-list fa-fw"></i>Archives</a></li><li class="menu-item menu-item-support"><a href="/support/" rel="section"><i class="fa fa-screwdriver-wrench fa-fw"></i>Support</a></li><li class="menu-item menu-item-books"><a href="/books/" rel="section"><i class="fa fa-book fa-fw"></i>Books</a></li><li class="menu-item menu-item-scholar"><a href="/scholar/" rel="section"><i class="fa fa-chart-column fa-fw"></i>Scholar</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">数据集类型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%98%A0%E5%B0%84%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.1.</span> <span class="nav-text">映射式数据集</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.2.</span> <span class="nav-text">可迭代式数据集</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%E5%92%8C-Sampler"><span class="nav-number">2.</span> <span class="nav-text">数据加载顺序和 Sampler</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A0%E8%BD%BD%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E9%9D%9E%E6%89%B9%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="nav-number">3.</span> <span class="nav-text">加载批处理和非批处理数据</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E9%BB%98%E8%AE%A4%EF%BC%89"><span class="nav-number">3.1.</span> <span class="nav-text">自动批处理（默认）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A6%81%E7%94%A8%E8%87%AA%E5%8A%A8%E6%89%B9%E5%A4%84%E7%90%86"><span class="nav-number">3.2.</span> <span class="nav-text">禁用自动批处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8collate-fn"><span class="nav-number">3.3.</span> <span class="nav-text">使用collate_fn</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="nav-number">4.</span> <span class="nav-text">单进程和多进程数据加载</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%95%E8%BF%9B%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%EF%BC%88%E9%BB%98%E8%AE%A4%EF%BC%89"><span class="nav-number">4.1.</span> <span class="nav-text">单进程数据加载（默认）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD"><span class="nav-number">4.2.</span> <span class="nav-text">多进程数据加载</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E9%94%81%E5%AE%9A"><span class="nav-number">5.</span> <span class="nav-text">内存锁定</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hai-Wei Chai (柴海伟)"
      src="/images/gamersky.gif">
  <p class="site-author-name" itemprop="name">Hai-Wei Chai (柴海伟)</p>
  <div class="site-description" itemprop="description">I am a slow walker, but never backwards!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/haiweichai" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;haiweichai" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:chw9402@mail.ustc.edu.com" title="E-Mail → mailto:chw9402@mail.ustc.edu.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hwchai.com/AI-DataLoader/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/gamersky.gif">
      <meta itemprop="name" content="Hai-Wei Chai (柴海伟)">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hai-Wei Chai's Blog">
      <meta itemprop="description" content="I am a slow walker, but never backwards!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="人工智能：Pytorch DataLoader | Hai-Wei Chai's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能：Pytorch DataLoader
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-10-18 11:45:09" itemprop="dateCreated datePublished" datetime="2024-10-18T11:45:09Z">2024-10-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-10-18 12:03:32" itemprop="dateModified" datetime="2024-10-18T12:03:32Z">2024-10-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline: </span>
  
    <a title="waline" href="/AI-DataLoader/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/AI-DataLoader/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><img src="https://s21.ax1x.com/2024/10/18/pAUyxEQ.png"></p>
<p>PyTorch 数据加载实用程序的核心是 <a target="_blank" rel="noopener" href="https://pytorch.ac.cn/docs/stable/data.html#torch.utils.data.DataLoader"><code>torch.utils.data.DataLoader</code></a> 类。它表示数据集上的 Python 可迭代对象，支持：映射式和可迭代式数据集；自定义数据加载顺序；自动批处理；单进程和多进程数据加载；自动内存固定。这些选项由 <code>DataLoader</code> 的构造函数参数配置，其签名为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>,</span><br><span class="line">           batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>,</span><br><span class="line">           pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>,</span><br><span class="line">           worker_init_fn=<span class="literal">None</span>, *, prefetch_factor=<span class="number">2</span>,</span><br><span class="line">           persistent_workers=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>本文将详细介绍了这些选项的效果和用法。内容参考 Pytorch 官方文档：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#module-torch.utils.data">https://pytorch.org/docs/stable/data.html#module-torch.utils.data</a></p>
<span id="more"></span>

<h2 id="数据集类型"><a href="#数据集类型" class="headerlink" title="数据集类型"></a>数据集类型</h2><p><code>DataLoader</code> 构造函数最重要的参数是 dataset，它指示要从中加载数据的 “映射式数据集” 与 “可迭代式数据集”。</p>
<h3 id="映射式数据集"><a href="#映射式数据集" class="headerlink" title="映射式数据集"></a>映射式数据集</h3><p>映射式数据集是实现了 <code>__getitem__()</code> 和 <code>__len__()</code> 协议的数据集，它表示从（可能是非整数）索引&#x2F;键到数据样本的映射。</p>
<p>例如，当使用 <code>dataset[idx]</code> 访问此类数据集时，它可以从磁盘上的文件夹读取第 <code>idx</code> 个图像及其相应的标签文件。有关更多详细信息，请参阅 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset">Dataset</a>。</p>
<h3 id="可迭代式数据集"><a href="#可迭代式数据集" class="headerlink" title="可迭代式数据集"></a>可迭代式数据集</h3><p>可迭代式数据集是 <code>IterableDataset</code> 子类的实例，它实现了 <code>__iter__()</code> 协议，</p>
<p>例如，当调用 <code>iter(dataset)</code> 时，此类数据集可以返回从数据库、远程服务器读取的数据流，甚至是实时生成的日志。有关更多详细信息，请参阅 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset">IterableDataset</a>。</p>
<p>当使用多进程数据加载的 IterableDataset 时。在每个工作进程上复制相同的数据集对象，因此必须对副本进行不同的配置，以避免重复数据。请参阅 IterableDataset 文档了解如何实现这一点。</p>
<h2 id="数据加载顺序和-Sampler"><a href="#数据加载顺序和-Sampler" class="headerlink" title="数据加载顺序和 Sampler"></a>数据加载顺序和 Sampler</h2><p>对于 可迭代式数据集，数据加载顺序完全由用户定义的可迭代对象控制。</p>
<p>本节的其余部分涉及 映射式数据集 的情况。</p>
<p>基于shuffle参数，DataLoader会自动构建顺序或随机采样器。 另外，用户可以使用sampler参数指定一个自定义的Sampler对象，该对象每次都会生成下一个要获取的索引&#x2F;键。</p>
<p>一个自定义的Sampler，每次生成一个批次索引列表，可以作为batch_sampler参数传递。 也可以通过batch_size和drop_last参数启用自动批处理。 有关详细信息，请参阅下一节。</p>
<p>注意</p>
<p>sampler和batch_sampler都不兼容可迭代数据集，因为此类数据集没有键或索引的概念。</p>
<h2 id="加载批处理和非批处理数据"><a href="#加载批处理和非批处理数据" class="headerlink" title="加载批处理和非批处理数据"></a>加载批处理和非批处理数据</h2><p>DataLoader支持通过参数batch_size、drop_last、batch_sampler和collate_fn（具有默认函数）自动将获取的单个数据样本整理成批次。</p>
<h3 id="自动批处理（默认）"><a href="#自动批处理（默认）" class="headerlink" title="自动批处理（默认）"></a>自动批处理（默认）</h3><p>这是最常见的情况，对应于获取一个数据小批量并将其整理成批处理样本，即包含一个维度为批次维度的张量（通常是第一个）。</p>
<p>当batch_size（默认1）不为None时，数据加载器会生成批处理样本，而不是单个样本。 batch_size和drop_last参数用于指定数据加载器如何获取数据集键的批次。 对于映射式数据集，用户可以另外指定batch_sampler，它每次生成一个键列表。</p>
<p>注意</p>
<p>batch_size和drop_last参数本质上用于从sampler构造batch_sampler。 对于映射式数据集，sampler由用户提供或根据shuffle参数构建。 对于可迭代数据集，sampler是一个虚拟的无限采样器。 有关采样器的更多详细信息，请参阅此节。</p>
<p>注意</p>
<p>当使用多进程从可迭代数据集中获取数据时，drop_last参数会删除每个工作程序的数据集副本的最后一个非满批次。</p>
<p>使用采样器中的索引获取样本列表后，作为collate_fn参数传递的函数用于将样本列表整理成批次。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"><span class="keyword">for</span> indices <span class="keyword">in</span> batch_sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn([<span class="built_in">next</span>(dataset_iter) <span class="keyword">for</span> _ <span class="keyword">in</span> indices])</span><br></pre></td></tr></table></figure>

<p>可以使用自定义的collate_fn来自定义整理，例如，将顺序数据填充到批次的最大长度。 有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="禁用自动批处理"><a href="#禁用自动批处理" class="headerlink" title="禁用自动批处理"></a>禁用自动批处理</h3><p>在某些情况下，用户可能希望在数据集代码中手动处理批处理，或者只是加载单个样本。 例如，直接加载批处理数据可能更便宜（例如，从数据库中批量读取或读取连续的内存块），或者批次大小取决于数据，或者程序被设计为处理单个样本。 在这些情况下，最好不要使用自动批处理（其中collate_fn用于整理样本），而是让数据加载器直接返回dataset对象的每个成员。</p>
<p>当batch_size和batch_sampler都为None（batch_sampler的默认值为None）时，自动批处理将被禁用。 从dataset中获取的每个样本都会使用作为collate_fn参数传递的函数进行处理。</p>
<p><strong>禁用自动批处理时</strong>，默认的collate_fn只会将NumPy数组转换为PyTorch张量，其他一切保持不变。</p>
<p>在这种情况下，从映射式数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> sampler:</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(dataset[index])</span><br></pre></td></tr></table></figure>

<p>从可迭代数据集加载大致等同于</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> <span class="built_in">iter</span>(dataset):</span><br><span class="line">    <span class="keyword">yield</span> collate_fn(data)</span><br></pre></td></tr></table></figure>

<p>有关collate_fn的更多信息，请参阅此节。</p>
<h3 id="使用collate-fn"><a href="#使用collate-fn" class="headerlink" title="使用collate_fn"></a>使用collate_fn</h3><p>启用或禁用自动批处理时，collate_fn的使用略有不同。</p>
<p><strong>禁用自动批处理时</strong>，collate_fn会针对每个单独的数据样本进行调用，并从数据加载器迭代器中生成输出。 在这种情况下，默认的collate_fn只会将NumPy数组转换为PyTorch张量。</p>
<p><strong>启用自动批处理时</strong>，collate_fn会每次针对一个数据样本列表进行调用。 它应该将输入样本整理成一个批次，以便从数据加载器迭代器中生成。 本节的其余部分描述了默认collate_fn（default_collate()）的行为。</p>
<p>例如，如果每个数据样本包含一个 3 通道图像和一个整型类标签，即数据集的每个元素返回一个元组(image, class_index)，则默认的collate_fn会将此类元组列表整理成一个包含批处理图像张量和批处理类标签张量的单个元组。 特别是，默认的collate_fn具有以下属性</p>
<p>它始终将一个新的维度作为批处理维度前置。</p>
<p>它会自动将NumPy数组和Python数值转换为PyTorch张量。</p>
<p>它会保留数据结构，例如，如果每个样本都是一个字典，它会输出一个具有相同键集但批处理张量作为值的字典（如果值不能转换为张量，则为列表）。 list、tuple、namedtuple等也是如此。</p>
<p>用户可以使用自定义的collate_fn来实现自定义批处理，例如，沿除第一个维度以外的维度整理，填充不同长度的序列，或添加对自定义数据类型的支持。</p>
<p>如果您遇到DataLoader的输出具有与预期不同的维度或类型的情况，您可能需要检查您的collate_fn。</p>
<h2 id="单进程和多进程数据加载"><a href="#单进程和多进程数据加载" class="headerlink" title="单进程和多进程数据加载"></a>单进程和多进程数据加载</h2><p>DataLoader默认使用单进程数据加载。</p>
<p>在 Python 进程中，全局解释器锁 (GIL)阻止了跨线程真正地完全并行化 Python 代码。 为了避免数据加载阻塞计算代码，PyTorch 提供了一个简单的开关来执行多进程数据加载，只需将参数num_workers设置为正整数即可。</p>
<h3 id="单进程数据加载（默认）"><a href="#单进程数据加载（默认）" class="headerlink" title="单进程数据加载（默认）"></a>单进程数据加载（默认）</h3><p>在此模式下，数据获取在DataLoader初始化的同一个进程中完成。 因此，数据加载可能会阻塞计算。 但是，当用于在进程之间共享数据的资源（例如，共享内存、文件描述符）有限，或者当整个数据集很小且可以完全加载到内存中时，此模式可能更受欢迎。 此外，单进程加载通常显示更易读的错误跟踪，因此对调试很有用。</p>
<h3 id="多进程数据加载"><a href="#多进程数据加载" class="headerlink" title="多进程数据加载"></a>多进程数据加载</h3><p>将参数num_workers设置为正整数将打开使用指定数量的加载器工作程序进程的多进程数据加载。</p>
<p>警告</p>
<p>经过多次迭代后，加载器工作进程将消耗与父进程相同的 CPU 内存，用于父进程中所有从工作进程访问的 Python 对象。如果数据集包含大量数据（例如，您在数据集构建时加载了非常大的文件名列表）和&#x2F;或您使用了很多工作进程（总内存使用量为 number of workers * size of parent process），这可能会带来问题。最简单的解决方法是用非引用计数表示替换 Python 对象，例如 Pandas、Numpy 或 PyArrow 对象。查看 问题 #13246 了解更多关于为什么会出现这种情况以及如何解决这些问题的示例代码。</p>
<p>在此模式下，每次创建 DataLoader 的迭代器（例如，当您调用 enumerate(dataloader) 时），都会创建 num_workers 个工作进程。此时，dataset、collate_fn 和 worker_init_fn 会传递给每个工作进程，并在其中用于初始化和获取数据。这意味着数据集访问及其内部 IO、转换（包括 collate_fn）将在工作进程中运行。</p>
<p>torch.utils.data.get_worker_info() 在工作进程中返回各种有用的信息（包括工作进程 ID、数据集副本、初始种子等），并在主进程中返回 None。用户可以在数据集代码和&#x2F;或 worker_init_fn 中使用此函数来单独配置每个数据集副本，并确定代码是否在工作进程中运行。例如，这在对数据集进行分片时尤其有用。</p>
<p>对于映射式数据集，主进程使用 sampler 生成索引，并将其发送给工作进程。因此，任何洗牌随机化操作都在主进程中完成，该操作通过分配要加载的索引来指导加载。</p>
<p>对于可迭代式数据集，由于每个工作进程都获得了 dataset 对象的副本，因此简单的多进程加载通常会导致数据重复。使用 torch.utils.data.get_worker_info() 和&#x2F;或 worker_init_fn，用户可以独立地配置每个副本。（请参阅 IterableDataset 文档了解如何实现这一点。）出于类似原因，在多进程加载中，drop_last 参数将丢弃每个工作进程的可迭代式数据集副本的最后一个非完整批次。</p>
<p>当迭代结束时或当迭代器被垃圾回收时，工作进程将关闭。</p>
<p>警告</p>
<p>一般不建议在多进程加载中返回 CUDA 张量，因为在多进程中使用 CUDA 和共享 CUDA 张量时存在许多细微之处（请参阅 多进程中的 CUDA）。相反，我们建议使用 自动内存锁定（即，设置 pin_memory&#x3D;True），它可以实现快速将数据传输到支持 CUDA 的 GPU。</p>
<p>特定于平台的行为<br>由于工作进程依赖于 Python multiprocessing，因此工作进程启动行为在 Windows 上与 Unix 上不同。</p>
<p>在 Unix 上，fork() 是默认的 multiprocessing 启动方法。使用 fork()，子工作进程通常可以通过克隆的地址空间直接访问 dataset 和 Python 参数函数。</p>
<p>在 Windows 或 MacOS 上，spawn() 是默认的 multiprocessing 启动方法。使用 spawn()，会启动另一个解释器来运行您的主脚本，然后是接收 dataset、collate_fn 和其他参数的内部工作进程函数，这些参数通过 pickle 序列化。</p>
<p>这种单独的序列化意味着您应该采取两个步骤来确保在使用多进程数据加载时与 Windows 兼容。</p>
<p>将您的大部分主脚本代码包装在 if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘: 块中，以确保它在每个工作进程启动时不会再次运行（很可能生成错误）。您可以将您的数据集和 DataLoader 实例创建逻辑放在这里，因为它不需要在工作进程中重新执行。</p>
<p>确保任何自定义 collate_fn、worker_init_fn 或 dataset 代码都声明为顶层定义，位于 <strong>main</strong> 检查之外。这确保它们在工作进程中可用。（这是必要的，因为函数仅以引用形式被腌制，而不是 bytecode。）</p>
<p>多进程数据加载中的随机性<br>默认情况下，每个工作进程的 PyTorch 种子将设置为 base_seed + worker_id，其中 base_seed 是主进程使用其 RNG 生成的长整型数（因此，强制性地消耗 RNG 状态）或指定的 generator。但是，在初始化工作进程时，其他库的种子可能会重复，导致每个工作进程返回相同的随机数。（请参阅常见问题解答中的 此部分。）</p>
<p>在 worker_init_fn 中，您可以使用 torch.utils.data.get_worker_info().seed 或 torch.initial_seed() 访问为每个工作进程设置的 PyTorch 种子，并在数据加载之前使用它来设置其他库的种子。</p>
<h2 id="内存锁定"><a href="#内存锁定" class="headerlink" title="内存锁定"></a>内存锁定</h2><p>当主机到 GPU 的复制来自锁定页面（页面锁定）内存时，速度会快得多。请参阅 使用锁定页面内存缓冲区，了解何时以及如何一般性地使用锁定页面内存。</p>
<p>对于数据加载，将 pin_memory&#x3D;True 传递给 DataLoader 将自动将获取的数据张量放入锁定页面内存中，从而可以更快地将数据传输到支持 CUDA 的 GPU。</p>
<p>默认内存锁定逻辑仅识别张量以及包含张量的映射和可迭代对象。默认情况下，如果锁定页面逻辑看到一个自定义类型（如果您的 collate_fn 返回自定义批次类型，就会发生这种情况），或者如果批次的每个元素都是自定义类型，则锁定页面逻辑将无法识别它们，并且它将返回该批次（或这些元素）而不锁定页面内存。要为自定义批次或数据类型启用内存锁定，请在自定义类型上定义 pin_memory() 方法。</p>
<p>请参阅下面的示例。</p>
<p>示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class SimpleCustomBatch:</span><br><span class="line">    def __init__(self, data):</span><br><span class="line">        transposed_data = list(zip(*data))</span><br><span class="line">        self.inp = torch.stack(transposed_data[0], 0)</span><br><span class="line">        self.tgt = torch.stack(transposed_data[1], 0)</span><br><span class="line"></span><br><span class="line">    # custom memory pinning method on custom type</span><br><span class="line">    def pin_memory(self):</span><br><span class="line">        self.inp = self.inp.pin_memory()</span><br><span class="line">        self.tgt = self.tgt.pin_memory()</span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">def collate_wrapper(batch):</span><br><span class="line">    return SimpleCustomBatch(batch)</span><br><span class="line"></span><br><span class="line">inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)</span><br><span class="line">dataset = TensorDataset(inps, tgts)</span><br><span class="line"></span><br><span class="line">loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,</span><br><span class="line">                    pin_memory=True)</span><br><span class="line"></span><br><span class="line">for batch_ndx, sample in enumerate(loader):</span><br><span class="line">    print(sample.inp.is_pinned())</span><br><span class="line">    print(sample.tgt.is_pinned())</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Class torch.utils.data.DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">None</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span>, multiprocessing_context=<span class="literal">None</span>, generator=<span class="literal">None</span>, *, prefetch_factor=<span class="literal">None</span>, persistent_workers=<span class="literal">False</span>, pin_memory_device=<span class="string">&#x27;&#x27;</span>)[source]</span><br></pre></td></tr></table></figure>

<p>数据加载器将数据集和采样器组合在一起，并提供一个遍历给定数据集的可迭代对象。</p>
<p>DataLoader 支持映射风格和可迭代风格的数据集，包含单进程或多进程加载、自定义加载顺序以及可选的自动批处理（整理）和内存固定。</p>
<p>更多细节请参见 torch.utils.data 文档页面。</p>
<p>参数<br>** dataset (Dataset) – 要加载数据的 dataset。<br>** batch_size (int, optional) – 每次加载多少个样本（默认：1）。<br>** shuffle (bool, optional) – 设置为 True 则在每个 epoch 时重新洗牌数据（默认：False）。<br>** sampler (Sampler or Iterable, optional) – 定义从 dataset 中抽取样本的策略。可以是任何实现了 <strong>len</strong> 的 Iterable。如果指定，则不能指定 shuffle。<br>** batch_sampler (Sampler or Iterable, optional) – 与 sampler 相似，但一次返回一批索引。与 batch_size、shuffle、sampler 和 drop_last 互斥。<br>** num_workers (int, optional) – 用于数据加载的子进程数量。0 表示数据将在主进程中加载。（默认：0）<br>** collate_fn (Callable, optional) – 将样本列表合并成一个包含张量（Tensor）的小批量。在使用映射风格数据集的批量加载时使用。<br>** pin_memory (bool, optional) – 如果为 True，数据加载器将在返回之前将张量复制到设备&#x2F;CUDA 固定内存中。如果你的数据元素是自定义类型，或者你的 collate_fn 返回一个自定义类型的批次，请参阅下面的示例。<br>** drop_last (bool, optional) – 设置为 True 以丢弃最后一个不完整的批次，如果数据集的大小不能被批次大小整除。如果为 False 且数据集大小不能被批次大小整除，则最后一个批次将更小。（默认：False）<br>** timeout (numeric, optional) – 如果为正数，则为从工作进程收集批次的超时值。应该始终为非负数。（默认：0）<br>** worker_init_fn (Callable, optional) – 如果不为 None，这将在每个工作进程子进程上调用，并将工作进程 ID（[0, num_workers - 1] 中的整数）作为输入，在播种和数据加载之前。（默认：None）<br>** multiprocessing_context (str or multiprocessing.context.BaseContext, optional) – 如果为 None，将使用操作系统的默认 多进程上下文。（默认：None）<br>** generator (torch.Generator, optional) – 如果不为 None，则随机采样器将使用此 RNG 生成随机索引，多进程将使用此 RNG 为工作进程生成 base_seed。（默认：None）<br>** prefetch_factor (int, optional, keyword-only arg) – 每个工作进程预先加载的批次数量。2 表示所有工作进程总共预取 2 * num_workers 个批次。（默认值取决于 num_workers 的设置值。如果 num_workers &#x3D; 0，则默认值为 ** None。否则，如果 num_workers &gt; 0，则默认值为 2）。<br>** persistent_workers (bool, optional) – 如果为 True，数据加载器在数据集被消费一次后不会关闭工作进程。这允许将工作进程的 Dataset 实例保持活动。（默认：False）<br>** pin_memory_device (str, optional) – 如果 pin_memory 为 True，则为要 pin_memory 的设备。</p>
<p>警告</p>
<p>如果使用 spawn 启动方法，则 worker_init_fn 不能是不可腌制的对象，例如 lambda 函数。有关 PyTorch 中多进程的更多详细信息，请参阅 多进程最佳实践。</p>
<p>警告</p>
<p>len(dataloader) 启发式基于所用采样器的长度。当 dataset 是一个 IterableDataset 时，它将返回一个基于 len(dataset) &#x2F; batch_size 的估计值，并根据 drop_last 进行适当的舍入，而与多进程加载配置无关。这代表了 PyTorch 可以做出的最佳猜测，因为 PyTorch 相信用户 dataset 代码在正确处理多进程加载以避免重复数据方面。</p>
<p>但是，如果分片导致多个工作进程具有不完整的最后一个批次，则此估计仍然可能不准确，因为 (1) 一个原本完整的批次可以被分成多个批次，(2) 当设置了 drop_last 时，可以丢弃多个批次。不幸的是，PyTorch 通常无法检测到此类情况。</p>
<p>有关这两种类型的数据集以及 IterableDataset 如何与 多进程数据加载 相互作用的更多详细信息，请参阅 数据集类型。</p>
<p>警告</p>
<p>有关随机种子相关问题的更多信息，请参阅 可重复性，以及 我的数据加载器工作进程返回相同的随机数 和 多进程数据加载中的随机性 说明。</p>
<p>classtorch.utils.data.Dataset(*args, **kwds)[source]<br>一个表示 Dataset 的抽象类。</p>
<p>所有表示从键到数据样本的映射的数据集都应该继承它。所有子类都应该覆盖 <strong>getitem</strong>()，支持获取给定键的数据样本。子类还可以选择覆盖 <strong>len</strong>()，这将返回许多 Sampler 实现和 DataLoader 的默认选项的数据集大小。子类还可以选择实现 <strong>getitems</strong>()，以加快批处理样本加载速度。此方法接受批次样本索引列表并返回样本列表。</p>
<p>注意</p>
<p>DataLoader 默认情况下会构造一个生成整数索引的索引采样器。要使其与具有非整数索引&#x2F;键的映射式数据集一起使用，必须提供自定义采样器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.IterableDataset(*args, **kwds)[source]</span><br></pre></td></tr></table></figure>

<p>一个可迭代的 Dataset。</p>
<p>所有表示数据样本可迭代的数据集都应该继承它。这种形式的数据集在数据来自流时特别有用。</p>
<p>所有子类都应该覆盖 <strong>iter</strong>()，它将返回此数据集中样本的迭代器。</p>
<p>当子类与 DataLoader 一起使用时，数据集中的每个项目都将从 DataLoader 迭代器中生成。当 num_workers &gt; 0 时，每个工作进程将拥有数据集对象的副本，因此通常需要独立配置每个副本，以避免工作进程返回重复数据。 get_worker_info()，在工作进程中调用时，返回有关工作进程的信息。它可以在数据集的 <strong>iter</strong>() 方法或 DataLoader 的 worker_init_fn 选项中使用，以修改每个副本的行为。</p>
<p>示例 1：在 <strong>iter</strong>() 中将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">if</span> worker_info <span class="keyword">is</span> <span class="literal">None</span>:  <span class="comment"># single-process data loading, return the full iterator</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="variable language_">self</span>.end</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">else</span>:  <span class="comment"># in a worker process</span></span><br><span class="line"><span class="meta">... </span>            <span class="comment"># split workload</span></span><br><span class="line"><span class="meta">... </span>            per_worker = <span class="built_in">int</span>(math.ceil((<span class="variable language_">self</span>.end - <span class="variable language_">self</span>.start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>            worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>            iter_start = <span class="variable language_">self</span>.start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>            iter_end = <span class="built_in">min</span>(iter_start + per_worker, <span class="variable language_">self</span>.end)</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(iter_start, iter_end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with two worker processes</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>)))</span><br><span class="line">[tensor([<span class="number">3</span>]), tensor([<span class="number">5</span>]), tensor([<span class="number">4</span>]), tensor([<span class="number">6</span>])]</span><br></pre></td></tr></table></figure>

<p>示例 2：使用 worker_init_fn 将工作负载分配到所有工作进程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">MyIterableDataset</span>(torch.utils.data.IterableDataset):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, start, end</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">super</span>(MyIterableDataset).__init__()</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">assert</span> end &gt; start, <span class="string">&quot;this example code only works with end &gt;= start&quot;</span></span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.start = start</span><br><span class="line"><span class="meta">... </span>        <span class="variable language_">self</span>.end = end</span><br><span class="line">...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(<span class="variable language_">self</span>.start, <span class="variable language_">self</span>.end))</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ds = MyIterableDataset(start=<span class="number">3</span>, end=<span class="number">7</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Single-process loading</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">0</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Directly doing multi-process loading yields duplicate data</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Define a `worker_init_fn` that configures each dataset copy differently</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">worker_init_fn</span>(<span class="params">worker_id</span>):</span><br><span class="line"><span class="meta">... </span>    worker_info = torch.utils.data.get_worker_info()</span><br><span class="line"><span class="meta">... </span>    dataset = worker_info.dataset  <span class="comment"># the dataset copy in this worker process</span></span><br><span class="line"><span class="meta">... </span>    overall_start = dataset.start</span><br><span class="line"><span class="meta">... </span>    overall_end = dataset.end</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># configure the dataset to only process the split workload</span></span><br><span class="line"><span class="meta">... </span>    per_worker = <span class="built_in">int</span>(math.ceil((overall_end - overall_start) / <span class="built_in">float</span>(worker_info.num_workers)))</span><br><span class="line"><span class="meta">... </span>    worker_id = worker_info.<span class="built_in">id</span></span><br><span class="line"><span class="meta">... </span>    dataset.start = overall_start + worker_id * per_worker</span><br><span class="line"><span class="meta">... </span>    dataset.end = <span class="built_in">min</span>(dataset.start + per_worker, overall_end)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Mult-process loading with the custom `worker_init_fn`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">2</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># With even more workers</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">list</span>(torch.utils.data.DataLoader(ds, num_workers=<span class="number">12</span>, worker_init_fn=worker_init_fn)))</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.TensorDataset(*tensors)[source]</span><br></pre></td></tr></table></figure>

<p>包装张量的 Dataset。</p>
<p>每个样本将通过沿第一维索引张量来检索。</p>
<p>参数<br>** tensors (Tensor) – 具有相同第一维大小的张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classtorch.utils.data.StackDataset(*args, **kwargs)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集堆叠在一起的 Dataset。</p>
<p>此类对于将作为数据集给出的复杂输入数据的不同部分组合在一起非常有用。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>images = ImageDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>texts = TextDataset()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack = StackDataset(images, texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple_stack[<span class="number">0</span>] == (images[<span class="number">0</span>], texts[<span class="number">0</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack = StackDataset(image=images, text=texts)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict_stack[<span class="number">0</span>] == &#123;<span class="string">&#x27;image&#x27;</span>: images[<span class="number">0</span>], <span class="string">&#x27;text&#x27;</span>: texts[<span class="number">0</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>参数<br>** args (Dataset) – 堆叠的数据集，作为元组返回。<br>** kwargs (Dataset) – 堆叠的数据集，作为字典返回。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ConcatDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>将多个数据集连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集组合在一起非常有用。</p>
<p>参数<br>** datasets (sequence) – 要连接的数据集列表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.ChainDataset(datasets)[source]</span><br></pre></td></tr></table></figure>

<p>用于将多个 IterableDataset 连接在一起的 Dataset。</p>
<p>此类对于将不同的现有数据集流组合在一起非常有用。连接操作是在运行时完成的，因此使用此类连接大型数据集将非常高效。</p>
<p>参数<br>** datasets (iterable of IterableDataset) – 要连接在一起的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">torch</span>.utils.data.Subset(dataset, indices)[source]</span><br></pre></td></tr></table></figure>

<p>在指定索引处的数据集的子集。</p>
<p>参数<br>** dataset (Dataset) – 整个 Dataset<br>** indices (sequence) – 为子集选择的整个集合中的索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data._utils.collate.collate(batch, *, collate_fn_map=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>处理每个批次中元素的集合类型的通用整理函数。</p>
<p>该函数还打开函数注册表以处理特定的元素类型。 default_collate_fn_map 为张量、NumPy 数组、数字和字符串提供默认的整理函数。</p>
<p>参数<br>** batch – 要整理的单个批次</p>
<p>collate_fn_map (Optional[Dict[Union[Type, Tuple[Type, …]], Callable]]) – 可选字典，将元素类型映射到相应的整理函数。如果元素类型不在此字典中，则此函数将按插入顺序遍历字典中的每个键，如果元素类型是键的子类，则调用相应的整理函数。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_tensor_fn</span>(<span class="params">batch, *, collate_fn_map</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="comment"># Extend this function to handle batch of tensors</span></span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> torch.stack(batch, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    collate_map = &#123;torch.Tensor: collate_tensor_fn&#125;</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> collate(batch, collate_fn_map=collate_map)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Extend `default_collate` by in-place modifying `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(&#123;torch.Tensor: collate_tensor_fn&#125;)</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p>每个整理函数都需要一个批次的定位参数和一个整理函数字典的关键字参数，作为 collate_fn_map。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.default_collate(batch)[source]</span><br></pre></td></tr></table></figure>
<p>接收一批数据，并将批次中的元素放入一个具有额外的外部维度（批次大小）的张量中。</p>
<p>确切的输出类型可以是 torch.Tensor、Sequence 的 torch.Tensor、torch.Tensor 的集合，或者保持不变，具体取决于输入类型。 当在 DataLoader 中定义了 batch_size 或 batch_sampler 时，这将用作合并的默认函数。</p>
<p>以下是通用输入类型（基于批次内元素的类型）到输出类型映射</p>
<p>torch.Tensor -&gt; torch.Tensor（添加了外部维度批次大小）</p>
<p>NumPy 数组 -&gt; torch.Tensor</p>
<p>float -&gt; torch.Tensor</p>
<p>int -&gt; torch.Tensor</p>
<p>str -&gt; str（保持不变）</p>
<p>bytes -&gt; bytes（保持不变）</p>
<p>Mapping[K, V_i] -&gt; Mapping[K, default_collate([V_1, V_2, …])]</p>
<p>NamedTuple[V1_i, V2_i, …] -&gt; NamedTuple[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>Sequence[V1_i, V2_i, …] -&gt; Sequence[default_collate([V1_1, V1_2, …]), default_collate([V2_1, V2_2, …]), …]</p>
<p>参数<br>batch – 要整理的单个批次</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `int`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with a batch of `str`s:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Map` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([&#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">1</span>&#125;, &#123;<span class="string">&#x27;A&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;B&#x27;</span>: <span class="number">100</span>&#125;])</span><br><span class="line">&#123;<span class="string">&#x27;A&#x27;</span>: tensor([  <span class="number">0</span>, <span class="number">100</span>]), <span class="string">&#x27;B&#x27;</span>: tensor([  <span class="number">1</span>, <span class="number">100</span>])&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `NamedTuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([Point(<span class="number">0</span>, <span class="number">0</span>), Point(<span class="number">1</span>, <span class="number">1</span>)])</span><br><span class="line">Point(x=tensor([<span class="number">0</span>, <span class="number">1</span>]), y=tensor([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `Tuple` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([(<span class="number">0</span>, <span class="number">1</span>), (<span class="number">2</span>, <span class="number">3</span>)])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `List` inside the batch:</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">2</span>]), tensor([<span class="number">1</span>, <span class="number">3</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Two options to extend `default_collate` to handle specific type</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 1: Write custom collate function and invoke `default_collate`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">custom_collate</span>(<span class="params">batch</span>):</span><br><span class="line"><span class="meta">... </span>    elem = batch[<span class="number">0</span>]</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> <span class="built_in">isinstance</span>(elem, CustomType):  <span class="comment"># Some custom condition</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">else</span>:  <span class="comment"># Fall back to `default_collate`</span></span><br><span class="line"><span class="meta">... </span>        <span class="keyword">return</span> default_collate(batch)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Option 2: In-place modify `default_collate_fn_map`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">def</span> <span class="title function_">collate_customtype_fn</span>(<span class="params">batch, *, collate_fn_map=<span class="literal">None</span></span>):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">return</span> ...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate_fn_map.update(CustomType, collate_customtype_fn)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_collate(batch)  <span class="comment"># Handle `CustomType` automatically</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.default_convert(data)[source]</span><br></pre></td></tr></table></figure>
<p>将每个 NumPy 数组元素转换为 torch.Tensor。</p>
<p>如果输入是 Sequence、Collection 或 Mapping，它会尝试将内部的每个元素转换为 torch.Tensor。 如果输入不是 NumPy 数组，则保持不变。 当在 DataLoader 中未定义 batch_sampler 和 batch_size 时，这将用作合并的默认函数。</p>
<p>通用输入类型到输出类型映射类似于 default_collate()。 有关更多详细信息，请参阅那里的描述。</p>
<p>参数<br>data – 要转换的单个数据点</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with `int`</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(<span class="number">0</span>)</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NumPy array</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(np.array([<span class="number">0</span>, <span class="number">1</span>]))</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with NamedTuple</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Point = namedtuple(<span class="string">&#x27;Point&#x27;</span>, [<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">Point(x=<span class="number">0</span>, y=<span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert(Point(np.array(<span class="number">0</span>), np.array(<span class="number">0</span>)))</span><br><span class="line">Point(x=tensor(<span class="number">0</span>), y=tensor(<span class="number">0</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="comment"># Example with List</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>default_convert([np.array([<span class="number">0</span>, <span class="number">1</span>]), np.array([<span class="number">2</span>, <span class="number">3</span>])])</span><br><span class="line">[tensor([<span class="number">0</span>, <span class="number">1</span>]), tensor([<span class="number">2</span>, <span class="number">3</span>])]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.get_worker_info()[source]</span><br></pre></td></tr></table></figure>

<p>返回有关当前 DataLoader 迭代器工作进程的信息。</p>
<p>在工作进程中调用时，这将返回一个保证具有以下属性的对象</p>
<p>id：当前工作进程 ID。</p>
<p>num_workers：工作进程的总数。</p>
<p>seed：为当前工作进程设置的随机种子。 此值由主进程 RNG 和工作进程 ID 确定。 有关更多详细信息，请参阅 DataLoader 的文档。</p>
<p>dataset：此进程中数据集对象的副本。 请注意，这将在与主进程不同的进程中成为不同的对象。</p>
<p>在主进程中调用时，这将返回 None。</p>
<p>注意</p>
<p>当在传递给 DataLoader 的 worker_init_fn 中使用时，此方法可用于以不同的方式设置每个工作进程，例如，使用 worker_id 配置 dataset 对象以仅读取分片数据集的特定部分，或使用 seed 为数据集代码中使用的其他库设置种子。</p>
<p>返回类型<br>Optional[WorkerInfo]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.random_split(dataset, lengths, generator=&lt;torch._C.Generator <span class="built_in">object</span>&gt;)[source]</span><br></pre></td></tr></table></figure>
<p>将数据集随机拆分为给定长度的非重叠新数据集。</p>
<p>如果给定一个加起来为 1 的分数列表，则长度将自动计算为每个提供的分数的 floor(frac * len(dataset))。</p>
<p>计算长度后，如果存在任何余数，将以循环方式将 1 个计数分配给长度，直到没有余数为止。</p>
<p>可以选择固定生成器以获得可重复的结果，例如：</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator1 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>generator2 = torch.Generator().manual_seed(<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">10</span>), [<span class="number">3</span>, <span class="number">7</span>], generator=generator1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>random_split(<span class="built_in">range</span>(<span class="number">30</span>), [<span class="number">0.3</span>, <span class="number">0.3</span>, <span class="number">0.4</span>], generator=generator2)</span><br></pre></td></tr></table></figure>

<p>参数<br>dataset (Dataset) – 要拆分的Dataset</p>
<p>lengths (sequence) – 要生成的拆分的长度或分数</p>
<p>generator (Generator) – 用于随机排列的生成器。</p>
<p>返回类型<br>List[Subset[T]]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classtorch.utils.data.Sampler(data_source=<span class="literal">None</span>)[source]</span><br></pre></td></tr></table></figure>

<p>所有 Sampler 的基类。</p>
<p>每个 Sampler 子类都必须提供一个 <strong>iter</strong>() 方法，提供一种方法来迭代数据集元素的索引或索引列表（批次），并且可以提供一个 <strong>len</strong>() 方法，该方法返回返回的迭代器的长度。</p>
<p>参数<br>data_source (Dataset) – 此参数未使用，将在 2.2.0 中删除。 您可能仍然拥有利用它的自定义实现。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthSampler</span>(Sampler[<span class="built_in">int</span>]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="built_in">int</span>]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">yield</span> <span class="keyword">from</span> torch.argsort(sizes).tolist()</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">class</span> <span class="title class_">AccedingSequenceLengthBatchSampler</span>(Sampler[<span class="type">List</span>[<span class="built_in">int</span>]]):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data: <span class="type">List</span>[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.data = data</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="variable language_">self</span>.batch_size = batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">return</span> (<span class="built_in">len</span>(<span class="variable language_">self</span>.data) + <span class="variable language_">self</span>.batch_size - <span class="number">1</span>) // <span class="variable language_">self</span>.batch_size</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>) -&gt; Iterator[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        sizes = torch.tensor([<span class="built_in">len</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="variable language_">self</span>.data])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>        <span class="keyword">for</span> batch <span class="keyword">in</span> torch.chunk(torch.argsort(sizes), <span class="built_in">len</span>(<span class="variable language_">self</span>)):</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>            <span class="keyword">yield</span> batch.tolist()</span><br></pre></td></tr></table></figure>

<p>注意</p>
<p><strong>len</strong>() 方法不是 DataLoader 严格要求的，但预期在涉及 DataLoader 长度的任何计算中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classtorch.utils.data.SequentialSampler(data_source)[source]</span><br></pre></td></tr></table></figure>

<p>按顺序采样元素，始终以相同的顺序。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>classtorch.utils.data.RandomSampler(data_source, replacement&#x3D;False, num_samples&#x3D;None, generator&#x3D;None)[source]<br>随机采样元素。 如果没有替换，则从洗牌后的数据集采样。</p>
<p>如果替换，则用户可以指定 num_samples 以进行抽取。</p>
<p>参数<br>data_source (Dataset) – 要从中采样的数据集</p>
<p>replacement (bool) – 如果 True，则按需从替换中抽取样本，默认值为 <code>False</code></p>
<p>num_samples (int) – 要抽取的样本数量，默认值为 <code>len(dataset)</code>。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.SubsetRandomSampler(indices, generator&#x3D;None)[source]<br>从给定的索引列表中随机采样元素，不进行替换。</p>
<p>参数<br>indices (sequence) – 索引序列</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>classtorch.utils.data.WeightedRandomSampler(weights, num_samples, replacement&#x3D;True, generator&#x3D;None)[source]<br>从 [0,..,len(weights)-1] 中根据给定的概率（权重）采样元素。</p>
<p>参数<br>weights (sequence) – 权重序列，不必加起来为1</p>
<p>num_samples (int) – 要抽取的样本数</p>
<p>replacement (bool) – 如果为 True，则有放回地抽取样本。否则，则无放回地抽取样本，这意味着当为一行抽取一个样本索引时，就不能再为该行抽取该索引。</p>
<p>generator (Generator) – 采样中使用的生成器。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.1</span>, <span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.7</span>, <span class="number">3.0</span>, <span class="number">0.6</span>], <span class="number">5</span>, replacement=<span class="literal">True</span>))</span><br><span class="line">[<span class="number">4</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(WeightedRandomSampler([<span class="number">0.9</span>, <span class="number">0.4</span>, <span class="number">0.05</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.1</span>], <span class="number">5</span>, replacement=<span class="literal">False</span>))</span><br><span class="line">[<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classtorch.utils.data.BatchSampler(sampler, batch_size, drop_last)[source]</span><br></pre></td></tr></table></figure>
<p>封装另一个采样器以生成一个索引小批量。</p>
<p>参数<br>sampler (Sampler or Iterable) – 基本采样器。可以是任何可迭代对象</p>
<p>batch_size (int) – 小批量的尺寸。</p>
<p>drop_last (bool) – 如果为 True，则采样器将丢弃最后一个小批量，如果其尺寸小于 batch_size</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(SequentialSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">True</span>))</span><br><span class="line">[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">classtorch.utils.data.distributed.DistributedSampler(dataset, num_replicas=<span class="literal">None</span>, rank=<span class="literal">None</span>, shuffle=<span class="literal">True</span>, seed=<span class="number">0</span>, drop_last=<span class="literal">False</span>)[source]</span><br></pre></td></tr></table></figure>
<p>限制数据加载到数据集子集的采样器。</p>
<p>它在与 torch.nn.parallel.DistributedDataParallel 结合使用时特别有用。在这种情况下，每个进程都可以将 DistributedSampler 实例作为 DataLoader 采样器传递，并加载一个独属于它的原始数据集的子集。</p>
<p>注意</p>
<p>假设数据集大小恒定，并且任何实例都始终以相同的顺序返回相同的元素。</p>
<p>参数<br>dataset – 用于采样的数据集。</p>
<p>num_replicas (int, optional) – 参与分布式训练的进程数。默认情况下，world_size 从当前分布式组中获取。</p>
<p>rank (int, optional) – 当前进程在 num_replicas 中的排名。默认情况下，rank 从当前分布式组中获取。</p>
<p>shuffle (bool, optional) – 如果为 True（默认），则采样器将随机打乱索引。</p>
<p>seed (int, optional) – 如果 shuffle&#x3D;True，则用于随机打乱采样器的随机种子。此数字在分布式组中的所有进程中应该相同。默认值：0。</p>
<p>drop_last (bool, optional) – 如果为 True，则采样器将丢弃数据的尾部，使其在副本数上均匀可分。如果为 False，则采样器将添加额外的索引以使数据在副本上均匀可分。默认值：False。</p>
<p>警告</p>
<p>在分布式模式下，在每个纪元开始时调用 set_epoch() 方法，在创建 DataLoader 迭代器之前，对于在多个纪元中使随机打乱正常工作是必要的。否则，将始终使用相同的排序。</p>
<p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>sampler = DistributedSampler(dataset) <span class="keyword">if</span> is_distributed <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loader = DataLoader(dataset, shuffle=(sampler <span class="keyword">is</span> <span class="literal">None</span>),</span><br><span class="line"><span class="meta">... </span>                    sampler=sampler)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, n_epochs):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">if</span> is_distributed:</span><br><span class="line"><span class="meta">... </span>        sampler.set_epoch(epoch)</span><br><span class="line"><span class="meta">... </span>    train(loader)</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Hai-Wei Chai (柴海伟)
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://hwchai.com/AI-DataLoader/" title="人工智能：Pytorch DataLoader">https://hwchai.com/AI-DataLoader/</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
              <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
              <a href="/tags/DataLoader/" rel="tag"># DataLoader</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/AI-Repeatability/" rel="prev" title="人工智能：Pytorch训练可重复性（Reproducibility）">
                  <i class="fa fa-angle-left"></i> 人工智能：Pytorch训练可重复性（Reproducibility）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/AI-STFT/" rel="next" title="数据科学：短时傅里叶变换（Short-Time Fourier Transform，STFT）">
                  数据科学：短时傅里叶变换（Short-Time Fourier Transform，STFT） <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2019 – 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-user"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Hai-Wei Chai (柴海伟)</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"https://vercel.hwchai.com/","cssUrl":"https://hwchai.com/download/Waline.css","commentCount":true,"pageview":false,"locale":{"placeholder":"请留下邮箱，若有回复您将收到提醒。QQ邮箱可以自动识别头像喔~"},"pageSize":10,"visitor":false,"comment_count":true,"meta":["nick","mail","link"],"requiredMeta":["nick"],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","emoji":["https://unpkg.com/@waline/emojis@1.0.1/bilibili"],"login":"disable","el":"#waline","comment":true,"path":"/AI-DataLoader/"}</script>
<link rel="stylesheet" href="https://hwchai.com/download/Waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
